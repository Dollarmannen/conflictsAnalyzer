=========================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1cc0e_d90c6/rev_1cc0e-d90c6.revisions
Conflict type: ModifierList
Conflict body: 
~~FSTMerge~~ public static final ##FSTMerge## ##FSTMerge## public static
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1cc0e_d90c6/rev_1cc0e-d90c6/lucene/src/java/org/apache/lucene/util/ByteBlockPool.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d2d9_7a124/rev_4d2d9-7a124.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4dfe8_17d38/rev_4dfe8-17d38.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_8476d_7702d/rev_8476d-7702d.revisions
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public DocumentsWriter.DocWriter processDocument() throws IOException {

    consumer.startDocument();
    fieldsWriter.startDocument();

    final Document doc = docState.doc;

    assert docFieldProcessor.docWriter.writer.testPoint("DocumentsWriter.ThreadState.init start");

    fieldCount = 0;
    
    final int thisFieldGen = fieldGen++;

    final List<Fieldable> docFields = doc.getFields();
    final int numDocFields = docFields.size();

    // Absorb any new fields first seen in this document.
    // Also absorb any changes to fields we had already
    // seen before (eg suddenly turning on norms or
    // vectors, etc.):

    for(int i=0;i<numDocFields;i++) {
      Fieldable field = docFields.get(i);
      final String fieldName = field.name();

      // Make sure we have a PerField allocated
      final int hashPos = fieldName.hashCode() & hashMask;
      DocFieldProcessorPerField fp = fieldHash[hashPos];
      while(fp != null && !fp.fieldInfo.name.equals(fieldName))
        fp = fp.next;

      if (fp == null) {

        // TODO FI: we need to genericize the "flags" that a
        // field holds, and, how these flags are merged; it
        // needs to be more "pluggable" such that if I want
        // to have a new "thing" my Fields can do, I can
        // easily add it
        FieldInfo fi = fieldInfos.add(fieldName, field.isIndexed(), field.isTermVectorStored(),
                                      field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                                      field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());

        fp = new DocFieldProcessorPerField(this, fi);
        fp.next = fieldHash[hashPos];
        fieldHash[hashPos] = fp;
        totalFieldCount++;

        if (totalFieldCount >= fieldHash.length/2)
          rehash();
      } else
        fp.fieldInfo.update(field.isIndexed(), field.isTermVectorStored(),
                            field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                            field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());

      if (thisFieldGen != fp.lastGen) {

        // First time we're seeing this field for this doc
        fp.fieldCount = 0;

        if (fieldCount == fields.length) {
          final int newSize = fields.length*2;
          DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];
          System.arraycopy(fields, 0, newArray, 0, fieldCount);
          fields = newArray;
        }

        fields[fieldCount++] = fp;
        fp.lastGen = thisFieldGen;
      }

      if (fp.fieldCount == fp.fields.length) {
        Fieldable[] newArray = new Fieldable[fp.fields.length*2];
        System.arraycopy(fp.fields, 0, newArray, 0, fp.fieldCount);
        fp.fields = newArray;
      }

      fp.fields[fp.fieldCount++] = field;
      if (field.isStored()) {
        fieldsWriter.addField(field, fp.fieldInfo);
      }
    }

    // If we are writing vectors then we must visit
    // fields in sorted order so they are written in
    // sorted order.  TODO: we actually only need to
    // sort the subset of fields that have vectors
    // enabled; we could save [small amount of] CPU
    // here.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419621836640/fstmerge_var1_7615906195788071662
    ArrayUtil.quickSort(fields, 0, fieldCount, fieldsComp);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419621836640/fstmerge_base_9123133307858989549
    quickSort(fields, 0, fieldCount-1);
=======
    quickSort(fields, 0, fieldCount-1);
   
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419621836640/fstmerge_var2_8434693287020567827

    for(int i=0;i<fieldCount;i++) {
      final DocFieldProcessorPerField perField = fields[i];
      final Fieldable fieldable = perField.fields[0];
      perField.consumer.processFields(perField.fields, perField.fieldCount);
     
      if(!fieldable.hasFieldAttribute())
        continue;
      final AttributeSource attrSource = fieldable.getFieldAttributes();
      if(!attrSource.hasAttribute(ValuesAttribute.class))
        continue;
      final ValuesAttribute attribute = attrSource.getAttribute(ValuesAttribute.class);
      final DocValuesConsumer consumer = docFieldProcessor.docValuesConsumer(docState.docWriter.directory,
              docState.docWriter.segment, fieldable.name(), attribute, perField.fieldInfo);
      consumer.add(docState.docID, attribute);
    }
    if (docState.maxTermPrefix != null && docState.infoStream != null) {
      docState.infoStream.println("WARNING: document contains at least one immense term (whose UTF8 encoding is longer than the max length " + DocumentsWriter.MAX_TERM_LENGTH_UTF8 + "), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '" + docState.maxTermPrefix + "...'"); 
      docState.maxTermPrefix = null;
    }

    final DocumentsWriter.DocWriter one = fieldsWriter.finishDocument();
    final DocumentsWriter.DocWriter two = consumer.finishDocument();
    if (one == null) {
      return two;
    } else if (two == null) {
      return one;
    } else {
      PerDoc both = getPerDoc();
      both.docID = docState.docID;
      assert one.docID == docState.docID;
      assert two.docID == docState.docID;
      both.one = one;
      both.two = two;
      return both;
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_8476d_7702d/rev_8476d-7702d/lucene/src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_78f3a_6c79a/rev_78f3a-6c79a.revisions
Conflict type: LineBasedMCFd
Conflict body: 
synchronized private void initFlushState(boolean onlyDocStore) {
    initSegmentName(onlyDocStore);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622723604/fstmerge_var1_6516332792258961747
    final SegmentCodecs info = SegmentCodecs.build(docFieldProcessor.fieldInfos, writer.codecs);
    flushState = new SegmentWriteState(infoStream, directory, segment, docFieldProcessor.fieldInfos,
                                       docStoreSegment, numDocsInRAM, numDocsInStore, writer.getConfig().getTermIndexInterval(), info);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622723604/fstmerge_base_3788178265835953854
    flushState = new SegmentWriteState(infoStream, directory, segment, docFieldProcessor.fieldInfos,
                                       docStoreSegment, numDocsInRAM, numDocsInStore, writer.getConfig().getTermIndexInterval(),
                                       writer.codecs);
=======
    flushState = segWriteState();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622723604/fstmerge_var2_3530566646476398758
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_78f3a_6c79a/rev_78f3a-6c79a/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
final List<String> createCompoundFile(String fileName, final SegmentInfo info)
          throws IOException {
    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);

    Set<String> fileSet = new HashSet<String>();

    // Basic files
    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {
      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&
                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622724223/fstmerge_var1_3472353094824289616

    segmentWriteState.segmentCodecs.files(directory, info, fileSet);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622724223/fstmerge_base_3976664043854657292

    codec.files(directory, info, fileSet);
=======
    codec.files(directory, info, fileSet);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622724223/fstmerge_var2_8390475513568067953
    
    // Fieldable norm files
    final int numFIs = fieldInfos.size();
    for (int i = 0; i < numFIs; i++) {
      final FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed && !fi.omitNorms) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", IndexFileNames.NORMS_EXTENSION));
        break;
      }
    }

    // Vector files
    if (fieldInfos.hasVectors() && mergeDocStores) {
      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
      }
    }

    // Now merge all added files
    for (String file : fileSet) {
      cfsWriter.addFile(file);
    }
    
    // Perform the merge
    cfsWriter.close();
   
    return new ArrayList<String>(fileSet);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_78f3a_6c79a/rev_78f3a-6c79a/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ static final int FORMAT_CURRENT = FORMAT_PER_FIELD_CODEC; ##FSTMerge## static final int FORMAT_CURRENT = FORMAT_START; ##FSTMerge## static final int FORMAT_CURRENT = FORMAT_INDEX_VALUES;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_78f3a_6c79a/rev_78f3a-6c79a/lucene/src/java/org/apache/lucene/index/FieldInfos.java
Conflict type: LineBasedMCFd
Conflict body: 
public void write(IndexOutput output) throws IOException {
    output.writeVInt(FORMAT_CURRENT);
    output.writeVInt(size());
    for (int i = 0; i < size(); i++) {
      FieldInfo fi = fieldInfo(i);
      byte bits = 0x0;
      if (fi.isIndexed) bits |= IS_INDEXED;
      if (fi.storeTermVector) bits |= STORE_TERMVECTOR;
      if (fi.storePositionWithTermVector) bits |= STORE_POSITIONS_WITH_TERMVECTOR;
      if (fi.storeOffsetWithTermVector) bits |= STORE_OFFSET_WITH_TERMVECTOR;
      if (fi.omitNorms) bits |= OMIT_NORMS;
      if (fi.storePayloads) bits |= STORE_PAYLOADS;
      if (fi.omitTermFreqAndPositions) bits |= OMIT_TERM_FREQ_AND_POSITIONS;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622726096/fstmerge_var1_4089571672331045241
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622726096/fstmerge_base_9197077578037173908
      
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622726096/fstmerge_var2_7342325714541627171
      output.writeString(fi.name);
      output.writeInt(fi.codecId);
      output.writeByte(bits);

      final byte b;

      if (fi.docValues == null) {
        b = 0;
      } else {
        switch(fi.docValues) {
        case PACKED_INTS:
          b = 1;
          break;
        case SIMPLE_FLOAT_4BYTE:
          b = 2;
          break;
        case SIMPLE_FLOAT_8BYTE:
          b = 3;
          break;
        case BYTES_FIXED_STRAIGHT:
          b = 4;
          break;
        case BYTES_FIXED_DEREF:
          b = 5;
          break;
        case BYTES_FIXED_SORTED:
          b = 6;
          break;
        case BYTES_VAR_STRAIGHT:
          b = 7;
          break;
        case BYTES_VAR_DEREF:
          b = 8;
          break;
        case BYTES_VAR_SORTED:
          b = 9;
          break;
        case PACKED_INTS_FIXED:
          b = 10;
          break;
        default:
          throw new IllegalStateException("unhandled indexValues type " + fi.docValues);
        }
      }
      output.writeByte(b);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_78f3a_6c79a/rev_78f3a-6c79a/lucene/src/java/org/apache/lucene/index/FieldInfos.java
Conflict type: LineBasedMCFd
Conflict body: 
private void read(IndexInput input, String fileName) throws IOException {
    format = input.readVInt();

    if (format > FORMAT_MINIMUM) {
      throw new IndexFormatTooOldException(fileName, format, FORMAT_MINIMUM, FORMAT_CURRENT);
    }
    if (format < FORMAT_CURRENT) {
      throw new IndexFormatTooNewException(fileName, format, FORMAT_MINIMUM, FORMAT_CURRENT);
    }

    final int size = input.readVInt(); //read in the size

    for (int i = 0; i < size; i++) {
      String name = StringHelper.intern(input.readString());
      // if this is a previous format codec 0 will be preflex!
      final int codecId = format <= FORMAT_PER_FIELD_CODEC? input.readInt():0;
      byte bits = input.readByte();
      boolean isIndexed = (bits & IS_INDEXED) != 0;
      boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;
      boolean storePositionsWithTermVector = (bits & STORE_POSITIONS_WITH_TERMVECTOR) != 0;
      boolean storeOffsetWithTermVector = (bits & STORE_OFFSET_WITH_TERMVECTOR) != 0;
      boolean omitNorms = (bits & OMIT_NORMS) != 0;
      boolean storePayloads = (bits & STORE_PAYLOADS) != 0;
      boolean omitTermFreqAndPositions = (bits & OMIT_TERM_FREQ_AND_POSITIONS) != 0;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622726101/fstmerge_var1_397716120846707489
      final FieldInfo addInternal = addInternal(name, isIndexed, storeTermVector, storePositionsWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
      addInternal.codecId = codecId;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622726101/fstmerge_base_840124409615068616
      
      addInternal(name, isIndexed, storeTermVector, storePositionsWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
=======
      
      FieldInfo fi = addInternal(name, isIndexed, storeTermVector, storePositionsWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
      if (format <= FORMAT_INDEX_VALUES) {
        final byte b = input.readByte();
        switch(b) {
        case 0:
          fi.docValues = null;
          break;
        case 1:
          fi.docValues = Values.PACKED_INTS;
          break;
        case 2:
          fi.docValues = Values.SIMPLE_FLOAT_4BYTE;
          break;
        case 3:
          fi.docValues = Values.SIMPLE_FLOAT_8BYTE;
          break;
        case 4:
          fi.docValues = Values.BYTES_FIXED_STRAIGHT;
          break;
        case 5:
          fi.docValues = Values.BYTES_FIXED_DEREF;
          break;
        case 6:
          fi.docValues = Values.BYTES_FIXED_SORTED;
          break;
        case 7:
          fi.docValues = Values.BYTES_VAR_STRAIGHT;
          break;
        case 8:
          fi.docValues = Values.BYTES_VAR_DEREF;
          break;
        case 9:
          fi.docValues = Values.BYTES_VAR_SORTED;
          break;
        case 10:
          fi.docValues = Values.PACKED_INTS_FIXED;
          break;
        default:
          throw new IllegalStateException("unhandled indexValues type " + b);
        }
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622726101/fstmerge_var2_8735654191210721143
    }

    if (input.getFilePointer() != input.length()) {
      throw new CorruptIndexException("did not read all bytes from file \"" + fileName + "\": read " + input.getFilePointer() + " vs size " + input.length());
    }    
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_78f3a_6c79a/rev_78f3a-6c79a/lucene/src/java/org/apache/lucene/index/FieldInfos.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622727542/fstmerge_var1_8270455076235074281
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622727542/fstmerge_base_6687879404531610353
CoreReaders(SegmentReader origInstance, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor, CodecProvider codecs) throws IOException {

      if (termsIndexDivisor == 0) {
        throw new IllegalArgumentException("indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)");
      }

      segment = si.name;
      if (codecs == null) {
        codecs = CodecProvider.getDefault();
      }
      this.codecs = codecs;      
      this.readBufferSize = readBufferSize;
      this.dir = dir;

      boolean success = false;

      try {
        Directory dir0 = dir;
        if (si.getUseCompoundFile()) {
          cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);
          dir0 = cfsReader;
        }
        cfsDir = dir0;

        fieldInfos = new FieldInfos(cfsDir, IndexFileNames.segmentFileName(segment, "", IndexFileNames.FIELD_INFOS_EXTENSION));

        this.termsIndexDivisor = termsIndexDivisor;

        // Ask codec for its Fields
        fields = si.getCodec().fieldsProducer(new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor));
        assert fields != null;

        success = true;
      } finally {
        if (!success) {
          decRef();
        }
      }

      // Must assign this at the end -- if we hit an
      // exception above core, we don't want to attempt to
      // purge the FieldCache (will hit NPE because core is
      // not assigned yet).
      this.origInstance = origInstance;
    }
=======
CoreReaders(SegmentReader origInstance, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor, CodecProvider codecs) throws IOException {

      if (termsIndexDivisor == 0) {
        throw new IllegalArgumentException("indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)");
      }

      segment = si.name;
      if (codecs == null) {
        codecs = CodecProvider.getDefault();
      }
      this.codecs = codecs;      
      this.readBufferSize = readBufferSize;
      this.dir = dir;

      boolean success = false;

      try {
        Directory dir0 = dir;
        if (si.getUseCompoundFile()) {
          cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);
          dir0 = cfsReader;
        }
        cfsDir = dir0;

        fieldInfos = new FieldInfos(cfsDir, IndexFileNames.segmentFileName(segment, "", IndexFileNames.FIELD_INFOS_EXTENSION));

        this.termsIndexDivisor = termsIndexDivisor;

        // Ask codec for its Fields
        fields = si.getCodec().fieldsProducer(new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor));
        assert fields != null;
        success = true;
      } finally {
        if (!success) {
          decRef();
        }
      }

      // Must assign this at the end -- if we hit an
      // exception above core, we don't want to attempt to
      // purge the FieldCache (will hit NPE because core is
      // not assigned yet).
      this.origInstance = origInstance;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419622727542/fstmerge_var2_6599935372349336051

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_78f3a_6c79a/rev_78f3a-6c79a/lucene/src/java/org/apache/lucene/index/SegmentReader.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_22762_1eef0/rev_22762-1eef0.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f4690_efbc5/rev_f4690-efbc5.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_41cc5_5e11f/rev_41cc5-5e11f.revisions
Conflict type: LineBasedMCFd
Conflict body: 
synchronized private void initFlushState(boolean onlyDocStore) {
    initSegmentName(onlyDocStore);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419625368206/fstmerge_var1_1180195671461010394
    final SegmentCodecs info = SegmentCodecs.build(fieldInfos, writer.codecs);
    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                       docStoreSegment, numDocsInRAM, numDocsInStore, writer.getConfig().getTermIndexInterval(), info);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419625368206/fstmerge_base_4451834545188351485
    final SegmentCodecs info = SegmentCodecs.build(docFieldProcessor.fieldInfos, writer.codecs);
    flushState = new SegmentWriteState(infoStream, directory, segment, docFieldProcessor.fieldInfos,
                                       docStoreSegment, numDocsInRAM, numDocsInStore, writer.getConfig().getTermIndexInterval(), info);
=======
    final SegmentCodecs info = SegmentCodecs.build(docFieldProcessor.fieldInfos, writer.codecs);
    flushState = new SegmentWriteState(infoStream, directory, segment, docFieldProcessor.fieldInfos,
                                       docStoreSegment, numDocsInRAM, numDocsInStore, writer.getConfig().getTermIndexInterval(), info, bytesUsed);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419625368206/fstmerge_var2_3088320566325857
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_41cc5_5e11f/rev_41cc5-5e11f/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)
          throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419625368854/fstmerge_var1_8973903750720994528
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419625368854/fstmerge_base_3394184921243330073
    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);

    Set<String> fileSet = new HashSet<String>();

    // Basic files
    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {
      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&
                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
    }

    segmentWriteState.segmentCodecs.files(directory, info, fileSet);
    
    // Fieldable norm files
    int numFIs = fieldInfos.size();
    for (int i = 0; i < numFIs; i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed && !fi.omitNorms) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", IndexFileNames.NORMS_EXTENSION));
        break;
      }
    }

    // Vector files
    if (fieldInfos.hasVectors() && mergeDocStores) {
      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
      }
    }
=======
    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);

    Set<String> fileSet = new HashSet<String>();

    // Basic files
    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {
      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&
                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
    }
    segmentWriteState.segmentCodecs.files(directory, info, fileSet);
    
    // Fieldable norm files
    final int numFIs = fieldInfos.size();
    for (int i = 0; i < numFIs; i++) {
      final FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed && !fi.omitNorms) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", IndexFileNames.NORMS_EXTENSION));
        break;
      }
    }

    // Vector files
    if (fieldInfos.hasVectors() && mergeDocStores) {
      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419625368854/fstmerge_var2_3186275793038665096

    // Now merge all added files
    Collection<String> files = getMergedFiles(info);
    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);
    for (String file : files) {
      cfsWriter.addFile(file);
    }
    
    // Perform the merge
    cfsWriter.close();
   
    return files;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_41cc5_5e11f/rev_41cc5-5e11f/lucene/src/java/org/apache/lucene/index/SegmentMerger.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_3660e_1df68/rev_3660e-1df68.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ba864_d4f7c/rev_ba864-d4f7c.revisions
Conflict type: LineBasedMCFd
Conflict body: 
private void write(final FieldInfos fieldInfos, final Directory dir, final FieldData[] fields) throws Throwable {

    final int termIndexInterval = this.nextInt(13, 27);
    final SegmentCodecs codecInfo = SegmentCodecs.build(fieldInfos, CodecProvider.getDefault());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627103755/fstmerge_var1_5298634112132463771
    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, 10000, termIndexInterval, codecInfo);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627103755/fstmerge_base_1132889536435144349
    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, null, 10000, 10000, termIndexInterval, codecInfo);
=======
    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, null, 10000, 10000, termIndexInterval, codecInfo, new AtomicLong());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627103755/fstmerge_var2_1362085438952717211

    final FieldsConsumer consumer = state.segmentCodecs.codec().fieldsConsumer(state);
    Arrays.sort(fields);
    for (final FieldData field : fields) {
      field.write(consumer);
    }
    consumer.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ba864_d4f7c/rev_ba864-d4f7c/lucene/src/test/org/apache/lucene/index/TestCodecs.java
Conflict type: LineBasedMCFd
Conflict body: 
public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,
        int readBufferSize, int indexDivisor) throws IOException {

      final int fieldCount = fieldInfos.size();
      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627122215/fstmerge_var1_1277404321322021078
      boolean success = false;
      try {
        for (int i = 0; i < fieldCount; i++) {
          FieldInfo fi = fieldInfos.fieldInfo(i);
          if (fi.isIndexed) { // TODO this does not work for non-indexed fields
            fields.add(fi.name);
            Codec codec = segmentCodecs.codecs[fi.codecId];
            if (!producers.containsKey(codec)) {
              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,
                                                                             si, fieldInfos, readBufferSize, indexDivisor, ""+fi.codecId)));
            }
            codecs.put(fi.name, producers.get(codec));
          }
        }
        success = true;
      } finally {
        if (!success) {
          // If we hit exception (eg, IOE because writer was
          // committing, or, for any other reason) we must
          // go back and close all FieldsProducers we opened:
          for(FieldsProducer fp : producers.values()) {
            try {
              fp.close();
            } catch (Throwable t) {
              // Suppress all exceptions here so we continue
              // to throw the original one
            }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627122215/fstmerge_base_5536309642420892949
      for (int i = 0; i < fieldCount; i++) {
        FieldInfo fi = fieldInfos.fieldInfo(i);
        if (fi.isIndexed) { // TODO this does not work for non-indexed fields
          fields.add(fi.name);
          Codec codec = segmentCodecs.codecs[fi.codecId];
          if (!producers.containsKey(codec)) {
            producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,
                si, fieldInfos, readBufferSize, indexDivisor, ""+fi.codecId)));
=======
      for (int i = 0; i < fieldCount; i++) {
        FieldInfo fi = fieldInfos.fieldInfo(i);
        if (fi.isIndexed || fi.hasDocValues()) { // TODO this does not work for non-indexed fields
          fields.add(fi.name);
          Codec codec = segmentCodecs.codecs[fi.codecId];
          if (!producers.containsKey(codec)) {
            producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,
                si, fieldInfos, readBufferSize, indexDivisor, ""+fi.codecId)));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627122215/fstmerge_var2_6520305305858031804
          }
        }
      }
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ba864_d4f7c/rev_ba864-d4f7c/lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627124651/fstmerge_var1_2322045492192105917
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627124651/fstmerge_base_2678659634875592272
synchronized private void initFlushState(boolean onlyDocStore) {
    initSegmentName(onlyDocStore);
    final SegmentCodecs info = SegmentCodecs.build(fieldInfos, writer.codecs);
    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                       docStoreSegment, numDocsInRAM, numDocsInStore, writer.getConfig().getTermIndexInterval(), info);
  }
=======
synchronized private void initFlushState(boolean onlyDocStore) {
    initSegmentName(onlyDocStore);
    final SegmentCodecs info = SegmentCodecs.build(fieldInfos, writer.codecs);
    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                       docStoreSegment, numDocsInRAM, numDocsInStore, writer.getConfig().getTermIndexInterval(), info, bytesUsed);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627124651/fstmerge_var2_1473074467103554607

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ba864_d4f7c/rev_ba864-d4f7c/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627125254/fstmerge_var1_7212828769412968508
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627125254/fstmerge_base_7437191951682972479
final int merge(boolean mergeDocStores) throws CorruptIndexException, IOException {

    this.mergeDocStores = mergeDocStores;
    
    // NOTE: it's important to add calls to
    // checkAbort.work(...) if you make any changes to this
    // method that will spend alot of time.  The frequency
    // of this check impacts how long
    // IndexWriter.close(false) takes to actually stop the
    // threads.

    mergedDocs = mergeFields();
    mergeTerms();
    mergeNorms();

    if (mergeDocStores && fieldInfos.hasVectors())
      mergeVectors();

    return mergedDocs;
  }
=======
final int merge(boolean mergeDocStores) throws CorruptIndexException, IOException {

    this.mergeDocStores = mergeDocStores;
    
    // NOTE: it's important to add calls to
    // checkAbort.work(...) if you make any changes to this
    // method that will spend alot of time.  The frequency
    // of this check impacts how long
    // IndexWriter.close(false) takes to actually stop the
    // threads.

    mergedDocs = mergeFields();
    mergeTerms();
    mergeNorms();

    if (mergeDocStores && fieldInfos.hasVectors())
      mergeVectors();
    return mergedDocs;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627125254/fstmerge_var2_6783968908055668432

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ba864_d4f7c/rev_ba864-d4f7c/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
Conflict type: LineBasedMCFd
Conflict body: 
private int mergeFields() throws CorruptIndexException, IOException {

    for (IndexReader reader : readers) {
      if (reader instanceof SegmentReader) {
        SegmentReader segmentReader = (SegmentReader) reader;
        FieldInfos readerFieldInfos = segmentReader.fieldInfos();
        int numReaderFieldInfos = readerFieldInfos.size();
        for (int j = 0; j < numReaderFieldInfos; j++) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627125276/fstmerge_var1_8050304555867355279
          fieldInfos.add(readerFieldInfos.fieldInfo(j));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627125276/fstmerge_base_7517233978693584133
          FieldInfo fi = readerFieldInfos.fieldInfo(j);
          fieldInfos.add(fi.name, fi.isIndexed, fi.storeTermVector,
              fi.storePositionWithTermVector, fi.storeOffsetWithTermVector,
              !reader.hasNorms(fi.name), fi.storePayloads,
              fi.omitTermFreqAndPositions);
=======
          FieldInfo fi = readerFieldInfos.fieldInfo(j);
          FieldInfo merged = fieldInfos.add(fi.name, fi.isIndexed, fi.storeTermVector,
                                            fi.storePositionWithTermVector, fi.storeOffsetWithTermVector,
                                            !reader.hasNorms(fi.name), fi.storePayloads,
                                            fi.omitTermFreqAndPositions);
          final Type fiIndexValues = fi.docValues;
          final Type mergedDocValues = merged.docValues;
          if (mergedDocValues == null) {
            merged.setDocValues(fiIndexValues);
          } else if (mergedDocValues != fiIndexValues) {
            // TODO -- can we recover from this?
            throw new IllegalStateException("cannot merge field " + fi.name + " indexValues changed from " + mergedDocValues + " to " + fiIndexValues);
          }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627125276/fstmerge_var2_9143411617032347847
        }
      } else {
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION_OFFSET), true, true, true, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION), true, true, false, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_OFFSET), true, false, true, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR), true, false, false, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.OMIT_TERM_FREQ_AND_POSITIONS), false, false, false, false, true);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.STORES_PAYLOADS), false, false, false, true, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.INDEXED), false, false, false, false, false);
        fieldInfos.add(reader.getFieldNames(FieldOption.UNINDEXED), false);
        fieldInfos.add(reader.getFieldNames(FieldOption.DOC_VALUES), false);
      }
    }
    final SegmentCodecs codecInfo = SegmentCodecs.build(fieldInfos, this.codecs);
    fieldInfos.write(directory, segment + ".fnm");

    int docCount = 0;

    setMatchingSegmentReaders();

    final FieldsWriter fieldsWriter = new FieldsWriter(directory, segment, fieldInfos);

    try {
      int idx = 0;
      for (IndexReader reader : readers) {
        final SegmentReader matchingSegmentReader = matchingSegmentReaders[idx++];
        FieldsReader matchingFieldsReader = null;
        if (matchingSegmentReader != null) {
          final FieldsReader fieldsReader = matchingSegmentReader.getFieldsReader();
          if (fieldsReader != null) {
            matchingFieldsReader = fieldsReader;
          }
        }
        if (reader.hasDeletions()) {
          docCount += copyFieldsWithDeletions(fieldsWriter,
                                              reader, matchingFieldsReader);
        } else {
          docCount += copyFieldsNoDeletions(fieldsWriter,
                                            reader, matchingFieldsReader);
        }
      }
    } finally {
      fieldsWriter.close();
    }

    final String fileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.FIELDS_INDEX_EXTENSION);
    final long fdxFileLength = directory.fileLength(fileName);

    if (4+((long) docCount)*8 != fdxFileLength)
      // This is most likely a bug in Sun JRE 1.6.0_04/_05;
      // we detect that the bug has struck, here, and
      // throw an exception to prevent the corruption from
      // entering the index.  See LUCENE-1282 for
      // details.
      throw new RuntimeException("mergeFields produced an invalid result: docCount is " + docCount + " but fdx file size is " + fdxFileLength + " file=" + fileName + " file exists?=" + directory.fileExists(fileName) + "; now aborting this merge to prevent index corruption");

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627125276/fstmerge_var1_8050304555867355279
    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, docCount, termIndexInterval, codecInfo);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627125276/fstmerge_base_7517233978693584133
    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, null, docCount, 0, termIndexInterval, codecInfo);
=======
    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, null, docCount, 0, termIndexInterval, codecInfo, new AtomicLong(0));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627125276/fstmerge_var2_9143411617032347847
    
    return docCount;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ba864_d4f7c/rev_ba864-d4f7c/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
Conflict type: LineBasedMCFd
Conflict body: 
public void deleteDocuments(Term... terms) throws CorruptIndexException, IOException {
    ensureOpen();
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627128117/fstmerge_var1_6645915306449116748
      if (docWriter.deleteTerm(term, false)) {
        flush(true, false);
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627128117/fstmerge_base_4515149465099597816
      boolean doFlush = docWriter.bufferDeleteTerm(term);
      if (doFlush)
        flush(true, false, false);
=======
      boolean doFlush = docWriter.bufferDeleteTerms(terms);
      if (doFlush)
        flush(true, false, false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627128117/fstmerge_var2_1595627801321432085
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Term..)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ba864_d4f7c/rev_ba864-d4f7c/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void deleteDocuments(Query... queries) throws CorruptIndexException, IOException {
    ensureOpen();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627128135/fstmerge_var1_5617678649206320572
    try {
      if (docWriter.deleteQuery(query)) {
        flush(true, false);
      }
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Query)");
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627128135/fstmerge_base_1307018434896328818
    boolean doFlush = docWriter.bufferDeleteQuery(query);
    if (doFlush)
      flush(true, false, false);
=======
    boolean doFlush = docWriter.bufferDeleteQueries(queries);
    if (doFlush)
      flush(true, false, false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627128135/fstmerge_var2_1444914420449822558
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ba864_d4f7c/rev_ba864-d4f7c/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private void startCommit(Map<String,String> commitUserData) throws IOException {

    assert testPoint("startStartCommit");
    assert pendingCommit == null;

    if (hitOOM) {
      throw new IllegalStateException("this writer hit an OutOfMemoryError; cannot commit");
    }

    try {

      if (infoStream != null)
        message("startCommit(): start");

      final SegmentInfos toSync;
      final long myChangeCount;

      synchronized(this) {

        assert lastCommitChangeCount <= changeCount;
        myChangeCount = changeCount;
        
        if (changeCount == lastCommitChangeCount) {
          if (infoStream != null)
            message("  skip startCommit(): no changes pending");
          return;
        }
        
        // First, we clone & incref the segmentInfos we intend
        // to sync, then, without locking, we sync() all files
        // referenced by toSync, in the background.
        
        if (infoStream != null)
          message("startCommit index=" + segString(segmentInfos) + " changeCount=" + changeCount);

        readerPool.commit();
        
        toSync = (SegmentInfos) segmentInfos.clone();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627128443/fstmerge_var1_8600953898142125866
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627128443/fstmerge_base_84474052544742710
        final String dss = docWriter.getDocStoreSegment();
        if (dss != null) {
          while(true) {
            final String dss2 = toSync.info(toSync.size()-1).getDocStoreSegment();
            if (dss2 == null || !dss2.equals(dss)) {
              break;
            }
            toSync.remove(toSync.size()-1);
            changeCount++;
          }
        }
=======
        final String dss = docWriter.getDocStoreSegment();
        if (dss != null) {
          while(true) {
            final String dss2 = toSync.info(toSync.size()-1).getDocStoreSegment();
            if (dss2 == null || !dss2.equals(dss)) {
              break;
            }
            toSync.remove(toSync.size()-1);
            changeCount++;
            segmentInfos.changed();
          }
        }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627128443/fstmerge_var2_7525643694736685447
        assert filesExist(toSync);
        
        if (commitUserData != null)
          toSync.setUserData(commitUserData);
        
        // This protects the segmentInfos we are now going
        // to commit.  This is important in case, eg, while
        // we are trying to sync all referenced files, a
        // merge completes which would otherwise have
        // removed the files we are now syncing.
        deleter.incRef(toSync, false);
      }

      assert testPoint("midStartCommit");

      try {
        // This call can take a long time -- 10s of seconds
        // or more.  We do it without sync:
        directory.sync(toSync.files(directory, false));

        assert testPoint("midStartCommit2");

        synchronized(this) {

          assert pendingCommit == null;

          assert segmentInfos.getGeneration() == toSync.getGeneration();

          // Exception here means nothing is prepared
          // (this method unwinds everything it did on
          // an exception)
          toSync.prepareCommit(directory);

          pendingCommit = toSync;
          pendingCommitChangeCount = myChangeCount;
        }

        if (infoStream != null)
          message("done all syncs");

        assert testPoint("midStartCommitSuccess");

      } finally {
        synchronized(this) {

          // Have our master segmentInfos record the
          // generations we just prepared.  We do this
          // on error or success so we don't
          // double-write a segments_N file.
          segmentInfos.updateGeneration(toSync);

          if (pendingCommit == null) {
            if (infoStream != null) {
              message("hit exception committing segments file");
            }

            deleter.decRef(toSync);
          }
        }
      }
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "startCommit");
    }
    assert testPoint("finishStartCommit");
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ba864_d4f7c/rev_ba864-d4f7c/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
synchronized boolean nrtIsCurrent(SegmentInfos infos) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627128498/fstmerge_var1_8159688949716585348
    return infos.version == segmentInfos.version && !docWriter.anyChanges() && !bufferedDeletes.any();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627128498/fstmerge_base_6258017836599751553
    if (!infos.equals(segmentInfos)) {
      // if any structural changes (new segments), we are
      // stale
      return false;
    } else if (infos.getGeneration() != segmentInfos.getGeneration()) {
      // if any commit took place since we were opened, we
      // are stale
      return false;
    } else {
      return !docWriter.anyChanges();
    }
=======
    return infos.version == segmentInfos.version && !docWriter.anyChanges();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627128498/fstmerge_var2_881101539936909568
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ba864_d4f7c/rev_ba864-d4f7c/lucene/src/java/org/apache/lucene/index/IndexWriter.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627942937/fstmerge_var1_3859708176292261651
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627942937/fstmerge_base_4793632437384486050
private void doTestSearch(PrintWriter out, boolean useCompoundFile)
    throws Exception {
      Directory directory = new RAMDirectory();
      Analyzer analyzer = new MockAnalyzer();
      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer);
      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
      lmp.setUseCompoundFile(useCompoundFile);
      lmp.setUseCompoundDocStore(useCompoundFile);
      IndexWriter writer = new IndexWriter(directory, conf);

      String[] docs = {
        "a b c d e",
        "a b c d e a b c d e",
        "a b c d e f g h i j",
        "a c e",
        "e c a",
        "a c e a c e",
        "a c e a b c"
      };
      for (int j = 0; j < docs.length; j++) {
        Document d = new Document();
        d.add(new Field("contents", docs[j], Field.Store.YES, Field.Index.ANALYZED));
        writer.addDocument(d);
      }
      writer.close();

      Searcher searcher = new IndexSearcher(directory, true);

      String[] queries = {
        "a b",
        "\"a b\"",
        "\"a b c\"",
        "a c",
        "\"a c\"",
        "\"a c e\"",
      };
      ScoreDoc[] hits = null;

      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, "contents", analyzer);
      parser.setPhraseSlop(4);
      for (int j = 0; j < queries.length; j++) {
        Query query = parser.parse(queries[j]);
        out.println("Query: " + query.toString("contents"));

      //DateFilter filter =
      //  new DateFilter("modified", Time(1997,0,1), Time(1998,0,1));
      //DateFilter filter = DateFilter.Before("modified", Time(1997,00,01));
      //System.out.println(filter);

        hits = searcher.search(query, null, 1000).scoreDocs;

        out.println(hits.length + " total results");
        for (int i = 0 ; i < hits.length && i < 10; i++) {
          Document d = searcher.doc(hits[i].doc);
          out.println(i + " " + hits[i].score
// 			   + " " + DateField.stringToDate(d.get("modified"))
                             + " " + d.get("contents"));
        }
      }
      searcher.close();
  }
=======
private void doTestSearch(PrintWriter out, boolean useCompoundFile)
    throws Exception {
      Directory directory = new RAMDirectory();
      Analyzer analyzer = new MockAnalyzer();
      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer);
      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
      lmp.setUseCompoundFile(useCompoundFile);
      IndexWriter writer = new IndexWriter(directory, conf);

      String[] docs = {
        "a b c d e",
        "a b c d e a b c d e",
        "a b c d e f g h i j",
        "a c e",
        "e c a",
        "a c e a c e",
        "a c e a b c"
      };
      for (int j = 0; j < docs.length; j++) {
        Document d = new Document();
        d.add(new Field("contents", docs[j], Field.Store.YES, Field.Index.ANALYZED));
        writer.addDocument(d);
      }
      writer.close();

      Searcher searcher = new IndexSearcher(directory, true);

      String[] queries = {
        "a b",
        "\"a b\"",
        "\"a b c\"",
        "a c",
        "\"a c\"",
        "\"a c e\"",
      };
      ScoreDoc[] hits = null;

      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, "contents", analyzer);
      parser.setPhraseSlop(4);
      for (int j = 0; j < queries.length; j++) {
        Query query = parser.parse(queries[j]);
        out.println("Query: " + query.toString("contents"));

      //DateFilter filter =
      //  new DateFilter("modified", Time(1997,0,1), Time(1998,0,1));
      //DateFilter filter = DateFilter.Before("modified", Time(1997,00,01));
      //System.out.println(filter);

        hits = searcher.search(query, null, 1000).scoreDocs;

        out.println(hits.length + " total results");
        for (int i = 0 ; i < hits.length && i < 10; i++) {
          Document d = searcher.doc(hits[i].doc);
          out.println(i + " " + hits[i].score
// 			   + " " + DateField.stringToDate(d.get("modified"))
                             + " " + d.get("contents"));
        }
      }
      searcher.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627942937/fstmerge_var2_4195451127504759573

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/TestSearch.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943343/fstmerge_var1_182680793346652641
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943343/fstmerge_base_117747489728914475
private void doTest(PrintWriter out, boolean useCompoundFiles) throws Exception {
      Directory directory = new RAMDirectory();
      Analyzer analyzer = new MockAnalyzer();
      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer);
      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
      lmp.setUseCompoundFile(useCompoundFiles);
      lmp.setUseCompoundDocStore(useCompoundFiles);
      IndexWriter writer = new IndexWriter(directory, conf);

      final int MAX_DOCS = 225;

      for (int j = 0; j < MAX_DOCS; j++) {
        Document d = new Document();
        d.add(new Field(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));

        // NOTE: this ID_FIELD produces no tokens since
        // MockAnalyzer discards numbers
        d.add(new Field(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));
        writer.addDocument(d);
      }
      writer.close();

      // try a search without OR
      Searcher searcher = new IndexSearcher(directory, true);

      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);

      Query query = parser.parse(HIGH_PRIORITY);
      out.println("Query: " + query.toString(PRIORITY_FIELD));

      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;
      printHits(out, hits, searcher);
      checkHits(hits, MAX_DOCS, searcher);

      searcher.close();

      // try a new search with OR
      searcher = new IndexSearcher(directory, true);
      hits = null;

      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);

      query = parser.parse(HIGH_PRIORITY + " OR " + MED_PRIORITY);
      out.println("Query: " + query.toString(PRIORITY_FIELD));

      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;
      printHits(out, hits, searcher);
      checkHits(hits, MAX_DOCS, searcher);

      searcher.close();
  }
=======
private void doTest(PrintWriter out, boolean useCompoundFiles) throws Exception {
      Directory directory = new RAMDirectory();
      Analyzer analyzer = new MockAnalyzer();
      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer);
      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
      lmp.setUseCompoundFile(useCompoundFiles);
      IndexWriter writer = new IndexWriter(directory, conf);

      final int MAX_DOCS = 225;

      for (int j = 0; j < MAX_DOCS; j++) {
        Document d = new Document();
        d.add(new Field(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));

        // NOTE: this ID_FIELD produces no tokens since
        // MockAnalyzer discards numbers
        d.add(new Field(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));
        writer.addDocument(d);
      }
      writer.close();

      // try a search without OR
      Searcher searcher = new IndexSearcher(directory, true);

      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);

      Query query = parser.parse(HIGH_PRIORITY);
      out.println("Query: " + query.toString(PRIORITY_FIELD));

      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;
      printHits(out, hits, searcher);
      checkHits(hits, MAX_DOCS, searcher);

      searcher.close();

      // try a new search with OR
      searcher = new IndexSearcher(directory, true);
      hits = null;

      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);

      query = parser.parse(HIGH_PRIORITY + " OR " + MED_PRIORITY);
      out.println("Query: " + query.toString(PRIORITY_FIELD));

      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;
      printHits(out, hits, searcher);
      checkHits(hits, MAX_DOCS, searcher);

      searcher.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943343/fstmerge_var2_404039776727100400

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/TestSearchForDuplicates.java
Conflict type: LineBasedMCFd
Conflict body: 
private IndexSearcher getIndex (boolean even, boolean odd)
  throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943365/fstmerge_var1_48827632208411021
    Directory indexStore = newDirectory();
    dirs.add(indexStore);
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943365/fstmerge_base_9021243979895995196
    RAMDirectory indexStore = new RAMDirectory();
    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);
=======
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943365/fstmerge_var2_3622138917699960055
    for (int i=0; i<data.length; ++i) {
      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {
        Document doc = new Document();
        doc.add (new Field ("tracer",   data[i][0], Field.Store.YES, Field.Index.NO));
        doc.add (new Field ("contents", data[i][1], Field.Store.NO, Field.Index.ANALYZED));
        if (data[i][2] != null) doc.add (new Field ("int",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][3] != null) doc.add (new Field ("float",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][4] != null) doc.add (new Field ("string",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][5] != null) doc.add (new Field ("custom",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][6] != null) doc.add (new Field ("i18n",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][7] != null) doc.add (new Field ("long",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][8] != null) doc.add (new Field ("double",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][9] != null) doc.add (new Field ("short",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][10] != null) doc.add (new Field ("byte",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][11] != null) doc.add (new Field ("parser",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));
        doc.setBoost(2);  // produce some scores above 1.0
        writer.addDocument (doc);
      }
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943365/fstmerge_base_9021243979895995196
    //writer.optimize ();
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943365/fstmerge_var2_3622138917699960055
    writer.close ();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943365/fstmerge_base_9021243979895995196
    IndexSearcher s = new IndexSearcher (indexStore, true);
=======
    IndexSearcher s = new IndexSearcher (reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943365/fstmerge_var2_3622138917699960055
    s.setDefaultFieldSortScoring(true, true);
    return s;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestSort.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943567/fstmerge_var1_529395122641314136
public void testLUCENE2142() throws IOException {
    Directory indexStore = newDirectory();
    IndexWriter writer = new IndexWriter(indexStore, newIndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i=0; i<5; i++) {
        Document doc = new Document();
        doc.add (new Field ("string", "a"+i, Field.Store.NO, Field.Index.NOT_ANALYZED));
        doc.add (new Field ("string", "b"+i, Field.Store.NO, Field.Index.NOT_ANALYZED));
        writer.addDocument (doc);
    }
    writer.optimize(); // enforce one segment to have a higher unique term count in all cases
    writer.close();
    sort.setSort(
        new SortField("string", SortField.STRING),
        SortField.FIELD_DOC );
    // this should not throw AIOOBE or RuntimeEx
    IndexSearcher searcher = new IndexSearcher(indexStore, true);
    searcher.search(new MatchAllDocsQuery(), null, 500, sort);
    searcher.close();
    indexStore.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943567/fstmerge_base_5525060586320041670
=======
public void testLUCENE2142() throws IOException {
    RAMDirectory indexStore = new RAMDirectory ();
    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i=0; i<5; i++) {
        Document doc = new Document();
        doc.add (new Field ("string", "a"+i, Field.Store.NO, Field.Index.NOT_ANALYZED));
        doc.add (new Field ("string", "b"+i, Field.Store.NO, Field.Index.NOT_ANALYZED));
        writer.addDocument (doc);
    }
    writer.optimize(); // enforce one segment to have a higher unique term count in all cases
    writer.close();
    sort.setSort(
        new SortField("string", SortField.STRING),
        SortField.FIELD_DOC );
    // this should not throw AIOOBE or RuntimeEx
    new IndexSearcher (indexStore, true).search(new MatchAllDocsQuery(), null, 500, sort);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943567/fstmerge_var2_391072781765160688

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestSort.java
Conflict type: LineBasedMCFd
Conflict body: 
public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943571/fstmerge_var1_2841396724404495436
    directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943571/fstmerge_base_2901558690491565718
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new MockAnalyzer(), true,
        IndexWriter.MaxFieldLength.LIMITED);
=======
    Random random = newRandom();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943571/fstmerge_var2_3500032838134258443
    Document doc = new Document();
    Field titleField = newField("title", "some title", Field.Store.NO,
        Field.Index.ANALYZED);
    Field field = newField(FN, "", Field.Store.NO,
        Field.Index.ANALYZED);
    Field footerField = newField("footer", "a footer", Field.Store.NO,
        Field.Index.ANALYZED);
    doc.add(titleField);
    doc.add(field);
    doc.add(footerField);
    field.setValue("\uD866\uDF05abcdef");
    writer.addDocument(doc);
    field.setValue("\uD866\uDF06ghijkl");
    writer.addDocument(doc);
    // this sorts before the previous two in UTF-8/UTF-32, but after in UTF-16!!!
    field.setValue("\uFB94mnopqr"); 
    writer.addDocument(doc);
    field.setValue("\uFB95stuvwx"); // this one too.
    writer.addDocument(doc);
    field.setValue("a\uFFFCbc");
    writer.addDocument(doc);
    field.setValue("a\uFFFDbc");
    writer.addDocument(doc);
    field.setValue("a\uFFFEbc");
    writer.addDocument(doc);
    field.setValue("a\uFB94bc");
    writer.addDocument(doc);
    field.setValue("bacadaba");
    writer.addDocument(doc);
    field.setValue("\uFFFD");
    writer.addDocument(doc);
    field.setValue("\uFFFD\uD866\uDF05");
    writer.addDocument(doc);
    field.setValue("\uFFFD\uFFFD");
    writer.addDocument(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943571/fstmerge_base_2901558690491565718
    writer.optimize();
=======
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943571/fstmerge_var2_3500032838134258443
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943571/fstmerge_base_2901558690491565718
    searcher = new IndexSearcher(directory, true);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943571/fstmerge_var2_3500032838134258443
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestAutomatonQueryUnicode.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {                  
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943602/fstmerge_var1_397346329664596539
    directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, new MockAnalyzer(MockTokenizer.SIMPLE, true));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943602/fstmerge_base_1153572928259763290
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));
=======
    random = newRandom();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, new MockAnalyzer(MockTokenizer.SIMPLE, true));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943602/fstmerge_var2_1637936967124086163
    //writer.setUseCompoundFile(true);
    //writer.infoStream = System.out;
    for (int i = 0; i < 1000; i++) {
      Document doc = new Document();
      Field.TermVector termVector;
      int mod3 = i % 3;
      int mod2 = i % 2;
      if (mod2 == 0 && mod3 == 0){
        termVector = Field.TermVector.WITH_POSITIONS_OFFSETS;
      }
      else if (mod2 == 0){
        termVector = Field.TermVector.WITH_POSITIONS;
      }
      else if (mod3 == 0){
        termVector = Field.TermVector.WITH_OFFSETS;
      }
      else {
        termVector = Field.TermVector.YES;
      }
      doc.add(new Field("field", English.intToEnglish(i),
          Field.Store.YES, Field.Index.ANALYZED, termVector));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943602/fstmerge_base_1153572928259763290
=======
      //test no term vectors too
      doc.add(new Field("noTV", English.intToEnglish(i),
          Field.Store.YES, Field.Index.ANALYZED));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943602/fstmerge_var2_1637936967124086163
      writer.addDocument(doc);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943602/fstmerge_base_1153572928259763290
=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943602/fstmerge_var2_1637936967124086163
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943602/fstmerge_base_1153572928259763290
    searcher = new IndexSearcher(directory, true);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943602/fstmerge_var2_1637936967124086163
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermVectors.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943607/fstmerge_var1_262408412495940683
@Override
  public void tearDown() throws Exception {
    searcher.close();
    reader.close();
    directory.close();
    super.tearDown();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943607/fstmerge_base_6333859662424726796
=======
@Override
  protected void tearDown() throws Exception {
    searcher.close();
    reader.close();
    directory.close();
    super.tearDown();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943607/fstmerge_var2_1238279531369557401

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermVectors.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testTermVectorsFieldOrder() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943620/fstmerge_var1_8288679036911178156
    Directory dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943620/fstmerge_base_6339087412048294593
    Directory dir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));
=======
    Directory dir = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943620/fstmerge_var2_6559635068504701872
    Document doc = new Document();
    doc.add(new Field("c", "some content here", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    doc.add(new Field("a", "some content here", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    doc.add(new Field("b", "some content here", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    doc.add(new Field("x", "some content here", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943620/fstmerge_base_6339087412048294593
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943620/fstmerge_var2_6559635068504701872
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943620/fstmerge_base_6339087412048294593
    IndexReader reader = IndexReader.open(dir, true);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943620/fstmerge_var2_6559635068504701872
    TermFreqVector[] v = reader.getTermFreqVectors(0);
    assertEquals(4, v.length);
    String[] expectedFields = new String[]{"a", "b", "c", "x"};
    int[] expectedPositions = new int[]{1, 2, 0};
    for(int i=0;i<v.length;i++) {
      TermPositionVector posVec = (TermPositionVector) v[i];
      assertEquals(expectedFields[i], posVec.getField());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943620/fstmerge_base_6339087412048294593
      String[] terms = posVec.getTerms();
=======
      BytesRef[] terms = posVec.getTerms();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943620/fstmerge_var2_6559635068504701872
      assertEquals(3, terms.length);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943620/fstmerge_base_6339087412048294593
      assertEquals("content", terms[0]);
      assertEquals("here", terms[1]);
      assertEquals("some", terms[2]);
=======
      assertEquals("content", terms[0].utf8ToString());
      assertEquals("here", terms[1].utf8ToString());
      assertEquals("some", terms[2].utf8ToString());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943620/fstmerge_var2_6559635068504701872
      for(int j=0;j<3;j++) {
        int[] positions = posVec.getTermPositions(j);
        assertEquals(1, positions.length);
        assertEquals(expectedPositions[j], positions[0]);
      }
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943620/fstmerge_base_6339087412048294593
=======
    reader.close();
    dir.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943620/fstmerge_var2_6559635068504701872
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermVectors.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_base_435094404106551161
public void testKnownSetOfDocuments() {
=======
public void testKnownSetOfDocuments() throws IOException {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_var2_3070004779958710629
    String test1 = "eating chocolate in a computer lab"; //6 terms
    String test2 = "computer in a computer lab"; //5 terms
    String test3 = "a chocolate lab grows old"; //5 terms
    String test4 = "eating chocolate with a chocolate lab in an old chocolate colored computer lab"; //13 terms
    Map<String,Integer> test4Map = new HashMap<String,Integer>();
    test4Map.put("chocolate", Integer.valueOf(3));
    test4Map.put("lab", Integer.valueOf(2));
    test4Map.put("eating", Integer.valueOf(1));
    test4Map.put("computer", Integer.valueOf(1));
    test4Map.put("with", Integer.valueOf(1));
    test4Map.put("a", Integer.valueOf(1));
    test4Map.put("colored", Integer.valueOf(1));
    test4Map.put("in", Integer.valueOf(1));
    test4Map.put("an", Integer.valueOf(1));
    test4Map.put("computer", Integer.valueOf(1));
    test4Map.put("old", Integer.valueOf(1));
    
    Document testDoc1 = new Document();
    setupDoc(testDoc1, test1);
    Document testDoc2 = new Document();
    setupDoc(testDoc2, test2);
    Document testDoc3 = new Document();
    setupDoc(testDoc3, test3);
    Document testDoc4 = new Document();
    setupDoc(testDoc4, test4);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_var1_2975721460616223217
    
    Directory dir = newDirectory();
    
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, 
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true))
        .setOpenMode(OpenMode.CREATE));
    writer.addDocument(testDoc1);
    writer.addDocument(testDoc2);
    writer.addDocument(testDoc3);
    writer.addDocument(testDoc4);
    IndexReader reader = writer.getReader();
    writer.close();
    IndexSearcher knownSearcher = new IndexSearcher(reader);
    FieldsEnum fields = MultiFields.getFields(knownSearcher.reader).iterator();
    
    DocsEnum docs = null;
    while(fields.next() != null) {
      TermsEnum terms = fields.terms();
      while(terms.next() != null) {
        String text = terms.term().utf8ToString();
        docs = terms.docs(MultiFields.getDeletedDocs(knownSearcher.reader), docs);
        
        while (docs.nextDoc() != DocsEnum.NO_MORE_DOCS) {
          int docId = docs.docID();
          int freq = docs.freq();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_base_435094404106551161
        
    Directory dir = new MockRAMDirectory();
    
    try {
      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
          TEST_VERSION_CURRENT, 
          new MockAnalyzer(MockTokenizer.SIMPLE, true))
          .setOpenMode(OpenMode.CREATE));
      writer.addDocument(testDoc1);
      writer.addDocument(testDoc2);
      writer.addDocument(testDoc3);
      writer.addDocument(testDoc4);
      writer.close();
      IndexSearcher knownSearcher = new IndexSearcher(dir, true);
      TermEnum termEnum = knownSearcher.reader.terms();
      TermDocs termDocs = knownSearcher.reader.termDocs();
      //System.out.println("Terms: " + termEnum.size() + " Orig Len: " + termArray.length);
      
      //Similarity sim = knownSearcher.getSimilarity();
      while (termEnum.next() == true)
      {
        Term term = termEnum.term();
        //System.out.println("Term: " + term);
        termDocs.seek(term);
        while (termDocs.next())
        {
          int docId = termDocs.doc();
          int freq = termDocs.freq();
=======
    
    Directory dir = new MockRAMDirectory();
    
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true))
        .setOpenMode(OpenMode.CREATE));
    writer.addDocument(testDoc1);
    writer.addDocument(testDoc2);
    writer.addDocument(testDoc3);
    writer.addDocument(testDoc4);
    IndexReader reader = writer.getReader();
    writer.close();
    IndexSearcher knownSearcher = new IndexSearcher(reader);
    FieldsEnum fields = MultiFields.getFields(knownSearcher.reader).iterator();
    
    DocsEnum docs = null;
    while(fields.next() != null) {
      TermsEnum terms = fields.terms();
      while(terms.next() != null) {
        String text = terms.term().utf8ToString();
        docs = terms.docs(MultiFields.getDeletedDocs(knownSearcher.reader), docs);
        
        while (docs.nextDoc() != DocsEnum.NO_MORE_DOCS) {
          int docId = docs.docID();
          int freq = docs.freq();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_var2_3070004779958710629
          //System.out.println("Doc Id: " + docId + " freq " + freq);
          TermFreqVector vector = knownSearcher.reader.getTermFreqVector(docId, "field");
          //float tf = sim.tf(freq);
          //float idf = sim.idf(knownSearcher.docFreq(term), knownSearcher.maxDoc());
          //float qNorm = sim.queryNorm()
          //This is fine since we don't have stop words
          //float lNorm = sim.lengthNorm("field", vector.getTerms().length);
          //float coord = sim.coord()
          //System.out.println("TF: " + tf + " IDF: " + idf + " LenNorm: " + lNorm);
          assertTrue(vector != null);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_base_435094404106551161
          String[] vTerms = vector.getTerms();
=======
          BytesRef[] vTerms = vector.getTerms();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_var2_3070004779958710629
          int [] freqs = vector.getTermFrequencies();
          for (int i = 0; i < vTerms.length; i++)
          {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_base_435094404106551161
            if (term.text().equals(vTerms[i]))
=======
            if (text.equals(vTerms[i].utf8ToString()))
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_var2_3070004779958710629
            {
              assertTrue(freqs[i] == freq);
            }
          }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_base_435094404106551161
          
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_var2_3070004779958710629
        }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_base_435094404106551161
        //System.out.println("--------");
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_var2_3070004779958710629
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_base_435094404106551161
      Query query = new TermQuery(new Term("field", "chocolate"));
      ScoreDoc[] hits = knownSearcher.search(query, null, 1000).scoreDocs;
      //doc 3 should be the first hit b/c it is the shortest match
      assertTrue(hits.length == 3);
      /*System.out.println("Hit 0: " + hits.id(0) + " Score: " + hits.score(0) + " String: " + hits.doc(0).toString());
=======
      //System.out.println("--------");
    }
    Query query = new TermQuery(new Term("field", "chocolate"));
    ScoreDoc[] hits = knownSearcher.search(query, null, 1000).scoreDocs;
    //doc 3 should be the first hit b/c it is the shortest match
    assertTrue(hits.length == 3);
    /*System.out.println("Hit 0: " + hits.id(0) + " Score: " + hits.score(0) + " String: " + hits.doc(0).toString());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_var2_3070004779958710629
      System.out.println("Explain: " + knownSearcher.explain(query, hits.id(0)));
      System.out.println("Hit 1: " + hits.id(1) + " Score: " + hits.score(1) + " String: " + hits.doc(1).toString());
      System.out.println("Explain: " + knownSearcher.explain(query, hits.id(1)));
      System.out.println("Hit 2: " + hits.id(2) + " Score: " + hits.score(2) + " String: " +  hits.doc(2).toString());
      System.out.println("Explain: " + knownSearcher.explain(query, hits.id(2)));*/
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_base_435094404106551161
      assertTrue(hits[0].doc == 2);
      assertTrue(hits[1].doc == 3);
      assertTrue(hits[2].doc == 0);
      TermFreqVector vector = knownSearcher.reader.getTermFreqVector(hits[1].doc, "field");
      assertTrue(vector != null);
      //System.out.println("Vector: " + vector);
      String[] terms = vector.getTerms();
      int [] freqs = vector.getTermFrequencies();
      assertTrue(terms != null && terms.length == 10);
      for (int i = 0; i < terms.length; i++) {
        String term = terms[i];
        //System.out.println("Term: " + term);
        int freq = freqs[i];
        assertTrue(test4.indexOf(term) != -1);
        Integer freqInt = test4Map.get(term);
        assertTrue(freqInt != null);
        assertTrue(freqInt.intValue() == freq);        
=======
    assertTrue(hits[0].doc == 2);
    assertTrue(hits[1].doc == 3);
    assertTrue(hits[2].doc == 0);
    TermFreqVector vector = knownSearcher.reader.getTermFreqVector(hits[1].doc, "field");
    assertTrue(vector != null);
    //System.out.println("Vector: " + vector);
    BytesRef[] terms = vector.getTerms();
    int [] freqs = vector.getTermFrequencies();
    assertTrue(terms != null && terms.length == 10);
    for (int i = 0; i < terms.length; i++) {
      String term = terms[i].utf8ToString();
      //System.out.println("Term: " + term);
      int freq = freqs[i];
      assertTrue(test4.indexOf(term) != -1);
      Integer freqInt = test4Map.get(term);
      assertTrue(freqInt != null);
      assertTrue(freqInt.intValue() == freq);        
    }
    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());
    knownSearcher.reader.getTermFreqVector(hits[1].doc, mapper);
    SortedSet<TermVectorEntry> vectorEntrySet = mapper.getTermVectorEntrySet();
    assertTrue("mapper.getTermVectorEntrySet() Size: " + vectorEntrySet.size() + " is not: " + 10, vectorEntrySet.size() == 10);
    TermVectorEntry last = null;
    for (final TermVectorEntry tve : vectorEntrySet) {
      if (tve != null && last != null)
      {
        assertTrue("terms are not properly sorted", last.getFrequency() >= tve.getFrequency());
        Integer expectedFreq =  test4Map.get(tve.getTerm().utf8ToString());
        //we expect double the expectedFreq, since there are two fields with the exact same text and we are collapsing all fields
        assertTrue("Frequency is not correct:", tve.getFrequency() == 2*expectedFreq.intValue());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_var2_3070004779958710629
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_base_435094404106551161
      SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());
      knownSearcher.reader.getTermFreqVector(hits[1].doc, mapper);
      SortedSet<TermVectorEntry> vectorEntrySet = mapper.getTermVectorEntrySet();
      assertTrue("mapper.getTermVectorEntrySet() Size: " + vectorEntrySet.size() + " is not: " + 10, vectorEntrySet.size() == 10);
      TermVectorEntry last = null;
      for (final TermVectorEntry tve : vectorEntrySet) {
        if (tve != null && last != null)
        {
          assertTrue("terms are not properly sorted", last.getFrequency() >= tve.getFrequency());
          Integer expectedFreq =  test4Map.get(tve.getTerm());
          //we expect double the expectedFreq, since there are two fields with the exact same text and we are collapsing all fields
          assertTrue("Frequency is not correct:", tve.getFrequency() == 2*expectedFreq.intValue());
        }
        last = tve;

      }

      FieldSortedTermVectorMapper fieldMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());
      knownSearcher.reader.getTermFreqVector(hits[1].doc, fieldMapper);
      Map<String,SortedSet<TermVectorEntry>> map = fieldMapper.getFieldToTerms();
      assertTrue("map Size: " + map.size() + " is not: " + 2, map.size() == 2);
      vectorEntrySet = map.get("field");
      assertTrue("vectorEntrySet is null and it shouldn't be", vectorEntrySet != null);
      assertTrue("vectorEntrySet Size: " + vectorEntrySet.size() + " is not: " + 10, vectorEntrySet.size() == 10);
      knownSearcher.close();
    } catch (IOException e) {
      e.printStackTrace();
      assertTrue(false);
=======
      last = tve;
      
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_var2_3070004779958710629
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_base_435094404106551161
=======
    
    FieldSortedTermVectorMapper fieldMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());
    knownSearcher.reader.getTermFreqVector(hits[1].doc, fieldMapper);
    Map<String,SortedSet<TermVectorEntry>> map = fieldMapper.getFieldToTerms();
    assertTrue("map Size: " + map.size() + " is not: " + 2, map.size() == 2);
    vectorEntrySet = map.get("field");
    assertTrue("vectorEntrySet is null and it shouldn't be", vectorEntrySet != null);
    assertTrue("vectorEntrySet Size: " + vectorEntrySet.size() + " is not: " + 10, vectorEntrySet.size() == 10);
    knownSearcher.close();
    reader.close();
    dir.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943635/fstmerge_var2_3070004779958710629
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermVectors.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testRareVectors() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943649/fstmerge_var1_1606666657234162449
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true))
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943649/fstmerge_base_8534717050332221374
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true))
=======
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true))
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943649/fstmerge_var2_3406058128184052372
        .setOpenMode(OpenMode.CREATE));
    writer.w.setInfoStream(VERBOSE ? System.out : null);
    if (VERBOSE) {
      System.out.println("TEST: now add non-vectors");
    }
    for (int i = 0; i < 100; i++) {
      Document doc = new Document();
      doc.add(new Field("field", English.intToEnglish(i),
                        Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.NO));
      writer.addDocument(doc);
    }
    if (VERBOSE) {
      System.out.println("TEST: now add vectors");
    }
    for(int i=0;i<10;i++) {
      Document doc = new Document();
      doc.add(new Field("field", English.intToEnglish(100+i),
                        Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
      writer.addDocument(doc);
    }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943649/fstmerge_var1_1606666657234162449
    if (VERBOSE) {
      System.out.println("TEST: now getReader");
    }
    IndexReader reader = writer.getReader();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943649/fstmerge_base_8534717050332221374
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943649/fstmerge_var2_3406058128184052372
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943649/fstmerge_base_8534717050332221374
    searcher = new IndexSearcher(directory, true);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943649/fstmerge_var2_3406058128184052372

    Query query = new TermQuery(new Term("field", "hundred"));
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(10, hits.length);
    for (int i = 0; i < hits.length; i++) {

      TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);
      assertTrue(vector != null);
      assertTrue(vector.length == 1);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943649/fstmerge_base_8534717050332221374
=======
    reader.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943649/fstmerge_var2_3406058128184052372
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermVectors.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testMixedVectrosVectors() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943654/fstmerge_var1_1946819407217410479
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(TEST_VERSION_CURRENT, 
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943654/fstmerge_base_2722655734921213968
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
        TEST_VERSION_CURRENT, 
=======
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, 
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943654/fstmerge_var2_8775235237147897699
        new MockAnalyzer(MockTokenizer.SIMPLE, true)).setOpenMode(OpenMode.CREATE));
    Document doc = new Document();
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.NO));
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.YES));
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS));
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_OFFSETS));
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943654/fstmerge_base_2722655734921213968
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943654/fstmerge_var2_8775235237147897699
    writer.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943654/fstmerge_base_2722655734921213968
    searcher = new IndexSearcher(directory, true);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943654/fstmerge_var2_8775235237147897699

    Query query = new TermQuery(new Term("field", "one"));
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);

    TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[0].doc);
    assertTrue(vector != null);
    assertTrue(vector.length == 1);
    TermPositionVector tfv = (TermPositionVector) vector[0];
    assertTrue(tfv.getField().equals("field"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943654/fstmerge_base_2722655734921213968
    String[] terms = tfv.getTerms();
=======
    BytesRef[] terms = tfv.getTerms();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943654/fstmerge_var2_8775235237147897699
    assertEquals(1, terms.length);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943654/fstmerge_base_2722655734921213968
    assertEquals(terms[0], "one");
=======
    assertEquals(terms[0].utf8ToString(), "one");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943654/fstmerge_var2_8775235237147897699
    assertEquals(5, tfv.getTermFrequencies()[0]);

    int[] positions = tfv.getTermPositions(0);
    assertEquals(5, positions.length);
    for(int i=0;i<5;i++)
      assertEquals(i, positions[i]);
    TermVectorOffsetInfo[] offsets = tfv.getOffsets(0);
    assertEquals(5, offsets.length);
    for(int i=0;i<5;i++) {
      assertEquals(4*i, offsets[i].getStartOffset());
      assertEquals(4*i+3, offsets[i].getEndOffset());
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943654/fstmerge_base_2722655734921213968
=======
    reader.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943654/fstmerge_var2_8775235237147897699
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermVectors.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943667/fstmerge_var1_6291963417668415129
  public void setUp() throws Exception {
    super.setUp();
    index = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, index);
    RandomGen random = new RandomGen(this.random);
    for (int i = 0; i < INDEX_SIZE; ++i) { // don't decrease; if to low the
                                           // problem doesn't show up
      Document doc = new Document();
      if ((i % 5) != 0) { // some documents must not have an entry in the first
                          // sort field
        doc.add(newField("publicationDate_", random.getLuceneDate(),
            Field.Store.YES, Field.Index.NOT_ANALYZED));
      }
      if ((i % 7) == 0) { // some documents to match the query (see below)
        doc.add(newField("content", "test", Field.Store.YES,
            Field.Index.ANALYZED));
      }
      // every document has a defined 'mandant' field
      doc.add(newField("mandant", Integer.toString(i % 3), Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
    query = new TermQuery(new Term("content", "test"));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943667/fstmerge_base_154218444509706960
  protected void setUp() throws Exception {
          super.setUp();
          index = getIndex();
          query = new TermQuery( new Term("content", "test"));
=======
  protected void setUp() throws Exception {
    super.setUp();
    Random rand = newRandom();
    index = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, index);
    RandomGen random = new RandomGen(rand);
    for (int i = 0; i < INDEX_SIZE; ++i) { // don't decrease; if to low the
                                           // problem doesn't show up
      Document doc = new Document();
      if ((i % 5) != 0) { // some documents must not have an entry in the first
                          // sort field
        doc.add(new Field("publicationDate_", random.getLuceneDate(),
            Field.Store.YES, Field.Index.NOT_ANALYZED));
      }
      if ((i % 7) == 0) { // some documents to match the query (see below)
        doc.add(new Field("content", "test", Field.Store.YES,
            Field.Index.ANALYZED));
      }
      // every document has a defined 'mandant' field
      doc.add(new Field("mandant", Integer.toString(i % 3), Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
    query = new TermQuery(new Term("content", "test"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943667/fstmerge_var2_9042344859534059033
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestCustomSearcherSort.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943671/fstmerge_var1_5760258200519018637
@Override
  public void tearDown() throws Exception {
    reader.close();
    index.close();
    super.tearDown();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943671/fstmerge_base_5656283726950118000
=======
@Override
  protected void tearDown() throws Exception {
    reader.close();
    index.close();
    super.tearDown();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943671/fstmerge_var2_8116685435130419043

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestCustomSearcherSort.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testFieldSortMultiCustomSearcher() throws Exception {
    // log("Run testFieldSortMultiCustomSearcher");
    // define the sort criteria
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943684/fstmerge_var1_263578779312007955
    Sort custSort = new Sort(
        new SortField("publicationDate_", SortField.STRING),
        SortField.FIELD_SCORE);
    Searcher searcher = new MultiSearcher(new CustomSearcher(reader, 0), new CustomSearcher(reader, 2));
    // search and check hits
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943684/fstmerge_base_8063450530058477139
      Sort custSort = new Sort(
              new SortField("publicationDate_", SortField.STRING), 
              SortField.FIELD_SCORE
      );
      Searcher searcher = 
          new MultiSearcher(new Searchable[] {
                  new CustomSearcher (index, 0),
                  new CustomSearcher (index, 2)});
      // search and check hits
=======
    Sort custSort = new Sort(
        new SortField("publicationDate_", SortField.STRING),
        SortField.FIELD_SCORE);
    Searcher searcher = new MultiSearcher(new Searchable[] {
        new CustomSearcher(reader, 0), new CustomSearcher(reader, 2)});
    // search and check hits
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943684/fstmerge_var2_1820351095436908450
    matchHits(searcher, custSort);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestCustomSearcherSort.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943729/fstmerge_var1_1654635364260785607
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943729/fstmerge_base_3025432361921347957
public TestMultiPhraseQuery(String name) {
        super(name);
    }
=======
public TestMultiPhraseQuery(String name) {
    super(name);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943729/fstmerge_var2_5750104587572574216

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testPhrasePrefix() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943734/fstmerge_var1_805087492643684504
    Directory indexStore = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
    add("blueberry pie", writer);
    add("blueberry strudel", writer);
    add("blueberry pizza", writer);
    add("blueberry chewing gum", writer);
    add("bluebird pizza", writer);
    add("bluebird foobar pizza", writer);
    add("piccadilly circus", writer);
    
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // search for "blueberry pi*":
    MultiPhraseQuery query1 = new MultiPhraseQuery();
    // search for "strawberry pi*":
    MultiPhraseQuery query2 = new MultiPhraseQuery();
    query1.add(new Term("body", "blueberry"));
    query2.add(new Term("body", "strawberry"));
    
    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();
    
    // this TermEnum gives "piccadilly", "pie" and "pizza".
    String prefix = "pi";
    TermsEnum te = MultiFields.getFields(reader).terms("body").iterator();
    te.seek(new BytesRef(prefix));
    do {
      String s = te.term().utf8ToString();
      if (s.startsWith(prefix)) {
        termsWithPrefix.add(new Term("body", s));
      } else {
        break;
      }
    } while (te.next() != null);
    
    query1.add(termsWithPrefix.toArray(new Term[0]));
    assertEquals("body:\"blueberry (piccadilly pie pizza)\"", query1.toString());
    query2.add(termsWithPrefix.toArray(new Term[0]));
    assertEquals("body:\"strawberry (piccadilly pie pizza)\"", query2
        .toString());
    
    ScoreDoc[] result;
    result = searcher.search(query1, null, 1000).scoreDocs;
    assertEquals(2, result.length);
    result = searcher.search(query2, null, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    // search for "blue* pizza":
    MultiPhraseQuery query3 = new MultiPhraseQuery();
    termsWithPrefix.clear();
    prefix = "blue";
    te.seek(new BytesRef(prefix));
    
    do {
      if (te.term().utf8ToString().startsWith(prefix)) {
        termsWithPrefix.add(new Term("body", te.term().utf8ToString()));
      }
    } while (te.next() != null);
    
    query3.add(termsWithPrefix.toArray(new Term[0]));
    query3.add(new Term("body", "pizza"));
    
    result = searcher.search(query3, null, 1000).scoreDocs;
    assertEquals(2, result.length); // blueberry pizza, bluebird pizza
    assertEquals("body:\"(blueberry bluebird) pizza\"", query3.toString());
    
    // test slop:
    query3.setSlop(1);
    result = searcher.search(query3, null, 1000).scoreDocs;
    
    // just make sure no exc:
    searcher.explain(query3, 0);
    
    assertEquals(3, result.length); // blueberry pizza, bluebird pizza, bluebird
                                    // foobar pizza
    
    MultiPhraseQuery query4 = new MultiPhraseQuery();
    try {
      query4.add(new Term("field1", "foo"));
      query4.add(new Term("field2", "foobar"));
      fail();
    } catch (IllegalArgumentException e) {
      // okay, all terms must belong to the same field
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943734/fstmerge_base_6686599016977256203
        MockRAMDirectory indexStore = new MockRAMDirectory();
        IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
        add("blueberry pie", writer);
        add("blueberry strudel", writer);
        add("blueberry pizza", writer);
        add("blueberry chewing gum", writer);
        add("bluebird pizza", writer);
        add("bluebird foobar pizza", writer);
        add("piccadilly circus", writer);
        writer.optimize();
        writer.close();

        IndexSearcher searcher = new IndexSearcher(indexStore, true);

        // search for "blueberry pi*":
        MultiPhraseQuery query1 = new MultiPhraseQuery();
        // search for "strawberry pi*":
        MultiPhraseQuery query2 = new MultiPhraseQuery();
        query1.add(new Term("body", "blueberry"));
        query2.add(new Term("body", "strawberry"));

        LinkedList<Term> termsWithPrefix = new LinkedList<Term>();
        IndexReader ir = IndexReader.open(indexStore, true);

        // this TermEnum gives "piccadilly", "pie" and "pizza".
        String prefix = "pi";
        TermEnum te = ir.terms(new Term("body", prefix));
        do {
            if (te.term().text().startsWith(prefix))
            {
                termsWithPrefix.add(te.term());
            }
        } while (te.next());

        query1.add(termsWithPrefix.toArray(new Term[0]));
        assertEquals("body:\"blueberry (piccadilly pie pizza)\"", query1.toString());
        query2.add(termsWithPrefix.toArray(new Term[0]));
        assertEquals("body:\"strawberry (piccadilly pie pizza)\"", query2.toString());

        ScoreDoc[] result;
        result = searcher.search(query1, null, 1000).scoreDocs;
        assertEquals(2, result.length);
        result = searcher.search(query2, null, 1000).scoreDocs;
        assertEquals(0, result.length);

        // search for "blue* pizza":
        MultiPhraseQuery query3 = new MultiPhraseQuery();
        termsWithPrefix.clear();
        prefix = "blue";
        te = ir.terms(new Term("body", prefix));
        do {
            if (te.term().text().startsWith(prefix))
            {
                termsWithPrefix.add(te.term());
            }
        } while (te.next());
        ir.close();
        query3.add(termsWithPrefix.toArray(new Term[0]));
        query3.add(new Term("body", "pizza"));

        result = searcher.search(query3, null, 1000).scoreDocs;
        assertEquals(2, result.length); // blueberry pizza, bluebird pizza
        assertEquals("body:\"(blueberry bluebird) pizza\"", query3.toString());

        // test slop:
        query3.setSlop(1);
        result = searcher.search(query3, null, 1000).scoreDocs;
        assertEquals(3, result.length); // blueberry pizza, bluebird pizza, bluebird foobar pizza

        MultiPhraseQuery query4 = new MultiPhraseQuery();
        try {
          query4.add(new Term("field1", "foo"));
          query4.add(new Term("field2", "foobar"));
          fail();
        } catch(IllegalArgumentException e) {
          // okay, all terms must belong to the same field
        }
        
        searcher.close();
        indexStore.close();

=======
    MockRAMDirectory indexStore = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);
    add("blueberry pie", writer);
    add("blueberry strudel", writer);
    add("blueberry pizza", writer);
    add("blueberry chewing gum", writer);
    add("bluebird pizza", writer);
    add("bluebird foobar pizza", writer);
    add("piccadilly circus", writer);
    
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // search for "blueberry pi*":
    MultiPhraseQuery query1 = new MultiPhraseQuery();
    // search for "strawberry pi*":
    MultiPhraseQuery query2 = new MultiPhraseQuery();
    query1.add(new Term("body", "blueberry"));
    query2.add(new Term("body", "strawberry"));
    
    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();
    
    // this TermEnum gives "piccadilly", "pie" and "pizza".
    String prefix = "pi";
    TermsEnum te = MultiFields.getFields(reader).terms("body").iterator();
    te.seek(new BytesRef(prefix));
    do {
      String s = te.term().utf8ToString();
      if (s.startsWith(prefix)) {
        termsWithPrefix.add(new Term("body", s));
      } else {
        break;
      }
    } while (te.next() != null);
    
    query1.add(termsWithPrefix.toArray(new Term[0]));
    assertEquals("body:\"blueberry (piccadilly pie pizza)\"", query1.toString());
    query2.add(termsWithPrefix.toArray(new Term[0]));
    assertEquals("body:\"strawberry (piccadilly pie pizza)\"", query2
        .toString());
    
    ScoreDoc[] result;
    result = searcher.search(query1, null, 1000).scoreDocs;
    assertEquals(2, result.length);
    result = searcher.search(query2, null, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    // search for "blue* pizza":
    MultiPhraseQuery query3 = new MultiPhraseQuery();
    termsWithPrefix.clear();
    prefix = "blue";
    te.seek(new BytesRef(prefix));
    
    do {
      if (te.term().utf8ToString().startsWith(prefix)) {
        termsWithPrefix.add(new Term("body", te.term().utf8ToString()));
      }
    } while (te.next() != null);
    
    query3.add(termsWithPrefix.toArray(new Term[0]));
    query3.add(new Term("body", "pizza"));
    
    result = searcher.search(query3, null, 1000).scoreDocs;
    assertEquals(2, result.length); // blueberry pizza, bluebird pizza
    assertEquals("body:\"(blueberry bluebird) pizza\"", query3.toString());
    
    // test slop:
    query3.setSlop(1);
    result = searcher.search(query3, null, 1000).scoreDocs;
    
    // just make sure no exc:
    searcher.explain(query3, 0);
    
    assertEquals(3, result.length); // blueberry pizza, bluebird pizza, bluebird
                                    // foobar pizza
    
    MultiPhraseQuery query4 = new MultiPhraseQuery();
    try {
      query4.add(new Term("field1", "foo"));
      query4.add(new Term("field2", "foobar"));
      fail();
    } catch (IllegalArgumentException e) {
      // okay, all terms must belong to the same field
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943734/fstmerge_var2_2644167849670199361
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943734/fstmerge_var1_805087492643684504
    
    writer.close();
    searcher.close();
    reader.close();
    indexStore.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943734/fstmerge_base_6686599016977256203
=======
    
    writer.close();
    searcher.close();
    reader.close();
    indexStore.close();
    
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943734/fstmerge_var2_2644167849670199361

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943741/fstmerge_var1_1392393207943182154
private void add(String s, RandomIndexWriter writer) throws IOException {
    Document doc = new Document();
    doc.add(newField("body", s, Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943741/fstmerge_base_3833431705750732360
=======
private void add(String s, RandomIndexWriter writer) throws IOException {
    Document doc = new Document();
    doc.add(new Field("body", s, Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943741/fstmerge_var2_6406363914430652755

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943747/fstmerge_var1_6981886988808840263
public void testBooleanQueryContainingSingleTermPrefixQuery()
      throws IOException {
    // this tests against bug 33161 (now fixed)
    // In order to cause the bug, the outer query must have more than one term
    // and all terms required.
    // The contained PhraseMultiQuery must contain exactly one term array.
    Directory indexStore = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
    add("blueberry pie", writer);
    add("blueberry chewing gum", writer);
    add("blue raspberry pie", writer);
    
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    // This query will be equivalent to +body:pie +body:"blue*"
    BooleanQuery q = new BooleanQuery();
    q.add(new TermQuery(new Term("body", "pie")), BooleanClause.Occur.MUST);
    
    MultiPhraseQuery trouble = new MultiPhraseQuery();
    trouble.add(new Term[] {new Term("body", "blueberry"),
        new Term("body", "blue")});
    q.add(trouble, BooleanClause.Occur.MUST);
    
    // exception will be thrown here without fix
    ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
    
    assertEquals("Wrong number of hits", 2, hits.length);
    
    // just make sure no exc:
    searcher.explain(q, 0);
    
    writer.close();
    searcher.close();
    reader.close();
    indexStore.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943747/fstmerge_base_4247734949457877598
public void testBooleanQueryContainingSingleTermPrefixQuery() throws IOException {
      // this tests against bug 33161 (now fixed)
      // In order to cause the bug, the outer query must have more than one term 
      // and all terms required.
      // The contained PhraseMultiQuery must contain exactly one term array.

      MockRAMDirectory indexStore = new MockRAMDirectory();
      IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
      add("blueberry pie", writer);
      add("blueberry chewing gum", writer);
      add("blue raspberry pie", writer);
      writer.optimize();
      writer.close();

      IndexSearcher searcher = new IndexSearcher(indexStore, true);
      // This query will be equivalent to +body:pie +body:"blue*"
      BooleanQuery q = new BooleanQuery();
      q.add(new TermQuery(new Term("body", "pie")), BooleanClause.Occur.MUST);

      MultiPhraseQuery trouble = new MultiPhraseQuery();
      trouble.add(new Term[] {
          new Term("body", "blueberry"),
          new Term("body", "blue")
      });
      q.add(trouble, BooleanClause.Occur.MUST);

      // exception will be thrown here without fix
      ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;

      assertEquals("Wrong number of hits", 2, hits.length);
      searcher.close();
      indexStore.close();
=======
public void testBooleanQueryContainingSingleTermPrefixQuery()
      throws IOException {
    // this tests against bug 33161 (now fixed)
    // In order to cause the bug, the outer query must have more than one term
    // and all terms required.
    // The contained PhraseMultiQuery must contain exactly one term array.
    
    MockRAMDirectory indexStore = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);
    add("blueberry pie", writer);
    add("blueberry chewing gum", writer);
    add("blue raspberry pie", writer);
    
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    // This query will be equivalent to +body:pie +body:"blue*"
    BooleanQuery q = new BooleanQuery();
    q.add(new TermQuery(new Term("body", "pie")), BooleanClause.Occur.MUST);
    
    MultiPhraseQuery trouble = new MultiPhraseQuery();
    trouble.add(new Term[] {new Term("body", "blueberry"),
        new Term("body", "blue")});
    q.add(trouble, BooleanClause.Occur.MUST);
    
    // exception will be thrown here without fix
    ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
    
    assertEquals("Wrong number of hits", 2, hits.length);
    
    // just make sure no exc:
    searcher.explain(q, 0);
    
    writer.close();
    searcher.close();
    reader.close();
    indexStore.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943747/fstmerge_var2_6912872132427612101
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testPhrasePrefixWithBooleanQuery() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_var1_2210916019145949805
    Directory indexStore = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_base_7822944514935464448
    MockRAMDirectory indexStore = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    MockRAMDirectory indexStore = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_var2_4641063419960634348
    add("This is a test", "object", writer);
    add("a note", "note", writer);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_base_7822944514935464448
    writer.close();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_var2_4641063419960634348
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_base_7822944514935464448
    IndexSearcher searcher = new IndexSearcher(indexStore, true);

=======
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_var2_4641063419960634348
    // This query will be equivalent to +type:note +body:"a t*"
    BooleanQuery q = new BooleanQuery();
    q.add(new TermQuery(new Term("type", "note")), BooleanClause.Occur.MUST);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_base_7822944514935464448

=======
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_var2_4641063419960634348
    MultiPhraseQuery trouble = new MultiPhraseQuery();
    trouble.add(new Term("body", "a"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_base_7822944514935464448
    trouble.add(new Term[] { new Term("body", "test"), new Term("body", "this") });
=======
    trouble
        .add(new Term[] {new Term("body", "test"), new Term("body", "this")});
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_var2_4641063419960634348
    q.add(trouble, BooleanClause.Occur.MUST);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_base_7822944514935464448

=======
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_var2_4641063419960634348
    // exception will be thrown here without fix for #35626:
    ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
    assertEquals("Wrong number of hits", 0, hits.length);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_base_7822944514935464448
=======
    writer.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_var2_4641063419960634348
    searcher.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_base_7822944514935464448
=======
    reader.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943751/fstmerge_var2_4641063419960634348
    indexStore.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testNoDocs() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943756/fstmerge_var1_7109588156695052248
    Directory indexStore = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943756/fstmerge_base_6367362536414603036
    MockRAMDirectory indexStore = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(indexStore, new MockAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
=======
    MockRAMDirectory indexStore = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943756/fstmerge_var2_3568273455532082466
    add("a note", "note", writer);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943756/fstmerge_base_6367362536414603036
    writer.close();

    IndexSearcher searcher = new IndexSearcher(indexStore, true);

=======
    
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943756/fstmerge_var2_3568273455532082466
    MultiPhraseQuery q = new MultiPhraseQuery();
    q.add(new Term("body", "a"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943756/fstmerge_base_6367362536414603036
    q.add(new Term[] { new Term("body", "nope"), new Term("body", "nope") });
    assertEquals("Wrong number of hits", 0, searcher.search(q, null, 1).totalHits);
=======
    q.add(new Term[] {new Term("body", "nope"), new Term("body", "nope")});
    assertEquals("Wrong number of hits", 0,
        searcher.search(q, null, 1).totalHits);
    
    // just make sure no exc:
    searcher.explain(q, 0);
    
    writer.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943756/fstmerge_var2_3568273455532082466
    searcher.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943756/fstmerge_base_6367362536414603036
=======
    reader.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943756/fstmerge_var2_3568273455532082466
    indexStore.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943765/fstmerge_var1_1121165628831663121
private void add(String s, String type, RandomIndexWriter writer)
      throws IOException {
    Document doc = new Document();
    doc.add(newField("body", s, Field.Store.YES, Field.Index.ANALYZED));
    doc.add(newField("type", type, Field.Store.YES, Field.Index.NOT_ANALYZED));
    writer.addDocument(doc);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943765/fstmerge_base_8512960267360211346
=======
private void add(String s, String type, RandomIndexWriter writer)
      throws IOException {
    Document doc = new Document();
    doc.add(new Field("body", s, Field.Store.YES, Field.Index.ANALYZED));
    doc.add(new Field("type", type, Field.Store.YES, Field.Index.NOT_ANALYZED));
    writer.addDocument(doc);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943765/fstmerge_var2_8926569807496783367

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943808/fstmerge_var1_3269665512611243654
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943808/fstmerge_base_8542120551234409923
public TestTermScorer(String s)
    {
        super(s);
    }
=======
public TestTermScorer(String s) {
    super(s);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943808/fstmerge_var2_7846602486465347639

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermScorer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943812/fstmerge_var1_7169697583408073004
  public void setUp() throws Exception {
    super.setUp();
    directory = newDirectory();
    
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
    for (int i = 0; i < values.length; i++) {
      Document doc = new Document();
      doc
          .add(newField(FIELD, values[i], Field.Store.YES,
              Field.Index.ANALYZED));
      writer.addDocument(doc);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943812/fstmerge_base_5265723066244741704
    protected void setUp() throws Exception {
        super.setUp();
        directory = new RAMDirectory();

        IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
        for (int i = 0; i < values.length; i++) {
            Document doc = new Document();
            doc.add(new Field(FIELD, values[i], Field.Store.YES, Field.Index.ANALYZED));
            writer.addDocument(doc);
        }
        writer.close();
        indexSearcher = new IndexSearcher(directory, false);
        indexReader = indexSearcher.getIndexReader();


=======
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    for (int i = 0; i < values.length; i++) {
      Document doc = new Document();
      doc
          .add(new Field(FIELD, values[i], Field.Store.YES,
              Field.Index.ANALYZED));
      writer.addDocument(doc);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943812/fstmerge_var2_466110154618123260
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943812/fstmerge_var1_7169697583408073004
    indexReader = new SlowMultiReaderWrapper(writer.getReader());
    writer.close();
    indexSearcher = new IndexSearcher(indexReader);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943812/fstmerge_base_5265723066244741704
=======
    indexReader = writer.getReader();
    writer.close();
    indexSearcher = new IndexSearcher(indexReader);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943812/fstmerge_var2_466110154618123260

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermScorer.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943816/fstmerge_var1_8335559177763996134
@Override
  public void tearDown() throws Exception {
    indexSearcher.close();
    indexReader.close();
    directory.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943816/fstmerge_base_6183325147044793105
=======
@Override
  protected void tearDown() throws Exception {
    indexSearcher.close();
    indexReader.close();
    directory.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943816/fstmerge_var2_3430851695191732215

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermScorer.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testNot() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943844/fstmerge_var1_8346585740828118061
    Directory store = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, store);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943844/fstmerge_base_7059914392162254847
    RAMDirectory store = new RAMDirectory();
    IndexWriter writer = new IndexWriter(store, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    RAMDirectory store = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), store);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943844/fstmerge_var2_6198515373684256373

    Document d1 = new Document();
    d1.add(newField("field", "a b", Field.Store.YES, Field.Index.ANALYZED));

    writer.addDocument(d1);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943844/fstmerge_base_7059914392162254847
    writer.optimize();
    writer.close();
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943844/fstmerge_var2_6198515373684256373

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943844/fstmerge_base_7059914392162254847
    Searcher searcher = new IndexSearcher(store, true);
=======
    Searcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943844/fstmerge_var2_6198515373684256373
      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, "field", new MockAnalyzer());
    Query query = parser.parse("a NOT b");
    //System.out.println(query);
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943844/fstmerge_base_7059914392162254847
=======
    writer.close();
    searcher.close();
    reader.close();
    store.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627943844/fstmerge_var2_6198515373684256373
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestNot.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testMultiValuedNRQ() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944203/fstmerge_var1_6115541925319899382
    Directory directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944203/fstmerge_base_2900176031645169645
    final Random rnd = newRandom();

    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    final Random rnd = newRandom();

    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rnd, directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944203/fstmerge_var2_8346238394660021673
    
    DecimalFormat format = new DecimalFormat("00000000000", new DecimalFormatSymbols(Locale.US));
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944203/fstmerge_base_2900176031645169645
    for (int l=0; l<5000*_TestUtil.getRandomMultiplier(); l++) {
=======
    int num = 5000 * RANDOM_MULTIPLIER;
    for (int l = 0; l < num; l++) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944203/fstmerge_var2_8346238394660021673
      Document doc = new Document();
      for (int m=0, c=random.nextInt(10); m<=c; m++) {
        int value = random.nextInt(Integer.MAX_VALUE);
        doc.add(newField("asc", format.format(value), Field.Store.NO, Field.Index.NOT_ANALYZED));
        doc.add(new NumericField("trie", Field.Store.NO, true).setIntValue(value));
      }
      writer.addDocument(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944203/fstmerge_base_2900176031645169645
    }  
=======
    }
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944203/fstmerge_var2_8346238394660021673
    writer.close();
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944203/fstmerge_var1_6115541925319899382
    Searcher searcher=new IndexSearcher(reader);
    num = 50 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      int lower=random.nextInt(Integer.MAX_VALUE);
      int upper=random.nextInt(Integer.MAX_VALUE);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944203/fstmerge_base_2900176031645169645
    Searcher searcher=new IndexSearcher(directory, true);
    for (int i=0; i<50*_TestUtil.getRandomMultiplier(); i++) {
      int lower=rnd.nextInt(Integer.MAX_VALUE);
      int upper=rnd.nextInt(Integer.MAX_VALUE);
=======
    Searcher searcher=new IndexSearcher(reader);
    num = 50 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      int lower=rnd.nextInt(Integer.MAX_VALUE);
      int upper=rnd.nextInt(Integer.MAX_VALUE);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944203/fstmerge_var2_8346238394660021673
      if (lower>upper) {
        int a=lower; lower=upper; upper=a;
      }
      TermRangeQuery cq=new TermRangeQuery("asc", format.format(lower), format.format(upper), true, true);
      NumericRangeQuery<Integer> tq=NumericRangeQuery.newIntRange("trie", lower, upper, true, true);
      TopDocs trTopDocs = searcher.search(cq, 1);
      TopDocs nrTopDocs = searcher.search(tq, 1);
      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", trTopDocs.totalHits, nrTopDocs.totalHits );
    }
    searcher.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944203/fstmerge_base_2900176031645169645

=======
    reader.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944203/fstmerge_var2_8346238394660021673
    directory.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestMultiValuedNumericRangeQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testNullDocIdSet() throws Exception {
    // Tests that if a Filter produces a null DocIdSet, which is given to
    // IndexSearcher, everything works fine. This came up in LUCENE-1754.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944214/fstmerge_var1_8206691106523650252
    Directory dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944214/fstmerge_base_2591172729094016215
    Directory dir = new RAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    Directory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944214/fstmerge_var2_7461956819675878056
    Document doc = new Document();
    doc.add(newField("c", "val", Store.NO, Index.NOT_ANALYZED_NO_NORMS));
    writer.addDocument(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944214/fstmerge_base_2591172729094016215
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944214/fstmerge_var2_7461956819675878056
    writer.close();
    
    // First verify the document is searchable.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944214/fstmerge_base_2591172729094016215
    IndexSearcher searcher = new IndexSearcher(dir, true);
=======
    IndexSearcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944214/fstmerge_var2_7461956819675878056
    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);
    
    // Now search w/ a Filter which returns a null DocIdSet
    Filter f = new Filter() {
      @Override
      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {
        return null;
      }
    };
    
    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);
    searcher.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944214/fstmerge_base_2591172729094016215
=======
    reader.close();
    dir.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944214/fstmerge_var2_7461956819675878056
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDocIdSet.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944225/fstmerge_var1_4120515940262391394
public void testMethod() throws Exception {
    Directory directory = newDirectory();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944225/fstmerge_base_1321101270738184233
public void testMethod() {
    RAMDirectory directory = new RAMDirectory();
=======
public void testMethod() throws Exception {
    RAMDirectory directory = new RAMDirectory();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944225/fstmerge_var2_3137218180697570075

    String[] values = new String[] { "1", "2", "3", "4" };

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944225/fstmerge_var1_4120515940262391394
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
    for (int i = 0; i < values.length; i++) {
      Document doc = new Document();
      doc.add(newField(FIELD, values[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944225/fstmerge_base_1321101270738184233
    try {
      IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
      for (int i = 0; i < values.length; i++) {
        Document doc = new Document();
        doc.add(new Field(FIELD, values[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
        writer.addDocument(doc);
      }
      writer.close();

      BooleanQuery booleanQuery1 = new BooleanQuery();
      booleanQuery1.add(new TermQuery(new Term(FIELD, "1")), BooleanClause.Occur.SHOULD);
      booleanQuery1.add(new TermQuery(new Term(FIELD, "2")), BooleanClause.Occur.SHOULD);

      BooleanQuery query = new BooleanQuery();
      query.add(booleanQuery1, BooleanClause.Occur.MUST);
      query.add(new TermQuery(new Term(FIELD, "9")), BooleanClause.Occur.MUST_NOT);

      IndexSearcher indexSearcher = new IndexSearcher(directory, true);
      ScoreDoc[] hits = indexSearcher.search(query, null, 1000).scoreDocs;
      assertEquals("Number of matched documents", 2, hits.length);

    }
    catch (IOException e) {
      fail(e.getMessage());
=======
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    for (int i = 0; i < values.length; i++) {
      Document doc = new Document();
      doc.add(new Field(FIELD, values[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944225/fstmerge_var2_3137218180697570075
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944225/fstmerge_base_1321101270738184233
=======
    IndexReader ir = writer.getReader();
    writer.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944225/fstmerge_var2_3137218180697570075

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944225/fstmerge_base_1321101270738184233
=======
    BooleanQuery booleanQuery1 = new BooleanQuery();
    booleanQuery1.add(new TermQuery(new Term(FIELD, "1")), BooleanClause.Occur.SHOULD);
    booleanQuery1.add(new TermQuery(new Term(FIELD, "2")), BooleanClause.Occur.SHOULD);

    BooleanQuery query = new BooleanQuery();
    query.add(booleanQuery1, BooleanClause.Occur.MUST);
    query.add(new TermQuery(new Term(FIELD, "9")), BooleanClause.Occur.MUST_NOT);

    IndexSearcher indexSearcher = new IndexSearcher(ir);
    ScoreDoc[] hits = indexSearcher.search(query, null, 1000).scoreDocs;
    assertEquals("Number of matched documents", 2, hits.length);
    ir.close();
    directory.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944225/fstmerge_var2_3137218180697570075
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestBooleanScorer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944235/fstmerge_var1_6531742394766830531
    dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, 
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))
        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944235/fstmerge_base_752385037793994061
    random = newRandom();
    RAMDirectory dir = new RAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new MockAnalyzer(MockTokenizer.KEYWORD, false),
        IndexWriter.MaxFieldLength.UNLIMITED);
    
=======
    random = newRandom();
    dir = new MockRAMDirectory();
    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.
    // currently, this means 'empty tokens' arent created/tested in the enumeration:
    // <mikemccand> it's like having a big hairy scary monster in the basement but being upset that it doesn't have fangs
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944235/fstmerge_var2_1835101290171287281
    Document doc = new Document();
    Field field = newField("field", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
    doc.add(field);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944235/fstmerge_base_752385037793994061
    
    for (int i = 0; i < 2000*_TestUtil.getRandomMultiplier(); i++) {
      field.setValue(_TestUtil.randomUnicodeString(random));
=======
    List<String> terms = new ArrayList<String>();
    int num = 2000 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      String s = _TestUtil.randomUnicodeString(random);
      field.setValue(s);
      terms.add(s);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944235/fstmerge_var2_1835101290171287281
      writer.addDocument(doc);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944235/fstmerge_base_752385037793994061
=======

    if (VERBOSE) {
      // utf16 order
      Collections.sort(terms);
      System.out.println("UTF16 order:");
      for(String s : terms) {
        System.out.println("  " + UnicodeUtil.toHexString(s));
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944235/fstmerge_var2_1835101290171287281
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944235/fstmerge_base_752385037793994061
    writer.optimize();
=======
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944235/fstmerge_var2_1835101290171287281
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944235/fstmerge_base_752385037793994061
    searcher = new IndexSearcher(dir);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944235/fstmerge_var2_1835101290171287281
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestRegexpRandom2.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944240/fstmerge_var1_7565902019679394805
  public void tearDown() throws Exception {
    reader.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944240/fstmerge_base_8790703635614528841
  protected void tearDown() throws Exception {
=======
  protected void tearDown() throws Exception {
    reader.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944240/fstmerge_var2_5975160150278230421
    searcher.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944240/fstmerge_base_8790703635614528841
=======
    dir.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944240/fstmerge_var2_5975160150278230421
    super.tearDown();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestRegexpRandom2.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testRegexps() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944266/fstmerge_var1_1822345311973248421
    // we generate aweful regexps: good for testing.
    // but for preflex codec, the test can be very slow, so use less iterations.
    int num = CodecProvider.getDefault().getFieldCodec("field").equals("PreFlex") ? 100 * RANDOM_MULTIPLIER : 1000 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      String reg = AutomatonTestUtil.randomRegexp(random);
      assertSame(reg);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944266/fstmerge_base_3539825687873882261
      for (int i = 0; i < 1000*_TestUtil.getRandomMultiplier(); i++)
        assertSame(AutomatonTestUtil.randomRegexp(random).toString());
=======

    int num = 1000 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      String reg = AutomatonTestUtil.randomRegexp(random).toString();
      assertSame(reg);
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944266/fstmerge_var2_426247017376455610
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestRegexpRandom2.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testBasic() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944298/fstmerge_var1_7885251916267659743
    Directory dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944298/fstmerge_base_1398655377229390529
    Directory dir = new RAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    Directory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944298/fstmerge_var2_5041315266052227550
    Document doc = new Document();
    doc.add(newField("field", "value", Store.NO, Index.ANALYZED));
    writer.addDocument(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944298/fstmerge_base_1398655377229390529
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944298/fstmerge_var2_5041315266052227550
    writer.close();

    TermQuery termQuery = new TermQuery(new Term("field", "value"));

    // should not throw exception with primitive query
    QueryWrapperFilter qwf = new QueryWrapperFilter(termQuery);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944298/fstmerge_base_1398655377229390529
    IndexSearcher searcher = new IndexSearcher(dir, true);
=======
    IndexSearcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944298/fstmerge_var2_5041315266052227550
    TopDocs hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
    assertEquals(1, hits.totalHits);
    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
    assertEquals(1, hits.totalHits);

    // should not throw exception with complex primitive query
    BooleanQuery booleanQuery = new BooleanQuery();
    booleanQuery.add(termQuery, Occur.MUST);
    booleanQuery.add(new TermQuery(new Term("field", "missing")),
        Occur.MUST_NOT);
    qwf = new QueryWrapperFilter(termQuery);

    hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
    assertEquals(1, hits.totalHits);
    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
    assertEquals(1, hits.totalHits);

    // should not throw exception with non primitive Query (doesn't implement
    // Query#createWeight)
    qwf = new QueryWrapperFilter(new FuzzyQuery(new Term("field", "valu")));

    hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
    assertEquals(1, hits.totalHits);
    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
    assertEquals(1, hits.totalHits);

    // test a query with no hits
    termQuery = new TermQuery(new Term("field", "not_exist"));
    qwf = new QueryWrapperFilter(termQuery);
    hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
    assertEquals(0, hits.totalHits);
    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
    assertEquals(0, hits.totalHits);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944298/fstmerge_base_1398655377229390529
=======
    searcher.close();
    reader.close();
    dir.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944298/fstmerge_var2_5041315266052227550
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java
Conflict type: SameIdFd
Conflict body: 
~~FSTMerge~~ static IndexReader reader; ##FSTMerge## ##FSTMerge## IndexReader reader;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestMultiTermConstantScore.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944420/fstmerge_var1_3190601344561318331
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944420/fstmerge_base_7894176656621951036
@Override
  protected void setUp() throws Exception {
    super.setUp();

    String[] data = new String[] { "A 1 2 3 4 5 6", "Z       4 5 6", null,
        "B   2   4 5 6", "Y     3   5 6", null, "C     3     6",
        "X       4 5 6" };

    small = new RAMDirectory();
    IndexWriter writer = new IndexWriter(small, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));

    for (int i = 0; i < data.length; i++) {
      Document doc = new Document();
      doc.add(new Field("id", String.valueOf(i), Field.Store.YES,
          Field.Index.NOT_ANALYZED));// Field.Keyword("id",String.valueOf(i)));
      doc
          .add(new Field("all", "all", Field.Store.YES,
              Field.Index.NOT_ANALYZED));// Field.Keyword("all","all"));
      if (null != data[i]) {
        doc.add(new Field("data", data[i], Field.Store.YES,
            Field.Index.ANALYZED));// Field.Text("data",data[i]));
      }
      writer.addDocument(doc);
    }

    writer.optimize();
    writer.close();
  }
=======
@Override
  protected void setUp() throws Exception {
    super.setUp();
    String[] data = new String[] { "A 1 2 3 4 5 6", "Z       4 5 6", null,
        "B   2   4 5 6", "Y     3   5 6", null, "C     3     6",
        "X       4 5 6" };

    small = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, small, new MockAnalyzer(MockTokenizer.WHITESPACE, false));

    for (int i = 0; i < data.length; i++) {
      Document doc = new Document();
      doc.add(new Field("id", String.valueOf(i), Field.Store.YES,
          Field.Index.NOT_ANALYZED));// Field.Keyword("id",String.valueOf(i)));
      doc
          .add(new Field("all", "all", Field.Store.YES,
              Field.Index.NOT_ANALYZED));// Field.Keyword("all","all"));
      if (null != data[i]) {
        doc.add(new Field("data", data[i], Field.Store.YES,
            Field.Index.ANALYZED));// Field.Text("data",data[i]));
      }
      writer.addDocument(doc);
    }

    reader = writer.getReader();
    writer.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944420/fstmerge_var2_8712360562363928898

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestMultiTermConstantScore.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testFarsi() throws Exception {

    /* build an index */
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944495/fstmerge_var1_3540642306055298816
    Directory farsiIndex = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, farsiIndex, new MockAnalyzer(MockTokenizer.SIMPLE, true));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944495/fstmerge_base_2718912035095297212
    RAMDirectory farsiIndex = new RAMDirectory();
    IndexWriter writer = new IndexWriter(farsiIndex, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));
=======
    RAMDirectory farsiIndex = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, farsiIndex, new MockAnalyzer(MockTokenizer.SIMPLE, true));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944495/fstmerge_var2_1989847912628355162
    Document doc = new Document();
    doc.add(newField("content", "\u0633\u0627\u0628", Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc
        .add(newField("body", "body", Field.Store.YES,
            Field.Index.NOT_ANALYZED));
    writer.addDocument(doc);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944495/fstmerge_base_2718912035095297212
    writer.optimize();
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944495/fstmerge_var2_1989847912628355162
    writer.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944495/fstmerge_base_2718912035095297212
    IndexReader reader = IndexReader.open(farsiIndex, true);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944495/fstmerge_var2_1989847912628355162
    IndexSearcher search = new IndexSearcher(reader);

    // Neither Java 1.4.2 nor 1.5.0 has Farsi Locale collation available in
    // RuleBasedCollator. However, the Arabic Locale seems to order the Farsi
    // characters properly.
    Collator c = Collator.getInstance(new Locale("ar"));

    // Unicode order would include U+0633 in [ U+062F - U+0698 ], but Farsi
    // orders the U+0698 character before the U+0633 character, so the single
    // index Term below should NOT be returned by a ConstantScoreRangeQuery
    // with a Farsi Collator (or an Arabic one for the case when Farsi is
    // not supported).
    ScoreDoc[] result = search.search(csrq("content", "\u062F", "\u0698", T, T,
        c), null, 1000).scoreDocs;
    assertEquals("The index Term should not be included.", 0, result.length);

    result = search.search(csrq("content", "\u0633", "\u0638", T, T, c), null,
        1000).scoreDocs;
    assertEquals("The index Term should be included.", 1, result.length);
    search.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944495/fstmerge_base_2718912035095297212
=======
    reader.close();
    farsiIndex.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944495/fstmerge_var2_1989847912628355162
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestMultiTermConstantScore.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testDanish() throws Exception {

    /* build an index */
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944500/fstmerge_var1_3832570921878703049
    Directory danishIndex = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, danishIndex, new MockAnalyzer(MockTokenizer.SIMPLE, true));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944500/fstmerge_base_8748949901783434308
    RAMDirectory danishIndex = new RAMDirectory();
    IndexWriter writer = new IndexWriter(danishIndex, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));
=======
    RAMDirectory danishIndex = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, danishIndex, new MockAnalyzer(MockTokenizer.SIMPLE, true));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944500/fstmerge_var2_1724227715771076441

    // Danish collation orders the words below in the given order
    // (example taken from TestSort.testInternationalSort() ).
    String[] words = { "H\u00D8T", "H\u00C5T", "MAND" };
    for (int docnum = 0 ; docnum < words.length ; ++docnum) {   
      Document doc = new Document();
      doc.add(newField("content", words[docnum], 
                        Field.Store.YES, Field.Index.NOT_ANALYZED));
      doc.add(newField("body", "body",
                        Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944500/fstmerge_base_8748949901783434308
    writer.optimize();
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944500/fstmerge_var2_1724227715771076441
    writer.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944500/fstmerge_base_8748949901783434308
    IndexReader reader = IndexReader.open(danishIndex, true);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944500/fstmerge_var2_1724227715771076441
    IndexSearcher search = new IndexSearcher(reader);

    Collator c = Collator.getInstance(new Locale("da", "dk"));

    // Unicode order would not include "H\u00C5T" in [ "H\u00D8T", "MAND" ],
    // but Danish collation does.
    ScoreDoc[] result = search.search
      (csrq("content", "H\u00D8T", "MAND", F, F, c), null, 1000).scoreDocs;
    assertEquals("The index Term should be included.", 1, result.length);

    result = search.search
      (csrq("content", "H\u00C5T", "MAND", F, F, c), null, 1000).scoreDocs;
    assertEquals("The index Term should not be included.", 0, result.length);
    search.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944500/fstmerge_base_8748949901783434308
=======
    reader.close();
    danishIndex.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944500/fstmerge_var2_1724227715771076441
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestMultiTermConstantScore.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
    // Create an index writer.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944505/fstmerge_var1_1368348754062973493
    directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944505/fstmerge_base_5428288955628212581
    directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944505/fstmerge_var2_3541088380657447344

    // oldest doc:
    // Add the first document.  text = "Document 1"  dateTime = Oct 10 03:25:22 EDT 2007
    writer.addDocument(createDocument("Document 1", 1192001122000L));
    // Add the second document.  text = "Document 2"  dateTime = Oct 10 03:25:26 EDT 2007 
    writer.addDocument(createDocument("Document 2", 1192001126000L));
    // Add the third document.  text = "Document 3"  dateTime = Oct 11 07:12:13 EDT 2007 
    writer.addDocument(createDocument("Document 3", 1192101133000L));
    // Add the fourth document.  text = "Document 4"  dateTime = Oct 11 08:02:09 EDT 2007
    writer.addDocument(createDocument("Document 4", 1192104129000L));
    // latest doc:
    // Add the fifth document.  text = "Document 5"  dateTime = Oct 12 13:25:43 EDT 2007
    writer.addDocument(createDocument("Document 5", 1192209943000L));

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944505/fstmerge_base_5428288955628212581
    writer.optimize();
=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944505/fstmerge_var2_3541088380657447344
    writer.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDateSort.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944510/fstmerge_var1_2475835033610008665
@Override
  public void tearDown() throws Exception {
    reader.close();
    directory.close();
    super.tearDown();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944510/fstmerge_base_7386305012212962435
=======
@Override
  protected void tearDown() throws Exception {
    reader.close();
    directory.close();
    super.tearDown();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944510/fstmerge_var2_3062643452898581784

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDateSort.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
    
    // populate an index with 30 documents, this should be enough for the test.
    // The documents have no content - the test uses MatchAllDocsQuery().
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944587/fstmerge_var1_4512359349276237851
    dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944587/fstmerge_base_1676484289276444654
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944587/fstmerge_var2_8495903873093610182
    for (int i = 0; i < 30; i++) {
      writer.addDocument(new Document());
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944587/fstmerge_base_1676484289276444654
=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944587/fstmerge_var2_8495903873093610182
    writer.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTopDocsCollector.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944592/fstmerge_var1_6118944597477131832
  public void tearDown() throws Exception {
    reader.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944592/fstmerge_base_3827120844934037470
  protected void tearDown() throws Exception {
=======
  protected void tearDown() throws Exception {
    reader.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944592/fstmerge_var2_2047840470857825695
    dir.close();
    dir = null;
    super.tearDown();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTopDocsCollector.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
    final String docText[] = {
        "docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero",
        "one blah three",
        "one foo three multiOne",
        "one foobar three multiThree",
        "blueberry pancakes",
        "blueberry pie",
        "blueberry strudel",
        "blueberry pizza",
    };
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944744/fstmerge_var1_58535465001592050
    directory = newDirectory();
    RandomIndexWriter iw = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944744/fstmerge_base_8321546004337392327
    Directory directory = new RAMDirectory();
    IndexWriter iw = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    directory = new RAMDirectory();
    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944744/fstmerge_var2_7165421360992401581
    
    for (int i=0; i<N_DOCS; i++) {
      add(docText[i%docText.length], iw);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944744/fstmerge_base_8321546004337392327
=======
    reader = iw.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944744/fstmerge_var2_7165421360992401581
    iw.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944744/fstmerge_base_8321546004337392327
    searcher = new IndexSearcher(directory, true);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944744/fstmerge_var2_7165421360992401581

    String qtxt = "one";
    // start from 1, so that the 0th doc never matches
    for (int i = 1; i < docText.length; i++) {
      qtxt += ' ' + docText[i]; // large query so that search will be longer
    }
    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());
    query = queryParser.parse(qtxt);
    
    // warm the searcher
    searcher.search(query, null, 1000);

  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944753/fstmerge_var1_4103116173122976880
private void add(String value, RandomIndexWriter iw) throws IOException {
    Document d = new Document();
    d.add(newField(FIELD_NAME, value, Field.Store.NO, Field.Index.ANALYZED));
    iw.addDocument(d);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944753/fstmerge_base_6086622844499125379
=======
private void add(String value, RandomIndexWriter iw) throws IOException {
    Document d = new Document();
    d.add(new Field(FIELD_NAME, value, Field.Store.NO, Field.Index.ANALYZED));
    iw.addDocument(d);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944753/fstmerge_var2_5475219525444438108

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void beforeClass() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944843/fstmerge_var1_1096706803784596098
    directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944843/fstmerge_base_4229911479635641387
    directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    directory = new RAMDirectory();
    Random random = newStaticRandom(TestNumericRangeQuery32.class);
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944843/fstmerge_var2_7090329404388180637
    
    NumericField
      field8 = new NumericField("field8", 8, Field.Store.YES, true),
      field4 = new NumericField("field4", 4, Field.Store.YES, true),
      field2 = new NumericField("field2", 2, Field.Store.YES, true),
      fieldNoTrie = new NumericField("field"+Integer.MAX_VALUE, Integer.MAX_VALUE, Field.Store.YES, true),
      ascfield8 = new NumericField("ascfield8", 8, Field.Store.NO, true),
      ascfield4 = new NumericField("ascfield4", 4, Field.Store.NO, true),
      ascfield2 = new NumericField("ascfield2", 2, Field.Store.NO, true);
    
    Document doc = new Document();
    // add fields, that have a distance to test general functionality
    doc.add(field8); doc.add(field4); doc.add(field2); doc.add(fieldNoTrie);
    // add ascending fields with a distance of 1, beginning at -noDocs/2 to test the correct splitting of range and inclusive/exclusive
    doc.add(ascfield8); doc.add(ascfield4); doc.add(ascfield2);
    
    // Add a series of noDocs docs with increasing int values
    for (int l=0; l<noDocs; l++) {
      int val=distance*l+startOffset;
      field8.setIntValue(val);
      field4.setIntValue(val);
      field2.setIntValue(val);
      fieldNoTrie.setIntValue(val);

      val=l-(noDocs/2);
      ascfield8.setIntValue(val);
      ascfield4.setIntValue(val);
      ascfield2.setIntValue(val);
      writer.addDocument(doc);
    }
  
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944843/fstmerge_base_4229911479635641387
    writer.optimize();
=======
    reader = writer.getReader();
    searcher=new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944843/fstmerge_var2_7090329404388180637
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944843/fstmerge_base_4229911479635641387
    searcher=new IndexSearcher(directory, true);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944843/fstmerge_var2_7090329404388180637
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java
Conflict type: LineBasedMCFd
Conflict body: 
private void testRandomTrieAndClassicRangeQuery(int precisionStep) throws Exception {
    String field="field"+precisionStep;
    int termCountT=0,termCountC=0;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944929/fstmerge_var1_7938099364318404655
    int num = 10 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      int lower=(int)(random.nextDouble()*noDocs*distance)+startOffset;
      int upper=(int)(random.nextDouble()*noDocs*distance)+startOffset;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944929/fstmerge_base_3624771099809911052
    for (int i=0; i<10*_TestUtil.getRandomMultiplier(); i++) {
      int lower=(int)(rnd.nextDouble()*noDocs*distance)+startOffset;
      int upper=(int)(rnd.nextDouble()*noDocs*distance)+startOffset;
=======
    int num = 10 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      int lower=(int)(rnd.nextDouble()*noDocs*distance)+startOffset;
      int upper=(int)(rnd.nextDouble()*noDocs*distance)+startOffset;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944929/fstmerge_var2_4394510884121745672
      if (lower>upper) {
        int a=lower; lower=upper; upper=a;
      }
      final BytesRef lowerBytes = new BytesRef(NumericUtils.BUF_SIZE_INT), upperBytes = new BytesRef(NumericUtils.BUF_SIZE_INT);
      NumericUtils.intToPrefixCoded(lower, 0, lowerBytes);
      NumericUtils.intToPrefixCoded(upper, 0, upperBytes);
      // TODO: when new TermRange ctors with BytesRef available, use them and do not convert to string!
      final String lowerString = lowerBytes.utf8ToString(), upperString = upperBytes.utf8ToString();

      // test inclusive range
      NumericRangeQuery<Integer> tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, true);
      TermRangeQuery cq=new TermRangeQuery(field, lowerString, upperString, true, true);
      TopDocs tTopDocs = searcher.search(tq, 1);
      TopDocs cTopDocs = searcher.search(cq, 1);
      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
      termCountT += tq.getTotalNumberOfTerms();
      termCountC += cq.getTotalNumberOfTerms();
      // test exclusive range
      tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, false, false);
      cq=new TermRangeQuery(field, lowerString, upperString, false, false);
      tTopDocs = searcher.search(tq, 1);
      cTopDocs = searcher.search(cq, 1);
      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
      termCountT += tq.getTotalNumberOfTerms();
      termCountC += cq.getTotalNumberOfTerms();
      // test left exclusive range
      tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, false, true);
      cq=new TermRangeQuery(field, lowerString, upperString, false, true);
      tTopDocs = searcher.search(tq, 1);
      cTopDocs = searcher.search(cq, 1);
      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
      termCountT += tq.getTotalNumberOfTerms();
      termCountC += cq.getTotalNumberOfTerms();
      // test right exclusive range
      tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, false);
      cq=new TermRangeQuery(field, lowerString, upperString, true, false);
      tTopDocs = searcher.search(tq, 1);
      cTopDocs = searcher.search(cq, 1);
      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
      termCountT += tq.getTotalNumberOfTerms();
      termCountC += cq.getTotalNumberOfTerms();
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944929/fstmerge_base_3624771099809911052
    if (precisionStep == Integer.MAX_VALUE) {
=======
    if (precisionStep == Integer.MAX_VALUE && searcher.getIndexReader().getSequentialSubReaders().length == 1) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944929/fstmerge_var2_4394510884121745672
      assertEquals("Total number of terms should be equal for unlimited precStep", termCountT, termCountC);
    } else if (VERBOSE) {
      System.out.println("Average number of terms during random search on '" + field + "':");
      System.out.println(" Trie query: " + (((double)termCountT)/(num * 4)));
      System.out.println(" Classical query: " + (((double)termCountC)/(num * 4)));
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java
Conflict type: LineBasedMCFd
Conflict body: 
private void testRangeSplit(int precisionStep) throws Exception {
    String field="ascfield"+precisionStep;
    // 10 random tests
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944953/fstmerge_var1_7936820810611125653
    int  num = 10 * RANDOM_MULTIPLIER;
    for (int  i =0;  i< num; i++) {
      int lower=(int)(random.nextDouble()*noDocs - noDocs/2);
      int upper=(int)(random.nextDouble()*noDocs - noDocs/2);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944953/fstmerge_base_1429285307413504114
    for (int i=0; i<10*_TestUtil.getRandomMultiplier(); i++) {
      int lower=(int)(rnd.nextDouble()*noDocs - noDocs/2);
      int upper=(int)(rnd.nextDouble()*noDocs - noDocs/2);
=======
    int  num = 10 * RANDOM_MULTIPLIER;
    for (int  i =0;  i< num; i++) {
      int lower=(int)(rnd.nextDouble()*noDocs - noDocs/2);
      int upper=(int)(rnd.nextDouble()*noDocs - noDocs/2);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944953/fstmerge_var2_2778579382629781947
      if (lower>upper) {
        int a=lower; lower=upper; upper=a;
      }
      // test inclusive range
      Query tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, true);
      TopDocs tTopDocs = searcher.search(tq, 1);
      assertEquals("Returned count of range query must be equal to inclusive range length", upper-lower+1, tTopDocs.totalHits );
      // test exclusive range
      tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, false, false);
      tTopDocs = searcher.search(tq, 1);
      assertEquals("Returned count of range query must be equal to exclusive range length", Math.max(upper-lower-1, 0), tTopDocs.totalHits );
      // test left exclusive range
      tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, false, true);
      tTopDocs = searcher.search(tq, 1);
      assertEquals("Returned count of range query must be equal to half exclusive range length", upper-lower, tTopDocs.totalHits );
      // test right exclusive range
      tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, false);
      tTopDocs = searcher.search(tq, 1);
      assertEquals("Returned count of range query must be equal to half exclusive range length", upper-lower, tTopDocs.totalHits );
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java
Conflict type: LineBasedMCFd
Conflict body: 
private void testSorting(int precisionStep) throws Exception {
    String field="field"+precisionStep;
    // 10 random tests, the index order is ascending,
    // so using a reverse sort field should retun descending documents
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944989/fstmerge_var1_3784028589946312543
    int num = 10 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      int lower=(int)(random.nextDouble()*noDocs*distance)+startOffset;
      int upper=(int)(random.nextDouble()*noDocs*distance)+startOffset;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944989/fstmerge_base_3579714892765690656
    for (int i=0; i<10*_TestUtil.getRandomMultiplier(); i++) {
      int lower=(int)(rnd.nextDouble()*noDocs*distance)+startOffset;
      int upper=(int)(rnd.nextDouble()*noDocs*distance)+startOffset;
=======
    int num = 10 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      int lower=(int)(rnd.nextDouble()*noDocs*distance)+startOffset;
      int upper=(int)(rnd.nextDouble()*noDocs*distance)+startOffset;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627944989/fstmerge_var2_1490286418631641504
      if (lower>upper) {
        int a=lower; lower=upper; upper=a;
      }
      Query tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, true);
      TopDocs topDocs = searcher.search(tq, null, noDocs, new Sort(new SortField(field, SortField.INT, true)));
      if (topDocs.totalHits==0) continue;
      ScoreDoc[] sd = topDocs.scoreDocs;
      assertNotNull(sd);
      int last=Integer.parseInt(searcher.doc(sd[0].doc).get(field));
      for (int j=1; j<sd.length; j++) {
        int act=Integer.parseInt(searcher.doc(sd[j].doc).get(field));
        assertTrue("Docs should be sorted backwards", last>act );
        last=act;
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testNullOrSubScorer() throws Throwable {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945354/fstmerge_var1_2413371725035214242
    Directory dir = newDirectory();
    RandomIndexWriter w = new RandomIndexWriter(random, dir);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945354/fstmerge_base_4563614493156294212
    Directory dir = new MockRAMDirectory();
    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    Directory dir = new MockRAMDirectory();
    RandomIndexWriter w = new RandomIndexWriter(newRandom(), dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945354/fstmerge_var2_1110225456918788026
    Document doc = new Document();
    doc.add(newField("field", "a b c d", Field.Store.NO, Field.Index.ANALYZED));
    w.addDocument(doc);

    IndexReader r = w.getReader();
    IndexSearcher s = new IndexSearcher(r);
    BooleanQuery q = new BooleanQuery();
    q.add(new TermQuery(new Term("field", "a")), BooleanClause.Occur.SHOULD);

    // LUCENE-2617: make sure that a term not in the index still contributes to the score via coord factor
    float score = s.search(q, 10).getMaxScore();
    Query subQuery = new TermQuery(new Term("field", "not_in_index"));
    subQuery.setBoost(0);
    q.add(subQuery, BooleanClause.Occur.SHOULD);
    float score2 = s.search(q, 10).getMaxScore();
    assertEquals(score*.5, score2, 1e-6);

    // LUCENE-2617: make sure that a clause not in the index still contributes to the score via coord factor
    BooleanQuery qq = (BooleanQuery)q.clone();
    PhraseQuery phrase = new PhraseQuery();
    phrase.add(new Term("field", "not_in_index"));
    phrase.add(new Term("field", "another_not_in_index"));
    phrase.setBoost(0);
    qq.add(phrase, BooleanClause.Occur.SHOULD);
    score2 = s.search(qq, 10).getMaxScore();
    assertEquals(score*(1.0/3), score2, 1e-6);

    // now test BooleanScorer2
    subQuery = new TermQuery(new Term("field", "b"));
    subQuery.setBoost(0);
    q.add(subQuery, BooleanClause.Occur.MUST);
    score2 = s.search(q, 10).getMaxScore();
    assertEquals(score*(2.0/3), score2, 1e-6);
 
    // PhraseQuery w/ no terms added returns a null scorer
    PhraseQuery pq = new PhraseQuery();
    q.add(pq, BooleanClause.Occur.SHOULD);
    assertEquals(1, s.search(q, 10).totalHits);

    // A required clause which returns null scorer should return null scorer to
    // IndexSearcher.
    q = new BooleanQuery();
    pq = new PhraseQuery();
    q.add(new TermQuery(new Term("field", "a")), BooleanClause.Occur.SHOULD);
    q.add(pq, BooleanClause.Occur.MUST);
    assertEquals(0, s.search(q, 10).totalHits);

    DisjunctionMaxQuery dmq = new DisjunctionMaxQuery(1.0f);
    dmq.add(new TermQuery(new Term("field", "a")));
    dmq.add(pq);
    assertEquals(1, s.search(dmq, 10).totalHits);
    
    r.close();
    w.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestBooleanQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void assertFromTestData(int codePointTable[]) throws Exception {
    InputStream stream = getClass().getResourceAsStream("fuzzyTestData.txt");
    BufferedReader reader = new BufferedReader(new InputStreamReader(stream, "UTF-8"));
    
    int bits = Integer.parseInt(reader.readLine());
    int terms = (int) Math.pow(2, bits);
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945404/fstmerge_var1_7718127317010183111
    Directory dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945404/fstmerge_base_3582273936459203681
    RAMDirectory dir = new RAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new MockAnalyzer(MockTokenizer.KEYWORD, false),
        IndexWriter.MaxFieldLength.UNLIMITED);
=======
    RAMDirectory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945404/fstmerge_var2_8180841454109005591
    
    Document doc = new Document();
    Field field = newField("field", "", Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field);
    
    for (int i = 0; i < terms; i++) {
      field.setValue(mapInt(codePointTable, i));
      writer.addDocument(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945404/fstmerge_base_3582273936459203681
    }
    
    writer.optimize();
    writer.close();   
=======
    }   
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945404/fstmerge_var2_8180841454109005591
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945404/fstmerge_base_3582273936459203681
    IndexSearcher searcher = new IndexSearcher(dir);
=======
    IndexReader r = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(r);
    writer.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945404/fstmerge_var2_8180841454109005591
    String line;
    while ((line = reader.readLine()) != null) {
      String params[] = line.split(",");
      String query = mapInt(codePointTable, Integer.parseInt(params[0]));
      int prefix = Integer.parseInt(params[1]);
      int pqSize = Integer.parseInt(params[2]);
      float minScore = Float.parseFloat(params[3]);
      FuzzyQuery q = new FuzzyQuery(new Term("field", query), minScore, prefix);
      q.setRewriteMethod(new MultiTermQuery.TopTermsBoostOnlyBooleanQueryRewrite(pqSize));
      int expectedResults = Integer.parseInt(reader.readLine());
      TopDocs docs = searcher.search(q, expectedResults);
      assertEquals(expectedResults, docs.totalHits);
      for (int i = 0; i < expectedResults; i++) {
        String scoreDoc[] = reader.readLine().split(",");
        assertEquals(Integer.parseInt(scoreDoc[0]), docs.scoreDocs[i].doc);
        assertEquals(Float.parseFloat(scoreDoc[1]), docs.scoreDocs[i].score, epsilon);
      }
    }
    searcher.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945404/fstmerge_base_3582273936459203681
=======
    r.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945404/fstmerge_var2_8180841454109005591
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestFuzzyQuery2.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945430/fstmerge_var1_5640177113945391164
@Test
  public void testRangeFilterId() throws IOException {
    
    IndexReader reader = signedIndexReader;
    IndexSearcher search = new IndexSearcher(reader);
    
    int medId = ((maxId - minId) / 2);
    
    String minIP = pad(minId);
    String maxIP = pad(maxId);
    String medIP = pad(medId);
    
    int numDocs = reader.numDocs();
    
    assertEquals("num of docs", numDocs, 1 + maxId - minId);
    
    ScoreDoc[] result;
    Query q = new TermQuery(new Term("body", "body"));
    
    // test id, bounded on both ends
    
    result = search.search(q, new TermRangeFilter("id", minIP, maxIP, T, T),
        numDocs).scoreDocs;
    assertEquals("find all", numDocs, result.length);
    
    result = search.search(q, new TermRangeFilter("id", minIP, maxIP, T, F),
        numDocs).scoreDocs;
    assertEquals("all but last", numDocs - 1, result.length);
    
    result = search.search(q, new TermRangeFilter("id", minIP, maxIP, F, T),
        numDocs).scoreDocs;
    assertEquals("all but first", numDocs - 1, result.length);
    
    result = search.search(q, new TermRangeFilter("id", minIP, maxIP, F, F),
        numDocs).scoreDocs;
    assertEquals("all but ends", numDocs - 2, result.length);
    
    result = search.search(q, new TermRangeFilter("id", medIP, maxIP, T, T),
        numDocs).scoreDocs;
    assertEquals("med and up", 1 + maxId - medId, result.length);
    
    result = search.search(q, new TermRangeFilter("id", minIP, medIP, T, T),
        numDocs).scoreDocs;
    assertEquals("up to med", 1 + medId - minId, result.length);
    
    // unbounded id
    
    result = search.search(q, new TermRangeFilter("id", minIP, null, T, F),
        numDocs).scoreDocs;
    assertEquals("min and up", numDocs, result.length);
    
    result = search.search(q, new TermRangeFilter("id", null, maxIP, F, T),
        numDocs).scoreDocs;
    assertEquals("max and down", numDocs, result.length);
    
    result = search.search(q, new TermRangeFilter("id", minIP, null, F, F),
        numDocs).scoreDocs;
    assertEquals("not min, but up", numDocs - 1, result.length);
    
    result = search.search(q, new TermRangeFilter("id", null, maxIP, F, F),
        numDocs).scoreDocs;
    assertEquals("not max, but down", numDocs - 1, result.length);
    
    result = search.search(q, new TermRangeFilter("id", medIP, maxIP, T, F),
        numDocs).scoreDocs;
    assertEquals("med and up, not max", maxId - medId, result.length);
    
    result = search.search(q, new TermRangeFilter("id", minIP, medIP, F, T),
        numDocs).scoreDocs;
    assertEquals("not min, up to med", medId - minId, result.length);
    
    // very small sets
    
    result = search.search(q, new TermRangeFilter("id", minIP, minIP, F, F),
        numDocs).scoreDocs;
    assertEquals("min,min,F,F", 0, result.length);
    result = search.search(q, new TermRangeFilter("id", medIP, medIP, F, F),
        numDocs).scoreDocs;
    assertEquals("med,med,F,F", 0, result.length);
    result = search.search(q, new TermRangeFilter("id", maxIP, maxIP, F, F),
        numDocs).scoreDocs;
    assertEquals("max,max,F,F", 0, result.length);
    
    result = search.search(q, new TermRangeFilter("id", minIP, minIP, T, T),
        numDocs).scoreDocs;
    assertEquals("min,min,T,T", 1, result.length);
    result = search.search(q, new TermRangeFilter("id", null, minIP, F, T),
        numDocs).scoreDocs;
    assertEquals("nul,min,F,T", 1, result.length);
    
    result = search.search(q, new TermRangeFilter("id", maxIP, maxIP, T, T),
        numDocs).scoreDocs;
    assertEquals("max,max,T,T", 1, result.length);
    result = search.search(q, new TermRangeFilter("id", maxIP, null, T, F),
        numDocs).scoreDocs;
    assertEquals("max,nul,T,T", 1, result.length);
    
    result = search.search(q, new TermRangeFilter("id", medIP, medIP, T, T),
        numDocs).scoreDocs;
    assertEquals("med,med,T,T", 1, result.length);
    
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945430/fstmerge_base_3563829850399820737
public void testRangeFilterId() throws IOException {

        IndexReader reader = IndexReader.open(signedIndex.index, true);
	IndexSearcher search = new IndexSearcher(reader);

        int medId = ((maxId - minId) / 2);
        
        String minIP = pad(minId);
        String maxIP = pad(maxId);
        String medIP = pad(medId);
    
        int numDocs = reader.numDocs();
        
        assertEquals("num of docs", numDocs, 1+ maxId - minId);
        
  ScoreDoc[] result;
        Query q = new TermQuery(new Term("body","body"));

        // test id, bounded on both ends
        
  result = search.search(q,new TermRangeFilter("id",minIP,maxIP,T,T), numDocs).scoreDocs;
  assertEquals("find all", numDocs, result.length);

  result = search.search(q,new TermRangeFilter("id",minIP,maxIP,T,F), numDocs).scoreDocs;
  assertEquals("all but last", numDocs-1, result.length);

  result = search.search(q,new TermRangeFilter("id",minIP,maxIP,F,T), numDocs).scoreDocs;
  assertEquals("all but first", numDocs-1, result.length);
        
  result = search.search(q,new TermRangeFilter("id",minIP,maxIP,F,F), numDocs).scoreDocs;
        assertEquals("all but ends", numDocs-2, result.length);
    
        result = search.search(q,new TermRangeFilter("id",medIP,maxIP,T,T), numDocs).scoreDocs;
        assertEquals("med and up", 1+ maxId-medId, result.length);
        
        result = search.search(q,new TermRangeFilter("id",minIP,medIP,T,T), numDocs).scoreDocs;
        assertEquals("up to med", 1+ medId-minId, result.length);

        // unbounded id

  result = search.search(q,new TermRangeFilter("id",minIP,null,T,F), numDocs).scoreDocs;
  assertEquals("min and up", numDocs, result.length);

  result = search.search(q,new TermRangeFilter("id",null,maxIP,F,T), numDocs).scoreDocs;
  assertEquals("max and down", numDocs, result.length);

  result = search.search(q,new TermRangeFilter("id",minIP,null,F,F), numDocs).scoreDocs;
  assertEquals("not min, but up", numDocs-1, result.length);
        
  result = search.search(q,new TermRangeFilter("id",null,maxIP,F,F), numDocs).scoreDocs;
  assertEquals("not max, but down", numDocs-1, result.length);
        
        result = search.search(q,new TermRangeFilter("id",medIP,maxIP,T,F), numDocs).scoreDocs;
        assertEquals("med and up, not max", maxId-medId, result.length);
        
        result = search.search(q,new TermRangeFilter("id",minIP,medIP,F,T), numDocs).scoreDocs;
        assertEquals("not min, up to med", medId-minId, result.length);

        // very small sets

  result = search.search(q,new TermRangeFilter("id",minIP,minIP,F,F), numDocs).scoreDocs;
  assertEquals("min,min,F,F", 0, result.length);
  result = search.search(q,new TermRangeFilter("id",medIP,medIP,F,F), numDocs).scoreDocs;
  assertEquals("med,med,F,F", 0, result.length);
  result = search.search(q,new TermRangeFilter("id",maxIP,maxIP,F,F), numDocs).scoreDocs;
  assertEquals("max,max,F,F", 0, result.length);
                     
  result = search.search(q,new TermRangeFilter("id",minIP,minIP,T,T), numDocs).scoreDocs;
  assertEquals("min,min,T,T", 1, result.length);
  result = search.search(q,new TermRangeFilter("id",null,minIP,F,T), numDocs).scoreDocs;
  assertEquals("nul,min,F,T", 1, result.length);

  result = search.search(q,new TermRangeFilter("id",maxIP,maxIP,T,T), numDocs).scoreDocs;
  assertEquals("max,max,T,T", 1, result.length);
  result = search.search(q,new TermRangeFilter("id",maxIP,null,T,F), numDocs).scoreDocs;
  assertEquals("max,nul,T,T", 1, result.length);

  result = search.search(q,new TermRangeFilter("id",medIP,medIP,T,T), numDocs).scoreDocs;
  assertEquals("med,med,T,T", 1, result.length);
        
    }
=======
public void testRangeFilterId() throws IOException {
    
    IndexReader reader = signedIndexReader;
    IndexSearcher search = new IndexSearcher(reader);
    
    int medId = ((maxId - minId) / 2);
    
    String minIP = pad(minId);
    String maxIP = pad(maxId);
    String medIP = pad(medId);
    
    int numDocs = reader.numDocs();
    
    assertEquals("num of docs", numDocs, 1 + maxId - minId);
    
    ScoreDoc[] result;
    Query q = new TermQuery(new Term("body", "body"));
    
    // test id, bounded on both ends
    
    result = search.search(q, new TermRangeFilter("id", minIP, maxIP, T, T),
        numDocs).scoreDocs;
    assertEquals("find all", numDocs, result.length);
    
    result = search.search(q, new TermRangeFilter("id", minIP, maxIP, T, F),
        numDocs).scoreDocs;
    assertEquals("all but last", numDocs - 1, result.length);
    
    result = search.search(q, new TermRangeFilter("id", minIP, maxIP, F, T),
        numDocs).scoreDocs;
    assertEquals("all but first", numDocs - 1, result.length);
    
    result = search.search(q, new TermRangeFilter("id", minIP, maxIP, F, F),
        numDocs).scoreDocs;
    assertEquals("all but ends", numDocs - 2, result.length);
    
    result = search.search(q, new TermRangeFilter("id", medIP, maxIP, T, T),
        numDocs).scoreDocs;
    assertEquals("med and up", 1 + maxId - medId, result.length);
    
    result = search.search(q, new TermRangeFilter("id", minIP, medIP, T, T),
        numDocs).scoreDocs;
    assertEquals("up to med", 1 + medId - minId, result.length);
    
    // unbounded id
    
    result = search.search(q, new TermRangeFilter("id", minIP, null, T, F),
        numDocs).scoreDocs;
    assertEquals("min and up", numDocs, result.length);
    
    result = search.search(q, new TermRangeFilter("id", null, maxIP, F, T),
        numDocs).scoreDocs;
    assertEquals("max and down", numDocs, result.length);
    
    result = search.search(q, new TermRangeFilter("id", minIP, null, F, F),
        numDocs).scoreDocs;
    assertEquals("not min, but up", numDocs - 1, result.length);
    
    result = search.search(q, new TermRangeFilter("id", null, maxIP, F, F),
        numDocs).scoreDocs;
    assertEquals("not max, but down", numDocs - 1, result.length);
    
    result = search.search(q, new TermRangeFilter("id", medIP, maxIP, T, F),
        numDocs).scoreDocs;
    assertEquals("med and up, not max", maxId - medId, result.length);
    
    result = search.search(q, new TermRangeFilter("id", minIP, medIP, F, T),
        numDocs).scoreDocs;
    assertEquals("not min, up to med", medId - minId, result.length);
    
    // very small sets
    
    result = search.search(q, new TermRangeFilter("id", minIP, minIP, F, F),
        numDocs).scoreDocs;
    assertEquals("min,min,F,F", 0, result.length);
    result = search.search(q, new TermRangeFilter("id", medIP, medIP, F, F),
        numDocs).scoreDocs;
    assertEquals("med,med,F,F", 0, result.length);
    result = search.search(q, new TermRangeFilter("id", maxIP, maxIP, F, F),
        numDocs).scoreDocs;
    assertEquals("max,max,F,F", 0, result.length);
    
    result = search.search(q, new TermRangeFilter("id", minIP, minIP, T, T),
        numDocs).scoreDocs;
    assertEquals("min,min,T,T", 1, result.length);
    result = search.search(q, new TermRangeFilter("id", null, minIP, F, T),
        numDocs).scoreDocs;
    assertEquals("nul,min,F,T", 1, result.length);
    
    result = search.search(q, new TermRangeFilter("id", maxIP, maxIP, T, T),
        numDocs).scoreDocs;
    assertEquals("max,max,T,T", 1, result.length);
    result = search.search(q, new TermRangeFilter("id", maxIP, null, T, F),
        numDocs).scoreDocs;
    assertEquals("max,nul,T,T", 1, result.length);
    
    result = search.search(q, new TermRangeFilter("id", medIP, medIP, T, T),
        numDocs).scoreDocs;
    assertEquals("med,med,T,T", 1, result.length);
    
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945430/fstmerge_var2_2171951631477735428

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermRangeFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945439/fstmerge_var1_5768380489816253808
@Test
  public void testRangeFilterIdCollating() throws IOException {
    
    IndexReader reader = signedIndexReader;
    IndexSearcher search = new IndexSearcher(reader);
    
    Collator c = Collator.getInstance(Locale.ENGLISH);
    
    int medId = ((maxId - minId) / 2);
    
    String minIP = pad(minId);
    String maxIP = pad(maxId);
    String medIP = pad(medId);
    
    int numDocs = reader.numDocs();
    
    assertEquals("num of docs", numDocs, 1 + maxId - minId);
    
    Query q = new TermQuery(new Term("body", "body"));
    
    // test id, bounded on both ends
    int numHits = search.search(q, new TermRangeFilter("id", minIP, maxIP, T,
        T, c), 1000).totalHits;
    assertEquals("find all", numDocs, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", minIP, maxIP, T, F, c), 1000).totalHits;
    assertEquals("all but last", numDocs - 1, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", minIP, maxIP, F, T, c), 1000).totalHits;
    assertEquals("all but first", numDocs - 1, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", minIP, maxIP, F, F, c), 1000).totalHits;
    assertEquals("all but ends", numDocs - 2, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", medIP, maxIP, T, T, c), 1000).totalHits;
    assertEquals("med and up", 1 + maxId - medId, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", minIP, medIP, T, T, c), 1000).totalHits;
    assertEquals("up to med", 1 + medId - minId, numHits);
    
    // unbounded id
    
    numHits = search.search(q, new TermRangeFilter("id", minIP, null, T, F, c),
        1000).totalHits;
    assertEquals("min and up", numDocs, numHits);
    
    numHits = search.search(q, new TermRangeFilter("id", null, maxIP, F, T, c),
        1000).totalHits;
    assertEquals("max and down", numDocs, numHits);
    
    numHits = search.search(q, new TermRangeFilter("id", minIP, null, F, F, c),
        1000).totalHits;
    assertEquals("not min, but up", numDocs - 1, numHits);
    
    numHits = search.search(q, new TermRangeFilter("id", null, maxIP, F, F, c),
        1000).totalHits;
    assertEquals("not max, but down", numDocs - 1, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", medIP, maxIP, T, F, c), 1000).totalHits;
    assertEquals("med and up, not max", maxId - medId, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", minIP, medIP, F, T, c), 1000).totalHits;
    assertEquals("not min, up to med", medId - minId, numHits);
    
    // very small sets
    
    numHits = search.search(q,
        new TermRangeFilter("id", minIP, minIP, F, F, c), 1000).totalHits;
    assertEquals("min,min,F,F", 0, numHits);
    numHits = search.search(q,
        new TermRangeFilter("id", medIP, medIP, F, F, c), 1000).totalHits;
    assertEquals("med,med,F,F", 0, numHits);
    numHits = search.search(q,
        new TermRangeFilter("id", maxIP, maxIP, F, F, c), 1000).totalHits;
    assertEquals("max,max,F,F", 0, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", minIP, minIP, T, T, c), 1000).totalHits;
    assertEquals("min,min,T,T", 1, numHits);
    numHits = search.search(q, new TermRangeFilter("id", null, minIP, F, T, c),
        1000).totalHits;
    assertEquals("nul,min,F,T", 1, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", maxIP, maxIP, T, T, c), 1000).totalHits;
    assertEquals("max,max,T,T", 1, numHits);
    numHits = search.search(q, new TermRangeFilter("id", maxIP, null, T, F, c),
        1000).totalHits;
    assertEquals("max,nul,T,T", 1, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", medIP, medIP, T, T, c), 1000).totalHits;
    assertEquals("med,med,T,T", 1, numHits);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945439/fstmerge_base_1129476082652782916
public void testRangeFilterIdCollating() throws IOException {

        IndexReader reader = IndexReader.open(signedIndex.index, true);
        IndexSearcher search = new IndexSearcher(reader);

        Collator c = Collator.getInstance(Locale.ENGLISH);

        int medId = ((maxId - minId) / 2);

        String minIP = pad(minId);
        String maxIP = pad(maxId);
        String medIP = pad(medId);

        int numDocs = reader.numDocs();

        assertEquals("num of docs", numDocs, 1+ maxId - minId);

        Query q = new TermQuery(new Term("body","body"));

        // test id, bounded on both ends
        int numHits = search.search(q,new TermRangeFilter("id",minIP,maxIP,T,T,c), 1000).totalHits;
        assertEquals("find all", numDocs, numHits);

        numHits = search.search(q,new TermRangeFilter("id",minIP,maxIP,T,F,c), 1000).totalHits;
        assertEquals("all but last", numDocs-1, numHits);

        numHits = search.search(q,new TermRangeFilter("id",minIP,maxIP,F,T,c), 1000).totalHits;
        assertEquals("all but first", numDocs-1, numHits);

        numHits = search.search(q,new TermRangeFilter("id",minIP,maxIP,F,F,c), 1000).totalHits;
        assertEquals("all but ends", numDocs-2, numHits);

        numHits = search.search(q,new TermRangeFilter("id",medIP,maxIP,T,T,c), 1000).totalHits;
        assertEquals("med and up", 1+ maxId-medId, numHits);

        numHits = search.search(q,new TermRangeFilter("id",minIP,medIP,T,T,c), 1000).totalHits;
        assertEquals("up to med", 1+ medId-minId, numHits);

        // unbounded id

        numHits = search.search(q,new TermRangeFilter("id",minIP,null,T,F,c), 1000).totalHits;
        assertEquals("min and up", numDocs, numHits);

        numHits = search.search(q,new TermRangeFilter("id",null,maxIP,F,T,c), 1000).totalHits;
        assertEquals("max and down", numDocs, numHits);

        numHits = search.search(q,new TermRangeFilter("id",minIP,null,F,F,c), 1000).totalHits;
        assertEquals("not min, but up", numDocs-1, numHits);

        numHits = search.search(q,new TermRangeFilter("id",null,maxIP,F,F,c), 1000).totalHits;
        assertEquals("not max, but down", numDocs-1, numHits);

        numHits = search.search(q,new TermRangeFilter("id",medIP,maxIP,T,F,c), 1000).totalHits;
        assertEquals("med and up, not max", maxId-medId, numHits);

        numHits = search.search(q,new TermRangeFilter("id",minIP,medIP,F,T,c), 1000).totalHits;
        assertEquals("not min, up to med", medId-minId, numHits);

        // very small sets

        numHits = search.search(q,new TermRangeFilter("id",minIP,minIP,F,F,c), 1000).totalHits;
        assertEquals("min,min,F,F", 0, numHits);
        numHits = search.search(q,new TermRangeFilter("id",medIP,medIP,F,F,c), 1000).totalHits;
        assertEquals("med,med,F,F", 0, numHits);
        numHits = search.search(q,new TermRangeFilter("id",maxIP,maxIP,F,F,c), 1000).totalHits;
        assertEquals("max,max,F,F", 0, numHits);

        numHits = search.search(q,new TermRangeFilter("id",minIP,minIP,T,T,c), 1000).totalHits;
        assertEquals("min,min,T,T", 1, numHits);
        numHits = search.search(q,new TermRangeFilter("id",null,minIP,F,T,c), 1000).totalHits;
        assertEquals("nul,min,F,T", 1, numHits);

        numHits = search.search(q,new TermRangeFilter("id",maxIP,maxIP,T,T,c), 1000).totalHits;
        assertEquals("max,max,T,T", 1, numHits);
        numHits = search.search(q,new TermRangeFilter("id",maxIP,null,T,F,c), 1000).totalHits;
        assertEquals("max,nul,T,T", 1, numHits);

        numHits = search.search(q,new TermRangeFilter("id",medIP,medIP,T,T,c), 1000).totalHits;
        assertEquals("med,med,T,T", 1, numHits);
    }
=======
public void testRangeFilterIdCollating() throws IOException {
    
    IndexReader reader = signedIndexReader;
    IndexSearcher search = new IndexSearcher(reader);
    
    Collator c = Collator.getInstance(Locale.ENGLISH);
    
    int medId = ((maxId - minId) / 2);
    
    String minIP = pad(minId);
    String maxIP = pad(maxId);
    String medIP = pad(medId);
    
    int numDocs = reader.numDocs();
    
    assertEquals("num of docs", numDocs, 1 + maxId - minId);
    
    Query q = new TermQuery(new Term("body", "body"));
    
    // test id, bounded on both ends
    int numHits = search.search(q, new TermRangeFilter("id", minIP, maxIP, T,
        T, c), 1000).totalHits;
    assertEquals("find all", numDocs, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", minIP, maxIP, T, F, c), 1000).totalHits;
    assertEquals("all but last", numDocs - 1, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", minIP, maxIP, F, T, c), 1000).totalHits;
    assertEquals("all but first", numDocs - 1, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", minIP, maxIP, F, F, c), 1000).totalHits;
    assertEquals("all but ends", numDocs - 2, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", medIP, maxIP, T, T, c), 1000).totalHits;
    assertEquals("med and up", 1 + maxId - medId, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", minIP, medIP, T, T, c), 1000).totalHits;
    assertEquals("up to med", 1 + medId - minId, numHits);
    
    // unbounded id
    
    numHits = search.search(q, new TermRangeFilter("id", minIP, null, T, F, c),
        1000).totalHits;
    assertEquals("min and up", numDocs, numHits);
    
    numHits = search.search(q, new TermRangeFilter("id", null, maxIP, F, T, c),
        1000).totalHits;
    assertEquals("max and down", numDocs, numHits);
    
    numHits = search.search(q, new TermRangeFilter("id", minIP, null, F, F, c),
        1000).totalHits;
    assertEquals("not min, but up", numDocs - 1, numHits);
    
    numHits = search.search(q, new TermRangeFilter("id", null, maxIP, F, F, c),
        1000).totalHits;
    assertEquals("not max, but down", numDocs - 1, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", medIP, maxIP, T, F, c), 1000).totalHits;
    assertEquals("med and up, not max", maxId - medId, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", minIP, medIP, F, T, c), 1000).totalHits;
    assertEquals("not min, up to med", medId - minId, numHits);
    
    // very small sets
    
    numHits = search.search(q,
        new TermRangeFilter("id", minIP, minIP, F, F, c), 1000).totalHits;
    assertEquals("min,min,F,F", 0, numHits);
    numHits = search.search(q,
        new TermRangeFilter("id", medIP, medIP, F, F, c), 1000).totalHits;
    assertEquals("med,med,F,F", 0, numHits);
    numHits = search.search(q,
        new TermRangeFilter("id", maxIP, maxIP, F, F, c), 1000).totalHits;
    assertEquals("max,max,F,F", 0, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", minIP, minIP, T, T, c), 1000).totalHits;
    assertEquals("min,min,T,T", 1, numHits);
    numHits = search.search(q, new TermRangeFilter("id", null, minIP, F, T, c),
        1000).totalHits;
    assertEquals("nul,min,F,T", 1, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", maxIP, maxIP, T, T, c), 1000).totalHits;
    assertEquals("max,max,T,T", 1, numHits);
    numHits = search.search(q, new TermRangeFilter("id", maxIP, null, T, F, c),
        1000).totalHits;
    assertEquals("max,nul,T,T", 1, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("id", medIP, medIP, T, T, c), 1000).totalHits;
    assertEquals("med,med,T,T", 1, numHits);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945439/fstmerge_var2_1947858452556804105

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermRangeFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945448/fstmerge_var1_1332353497672160181
@Test
  public void testRangeFilterRand() throws IOException {
    
    IndexReader reader = signedIndexReader;
    IndexSearcher search = new IndexSearcher(reader);
    
    String minRP = pad(signedIndexDir.minR);
    String maxRP = pad(signedIndexDir.maxR);
    
    int numDocs = reader.numDocs();
    
    assertEquals("num of docs", numDocs, 1 + maxId - minId);
    
    ScoreDoc[] result;
    Query q = new TermQuery(new Term("body", "body"));
    
    // test extremes, bounded on both ends
    
    result = search.search(q, new TermRangeFilter("rand", minRP, maxRP, T, T),
        numDocs).scoreDocs;
    assertEquals("find all", numDocs, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", minRP, maxRP, T, F),
        numDocs).scoreDocs;
    assertEquals("all but biggest", numDocs - 1, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", minRP, maxRP, F, T),
        numDocs).scoreDocs;
    assertEquals("all but smallest", numDocs - 1, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", minRP, maxRP, F, F),
        numDocs).scoreDocs;
    assertEquals("all but extremes", numDocs - 2, result.length);
    
    // unbounded
    
    result = search.search(q, new TermRangeFilter("rand", minRP, null, T, F),
        numDocs).scoreDocs;
    assertEquals("smallest and up", numDocs, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", null, maxRP, F, T),
        numDocs).scoreDocs;
    assertEquals("biggest and down", numDocs, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", minRP, null, F, F),
        numDocs).scoreDocs;
    assertEquals("not smallest, but up", numDocs - 1, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", null, maxRP, F, F),
        numDocs).scoreDocs;
    assertEquals("not biggest, but down", numDocs - 1, result.length);
    
    // very small sets
    
    result = search.search(q, new TermRangeFilter("rand", minRP, minRP, F, F),
        numDocs).scoreDocs;
    assertEquals("min,min,F,F", 0, result.length);
    result = search.search(q, new TermRangeFilter("rand", maxRP, maxRP, F, F),
        numDocs).scoreDocs;
    assertEquals("max,max,F,F", 0, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", minRP, minRP, T, T),
        numDocs).scoreDocs;
    assertEquals("min,min,T,T", 1, result.length);
    result = search.search(q, new TermRangeFilter("rand", null, minRP, F, T),
        numDocs).scoreDocs;
    assertEquals("nul,min,F,T", 1, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", maxRP, maxRP, T, T),
        numDocs).scoreDocs;
    assertEquals("max,max,T,T", 1, result.length);
    result = search.search(q, new TermRangeFilter("rand", maxRP, null, T, F),
        numDocs).scoreDocs;
    assertEquals("max,nul,T,T", 1, result.length);
    
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945448/fstmerge_base_2157520448895272580
public void testRangeFilterRand() throws IOException {

  IndexReader reader = IndexReader.open(signedIndex.index, true);
	IndexSearcher search = new IndexSearcher(reader);

        String minRP = pad(signedIndex.minR);
        String maxRP = pad(signedIndex.maxR);
    
        int numDocs = reader.numDocs();
        
        assertEquals("num of docs", numDocs, 1+ maxId - minId);
        
  ScoreDoc[] result;
        Query q = new TermQuery(new Term("body","body"));

        // test extremes, bounded on both ends
        
  result = search.search(q,new TermRangeFilter("rand",minRP,maxRP,T,T), numDocs).scoreDocs;
  assertEquals("find all", numDocs, result.length);

  result = search.search(q,new TermRangeFilter("rand",minRP,maxRP,T,F), numDocs).scoreDocs;
  assertEquals("all but biggest", numDocs-1, result.length);

  result = search.search(q,new TermRangeFilter("rand",minRP,maxRP,F,T), numDocs).scoreDocs;
  assertEquals("all but smallest", numDocs-1, result.length);
        
  result = search.search(q,new TermRangeFilter("rand",minRP,maxRP,F,F), numDocs).scoreDocs;
        assertEquals("all but extremes", numDocs-2, result.length);
    
        // unbounded

  result = search.search(q,new TermRangeFilter("rand",minRP,null,T,F), numDocs).scoreDocs;
  assertEquals("smallest and up", numDocs, result.length);

  result = search.search(q,new TermRangeFilter("rand",null,maxRP,F,T), numDocs).scoreDocs;
  assertEquals("biggest and down", numDocs, result.length);

  result = search.search(q,new TermRangeFilter("rand",minRP,null,F,F), numDocs).scoreDocs;
  assertEquals("not smallest, but up", numDocs-1, result.length);
        
  result = search.search(q,new TermRangeFilter("rand",null,maxRP,F,F), numDocs).scoreDocs;
  assertEquals("not biggest, but down", numDocs-1, result.length);
        
        // very small sets

  result = search.search(q,new TermRangeFilter("rand",minRP,minRP,F,F), numDocs).scoreDocs;
  assertEquals("min,min,F,F", 0, result.length);
  result = search.search(q,new TermRangeFilter("rand",maxRP,maxRP,F,F), numDocs).scoreDocs;
  assertEquals("max,max,F,F", 0, result.length);
                     
  result = search.search(q,new TermRangeFilter("rand",minRP,minRP,T,T), numDocs).scoreDocs;
  assertEquals("min,min,T,T", 1, result.length);
  result = search.search(q,new TermRangeFilter("rand",null,minRP,F,T), numDocs).scoreDocs;
  assertEquals("nul,min,F,T", 1, result.length);

  result = search.search(q,new TermRangeFilter("rand",maxRP,maxRP,T,T), numDocs).scoreDocs;
  assertEquals("max,max,T,T", 1, result.length);
  result = search.search(q,new TermRangeFilter("rand",maxRP,null,T,F), numDocs).scoreDocs;
  assertEquals("max,nul,T,T", 1, result.length);
        
    }
=======
public void testRangeFilterRand() throws IOException {
    
    IndexReader reader = signedIndexReader;
    IndexSearcher search = new IndexSearcher(reader);
    
    String minRP = pad(signedIndexDir.minR);
    String maxRP = pad(signedIndexDir.maxR);
    
    int numDocs = reader.numDocs();
    
    assertEquals("num of docs", numDocs, 1 + maxId - minId);
    
    ScoreDoc[] result;
    Query q = new TermQuery(new Term("body", "body"));
    
    // test extremes, bounded on both ends
    
    result = search.search(q, new TermRangeFilter("rand", minRP, maxRP, T, T),
        numDocs).scoreDocs;
    assertEquals("find all", numDocs, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", minRP, maxRP, T, F),
        numDocs).scoreDocs;
    assertEquals("all but biggest", numDocs - 1, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", minRP, maxRP, F, T),
        numDocs).scoreDocs;
    assertEquals("all but smallest", numDocs - 1, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", minRP, maxRP, F, F),
        numDocs).scoreDocs;
    assertEquals("all but extremes", numDocs - 2, result.length);
    
    // unbounded
    
    result = search.search(q, new TermRangeFilter("rand", minRP, null, T, F),
        numDocs).scoreDocs;
    assertEquals("smallest and up", numDocs, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", null, maxRP, F, T),
        numDocs).scoreDocs;
    assertEquals("biggest and down", numDocs, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", minRP, null, F, F),
        numDocs).scoreDocs;
    assertEquals("not smallest, but up", numDocs - 1, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", null, maxRP, F, F),
        numDocs).scoreDocs;
    assertEquals("not biggest, but down", numDocs - 1, result.length);
    
    // very small sets
    
    result = search.search(q, new TermRangeFilter("rand", minRP, minRP, F, F),
        numDocs).scoreDocs;
    assertEquals("min,min,F,F", 0, result.length);
    result = search.search(q, new TermRangeFilter("rand", maxRP, maxRP, F, F),
        numDocs).scoreDocs;
    assertEquals("max,max,F,F", 0, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", minRP, minRP, T, T),
        numDocs).scoreDocs;
    assertEquals("min,min,T,T", 1, result.length);
    result = search.search(q, new TermRangeFilter("rand", null, minRP, F, T),
        numDocs).scoreDocs;
    assertEquals("nul,min,F,T", 1, result.length);
    
    result = search.search(q, new TermRangeFilter("rand", maxRP, maxRP, T, T),
        numDocs).scoreDocs;
    assertEquals("max,max,T,T", 1, result.length);
    result = search.search(q, new TermRangeFilter("rand", maxRP, null, T, F),
        numDocs).scoreDocs;
    assertEquals("max,nul,T,T", 1, result.length);
    
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945448/fstmerge_var2_1040759259344876927

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermRangeFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945455/fstmerge_var1_2117681916501059913
@Test
  public void testRangeFilterRandCollating() throws IOException {
    
    // using the unsigned index because collation seems to ignore hyphens
    IndexReader reader = unsignedIndexReader;
    IndexSearcher search = new IndexSearcher(reader);
    
    Collator c = Collator.getInstance(Locale.ENGLISH);
    
    String minRP = pad(unsignedIndexDir.minR);
    String maxRP = pad(unsignedIndexDir.maxR);
    
    int numDocs = reader.numDocs();
    
    assertEquals("num of docs", numDocs, 1 + maxId - minId);
    
    Query q = new TermQuery(new Term("body", "body"));
    
    // test extremes, bounded on both ends
    
    int numHits = search.search(q, new TermRangeFilter("rand", minRP, maxRP, T,
        T, c), 1000).totalHits;
    assertEquals("find all", numDocs, numHits);
    
    numHits = search.search(q, new TermRangeFilter("rand", minRP, maxRP, T, F,
        c), 1000).totalHits;
    assertEquals("all but biggest", numDocs - 1, numHits);
    
    numHits = search.search(q, new TermRangeFilter("rand", minRP, maxRP, F, T,
        c), 1000).totalHits;
    assertEquals("all but smallest", numDocs - 1, numHits);
    
    numHits = search.search(q, new TermRangeFilter("rand", minRP, maxRP, F, F,
        c), 1000).totalHits;
    assertEquals("all but extremes", numDocs - 2, numHits);
    
    // unbounded
    
    numHits = search.search(q,
        new TermRangeFilter("rand", minRP, null, T, F, c), 1000).totalHits;
    assertEquals("smallest and up", numDocs, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("rand", null, maxRP, F, T, c), 1000).totalHits;
    assertEquals("biggest and down", numDocs, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("rand", minRP, null, F, F, c), 1000).totalHits;
    assertEquals("not smallest, but up", numDocs - 1, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("rand", null, maxRP, F, F, c), 1000).totalHits;
    assertEquals("not biggest, but down", numDocs - 1, numHits);
    
    // very small sets
    
    numHits = search.search(q, new TermRangeFilter("rand", minRP, minRP, F, F,
        c), 1000).totalHits;
    assertEquals("min,min,F,F", 0, numHits);
    numHits = search.search(q, new TermRangeFilter("rand", maxRP, maxRP, F, F,
        c), 1000).totalHits;
    assertEquals("max,max,F,F", 0, numHits);
    
    numHits = search.search(q, new TermRangeFilter("rand", minRP, minRP, T, T,
        c), 1000).totalHits;
    assertEquals("min,min,T,T", 1, numHits);
    numHits = search.search(q,
        new TermRangeFilter("rand", null, minRP, F, T, c), 1000).totalHits;
    assertEquals("nul,min,F,T", 1, numHits);
    
    numHits = search.search(q, new TermRangeFilter("rand", maxRP, maxRP, T, T,
        c), 1000).totalHits;
    assertEquals("max,max,T,T", 1, numHits);
    numHits = search.search(q,
        new TermRangeFilter("rand", maxRP, null, T, F, c), 1000).totalHits;
    assertEquals("max,nul,T,T", 1, numHits);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945455/fstmerge_base_969131898738438341
public void testRangeFilterRandCollating() throws IOException {

        // using the unsigned index because collation seems to ignore hyphens
        IndexReader reader = IndexReader.open(unsignedIndex.index, true);
        IndexSearcher search = new IndexSearcher(reader);

        Collator c = Collator.getInstance(Locale.ENGLISH);

        String minRP = pad(unsignedIndex.minR);
        String maxRP = pad(unsignedIndex.maxR);

        int numDocs = reader.numDocs();

        assertEquals("num of docs", numDocs, 1+ maxId - minId);

        Query q = new TermQuery(new Term("body","body"));

        // test extremes, bounded on both ends

        int numHits = search.search(q,new TermRangeFilter("rand",minRP,maxRP,T,T,c), 1000).totalHits;
        assertEquals("find all", numDocs, numHits);

        numHits = search.search(q,new TermRangeFilter("rand",minRP,maxRP,T,F,c), 1000).totalHits;
        assertEquals("all but biggest", numDocs-1, numHits);

        numHits = search.search(q,new TermRangeFilter("rand",minRP,maxRP,F,T,c), 1000).totalHits;
        assertEquals("all but smallest", numDocs-1, numHits);

        numHits = search.search(q,new TermRangeFilter("rand",minRP,maxRP,F,F,c), 1000).totalHits;
        assertEquals("all but extremes", numDocs-2, numHits);

        // unbounded

        numHits = search.search(q,new TermRangeFilter("rand",minRP,null,T,F,c), 1000).totalHits;
        assertEquals("smallest and up", numDocs, numHits);

        numHits = search.search(q,new TermRangeFilter("rand",null,maxRP,F,T,c), 1000).totalHits;
        assertEquals("biggest and down", numDocs, numHits);

        numHits = search.search(q,new TermRangeFilter("rand",minRP,null,F,F,c), 1000).totalHits;
        assertEquals("not smallest, but up", numDocs-1, numHits);

        numHits = search.search(q,new TermRangeFilter("rand",null,maxRP,F,F,c), 1000).totalHits;
        assertEquals("not biggest, but down", numDocs-1, numHits);

        // very small sets

        numHits = search.search(q,new TermRangeFilter("rand",minRP,minRP,F,F,c), 1000).totalHits;
        assertEquals("min,min,F,F", 0, numHits);
        numHits = search.search(q,new TermRangeFilter("rand",maxRP,maxRP,F,F,c), 1000).totalHits;
        assertEquals("max,max,F,F", 0, numHits);

        numHits = search.search(q,new TermRangeFilter("rand",minRP,minRP,T,T,c), 1000).totalHits;
        assertEquals("min,min,T,T", 1, numHits);
        numHits = search.search(q,new TermRangeFilter("rand",null,minRP,F,T,c), 1000).totalHits;
        assertEquals("nul,min,F,T", 1, numHits);

        numHits = search.search(q,new TermRangeFilter("rand",maxRP,maxRP,T,T,c), 1000).totalHits;
        assertEquals("max,max,T,T", 1, numHits);
        numHits = search.search(q,new TermRangeFilter("rand",maxRP,null,T,F,c), 1000).totalHits;
        assertEquals("max,nul,T,T", 1, numHits);
    }
=======
public void testRangeFilterRandCollating() throws IOException {
    
    // using the unsigned index because collation seems to ignore hyphens
    IndexReader reader = unsignedIndexReader;
    IndexSearcher search = new IndexSearcher(reader);
    
    Collator c = Collator.getInstance(Locale.ENGLISH);
    
    String minRP = pad(unsignedIndexDir.minR);
    String maxRP = pad(unsignedIndexDir.maxR);
    
    int numDocs = reader.numDocs();
    
    assertEquals("num of docs", numDocs, 1 + maxId - minId);
    
    Query q = new TermQuery(new Term("body", "body"));
    
    // test extremes, bounded on both ends
    
    int numHits = search.search(q, new TermRangeFilter("rand", minRP, maxRP, T,
        T, c), 1000).totalHits;
    assertEquals("find all", numDocs, numHits);
    
    numHits = search.search(q, new TermRangeFilter("rand", minRP, maxRP, T, F,
        c), 1000).totalHits;
    assertEquals("all but biggest", numDocs - 1, numHits);
    
    numHits = search.search(q, new TermRangeFilter("rand", minRP, maxRP, F, T,
        c), 1000).totalHits;
    assertEquals("all but smallest", numDocs - 1, numHits);
    
    numHits = search.search(q, new TermRangeFilter("rand", minRP, maxRP, F, F,
        c), 1000).totalHits;
    assertEquals("all but extremes", numDocs - 2, numHits);
    
    // unbounded
    
    numHits = search.search(q,
        new TermRangeFilter("rand", minRP, null, T, F, c), 1000).totalHits;
    assertEquals("smallest and up", numDocs, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("rand", null, maxRP, F, T, c), 1000).totalHits;
    assertEquals("biggest and down", numDocs, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("rand", minRP, null, F, F, c), 1000).totalHits;
    assertEquals("not smallest, but up", numDocs - 1, numHits);
    
    numHits = search.search(q,
        new TermRangeFilter("rand", null, maxRP, F, F, c), 1000).totalHits;
    assertEquals("not biggest, but down", numDocs - 1, numHits);
    
    // very small sets
    
    numHits = search.search(q, new TermRangeFilter("rand", minRP, minRP, F, F,
        c), 1000).totalHits;
    assertEquals("min,min,F,F", 0, numHits);
    numHits = search.search(q, new TermRangeFilter("rand", maxRP, maxRP, F, F,
        c), 1000).totalHits;
    assertEquals("max,max,F,F", 0, numHits);
    
    numHits = search.search(q, new TermRangeFilter("rand", minRP, minRP, T, T,
        c), 1000).totalHits;
    assertEquals("min,min,T,T", 1, numHits);
    numHits = search.search(q,
        new TermRangeFilter("rand", null, minRP, F, T, c), 1000).totalHits;
    assertEquals("nul,min,F,T", 1, numHits);
    
    numHits = search.search(q, new TermRangeFilter("rand", maxRP, maxRP, T, T,
        c), 1000).totalHits;
    assertEquals("max,max,T,T", 1, numHits);
    numHits = search.search(q,
        new TermRangeFilter("rand", maxRP, null, T, F, c), 1000).totalHits;
    assertEquals("max,nul,T,T", 1, numHits);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945455/fstmerge_var2_2527486383105098106

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermRangeFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945462/fstmerge_var1_7337392041002418222
@Test
  public void testFarsi() throws Exception {
    
    /* build an index */
    Directory farsiIndex = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, farsiIndex);
    Document doc = new Document();
    doc.add(newField("content", "\u0633\u0627\u0628", Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc
        .add(newField("body", "body", Field.Store.YES,
            Field.Index.NOT_ANALYZED));
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    writer.close();
    
    IndexSearcher search = new IndexSearcher(reader);
    Query q = new TermQuery(new Term("body", "body"));
    
    // Neither Java 1.4.2 nor 1.5.0 has Farsi Locale collation available in
    // RuleBasedCollator. However, the Arabic Locale seems to order the Farsi
    // characters properly.
    Collator collator = Collator.getInstance(new Locale("ar"));
    
    // Unicode order would include U+0633 in [ U+062F - U+0698 ], but Farsi
    // orders the U+0698 character before the U+0633 character, so the single
    // index Term below should NOT be returned by a TermRangeFilter with a Farsi
    // Collator (or an Arabic one for the case when Farsi is not supported).
    int numHits = search.search(q, new TermRangeFilter("content", "\u062F",
        "\u0698", T, T, collator), 1000).totalHits;
    assertEquals("The index Term should not be included.", 0, numHits);
    
    numHits = search.search(q, new TermRangeFilter("content", "\u0633",
        "\u0638", T, T, collator), 1000).totalHits;
    assertEquals("The index Term should be included.", 1, numHits);
    search.close();
    reader.close();
    farsiIndex.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945462/fstmerge_base_4601479069303950356
public void testFarsi() throws Exception {
            
        /* build an index */
      RAMDirectory farsiIndex = new RAMDirectory();
      IndexWriter writer = new IndexWriter(farsiIndex, new IndexWriterConfig(
          TEST_VERSION_CURRENT, new MockAnalyzer()));
        Document doc = new Document();
        doc.add(new Field("content","\u0633\u0627\u0628", 
                          Field.Store.YES, Field.Index.NOT_ANALYZED));
        doc.add(new Field("body", "body",
                          Field.Store.YES, Field.Index.NOT_ANALYZED));
        writer.addDocument(doc);
            
        writer.optimize();
        writer.close();

        IndexReader reader = IndexReader.open(farsiIndex, true);
        IndexSearcher search = new IndexSearcher(reader);
        Query q = new TermQuery(new Term("body","body"));

        // Neither Java 1.4.2 nor 1.5.0 has Farsi Locale collation available in
        // RuleBasedCollator.  However, the Arabic Locale seems to order the Farsi
        // characters properly.
        Collator collator = Collator.getInstance(new Locale("ar"));
        
        // Unicode order would include U+0633 in [ U+062F - U+0698 ], but Farsi
        // orders the U+0698 character before the U+0633 character, so the single
        // index Term below should NOT be returned by a TermRangeFilter with a Farsi
        // Collator (or an Arabic one for the case when Farsi is not supported).
        int numHits = search.search
            (q, new TermRangeFilter("content", "\u062F", "\u0698", T, T, collator), 1000).totalHits;
        assertEquals("The index Term should not be included.", 0, numHits);

        numHits = search.search
            (q, new TermRangeFilter("content", "\u0633", "\u0638", T, T, collator), 1000).totalHits;
        assertEquals("The index Term should be included.", 1, numHits);
        search.close();
    }
=======
public void testFarsi() throws Exception {
    
    /* build an index */
    RAMDirectory farsiIndex = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, farsiIndex);
    Document doc = new Document();
    doc.add(new Field("content", "\u0633\u0627\u0628", Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc
        .add(new Field("body", "body", Field.Store.YES,
            Field.Index.NOT_ANALYZED));
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    writer.close();
    
    IndexSearcher search = new IndexSearcher(reader);
    Query q = new TermQuery(new Term("body", "body"));
    
    // Neither Java 1.4.2 nor 1.5.0 has Farsi Locale collation available in
    // RuleBasedCollator. However, the Arabic Locale seems to order the Farsi
    // characters properly.
    Collator collator = Collator.getInstance(new Locale("ar"));
    
    // Unicode order would include U+0633 in [ U+062F - U+0698 ], but Farsi
    // orders the U+0698 character before the U+0633 character, so the single
    // index Term below should NOT be returned by a TermRangeFilter with a Farsi
    // Collator (or an Arabic one for the case when Farsi is not supported).
    int numHits = search.search(q, new TermRangeFilter("content", "\u062F",
        "\u0698", T, T, collator), 1000).totalHits;
    assertEquals("The index Term should not be included.", 0, numHits);
    
    numHits = search.search(q, new TermRangeFilter("content", "\u0633",
        "\u0638", T, T, collator), 1000).totalHits;
    assertEquals("The index Term should be included.", 1, numHits);
    search.close();
    reader.close();
    farsiIndex.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945462/fstmerge_var2_3075738680983116454

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermRangeFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945469/fstmerge_var1_8658931694006079454
@Test
  public void testDanish() throws Exception {
    
    /* build an index */
    Directory danishIndex = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, danishIndex);
    // Danish collation orders the words below in the given order
    // (example taken from TestSort.testInternationalSort() ).
    String[] words = {"H\u00D8T", "H\u00C5T", "MAND"};
    for (int docnum = 0; docnum < words.length; ++docnum) {
      Document doc = new Document();
      doc.add(newField("content", words[docnum], Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      doc.add(newField("body", "body", Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945469/fstmerge_base_3703558386394602675
public void testDanish() throws Exception {
            
        /* build an index */
        RAMDirectory danishIndex = new RAMDirectory();
        IndexWriter writer = new IndexWriter(danishIndex, new IndexWriterConfig(
            TEST_VERSION_CURRENT, new MockAnalyzer()));
        // Danish collation orders the words below in the given order
        // (example taken from TestSort.testInternationalSort() ).
        String[] words = { "H\u00D8T", "H\u00C5T", "MAND" };
        for (int docnum = 0 ; docnum < words.length ; ++docnum) {   
            Document doc = new Document();
            doc.add(new Field("content", words[docnum], 
                              Field.Store.YES, Field.Index.NOT_ANALYZED));
            doc.add(new Field("body", "body",
                              Field.Store.YES, Field.Index.NOT_ANALYZED));
            writer.addDocument(doc);
        }
        writer.optimize();
        writer.close();

        IndexReader reader = IndexReader.open(danishIndex, true);
        IndexSearcher search = new IndexSearcher(reader);
        Query q = new TermQuery(new Term("body","body"));

        Collator collator = Collator.getInstance(new Locale("da", "dk"));

        // Unicode order would not include "H\u00C5T" in [ "H\u00D8T", "MAND" ],
        // but Danish collation does.
        int numHits = search.search
            (q, new TermRangeFilter("content", "H\u00D8T", "MAND", F, F, collator), 1000).totalHits;
        assertEquals("The index Term should be included.", 1, numHits);

        numHits = search.search
            (q, new TermRangeFilter("content", "H\u00C5T", "MAND", F, F, collator), 1000).totalHits;
        assertEquals
            ("The index Term should not be included.", 0, numHits);
        search.close();
=======
public void testDanish() throws Exception {
    
    /* build an index */
    RAMDirectory danishIndex = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, danishIndex);
    // Danish collation orders the words below in the given order
    // (example taken from TestSort.testInternationalSort() ).
    String[] words = {"H\u00D8T", "H\u00C5T", "MAND"};
    for (int docnum = 0; docnum < words.length; ++docnum) {
      Document doc = new Document();
      doc.add(new Field("content", words[docnum], Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      doc.add(new Field("body", "body", Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945469/fstmerge_var2_4961571691988244829
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945469/fstmerge_base_3703558386394602675
=======
    IndexReader reader = writer.getReader();
    writer.close();
    
    IndexSearcher search = new IndexSearcher(reader);
    Query q = new TermQuery(new Term("body", "body"));
    
    Collator collator = Collator.getInstance(new Locale("da", "dk"));
    
    // Unicode order would not include "H\u00C5T" in [ "H\u00D8T", "MAND" ],
    // but Danish collation does.
    int numHits = search.search(q, new TermRangeFilter("content", "H\u00D8T",
        "MAND", F, F, collator), 1000).totalHits;
    assertEquals("The index Term should be included.", 1, numHits);
    
    numHits = search.search(q, new TermRangeFilter("content", "H\u00C5T",
        "MAND", F, F, collator), 1000).totalHits;
    assertEquals("The index Term should not be included.", 0, numHits);
    search.close();
    reader.close();
    danishIndex.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945469/fstmerge_var2_4961571691988244829

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTermRangeFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945476/fstmerge_var1_7138544323967302739
    dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945476/fstmerge_base_943777856058117240
    RAMDirectory dir = new RAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new MockAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);
=======
    random = newRandom();
    dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945476/fstmerge_var2_6044795724992405168
    
    Document doc = new Document();
    Field field = newField("field", "", Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field);
    
    NumberFormat df = new DecimalFormat("0000", new DecimalFormatSymbols(Locale.ENGLISH));
    for (int i = 0; i < 10000; i++) {
      field.setValue(df.format(i));
      writer.addDocument(doc);
    }
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945476/fstmerge_base_943777856058117240
    writer.optimize();
=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945476/fstmerge_var2_6044795724992405168
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945476/fstmerge_base_943777856058117240
    searcher = new IndexSearcher(dir);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945476/fstmerge_var2_6044795724992405168
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestRegexpRandom.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945509/fstmerge_var1_3690242537971788381
    directory = newDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945509/fstmerge_base_5458470809761881932
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer= new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945509/fstmerge_var2_8840066367207630938
    for (int i = 0; i < docFields.length; i++) {
      Document doc = new Document();
      doc.add(newField(KEY, ""+i, Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(newField(FIELD, docFields[i], Field.Store.NO, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945509/fstmerge_base_5458470809761881932
=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945509/fstmerge_var2_8840066367207630938
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945509/fstmerge_base_5458470809761881932
    searcher = new IndexSearcher(directory, true);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945509/fstmerge_var2_8840066367207630938
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestExplanations.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();

    //
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945696/fstmerge_var1_3048977426635671333
    dir = newDirectory();

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945696/fstmerge_base_5751389169179889737
    RAMDirectory rd = new RAMDirectory();
=======
    dir = new RAMDirectory();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945696/fstmerge_var2_8357826422871317963

    Random random = newRandom();
    //
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945696/fstmerge_base_5751389169179889737
    IndexWriter writer = new IndexWriter(rd, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945696/fstmerge_var2_8357826422871317963

    //
    Document d = new Document();
    d.add(newField(
        FIELD_T,
        "Optimize not deleting all files",
        Field.Store.YES,
        Field.Index.ANALYZED));
    d.add(newField(
        FIELD_C,
        "Deleted When I run an optimize in our production environment.",
        Field.Store.YES,
        Field.Index.ANALYZED));

    //
    writer.addDocument(d);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945696/fstmerge_base_5751389169179889737
    writer.close();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945696/fstmerge_var2_8357826422871317963

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945696/fstmerge_base_5751389169179889737
=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945696/fstmerge_var2_8357826422871317963
    //
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945696/fstmerge_base_5751389169179889737
    searcher = new IndexSearcher(rd, true);
=======
    searcher = new IndexSearcher(reader);
    writer.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945696/fstmerge_var2_8357826422871317963
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestBooleanOr.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945701/fstmerge_var1_8824280223016429725
@Override
  public void tearDown() throws Exception {
    searcher.close();
    reader.close();
    dir.close();
    super.tearDown();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945701/fstmerge_base_1353609323722811302
=======
@Override
  protected void tearDown() throws Exception {
    searcher.close();
    reader.close();
    dir.close();
    super.tearDown();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945701/fstmerge_var2_7108544923883159181

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestBooleanOr.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945706/fstmerge_var1_3899627574964704187
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945706/fstmerge_base_2746200426661632253
@Override
  protected void setUp() throws Exception {
    super.setUp();
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer= new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < docFields.length; i++) {
      Document doc = new Document();
      doc.add(new Field(field, docFields[i], Field.Store.NO, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    writer.close();
    searcher = new IndexSearcher(directory, true);

    // Make big index
    dir2 = new MockRAMDirectory(directory);

    // First multiply small test index:
    mulFactor = 1;
    int docCount = 0;
    do {
      final Directory copy = new RAMDirectory(dir2);
      IndexWriter w = new IndexWriter(dir2, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
      w.addIndexes(new Directory[] {copy});
      docCount = w.maxDoc();
      w.close();
      mulFactor *= 2;
    } while(docCount < 3000);

    IndexWriter w = new IndexWriter(dir2, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    doc.add(new Field("field2", "xxx", Field.Store.NO, Field.Index.ANALYZED));
    for(int i=0;i<NUM_EXTRA_DOCS/2;i++) {
      w.addDocument(doc);
    }
    doc = new Document();
    doc.add(new Field("field2", "big bad bug", Field.Store.NO, Field.Index.ANALYZED));
    for(int i=0;i<NUM_EXTRA_DOCS/2;i++) {
      w.addDocument(doc);
    }
    // optimize to 1 segment
    w.optimize();
    reader = w.getReader();
    w.close();
    bigSearcher = new IndexSearcher(reader);
  }
=======
@Override
  protected void setUp() throws Exception {
    super.setUp();
    rnd = newRandom();
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(rnd, directory);
    for (int i = 0; i < docFields.length; i++) {
      Document doc = new Document();
      doc.add(new Field(field, docFields[i], Field.Store.NO, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    writer.close();
    searcher = new IndexSearcher(directory, true);

    // Make big index
    dir2 = new MockRAMDirectory(directory);

    // First multiply small test index:
    mulFactor = 1;
    int docCount = 0;
    do {
      final Directory copy = new RAMDirectory(dir2);
      RandomIndexWriter w = new RandomIndexWriter(rnd, dir2);
      w.addIndexes(new Directory[] {copy});
      docCount = w.maxDoc();
      w.close();
      mulFactor *= 2;
    } while(docCount < 3000);

    RandomIndexWriter w = new RandomIndexWriter(rnd, dir2);
    Document doc = new Document();
    doc.add(new Field("field2", "xxx", Field.Store.NO, Field.Index.ANALYZED));
    for(int i=0;i<NUM_EXTRA_DOCS/2;i++) {
      w.addDocument(doc);
    }
    doc = new Document();
    doc.add(new Field("field2", "big bad bug", Field.Store.NO, Field.Index.ANALYZED));
    for(int i=0;i<NUM_EXTRA_DOCS/2;i++) {
      w.addDocument(doc);
    }
    reader = w.getReader();
    bigSearcher = new IndexSearcher(reader);
    w.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945706/fstmerge_var2_2090353812975063147

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestBoolean2.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945766/fstmerge_var1_2194714576534166400
@Test
  public void testRandomQueries() throws Exception {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945766/fstmerge_base_9019489756930826150
public void testRandomQueries() throws Exception {
    Random rnd = newRandom();

=======
public void testRandomQueries() throws Exception {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945766/fstmerge_var2_7370023252582434435
    String[] vals = {"w1","w2","w3","w4","w5","xx","yy","zzz"};

    int tot=0;

    BooleanQuery q1 = null;
    try {

      // increase number of iterations for more complete testing
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945766/fstmerge_var1_2194714576534166400
      int num = 50 * RANDOM_MULTIPLIER;
      for (int i=0; i<num; i++) {
        int level = random.nextInt(3);
        q1 = randBoolQuery(new Random(random.nextLong()), random.nextBoolean(), level, field, vals, null);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945766/fstmerge_base_9019489756930826150
      for (int i=0; i<50*_TestUtil.getRandomMultiplier(); i++) {
        int level = rnd.nextInt(3);
        q1 = randBoolQuery(new Random(rnd.nextLong()), rnd.nextBoolean(), level, field, vals, null);
=======
      int num = 50 * RANDOM_MULTIPLIER;
      for (int i=0; i<num; i++) {
        int level = rnd.nextInt(3);
        q1 = randBoolQuery(new Random(rnd.nextLong()), rnd.nextBoolean(), level, field, vals, null);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945766/fstmerge_var2_7370023252582434435
        
        // Can't sort by relevance since floating point numbers may not quite
        // match up.
        Sort sort = Sort.INDEXORDER;

        QueryUtils.check(random, q1,searcher);

        TopFieldCollector collector = TopFieldCollector.create(sort, 1000,
            false, true, true, true);

        searcher.search(q1, null, collector);
        ScoreDoc[] hits1 = collector.topDocs().scoreDocs;

        collector = TopFieldCollector.create(sort, 1000,
            false, true, true, false);
        
        searcher.search(q1, null, collector);
        ScoreDoc[] hits2 = collector.topDocs().scoreDocs;
        tot+=hits2.length;
        CheckHits.checkEqual(q1, hits1, hits2);

        BooleanQuery q3 = new BooleanQuery();
        q3.add(q1, BooleanClause.Occur.SHOULD);
        q3.add(new PrefixQuery(new Term("field2", "b")), BooleanClause.Occur.SHOULD);
        TopDocs hits4 = bigSearcher.search(q3, 1);
        assertEquals(mulFactor*collector.totalHits + NUM_EXTRA_DOCS/2, hits4.totalHits);
      }

    } catch (Exception e) {
      // For easier debugging
      System.out.println("failed query: " + q1);
      throw e;
    }

    // System.out.println("Total hits:"+tot);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestBoolean2.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testMethod() throws Exception {
    Directory directory = newDirectory();

    String[] categories = new String[]{"food",
                                       "foodanddrink",
                                       "foodanddrinkandgoodtimes",
                                       "food and drink"};

    Query rw1 = null;
    Query rw2 = null;
    IndexReader reader = null;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945793/fstmerge_var1_8809713747858231031
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
    for (int i = 0; i < categories.length; i++) {
      Document doc = new Document();
      doc.add(newField("category", categories[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945793/fstmerge_base_1191797916178111865
    try {
      IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
          TEST_VERSION_CURRENT, new MockAnalyzer()));
      for (int i = 0; i < categories.length; i++) {
        Document doc = new Document();
        doc.add(new Field("category", categories[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
        writer.addDocument(doc);
      }
      writer.close();
=======
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    for (int i = 0; i < categories.length; i++) {
      Document doc = new Document();
      doc.add(new Field("category", categories[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945793/fstmerge_var2_7838481543486703997
      
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945793/fstmerge_base_1191797916178111865
      reader = IndexReader.open(directory, true);
      PrefixQuery query = new PrefixQuery(new Term("category", "foo"));
      rw1 = query.rewrite(reader);
=======
    PrefixQuery query = new PrefixQuery(new Term("category", "foo"));
    rw1 = query.rewrite(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945793/fstmerge_var2_7838481543486703997
      
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945793/fstmerge_base_1191797916178111865
      BooleanQuery bq = new BooleanQuery();
      bq.add(query, BooleanClause.Occur.MUST);
=======
    BooleanQuery bq = new BooleanQuery();
    bq.add(query, BooleanClause.Occur.MUST);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945793/fstmerge_var2_7838481543486703997
      
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945793/fstmerge_base_1191797916178111865
      rw2 = bq.rewrite(reader);
    } catch (IOException e) {
      fail(e.getMessage());
    }
=======
    rw2 = bq.rewrite(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945793/fstmerge_var2_7838481543486703997

    assertEquals("Number of Clauses Mismatch", getCount(reader, rw1), getCount(reader, rw2));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945793/fstmerge_base_1191797916178111865
=======
    reader.close();
    directory.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945793/fstmerge_var2_7838481543486703997
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestBooleanPrefixQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testDocBoost() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945807/fstmerge_var1_8484287298973932155
    Directory store = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, store);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945807/fstmerge_base_6167533805498283453
    RAMDirectory store = new RAMDirectory();
    IndexWriter writer = new IndexWriter(store, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    RAMDirectory store = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), store);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945807/fstmerge_var2_4566728877496184837

    Fieldable f1 = newField("field", "word", Field.Store.YES, Field.Index.ANALYZED);
    Fieldable f2 = newField("field", "word", Field.Store.YES, Field.Index.ANALYZED);
    f2.setBoost(2.0f);

    Document d1 = new Document();
    Document d2 = new Document();
    Document d3 = new Document();
    Document d4 = new Document();
    d3.setBoost(3.0f);
    d4.setBoost(2.0f);

    d1.add(f1);                                 // boost = 1
    d2.add(f2);                                 // boost = 2
    d3.add(f1);                                 // boost = 3
    d4.add(f2);                                 // boost = 4

    writer.addDocument(d1);
    writer.addDocument(d2);
    writer.addDocument(d3);
    writer.addDocument(d4);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945807/fstmerge_base_6167533805498283453
    writer.optimize();
=======

    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945807/fstmerge_var2_4566728877496184837
    writer.close();

    final float[] scores = new float[4];

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945807/fstmerge_base_6167533805498283453
    new IndexSearcher(store, true).search
=======
    new IndexSearcher(reader).search
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945807/fstmerge_var2_4566728877496184837
      (new TermQuery(new Term("field", "word")),
       new Collector() {
         private int base = 0;
         private Scorer scorer;
         @Override
         public void setScorer(Scorer scorer) throws IOException {
          this.scorer = scorer;
         }
         @Override
         public final void collect(int doc) throws IOException {
           scores[doc + base] = scorer.score();
         }
         @Override
         public void setNextReader(IndexReader reader, int docBase) {
           base = docBase;
         }
         @Override
         public boolean acceptsDocsOutOfOrder() {
           return true;
         }
       });

    float lastScore = 0.0f;

    for (int i = 0; i < 4; i++) {
      assertTrue(scores[i] > lastScore);
      lastScore = scores[i];
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945807/fstmerge_base_6167533805498283453
=======
    
    reader.close();
    store.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945807/fstmerge_var2_4566728877496184837
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDocBoost.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945854/fstmerge_var1_542327611343100940
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945854/fstmerge_base_5198635752440809442
TestIndex(int minR, int maxR, boolean allowNegativeRandomInts) {
            this.minR = minR;
            this.maxR = maxR;
            this.allowNegativeRandomInts = allowNegativeRandomInts;
        }
=======
TestIndex(int minR, int maxR, boolean allowNegativeRandomInts) {
      this.minR = minR;
      this.maxR = maxR;
      this.allowNegativeRandomInts = allowNegativeRandomInts;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945854/fstmerge_var2_4060034816389536994

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
Conflict type: SameIdFd
Conflict body: 
~~FSTMerge~~ static IndexReader signedIndexReader; ##FSTMerge## ##FSTMerge## IndexReader signedIndexReader;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
Conflict type: SameIdFd
Conflict body: 
~~FSTMerge~~ static IndexReader unsignedIndexReader; ##FSTMerge## ##FSTMerge## IndexReader unsignedIndexReader;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
Conflict type: SameIdFd
Conflict body: 
~~FSTMerge~~ static TestIndex signedIndexDir; ##FSTMerge## ##FSTMerge## TestIndex signedIndexDir = new TestIndex(Integer.MAX_VALUE, Integer.MIN_VALUE, true);
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
Conflict type: SameIdFd
Conflict body: 
~~FSTMerge~~ static TestIndex unsignedIndexDir; ##FSTMerge## ##FSTMerge## TestIndex unsignedIndexDir = new TestIndex(Integer.MAX_VALUE, 0, false);
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945863/fstmerge_var1_6079167937777425466
private static IndexReader build(Random random, TestIndex index) throws IOException {
    /* build an index */
    
    Document doc = new Document();
    Field idField = newField(random, "id", "", Field.Store.YES, Field.Index.NOT_ANALYZED);
    Field randField = newField(random, "rand", "", Field.Store.YES, Field.Index.NOT_ANALYZED);
    Field bodyField = newField(random, "body", "", Field.Store.YES, Field.Index.NOT_ANALYZED);
    doc.add(idField);
    doc.add(randField);
    doc.add(bodyField);

    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, 
                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));
    while(true) {

      int minCount = 0;
      int maxCount = 0;

      _TestUtil.reduceOpenFiles(writer.w);

      for (int d = minId; d <= maxId; d++) {
        idField.setValue(pad(d));
        int r = index.allowNegativeRandomInts ? random.nextInt() : random
          .nextInt(Integer.MAX_VALUE);
        if (index.maxR < r) {
          index.maxR = r;
          maxCount = 1;
        } else if (index.maxR == r) {
          maxCount++;
        }

        if (r < index.minR) {
          index.minR = r;
          minCount = 1;
        } else if (r == index.minR) {
          minCount++;
        }
        randField.setValue(pad(r));
        bodyField.setValue("body");
        writer.addDocument(doc);
      }

      if (minCount == 1 && maxCount == 1) {
        // our subclasses rely on only 1 doc having the min or
        // max, so, we loop until we satisfy that.  it should be
        // exceedingly rare (Yonik calculates 1 in ~429,000)
        // times) that this loop requires more than one try:
        IndexReader ir = writer.getReader();
        writer.close();
        return ir;
      }

      // try again
      writer.deleteAll();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945863/fstmerge_base_2028339130873957712
=======
private IndexReader build(Random random, TestIndex index) throws IOException {
    /* build an index */
    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
    .setOpenMode(OpenMode.CREATE));
    
    for (int d = minId; d <= maxId; d++) {
      Document doc = new Document();
      doc.add(new Field("id", pad(d), Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      int r = index.allowNegativeRandomInts ? rand.nextInt() : rand
          .nextInt(Integer.MAX_VALUE);
      if (index.maxR < r) {
        index.maxR = r;
      }
      if (r < index.minR) {
        index.minR = r;
      }
      doc.add(new Field("rand", pad(r), Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      doc.add(new Field("body", "body", Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    
    IndexReader ir = writer.getReader();
    writer.close();
    return ir;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945863/fstmerge_var2_6953410137305728996

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945868/fstmerge_var1_3504108754824685673
@Test
  public void testPad() {
    
    int[] tests = new int[] {-9999999, -99560, -100, -3, -1, 0, 3, 9, 10, 1000,
        999999999};
    for (int i = 0; i < tests.length - 1; i++) {
      int a = tests[i];
      int b = tests[i + 1];
      String aa = pad(a);
      String bb = pad(b);
      String label = a + ":" + aa + " vs " + b + ":" + bb;
      assertEquals("length of " + label, aa.length(), bb.length());
      assertTrue("compare less than " + label, aa.compareTo(bb) < 0);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945868/fstmerge_base_4468397302556619465
public void testPad() {

        int[] tests = new int[] {
            -9999999, -99560, -100, -3, -1, 0, 3, 9, 10, 1000, 999999999
        };
        for (int i = 0; i < tests.length - 1; i++) {
            int a = tests[i];
            int b = tests[i+1];
            String aa = pad(a);
            String bb = pad(b);
            String label = a + ":" + aa + " vs " + b + ":" + bb;
            assertEquals("length of " + label, aa.length(), bb.length());
            assertTrue("compare less than " + label, aa.compareTo(bb) < 0);
        }

=======
public void testPad() {
    
    int[] tests = new int[] {-9999999, -99560, -100, -3, -1, 0, 3, 9, 10, 1000,
        999999999};
    for (int i = 0; i < tests.length - 1; i++) {
      int a = tests[i];
      int b = tests[i + 1];
      String aa = pad(a);
      String bb = pad(b);
      String label = a + ":" + aa + " vs " + b + ":" + bb;
      assertEquals("length of " + label, aa.length(), bb.length());
      assertTrue("compare less than " + label, aa.compareTo(bb) < 0);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945868/fstmerge_var2_4738960746494854583
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945868/fstmerge_base_4468397302556619465
=======
    
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945868/fstmerge_var2_4738960746494854583

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945873/fstmerge_var1_1482233294234535847
    dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945873/fstmerge_base_7417776783678507756
    RAMDirectory dir = new RAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new MockAnalyzer(),
        IndexWriter.MaxFieldLength.UNLIMITED);
=======
    random = newRandom();
    dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945873/fstmerge_var2_4069235419378613625
    
    Document doc = new Document();
    Field field = newField("field", "", Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field);
    
    NumberFormat df = new DecimalFormat("0000", new DecimalFormatSymbols(Locale.ENGLISH));
    for (int i = 0; i < 10000; i++) {
      field.setValue(df.format(i));
      writer.addDocument(doc);
    }
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945873/fstmerge_var1_1482233294234535847
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945873/fstmerge_base_7417776783678507756
    writer.optimize();
=======
    IndexReader reader = writer.getReader();
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945873/fstmerge_var2_4069235419378613625
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945873/fstmerge_base_7417776783678507756
    searcher = new IndexSearcher(dir);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945873/fstmerge_var2_4069235419378613625
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestWildcardRandom.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void tearDown() throws Exception {
    searcher.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945891/fstmerge_var1_3875618250351220867
    reader.close();
    dir.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945891/fstmerge_base_9065302462096583739
=======
    dir.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945891/fstmerge_var2_3701678603418155724
    super.tearDown();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestWildcardRandom.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testPrefixQuery() throws Exception {
    Directory directory = newDirectory();

    String[] categories = new String[] {"/Computers",
                                        "/Computers/Mac",
                                        "/Computers/Windows"};
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945941/fstmerge_var1_532811388265310298
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945941/fstmerge_base_4799665078727189840
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945941/fstmerge_var2_3006569200870138404
    for (int i = 0; i < categories.length; i++) {
      Document doc = new Document();
      doc.add(newField("category", categories[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945941/fstmerge_base_4799665078727189840
    writer.close();
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945941/fstmerge_var2_3006569200870138404

    PrefixQuery query = new PrefixQuery(new Term("category", "/Computers"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945941/fstmerge_base_4799665078727189840
    IndexSearcher searcher = new IndexSearcher(directory, true);
=======
    IndexSearcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945941/fstmerge_var2_3006569200870138404
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("All documents in /Computers category and below", 3, hits.length);

    query = new PrefixQuery(new Term("category", "/Computers/Mac"));
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("One in /Computers/Mac", 1, hits.length);

    query = new PrefixQuery(new Term("category", ""));
    Terms terms = MultiFields.getTerms(searcher.getIndexReader(), "category");
    assertFalse(query.getTermsEnum(terms) instanceof PrefixTermsEnum);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("everything", 3, hits.length);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945941/fstmerge_base_4799665078727189840
=======
    writer.close();
    searcher.close();
    reader.close();
    directory.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945941/fstmerge_var2_3006569200870138404
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestPrefixQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testFuzziness() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945945/fstmerge_var1_5990490672940530089
    Directory directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945945/fstmerge_base_5967004749813567323
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945945/fstmerge_var2_2086019338681479571
    addDoc("aaaaa", writer);
    addDoc("aaaab", writer);
    addDoc("aaabb", writer);
    addDoc("aabbb", writer);
    addDoc("abbbb", writer);
    addDoc("bbbbb", writer);
    addDoc("ddddd", writer);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945945/fstmerge_base_5967004749813567323
    writer.optimize();
=======

    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945945/fstmerge_var2_2086019338681479571
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945945/fstmerge_base_5967004749813567323
    IndexSearcher searcher = new IndexSearcher(directory, true);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945945/fstmerge_var2_2086019338681479571

    FuzzyQuery query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 0);   
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    
    // same with prefix
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 3);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 4);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 5);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 6);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    
    // test scoring
    query = new FuzzyQuery(new Term("field", "bbbbb"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("3 documents should match", 3, hits.length);
    List<String> order = Arrays.asList("bbbbb","abbbb","aabbb");
    for (int i = 0; i < hits.length; i++) {
      final String term = searcher.doc(hits[i].doc).get("field");
      //System.out.println(hits[i].score);
      assertEquals(order.get(i), term);
    }

    // test pq size by supplying maxExpansions=2
    // This query would normally return 3 documents, because 3 terms match (see above):
    query = new FuzzyQuery(new Term("field", "bbbbb"), FuzzyQuery.defaultMinSimilarity, 0, 2); 
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("only 2 documents should match", 2, hits.length);
    order = Arrays.asList("bbbbb","abbbb");
    for (int i = 0; i < hits.length; i++) {
      final String term = searcher.doc(hits[i].doc).get("field");
      //System.out.println(hits[i].score);
      assertEquals(order.get(i), term);
    }

    // not similar enough:
    query = new FuzzyQuery(new Term("field", "xxxxx"), FuzzyQuery.defaultMinSimilarity, 0);  	
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    query = new FuzzyQuery(new Term("field", "aaccc"), FuzzyQuery.defaultMinSimilarity, 0);   // edit distance to "aaaaa" = 3
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // query identical to a word in the index:
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    // default allows for up to two edits:
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));

    // query similar to a word in the index:
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 3);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 4);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 5);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    

    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 3);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 4);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 5);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    

    // different field = no match:
    query = new FuzzyQuery(new Term("anotherfield", "ddddX"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    searcher.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945945/fstmerge_base_5967004749813567323
=======
    reader.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945945/fstmerge_var2_2086019338681479571
    directory.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestFuzzyQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testFuzzinessLong() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945953/fstmerge_var1_5159255923909415453
    Directory directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945953/fstmerge_base_7864946946618977307
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945953/fstmerge_var2_7132133312301265138
    addDoc("aaaaaaa", writer);
    addDoc("segment", writer);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945953/fstmerge_base_7864946946618977307
    writer.optimize();
=======

    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945953/fstmerge_var2_7132133312301265138
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945953/fstmerge_base_7864946946618977307
    IndexSearcher searcher = new IndexSearcher(directory, true);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945953/fstmerge_var2_7132133312301265138

    FuzzyQuery query;
    // not similar enough:
    query = new FuzzyQuery(new Term("field", "xxxxx"), 0.5f, 0);   
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    // edit distance to "aaaaaaa" = 3, this matches because the string is longer than
    // in testDefaultFuzziness so a bigger difference is allowed:
    query = new FuzzyQuery(new Term("field", "aaaaccc"), 0.5f, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "aaaaccc"), 0.5f, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
    query = new FuzzyQuery(new Term("field", "aaaaccc"), 0.5f, 4);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
    query = new FuzzyQuery(new Term("field", "aaaaccc"), 0.5f, 5);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // no match, more than half of the characters is wrong:
    query = new FuzzyQuery(new Term("field", "aaacccc"), 0.5f, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "aaacccc"), 0.5f, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // "student" and "stellent" are indeed similar to "segment" by default:
    query = new FuzzyQuery(new Term("field", "student"), 0.5f, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    query = new FuzzyQuery(new Term("field", "stellent"), 0.5f, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "student"), 0.5f, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    query = new FuzzyQuery(new Term("field", "stellent"), 0.5f, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    query = new FuzzyQuery(new Term("field", "student"), 0.5f, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    query = new FuzzyQuery(new Term("field", "stellent"), 0.5f, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    
    // "student" doesn't match anymore thanks to increased minimum similarity:
    query = new FuzzyQuery(new Term("field", "student"), 0.6f, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    try {
      query = new FuzzyQuery(new Term("field", "student"), 1.1f);
      fail("Expected IllegalArgumentException");
    } catch (IllegalArgumentException e) {
      // expecting exception
    }
    try {
      query = new FuzzyQuery(new Term("field", "student"), -0.1f);
      fail("Expected IllegalArgumentException");
    } catch (IllegalArgumentException e) {
      // expecting exception
    }

    searcher.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945953/fstmerge_base_7864946946618977307
=======
    reader.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945953/fstmerge_var2_7132133312301265138
    directory.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestFuzzyQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testTokenLengthOpt() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945958/fstmerge_var1_8002283248908647192
    Directory directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945958/fstmerge_base_6232329879641894237
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945958/fstmerge_var2_47731092199864521
    addDoc("12345678911", writer);
    addDoc("segment", writer);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945958/fstmerge_base_6232329879641894237
    writer.optimize();
=======

    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945958/fstmerge_var2_47731092199864521
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945958/fstmerge_base_6232329879641894237
    IndexSearcher searcher = new IndexSearcher(directory, true);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945958/fstmerge_var2_47731092199864521

    Query query;
    // term not over 10 chars, so optimization shortcuts
    query = new FuzzyQuery(new Term("field", "1234569"), 0.9f);
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // 10 chars, so no optimization
    query = new FuzzyQuery(new Term("field", "1234567891"), 0.9f);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    
    // over 10 chars, so no optimization
    query = new FuzzyQuery(new Term("field", "12345678911"), 0.9f);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);

    // over 10 chars, no match
    query = new FuzzyQuery(new Term("field", "sdfsdfsdfsdf"), 0.9f);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945958/fstmerge_base_6232329879641894237
=======
    
    searcher.close();
    reader.close();
    directory.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945958/fstmerge_var2_47731092199864521
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestFuzzyQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testBoostOnlyRewrite() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945963/fstmerge_var1_1509594726605145496
    Directory directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945963/fstmerge_base_7411245584669561032
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945963/fstmerge_var2_9055948408910361726
    addDoc("Lucene", writer);
    addDoc("Lucene", writer);
    addDoc("Lucenne", writer);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945963/fstmerge_base_7411245584669561032
    writer.optimize();
=======

    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945963/fstmerge_var2_9055948408910361726
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945963/fstmerge_var1_1509594726605145496
    
    FuzzyQuery query = new FuzzyQuery(new Term("field", "lucene"));
    query.setRewriteMethod(new MultiTermQuery.TopTermsBoostOnlyBooleanQueryRewrite(50));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945963/fstmerge_base_7411245584669561032
    IndexSearcher searcher = new IndexSearcher(directory, true);
    IndexReader reader = searcher.getIndexReader();
    FuzzyQuery query = new FuzzyQuery(new Term("field", "Lucene"));
    query.setRewriteMethod(new MultiTermQuery.TopTermsBoostOnlyBooleanQueryRewrite());
=======
    
    FuzzyQuery query = new FuzzyQuery(new Term("field", "Lucene"));
    query.setRewriteMethod(new MultiTermQuery.TopTermsBoostOnlyBooleanQueryRewrite());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945963/fstmerge_var2_9055948408910361726
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    // normally, 'Lucenne' would be the first result as IDF will skew the score.
    assertEquals("Lucene", reader.document(hits[0].doc).get("field"));
    assertEquals("Lucene", reader.document(hits[1].doc).get("field"));
    assertEquals("Lucenne", reader.document(hits[2].doc).get("field"));
    searcher.close();
    reader.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945963/fstmerge_base_7411245584669561032
=======
    directory.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945963/fstmerge_var2_9055948408910361726
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestFuzzyQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testGiga() throws Exception {

    MockAnalyzer analyzer = new MockAnalyzer();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945977/fstmerge_var1_1756286431710641977
    Directory index = newDirectory();
    RandomIndexWriter w = new RandomIndexWriter(random, index);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945977/fstmerge_base_8732854852061227279

    Directory index = new MockRAMDirectory();
    IndexWriter w = new IndexWriter(index, new IndexWriterConfig(
        TEST_VERSION_CURRENT, analyzer));
=======

    Directory index = new MockRAMDirectory();
    RandomIndexWriter w = new RandomIndexWriter(newRandom(), index);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945977/fstmerge_var2_5859832736354137233

    addDoc("Lucene in Action", w);
    addDoc("Lucene for Dummies", w);

    //addDoc("Giga", w);
    addDoc("Giga byte", w);

    addDoc("ManagingGigabytesManagingGigabyte", w);
    addDoc("ManagingGigabytesManagingGigabytes", w);

    addDoc("The Art of Computer Science", w);
    addDoc("J. K. Rowling", w);
    addDoc("JK Rowling", w);
    addDoc("Joanne K Roling", w);
    addDoc("Bruce Willis", w);
    addDoc("Willis bruce", w);
    addDoc("Brute willis", w);
    addDoc("B. willis", w);
    IndexReader r = w.getReader();
    w.close();

    Query q = new QueryParser(TEST_VERSION_CURRENT, "field", analyzer).parse( "giga~0.9" );

    // 3. search
    IndexSearcher searcher = new IndexSearcher(r);
    ScoreDoc[] hits = searcher.search(q, 10).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals("Giga byte", searcher.doc(hits[0].doc).get("field"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945977/fstmerge_base_8732854852061227279
=======
    searcher.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945977/fstmerge_var2_5859832736354137233
    r.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945977/fstmerge_base_8732854852061227279
=======
    index.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945977/fstmerge_var2_5859832736354137233
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestFuzzyQuery.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945982/fstmerge_var1_7698207789406566546
private void addDoc(String text, RandomIndexWriter writer) throws IOException {
    Document doc = new Document();
    doc.add(newField("field", text, Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945982/fstmerge_base_7002973823415190614
=======
private void addDoc(String text, RandomIndexWriter writer) throws IOException {
    Document doc = new Document();
    doc.add(new Field("field", text, Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945982/fstmerge_var2_4337618283980022800

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestFuzzyQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945987/fstmerge_var1_7685519242730236936
    directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945987/fstmerge_base_3793979755222757810
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new MockAnalyzer(),
        true, IndexWriter.MaxFieldLength.LIMITED);
=======
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945987/fstmerge_var2_7906438174996799367
    Document doc = new Document();
    doc.add(newField(FN,
        "the quick brown fox jumps over the lazy ??? dog 493432 49344",
        Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945987/fstmerge_base_3793979755222757810
    writer.optimize();
=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945987/fstmerge_var2_7906438174996799367
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945987/fstmerge_base_3793979755222757810
    searcher = new IndexSearcher(directory, true);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627945987/fstmerge_var2_7906438174996799367
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestRegexpQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946071/fstmerge_var1_219299667239382465
    directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946071/fstmerge_base_5711823743537715395
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new MockAnalyzer(), true,
        IndexWriter.MaxFieldLength.LIMITED);
=======
    Random random = newRandom();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946071/fstmerge_var2_6309039500031509814
    Document doc = new Document();
    Field titleField = newField("title", "some title", Field.Store.NO,
        Field.Index.ANALYZED);
    Field field = newField(FN, "this is document one 2345", Field.Store.NO,
        Field.Index.ANALYZED);
    Field footerField = newField("footer", "a footer", Field.Store.NO,
        Field.Index.ANALYZED);
    doc.add(titleField);
    doc.add(field);
    doc.add(footerField);
    writer.addDocument(doc);
    field.setValue("some text from doc two a short piece 5678.91");
    writer.addDocument(doc);
    field.setValue("doc three has some different stuff"
        + " with numbers 1234 5678.9 and letter b");
    writer.addDocument(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946071/fstmerge_base_5711823743537715395
    writer.optimize();
=======
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946071/fstmerge_var2_6309039500031509814
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946071/fstmerge_base_5711823743537715395
    searcher = new IndexSearcher(directory, true);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946071/fstmerge_var2_6309039500031509814
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestAutomatonQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946131/fstmerge_var1_7180259319174705831
    directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter (random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946131/fstmerge_base_3240941879669667138
    directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter (directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter (newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946131/fstmerge_var2_2818082036657662325

    Document doc = new Document();
    doc.add (newField("field", "one two three four five", Field.Store.YES, Field.Index.ANALYZED));
    doc.add (newField("sorter", "b", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument (doc);

    doc = new Document();
    doc.add (newField("field", "one two three four", Field.Store.YES, Field.Index.ANALYZED));
    doc.add (newField("sorter", "d", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument (doc);

    doc = new Document();
    doc.add (newField("field", "one two three y", Field.Store.YES, Field.Index.ANALYZED));
    doc.add (newField("sorter", "a", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument (doc);

    doc = new Document();
    doc.add (newField("field", "one two x", Field.Store.YES, Field.Index.ANALYZED));
    doc.add (newField("sorter", "c", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument (doc);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946131/fstmerge_base_3240941879669667138
    writer.optimize ();
=======
    // tests here require single segment (eg try seed
    // 8239472272678419952L), because SingleDocTestFilter(x)
    // blindly accepts that docID in any sub-segment
    writer.optimize();

    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946131/fstmerge_var2_2818082036657662325
    writer.close ();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946131/fstmerge_base_3240941879669667138
    searcher = new IndexSearcher (directory, true);
=======
    searcher = new IndexSearcher (reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946131/fstmerge_var2_2818082036657662325
    query = new TermQuery (new Term ("field", "three"));
    filter = newStaticFilterB();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestFilteredQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testMissingTerms() throws Exception {
    String fieldName = "field1";
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946171/fstmerge_var1_6330818761741613290
    Directory rd = newDirectory();
    RandomIndexWriter w = new RandomIndexWriter(random, rd);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946171/fstmerge_base_3861887410591445373
    MockRAMDirectory rd = new MockRAMDirectory();
    IndexWriter w = new IndexWriter(rd, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    MockRAMDirectory rd = new MockRAMDirectory();
    RandomIndexWriter w = new RandomIndexWriter(newRandom(), rd);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946171/fstmerge_var2_4268817154754755386
    for (int i = 0; i < 100; i++) {
      Document doc = new Document();
      int term = i * 10; //terms are units of 10;
      doc.add(newField(fieldName, "" + term, Field.Store.YES, Field.Index.NOT_ANALYZED));
      w.addDocument(doc);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946171/fstmerge_base_3861887410591445373
=======
    IndexReader reader = w.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946171/fstmerge_var2_4268817154754755386
    w.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946171/fstmerge_base_3861887410591445373
    IndexReader reader = IndexReader.open(rd, true);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946171/fstmerge_var2_4268817154754755386
    IndexSearcher searcher = new IndexSearcher(reader);
    int numDocs = reader.numDocs();
    ScoreDoc[] results;
    MatchAllDocsQuery q = new MatchAllDocsQuery();

    List<String> terms = new ArrayList<String>();
    terms.add("5");
    results = searcher.search(q, new FieldCacheTermsFilter(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
    assertEquals("Must match nothing", 0, results.length);

    terms = new ArrayList<String>();
    terms.add("10");
    results = searcher.search(q, new FieldCacheTermsFilter(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
    assertEquals("Must match 1", 1, results.length);

    terms = new ArrayList<String>();
    terms.add("10");
    terms.add("20");
    results = searcher.search(q, new FieldCacheTermsFilter(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
    assertEquals("Must match 2", 2, results.length);

    reader.close();
    rd.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestFieldCacheTermsFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {
    query.setSlop(slop);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946201/fstmerge_var1_2109736168668444401
    Directory ramDir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, ramDir, new MockAnalyzer(MockTokenizer.WHITESPACE, false));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946201/fstmerge_base_3210113827963416114
    RAMDirectory ramDir = new RAMDirectory();
    IndexWriter writer = new IndexWriter(ramDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
=======
    RAMDirectory ramDir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, ramDir, new MockAnalyzer(MockTokenizer.WHITESPACE, false));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946201/fstmerge_var2_6765896429727625891
    writer.addDocument(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946201/fstmerge_base_3210113827963416114
    writer.close();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946201/fstmerge_var2_6765896429727625891

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946201/fstmerge_base_3210113827963416114
    IndexSearcher searcher = new IndexSearcher(ramDir, true);
=======
    IndexReader reader = writer.getReader();

    IndexSearcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946201/fstmerge_var2_6765896429727625891
    TopDocs td = searcher.search(query,null,10);
    //System.out.println("slop: "+slop+"  query: "+query+"  doc: "+doc+"  Expecting number of hits: "+expectedNumResults+" maxScore="+td.getMaxScore());
    assertEquals("slop: "+slop+"  query: "+query+"  doc: "+doc+"  Wrong number of hits", expectedNumResults, td.totalHits);

    //QueryUtils.check(query,searcher);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946201/fstmerge_base_3210113827963416114

=======
    writer.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946201/fstmerge_var2_6765896429727625891
    searcher.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946201/fstmerge_base_3210113827963416114
=======
    reader.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946201/fstmerge_var2_6765896429727625891
    ramDir.close();

    return td.getMaxScore();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestSloppyPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946228/fstmerge_var1_4221299925802276475
    directory = newDirectory();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946228/fstmerge_base_4711990198636883398
    directory = new RAMDirectory();
=======
    random = newRandom();
    directory = new RAMDirectory();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946228/fstmerge_var2_5543331572618262356
    Analyzer analyzer = new Analyzer() {
      @Override
      public TokenStream tokenStream(String fieldName, Reader reader) {
        return new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
      }

      @Override
      public int getPositionIncrementGap(String fieldName) {
        return 100;
      }
    };
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946228/fstmerge_base_4711990198636883398
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
=======
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, analyzer);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946228/fstmerge_var2_5543331572618262356
    
    Document doc = new Document();
    doc.add(newField("field", "one two three four five", Field.Store.YES, Field.Index.ANALYZED));
    doc.add(newField("repeated", "this is a repeated field - first part", Field.Store.YES, Field.Index.ANALYZED));
    Fieldable repeatedField = newField("repeated", "second part of a repeated field", Field.Store.YES, Field.Index.ANALYZED);
    doc.add(repeatedField);
    doc.add(newField("palindrome", "one two three two one", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    doc = new Document();
    doc.add(newField("nonexist", "phrase exist notexist exist found", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    doc = new Document();
    doc.add(newField("nonexist", "phrase exist notexist exist found", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946228/fstmerge_base_4711990198636883398
    writer.optimize();
=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946228/fstmerge_var2_5543331572618262356
    writer.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946228/fstmerge_base_4711990198636883398
    searcher = new IndexSearcher(directory, true);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946228/fstmerge_var2_5543331572618262356
    query = new PhraseQuery();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testPhraseQueryWithStopAnalyzer() throws Exception {
    Directory directory = newDirectory();
    Analyzer stopAnalyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, false);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946271/fstmerge_var1_6407984514228887838
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946271/fstmerge_base_5012527335214993132
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
        Version.LUCENE_24, stopAnalyzer));
=======
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(random, Version.LUCENE_24, stopAnalyzer));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946271/fstmerge_var2_8820640408089356134
    Document doc = new Document();
    doc.add(newField("field", "the stop words are here", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946271/fstmerge_base_5012527335214993132
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946271/fstmerge_var2_8820640408089356134
    writer.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946271/fstmerge_base_5012527335214993132
    IndexSearcher searcher = new IndexSearcher(directory, true);
=======
    IndexSearcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946271/fstmerge_var2_8820640408089356134

    // valid exact phrase query
    PhraseQuery query = new PhraseQuery();
    query.add(new Term("field","stop"));
    query.add(new Term("field","words"));
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    QueryUtils.check(random, query,searcher);


    // StopAnalyzer as of 2.4 does not leave "holes", so this matches.
    query = new PhraseQuery();
    query.add(new Term("field", "words"));
    query.add(new Term("field", "here"));
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    QueryUtils.check(random, query,searcher);


    searcher.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946271/fstmerge_base_5012527335214993132
=======
    reader.close();
    directory.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946271/fstmerge_var2_8820640408089356134
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testPhraseQueryInConjunctionScorer() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_var1_3016418997944216742
    Directory directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_base_23573908101547702
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_var2_4542149218395888324
    
    Document doc = new Document();
    doc.add(newField("source", "marketing info", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    doc = new Document();
    doc.add(newField("contents", "foobar", Field.Store.YES, Field.Index.ANALYZED));
    doc.add(newField("source", "marketing info", Field.Store.YES, Field.Index.ANALYZED)); 
    writer.addDocument(doc);
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_base_23573908101547702
    writer.optimize();
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_var2_4542149218395888324
    writer.close();
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_base_23573908101547702
    IndexSearcher searcher = new IndexSearcher(directory, true);
=======
    IndexSearcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_var2_4542149218395888324
    
    PhraseQuery phraseQuery = new PhraseQuery();
    phraseQuery.add(new Term("source", "marketing"));
    phraseQuery.add(new Term("source", "info"));
    ScoreDoc[] hits = searcher.search(phraseQuery, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    QueryUtils.check(random, phraseQuery,searcher);

    
    TermQuery termQuery = new TermQuery(new Term("contents","foobar"));
    BooleanQuery booleanQuery = new BooleanQuery();
    booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
    booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    QueryUtils.check(random, termQuery,searcher);

    
    searcher.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_base_23573908101547702
=======
    reader.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_var2_4542149218395888324
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_var1_3016418997944216742
    writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_base_23573908101547702
    writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
=======
    writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_var2_4542149218395888324
    doc = new Document();
    doc.add(newField("contents", "map entry woo", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);

    doc = new Document();
    doc.add(newField("contents", "woo map entry", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);

    doc = new Document();
    doc.add(newField("contents", "map foobarword entry woo", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_base_23573908101547702
    writer.optimize();
=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_var2_4542149218395888324
    writer.close();
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_base_23573908101547702
    searcher = new IndexSearcher(directory, true);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_var2_4542149218395888324
    
    termQuery = new TermQuery(new Term("contents","woo"));
    phraseQuery = new PhraseQuery();
    phraseQuery.add(new Term("contents","map"));
    phraseQuery.add(new Term("contents","entry"));
    
    hits = searcher.search(termQuery, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    hits = searcher.search(phraseQuery, null, 1000).scoreDocs;
    assertEquals(2, hits.length);

    
    booleanQuery = new BooleanQuery();
    booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
    booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    
    booleanQuery = new BooleanQuery();
    booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
    booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    QueryUtils.check(random, booleanQuery,searcher);

    
    searcher.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_base_23573908101547702
=======
    reader.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946276/fstmerge_var2_4542149218395888324
    directory.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testSlopScoring() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_var1_1852689520317415076
    Directory directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_base_5799233932808823729
    Directory directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    Directory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_var2_3115303945155155131

    Document doc = new Document();
    doc.add(newField("field", "foo firstname lastname foo", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    Document doc2 = new Document();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_var1_1852689520317415076
    doc2.add(newField("field", "foo firstname zzz lastname foo", Field.Store.YES, Field.Index.ANALYZED));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_base_5799233932808823729
    doc2.add(new Field("field", "foo firstname xxx lastname foo", Field.Store.YES, Field.Index.ANALYZED));
=======
    doc2.add(new Field("field", "foo firstname zzz lastname foo", Field.Store.YES, Field.Index.ANALYZED));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_var2_3115303945155155131
    writer.addDocument(doc2);
    
    Document doc3 = new Document();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_var1_1852689520317415076
    doc3.add(newField("field", "foo firstname zzz yyy lastname foo", Field.Store.YES, Field.Index.ANALYZED));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_base_5799233932808823729
    doc3.add(new Field("field", "foo firstname xxx yyy lastname foo", Field.Store.YES, Field.Index.ANALYZED));
=======
    doc3.add(new Field("field", "foo firstname zzz yyy lastname foo", Field.Store.YES, Field.Index.ANALYZED));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_var2_3115303945155155131
    writer.addDocument(doc3);
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_base_5799233932808823729
    writer.optimize();
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_var2_3115303945155155131
    writer.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_base_5799233932808823729
    Searcher searcher = new IndexSearcher(directory, true);
=======
    Searcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_var2_3115303945155155131
    PhraseQuery query = new PhraseQuery();
    query.add(new Term("field", "firstname"));
    query.add(new Term("field", "lastname"));
    query.setSlop(Integer.MAX_VALUE);
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    // Make sure that those matches where the terms appear closer to
    // each other get a higher score:
    assertEquals(0.71, hits[0].score, 0.01);
    assertEquals(0, hits[0].doc);
    assertEquals(0.44, hits[1].score, 0.01);
    assertEquals(1, hits[1].doc);
    assertEquals(0.31, hits[2].score, 0.01);
    assertEquals(2, hits[2].doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_var1_1852689520317415076
    QueryUtils.check(random, query,searcher);
    searcher.close();
    reader.close();
    directory.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_base_5799233932808823729
    QueryUtils.check(query,searcher);        
=======
    QueryUtils.check(query,searcher);
    searcher.close();
    reader.close();
    directory.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946282/fstmerge_var2_3115303945155155131
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946321/fstmerge_var1_7490861336513366864
public void testRandomPhrases() throws Exception {
    Directory dir = newDirectory();
    Analyzer analyzer = new MockAnalyzer();

    RandomIndexWriter w  = new RandomIndexWriter(random, dir, analyzer);
    List<List<String>> docs = new ArrayList<List<String>>();
    Document d = new Document();
    Field f = newField("f", "", Field.Store.NO, Field.Index.ANALYZED);
    d.add(f);

    Random r = random;

    int NUM_DOCS = 10 * RANDOM_MULTIPLIER;
    for (int i = 0; i < NUM_DOCS; i++) {
      // must be > 4096 so it spans multiple chunks
      int termCount = _TestUtil.nextInt(r, 10000, 30000);

      List<String> doc = new ArrayList<String>();

      StringBuilder sb = new StringBuilder();
      while(doc.size() < termCount) {
        if (r.nextInt(5) == 1 || docs.size() == 0) {
          // make new non-empty-string term
          String term;
          while(true) {
            term = _TestUtil.randomUnicodeString(r);
            if (term.length() > 0) {
              break;
            }
          }
          TokenStream ts = analyzer.reusableTokenStream("ignore", new StringReader(term));
          CharTermAttribute termAttr = ts.addAttribute(CharTermAttribute.class);
          while(ts.incrementToken()) {
            String text = termAttr.toString();
            doc.add(text);
            sb.append(text).append(' ');
          }
        } else {
          // pick existing sub-phrase
          List<String> lastDoc = docs.get(r.nextInt(docs.size()));
          int len = _TestUtil.nextInt(r, 1, 10);
          int start = r.nextInt(lastDoc.size()-len);
          for(int k=start;k<start+len;k++) {
            String t = lastDoc.get(k);
            doc.add(t);
            sb.append(t).append(' ');
          }
        }
      }
      docs.add(doc);
      f.setValue(sb.toString());
      w.addDocument(d);
    }

    IndexReader reader = w.getReader();
    IndexSearcher s = new IndexSearcher(reader);
    w.close();

    // now search
    int num = 100 * RANDOM_MULTIPLIER;
    for(int i=0;i<num;i++) {
      int docID = r.nextInt(docs.size());
      List<String> doc = docs.get(docID);
      
      final int numTerm = _TestUtil.nextInt(r, 2, 20);
      final int start = r.nextInt(doc.size()-numTerm);
      PhraseQuery pq = new PhraseQuery();
      StringBuilder sb = new StringBuilder();
      for(int t=start;t<start+numTerm;t++) {
        pq.add(new Term("f", doc.get(t)));
        sb.append(doc.get(t)).append(' ');
      }

      TopDocs hits = s.search(pq, NUM_DOCS);
      boolean found = false;
      for(int j=0;j<hits.scoreDocs.length;j++) {
        if (hits.scoreDocs[j].doc == docID) {
          found = true;
          break;
        }
      }

      assertTrue("phrase '" + sb + "' not found; start=" + start, found);
    }

    reader.close();
    s.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946321/fstmerge_base_8701968509289395514
=======
public void testRandomPhrases() throws Exception {
    Directory dir = new MockRAMDirectory();
    Analyzer analyzer = new MockAnalyzer();

    RandomIndexWriter w  = new RandomIndexWriter(random, dir, analyzer);
    List<List<String>> docs = new ArrayList<List<String>>();
    Document d = new Document();
    Field f = new Field("f", "", Field.Store.NO, Field.Index.ANALYZED);
    d.add(f);

    Random r = random;

    int NUM_DOCS = 10 * RANDOM_MULTIPLIER;
    for (int i = 0; i < NUM_DOCS; i++) {
      // must be > 4096 so it spans multiple chunks
      int termCount = _TestUtil.nextInt(r, 10000, 30000);

      List<String> doc = new ArrayList<String>();

      StringBuilder sb = new StringBuilder();
      while(doc.size() < termCount) {
        if (r.nextInt(5) == 1 || docs.size() == 0) {
          // make new non-empty-string term
          String term;
          while(true) {
            term = _TestUtil.randomUnicodeString(r);
            if (term.length() > 0) {
              break;
            }
          }
          TokenStream ts = analyzer.reusableTokenStream("ignore", new StringReader(term));
          CharTermAttribute termAttr = ts.addAttribute(CharTermAttribute.class);
          while(ts.incrementToken()) {
            String text = termAttr.toString();
            doc.add(text);
            sb.append(text).append(' ');
          }
        } else {
          // pick existing sub-phrase
          List<String> lastDoc = docs.get(r.nextInt(docs.size()));
          int len = _TestUtil.nextInt(r, 1, 10);
          int start = r.nextInt(lastDoc.size()-len);
          for(int k=start;k<start+len;k++) {
            String t = lastDoc.get(k);
            doc.add(t);
            sb.append(t).append(' ');
          }
        }
      }
      docs.add(doc);
      f.setValue(sb.toString());
      w.addDocument(d);
    }

    IndexReader reader = w.getReader();
    IndexSearcher s = new IndexSearcher(reader);
    w.close();

    // now search
    int num = 100 * RANDOM_MULTIPLIER;
    for(int i=0;i<num;i++) {
      int docID = r.nextInt(docs.size());
      List<String> doc = docs.get(docID);
      
      final int numTerm = _TestUtil.nextInt(r, 2, 20);
      final int start = r.nextInt(doc.size()-numTerm);
      PhraseQuery pq = new PhraseQuery();
      StringBuilder sb = new StringBuilder();
      for(int t=start;t<start+numTerm;t++) {
        pq.add(new Term("f", doc.get(t)));
        sb.append(doc.get(t)).append(' ');
      }

      TopDocs hits = s.search(pq, NUM_DOCS);
      boolean found = false;
      for(int j=0;j<hits.scoreDocs.length;j++) {
        if (hits.scoreDocs[j].doc == docID) {
          found = true;
          break;
        }
      }

      assertTrue("phrase '" + sb + "' not found; start=" + start, found);
    }

    reader.close();
    s.close();
    dir.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946321/fstmerge_var2_5611583287496218831

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946332/fstmerge_base_2583071035616917998
public static void testBefore() throws IOException {
=======
public void testBefore() throws IOException {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946332/fstmerge_var2_2974836718471437448
    // create an index
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946332/fstmerge_var1_5199023429523703540
    Directory indexStore = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946332/fstmerge_base_2583071035616917998
    RAMDirectory indexStore = new RAMDirectory();
    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));

=======
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946332/fstmerge_var2_2974836718471437448
    long now = System.currentTimeMillis();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946332/fstmerge_var1_5199023429523703540
    
    Document doc = new Document();
    // add time that is in the past
    doc.add(newField("datefield", DateTools.timeToString(now - 1000,
        DateTools.Resolution.MILLISECOND), Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc.add(newField("body", "Today is a very sunny day in New York City",
        Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    writer.close();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // filter that should preserve matches
    // DateFilter df1 = DateFilter.Before("datefield", now);
    TermRangeFilter df1 = new TermRangeFilter("datefield", DateTools
        .timeToString(now - 2000, DateTools.Resolution.MILLISECOND), DateTools
        .timeToString(now, DateTools.Resolution.MILLISECOND), false, true);
    // filter that should discard matches
    // DateFilter df2 = DateFilter.Before("datefield", now - 999999);
    TermRangeFilter df2 = new TermRangeFilter("datefield", DateTools
        .timeToString(0, DateTools.Resolution.MILLISECOND), DateTools
        .timeToString(now - 2000, DateTools.Resolution.MILLISECOND), true,
        false);
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946332/fstmerge_base_2583071035616917998

 	Document doc = new Document();
 	// add time that is in the past
 	doc.add(new Field("datefield", DateTools.timeToString(now - 1000, DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));
 	doc.add(new Field("body", "Today is a very sunny day in New York City", Field.Store.YES, Field.Index.ANALYZED));
  	writer.addDocument(doc);
 	writer.optimize();
	writer.close();

	IndexSearcher searcher = new IndexSearcher(indexStore, true);

	// filter that should preserve matches
	//DateFilter df1 = DateFilter.Before("datefield", now);
    TermRangeFilter df1 = new TermRangeFilter("datefield", DateTools.timeToString(now - 2000, DateTools.Resolution.MILLISECOND),
                                      DateTools.timeToString(now, DateTools.Resolution.MILLISECOND), false, true);
	// filter that should discard matches
	//DateFilter df2 = DateFilter.Before("datefield", now - 999999);
    TermRangeFilter df2 = new TermRangeFilter("datefield", DateTools.timeToString(0, DateTools.Resolution.MILLISECOND),
                                      DateTools.timeToString(now - 2000, DateTools.Resolution.MILLISECOND), true, false);

=======
    
    Document doc = new Document();
    // add time that is in the past
    doc.add(new Field("datefield", DateTools.timeToString(now - 1000,
        DateTools.Resolution.MILLISECOND), Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc.add(new Field("body", "Today is a very sunny day in New York City",
        Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    writer.close();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // filter that should preserve matches
    // DateFilter df1 = DateFilter.Before("datefield", now);
    TermRangeFilter df1 = new TermRangeFilter("datefield", DateTools
        .timeToString(now - 2000, DateTools.Resolution.MILLISECOND), DateTools
        .timeToString(now, DateTools.Resolution.MILLISECOND), false, true);
    // filter that should discard matches
    // DateFilter df2 = DateFilter.Before("datefield", now - 999999);
    TermRangeFilter df2 = new TermRangeFilter("datefield", DateTools
        .timeToString(0, DateTools.Resolution.MILLISECOND), DateTools
        .timeToString(now - 2000, DateTools.Resolution.MILLISECOND), true,
        false);
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946332/fstmerge_var2_2974836718471437448
    // search something that doesn't exist with DateFilter
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946332/fstmerge_base_2583071035616917998
	Query query1 = new TermQuery(new Term("body", "NoMatchForThis"));

	// search for something that does exists
	Query query2 = new TermQuery(new Term("body", "sunny"));

  ScoreDoc[] result;

	// ensure that queries return expected results without DateFilter first
  result = searcher.search(query1, null, 1000).scoreDocs;
  assertEquals(0, result.length);

  result = searcher.search(query2, null, 1000).scoreDocs;
  assertEquals(1, result.length);


	// run queries with DateFilter
  result = searcher.search(query1, df1, 1000).scoreDocs;
  assertEquals(0, result.length);

  result = searcher.search(query1, df2, 1000).scoreDocs;
  assertEquals(0, result.length);

   result = searcher.search(query2, df1, 1000).scoreDocs;
   assertEquals(1, result.length);

  result = searcher.search(query2, df2, 1000).scoreDocs;
  assertEquals(0, result.length);
    }
=======
    Query query1 = new TermQuery(new Term("body", "NoMatchForThis"));
    
    // search for something that does exists
    Query query2 = new TermQuery(new Term("body", "sunny"));
    
    ScoreDoc[] result;
    
    // ensure that queries return expected results without DateFilter first
    result = searcher.search(query1, null, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query2, null, 1000).scoreDocs;
    assertEquals(1, result.length);
    
    // run queries with DateFilter
    result = searcher.search(query1, df1, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query1, df2, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query2, df1, 1000).scoreDocs;
    assertEquals(1, result.length);
    
    result = searcher.search(query2, df2, 1000).scoreDocs;
    assertEquals(0, result.length);
    reader.close();
    indexStore.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946332/fstmerge_var2_2974836718471437448

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDateFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946338/fstmerge_var1_2237906129889601355
public void testAfter() throws IOException {
    // create an index
    Directory indexStore = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
    
    long now = System.currentTimeMillis();
    
    Document doc = new Document();
    // add time that is in the future
    doc.add(newField("datefield", DateTools.timeToString(now + 888888,
        DateTools.Resolution.MILLISECOND), Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc.add(newField("body", "Today is a very sunny day in New York City",
        Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    writer.close();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // filter that should preserve matches
    // DateFilter df1 = DateFilter.After("datefield", now);
    TermRangeFilter df1 = new TermRangeFilter("datefield", DateTools
        .timeToString(now, DateTools.Resolution.MILLISECOND), DateTools
        .timeToString(now + 999999, DateTools.Resolution.MILLISECOND), true,
        false);
    // filter that should discard matches
    // DateFilter df2 = DateFilter.After("datefield", now + 999999);
    TermRangeFilter df2 = new TermRangeFilter("datefield", DateTools
        .timeToString(now + 999999, DateTools.Resolution.MILLISECOND),
        DateTools.timeToString(now + 999999999,
            DateTools.Resolution.MILLISECOND), false, true);
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946338/fstmerge_base_4470382236981249009
public static void testAfter()
	throws IOException
    {
	// create an index
        RAMDirectory indexStore = new RAMDirectory();
        IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));

 	long now = System.currentTimeMillis();

 	Document doc = new Document();
 	// add time that is in the future
 	doc.add(new Field("datefield", DateTools.timeToString(now + 888888, DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));
 	doc.add(new Field("body", "Today is a very sunny day in New York City", Field.Store.YES, Field.Index.ANALYZED));
  	writer.addDocument(doc);
 	writer.optimize();
	writer.close();

	IndexSearcher searcher = new IndexSearcher(indexStore, true);

	// filter that should preserve matches
	//DateFilter df1 = DateFilter.After("datefield", now);
    TermRangeFilter df1 = new TermRangeFilter("datefield", DateTools.timeToString(now, DateTools.Resolution.MILLISECOND),
                                      DateTools.timeToString(now + 999999, DateTools.Resolution.MILLISECOND), true, false);
	// filter that should discard matches
	//DateFilter df2 = DateFilter.After("datefield", now + 999999);
    TermRangeFilter df2 = new TermRangeFilter("datefield", DateTools.timeToString(now + 999999, DateTools.Resolution.MILLISECOND),
                                          DateTools.timeToString(now + 999999999, DateTools.Resolution.MILLISECOND), false, true);

=======
public void testAfter() throws IOException {
    // create an index
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);
    
    long now = System.currentTimeMillis();
    
    Document doc = new Document();
    // add time that is in the future
    doc.add(new Field("datefield", DateTools.timeToString(now + 888888,
        DateTools.Resolution.MILLISECOND), Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc.add(new Field("body", "Today is a very sunny day in New York City",
        Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    writer.close();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // filter that should preserve matches
    // DateFilter df1 = DateFilter.After("datefield", now);
    TermRangeFilter df1 = new TermRangeFilter("datefield", DateTools
        .timeToString(now, DateTools.Resolution.MILLISECOND), DateTools
        .timeToString(now + 999999, DateTools.Resolution.MILLISECOND), true,
        false);
    // filter that should discard matches
    // DateFilter df2 = DateFilter.After("datefield", now + 999999);
    TermRangeFilter df2 = new TermRangeFilter("datefield", DateTools
        .timeToString(now + 999999, DateTools.Resolution.MILLISECOND),
        DateTools.timeToString(now + 999999999,
            DateTools.Resolution.MILLISECOND), false, true);
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946338/fstmerge_var2_3480715886994923597
    // search something that doesn't exist with DateFilter
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946338/fstmerge_base_4470382236981249009
	Query query1 = new TermQuery(new Term("body", "NoMatchForThis"));

	// search for something that does exists
	Query query2 = new TermQuery(new Term("body", "sunny"));

  ScoreDoc[] result;

	// ensure that queries return expected results without DateFilter first
  result = searcher.search(query1, null, 1000).scoreDocs;
  assertEquals(0, result.length);

  result = searcher.search(query2, null, 1000).scoreDocs;
  assertEquals(1, result.length);


	// run queries with DateFilter
  result = searcher.search(query1, df1, 1000).scoreDocs;
  assertEquals(0, result.length);

  result = searcher.search(query1, df2, 1000).scoreDocs;
  assertEquals(0, result.length);

   result = searcher.search(query2, df1, 1000).scoreDocs;
   assertEquals(1, result.length);

  result = searcher.search(query2, df2, 1000).scoreDocs;
  assertEquals(0, result.length);
    }
=======
    Query query1 = new TermQuery(new Term("body", "NoMatchForThis"));
    
    // search for something that does exists
    Query query2 = new TermQuery(new Term("body", "sunny"));
    
    ScoreDoc[] result;
    
    // ensure that queries return expected results without DateFilter first
    result = searcher.search(query1, null, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query2, null, 1000).scoreDocs;
    assertEquals(1, result.length);
    
    // run queries with DateFilter
    result = searcher.search(query1, df1, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query1, df2, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query2, df1, 1000).scoreDocs;
    assertEquals(1, result.length);
    
    result = searcher.search(query2, df2, 1000).scoreDocs;
    assertEquals(0, result.length);
    reader.close();
    indexStore.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946338/fstmerge_var2_3480715886994923597

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDateFilter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946344/fstmerge_var1_2950051531453175311
@Override
  public void setUp() throws Exception {
    super.setUp();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946344/fstmerge_base_3721935078849495285
=======
@Override
  public void setUp() throws Exception {
    super.setUp();
    random = newRandom();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946344/fstmerge_var2_183676739107011655

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestWildcard.java
Conflict type: LineBasedMCFd
Conflict body: 
private Directory getIndexStore(String field, String[] contents)
      throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946377/fstmerge_var1_4018227544619105884
    Directory indexStore = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946377/fstmerge_base_1339217987428553830
    RAMDirectory indexStore = new RAMDirectory();
    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946377/fstmerge_var2_8085977848347991243
    for (int i = 0; i < contents.length; ++i) {
      Document doc = new Document();
      doc.add(newField(field, contents[i], Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946377/fstmerge_base_1339217987428553830
    writer.optimize();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946377/fstmerge_var2_8085977848347991243
    writer.close();

    return indexStore;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestWildcard.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testParsingAndSearching() throws Exception {
    String field = "content";
    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, field, new MockAnalyzer());
    qp.setAllowLeadingWildcard(true);
    String docs[] = {
        "\\ abcdefg1",
        "\\79 hijklmn1",
        "\\\\ opqrstu1",
    };
    // queries that should find all docs
    String matchAll[] = {
        "*", "*1", "**1", "*?", "*?1", "?*1", "**", "***", "\\\\*"
    };
    // queries that should find no docs
    String matchNone[] = {
        "a*h", "a?h", "*a*h", "?a", "a?",
    };
    // queries that should be parsed to prefix queries
    String matchOneDocPrefix[][] = {
        {"a*", "ab*", "abc*", }, // these should find only doc 0 
        {"h*", "hi*", "hij*", "\\\\7*"}, // these should find only doc 1
        {"o*", "op*", "opq*", "\\\\\\\\*"}, // these should find only doc 2
    };
    // queries that should be parsed to wildcard queries
    String matchOneDocWild[][] = {
        {"*a*", "*ab*", "*abc**", "ab*e*", "*g?", "*f?1", "abc**"}, // these should find only doc 0
        {"*h*", "*hi*", "*hij**", "hi*k*", "*n?", "*m?1", "hij**"}, // these should find only doc 1
        {"*o*", "*op*", "*opq**", "op*q*", "*u?", "*t?1", "opq**"}, // these should find only doc 2
    };

    // prepare the index
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946387/fstmerge_var1_6989317033019019034
    Directory dir = newDirectory();
    RandomIndexWriter iw = new RandomIndexWriter(random, dir);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946387/fstmerge_base_4110714547416136179
    RAMDirectory dir = new RAMDirectory();
    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    RAMDirectory dir = new RAMDirectory();
    RandomIndexWriter iw = new RandomIndexWriter(random, dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946387/fstmerge_var2_8456088766117843624
    for (int i = 0; i < docs.length; i++) {
      Document doc = new Document();
      doc.add(newField(field,docs[i],Store.NO,Index.ANALYZED));
      iw.addDocument(doc);
    }
    iw.close();
    
    IndexSearcher searcher = new IndexSearcher(dir, true);
    
    // test queries that must find all
    for (int i = 0; i < matchAll.length; i++) {
      String qtxt = matchAll[i];
      Query q = qp.parse(qtxt);
      if (VERBOSE) System.out.println("matchAll: qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
      ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
      assertEquals(docs.length,hits.length);
    }
    
    // test queries that must find none
    for (int i = 0; i < matchNone.length; i++) {
      String qtxt = matchNone[i];
      Query q = qp.parse(qtxt);
      if (VERBOSE) System.out.println("matchNone: qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
      ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
      assertEquals(0,hits.length);
    }

    // test queries that must be prefix queries and must find only one doc
    for (int i = 0; i < matchOneDocPrefix.length; i++) {
      for (int j = 0; j < matchOneDocPrefix[i].length; j++) {
        String qtxt = matchOneDocPrefix[i][j];
        Query q = qp.parse(qtxt);
        if (VERBOSE) System.out.println("match 1 prefix: doc="+docs[i]+" qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
        assertEquals(PrefixQuery.class, q.getClass());
        ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
        assertEquals(1,hits.length);
        assertEquals(i,hits[0].doc);
      }
    }

    // test queries that must be wildcard queries and must find only one doc
    for (int i = 0; i < matchOneDocPrefix.length; i++) {
      for (int j = 0; j < matchOneDocWild[i].length; j++) {
        String qtxt = matchOneDocWild[i][j];
        Query q = qp.parse(qtxt);
        if (VERBOSE) System.out.println("match 1 wild: doc="+docs[i]+" qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
        assertEquals(WildcardQuery.class, q.getClass());
        ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
        assertEquals(1,hits.length);
        assertEquals(i,hits[0].doc);
      }
    }

    searcher.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestWildcard.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946397/fstmerge_var1_7855575429812645405
public void testPhrasePrefix() throws IOException {
    Directory indexStore = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
    Document doc1 = new Document();
    Document doc2 = new Document();
    Document doc3 = new Document();
    Document doc4 = new Document();
    Document doc5 = new Document();
    doc1.add(newField("body", "blueberry pie", Field.Store.YES,
        Field.Index.ANALYZED));
    doc2.add(newField("body", "blueberry strudel", Field.Store.YES,
        Field.Index.ANALYZED));
    doc3.add(newField("body", "blueberry pizza", Field.Store.YES,
        Field.Index.ANALYZED));
    doc4.add(newField("body", "blueberry chewing gum", Field.Store.YES,
        Field.Index.ANALYZED));
    doc5.add(newField("body", "piccadilly circus", Field.Store.YES,
        Field.Index.ANALYZED));
    writer.addDocument(doc1);
    writer.addDocument(doc2);
    writer.addDocument(doc3);
    writer.addDocument(doc4);
    writer.addDocument(doc5);
    IndexReader reader = writer.getReader();
    writer.close();
    
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();
    MultiPhraseQuery query1 = new MultiPhraseQuery();
    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();
    MultiPhraseQuery query2 = new MultiPhraseQuery();
    query1.add(new Term("body", "blueberry"));
    query2.add(new Term("body", "strawberry"));
    
    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();
    
    // this TermEnum gives "piccadilly", "pie" and "pizza".
    String prefix = "pi";
    TermsEnum te = MultiFields.getFields(reader).terms("body").iterator();
    te.seek(new BytesRef(prefix));
    do {
      String s = te.term().utf8ToString();
      if (s.startsWith(prefix)) {
        termsWithPrefix.add(new Term("body", s));
      } else {
        break;
      }
    } while (te.next() != null);
    
    query1.add(termsWithPrefix.toArray(new Term[0]));
    query2.add(termsWithPrefix.toArray(new Term[0]));
    
    ScoreDoc[] result;
    result = searcher.search(query1, null, 1000).scoreDocs;
    assertEquals(2, result.length);
    
    result = searcher.search(query2, null, 1000).scoreDocs;
    assertEquals(0, result.length);
    searcher.close();
    reader.close();
    indexStore.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946397/fstmerge_base_1992041209386857838
public void testPhrasePrefix()
        throws IOException
    {
        RAMDirectory indexStore = new RAMDirectory();
        IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
        Document doc1 = new Document();
        Document doc2 = new Document();
        Document doc3 = new Document();
        Document doc4 = new Document();
        Document doc5 = new Document();
        doc1.add(new Field("body", "blueberry pie", Field.Store.YES, Field.Index.ANALYZED));
        doc2.add(new Field("body", "blueberry strudel", Field.Store.YES, Field.Index.ANALYZED));
        doc3.add(new Field("body", "blueberry pizza", Field.Store.YES, Field.Index.ANALYZED));
        doc4.add(new Field("body", "blueberry chewing gum", Field.Store.YES, Field.Index.ANALYZED));
        doc5.add(new Field("body", "piccadilly circus", Field.Store.YES, Field.Index.ANALYZED));
        writer.addDocument(doc1);
        writer.addDocument(doc2);
        writer.addDocument(doc3);
        writer.addDocument(doc4);
        writer.addDocument(doc5);
        writer.optimize();
        writer.close();

        IndexSearcher searcher = new IndexSearcher(indexStore, true);

        //PhrasePrefixQuery query1 = new PhrasePrefixQuery();
        MultiPhraseQuery query1 = new MultiPhraseQuery();
        //PhrasePrefixQuery query2 = new PhrasePrefixQuery();
        MultiPhraseQuery query2 = new MultiPhraseQuery();
        query1.add(new Term("body", "blueberry"));
        query2.add(new Term("body", "strawberry"));

        LinkedList<Term> termsWithPrefix = new LinkedList<Term>();
        IndexReader ir = IndexReader.open(indexStore, true);

        // this TermEnum gives "piccadilly", "pie" and "pizza".
        String prefix = "pi";
        TermEnum te = ir.terms(new Term("body", prefix + "*"));
        do {
            if (te.term().text().startsWith(prefix))
            {
                termsWithPrefix.add(te.term());
            }
        } while (te.next());

        query1.add(termsWithPrefix.toArray(new Term[0]));
        query2.add(termsWithPrefix.toArray(new Term[0]));

        ScoreDoc[] result;
        result = searcher.search(query1, null, 1000).scoreDocs;
        assertEquals(2, result.length);

        result = searcher.search(query2, null, 1000).scoreDocs;
        assertEquals(0, result.length);
    }
=======
public void testPhrasePrefix() throws IOException {
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);
    Document doc1 = new Document();
    Document doc2 = new Document();
    Document doc3 = new Document();
    Document doc4 = new Document();
    Document doc5 = new Document();
    doc1.add(new Field("body", "blueberry pie", Field.Store.YES,
        Field.Index.ANALYZED));
    doc2.add(new Field("body", "blueberry strudel", Field.Store.YES,
        Field.Index.ANALYZED));
    doc3.add(new Field("body", "blueberry pizza", Field.Store.YES,
        Field.Index.ANALYZED));
    doc4.add(new Field("body", "blueberry chewing gum", Field.Store.YES,
        Field.Index.ANALYZED));
    doc5.add(new Field("body", "piccadilly circus", Field.Store.YES,
        Field.Index.ANALYZED));
    writer.addDocument(doc1);
    writer.addDocument(doc2);
    writer.addDocument(doc3);
    writer.addDocument(doc4);
    writer.addDocument(doc5);
    IndexReader reader = writer.getReader();
    writer.close();
    
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();
    MultiPhraseQuery query1 = new MultiPhraseQuery();
    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();
    MultiPhraseQuery query2 = new MultiPhraseQuery();
    query1.add(new Term("body", "blueberry"));
    query2.add(new Term("body", "strawberry"));
    
    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();
    
    // this TermEnum gives "piccadilly", "pie" and "pizza".
    String prefix = "pi";
    TermsEnum te = MultiFields.getFields(reader).terms("body").iterator();
    te.seek(new BytesRef(prefix));
    do {
      String s = te.term().utf8ToString();
      if (s.startsWith(prefix)) {
        termsWithPrefix.add(new Term("body", s));
      } else {
        break;
      }
    } while (te.next() != null);
    
    query1.add(termsWithPrefix.toArray(new Term[0]));
    query2.add(termsWithPrefix.toArray(new Term[0]));
    
    ScoreDoc[] result;
    result = searcher.search(query1, null, 1000).scoreDocs;
    assertEquals(2, result.length);
    
    result = searcher.search(query2, null, 1000).scoreDocs;
    assertEquals(0, result.length);
    searcher.close();
    reader.close();
    indexStore.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946397/fstmerge_var2_4789193246670943861

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testPrefixFilter() throws Exception {
    Directory directory = newDirectory();

    String[] categories = new String[] {"/Computers/Linux",
                                        "/Computers/Mac/One",
                                        "/Computers/Mac/Two",
                                        "/Computers/Windows"};
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946571/fstmerge_var1_966736173146834666
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946571/fstmerge_base_6792570247435064000
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946571/fstmerge_var2_6493433540002155461
    for (int i = 0; i < categories.length; i++) {
      Document doc = new Document();
      doc.add(newField("category", categories[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946571/fstmerge_base_6792570247435064000
    writer.close();
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946571/fstmerge_var2_6493433540002155461

    // PrefixFilter combined with ConstantScoreQuery
    PrefixFilter filter = new PrefixFilter(new Term("category", "/Computers"));
    Query query = new ConstantScoreQuery(filter);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946571/fstmerge_base_6792570247435064000
    IndexSearcher searcher = new IndexSearcher(directory, true);
=======
    IndexSearcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946571/fstmerge_var2_6493433540002155461
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(4, hits.length);

    // test middle of values
    filter = new PrefixFilter(new Term("category", "/Computers/Mac"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(2, hits.length);

    // test start of values
    filter = new PrefixFilter(new Term("category", "/Computers/Linux"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);

    // test end of values
    filter = new PrefixFilter(new Term("category", "/Computers/Windows"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);

    // test non-existant
    filter = new PrefixFilter(new Term("category", "/Computers/ObsoleteOS"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // test non-existant, before values
    filter = new PrefixFilter(new Term("category", "/Computers/AAA"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // test non-existant, after values
    filter = new PrefixFilter(new Term("category", "/Computers/ZZZ"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // test zero length prefix
    filter = new PrefixFilter(new Term("category", ""));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(4, hits.length);

    // test non existent field
    filter = new PrefixFilter(new Term("nonexistantfield", "/Computers"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946571/fstmerge_base_6792570247435064000
=======
    
    writer.close();
    searcher.close();
    reader.close();
    directory.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946571/fstmerge_var2_6493433540002155461
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestPrefixFilter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946582/fstmerge_var1_3794739569366004701
@Override
  public void setUp() throws Exception {
    super.setUp();
    dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, 
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false))
        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));
    
    Document doc = new Document();
    Field field = newField("field", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
    doc.add(field);

    // we generate aweful prefixes: good for testing.
    // but for preflex codec, the test can be very slow, so use less iterations.
    final String codec = CodecProvider.getDefault().getFieldCodec("field");
    int num = codec.equals("PreFlex") ? 200 * RANDOM_MULTIPLIER : 2000 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      field.setValue(_TestUtil.randomUnicodeString(random, 10));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946582/fstmerge_base_2606309394350921689
=======
@Override
  protected void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    dir = new MockRAMDirectory();
    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));
    
    Document doc = new Document();
    Field field = new Field("field", "", Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field);

    int num = 2000 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      field.setValue(_TestUtil.randomUnicodeString(random, 10));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946582/fstmerge_var2_755921722893380785

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestPrefixRandom.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946586/fstmerge_var1_4568595077100283089
@Override
  public void tearDown() throws Exception {
    reader.close();
    searcher.close();
    dir.close();
    super.tearDown();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946586/fstmerge_base_3636301022732177610
=======
@Override
  protected void tearDown() throws Exception {
    reader.close();
    searcher.close();
    dir.close();
    super.tearDown();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946586/fstmerge_var2_1806552144317693012

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestPrefixRandom.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testSimilarity() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946634/fstmerge_var1_7794306075020725926
    Directory store = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, store, 
        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
        .setSimilarity(new SimpleSimilarity()));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946634/fstmerge_base_7959044761748652542
    RAMDirectory store = new RAMDirectory();
    IndexWriter writer = new IndexWriter(store, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()).setSimilarity(new SimpleSimilarity()));
=======
    RAMDirectory store = new RAMDirectory();
    Random random = newRandom();
    RandomIndexWriter writer = new RandomIndexWriter(random, store, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
        .setSimilarity(new SimpleSimilarity()));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946634/fstmerge_var2_7665422451666777594
    
    Document d1 = new Document();
    d1.add(newField("field", "a c", Field.Store.YES, Field.Index.ANALYZED));

    Document d2 = new Document();
    d2.add(newField("field", "a b c", Field.Store.YES, Field.Index.ANALYZED));
    
    writer.addDocument(d1);
    writer.addDocument(d2);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946634/fstmerge_base_7959044761748652542
    writer.optimize();
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946634/fstmerge_var2_7665422451666777594
    writer.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946634/fstmerge_base_7959044761748652542
    Searcher searcher = new IndexSearcher(store, true);
=======
    Searcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946634/fstmerge_var2_7665422451666777594
    searcher.setSimilarity(new SimpleSimilarity());

    Term a = new Term("field", "a");
    Term b = new Term("field", "b");
    Term c = new Term("field", "c");

    searcher.search(new TermQuery(b), new Collector() {
         private Scorer scorer;
         @Override
        public void setScorer(Scorer scorer) throws IOException {
           this.scorer = scorer; 
         }
         @Override
        public final void collect(int doc) throws IOException {
           assertEquals(1.0f, scorer.score());
         }
         @Override
        public void setNextReader(IndexReader reader, int docBase) {}
         @Override
        public boolean acceptsDocsOutOfOrder() {
           return true;
         }
       });

    BooleanQuery bq = new BooleanQuery();
    bq.add(new TermQuery(a), BooleanClause.Occur.SHOULD);
    bq.add(new TermQuery(b), BooleanClause.Occur.SHOULD);
    //System.out.println(bq.toString("field"));
    searcher.search(bq, new Collector() {
         private int base = 0;
         private Scorer scorer;
         @Override
        public void setScorer(Scorer scorer) throws IOException {
           this.scorer = scorer; 
         }
         @Override
        public final void collect(int doc) throws IOException {
           //System.out.println("Doc=" + doc + " score=" + score);
           assertEquals((float)doc+base+1, scorer.score());
         }
         @Override
        public void setNextReader(IndexReader reader, int docBase) {
           base = docBase;
         }
         @Override
        public boolean acceptsDocsOutOfOrder() {
           return true;
         }
       });

    PhraseQuery pq = new PhraseQuery();
    pq.add(a);
    pq.add(c);
    //System.out.println(pq.toString("field"));
    searcher.search(pq,
       new Collector() {
         private Scorer scorer;
         @Override
         public void setScorer(Scorer scorer) throws IOException {
          this.scorer = scorer; 
         }
         @Override
         public final void collect(int doc) throws IOException {
           //System.out.println("Doc=" + doc + " score=" + score);
           assertEquals(1.0f, scorer.score());
         }
         @Override
         public void setNextReader(IndexReader reader, int docBase) {}
         @Override
         public boolean acceptsDocsOutOfOrder() {
           return true;
         }
       });

    pq.setSlop(2);
    //System.out.println(pq.toString("field"));
    searcher.search(pq, new Collector() {
      private Scorer scorer;
      @Override
      public void setScorer(Scorer scorer) throws IOException {
        this.scorer = scorer; 
      }
      @Override
      public final void collect(int doc) throws IOException {
        //System.out.println("Doc=" + doc + " score=" + score);
        assertEquals(2.0f, scorer.score());
      }
      @Override
      public void setNextReader(IndexReader reader, int docBase) {}
      @Override
      public boolean acceptsDocsOutOfOrder() {
        return true;
      }
    });
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946634/fstmerge_base_7959044761748652542
=======

    searcher.close();
    reader.close();
    store.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946634/fstmerge_var2_7665422451666777594
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestSimilarity.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public void setUp() throws Exception {
        super.setUp();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946681/fstmerge_var1_18741798472128473
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946681/fstmerge_base_3969251580511993617

=======
        rnd = newRandom();
        
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946681/fstmerge_var2_4041053864461884256
        String[] data = new String [] {
            "A 1 2 3 4 5 6",
            "Z       4 5 6",
            null,
            "B   2   4 5 6",
            "Y     3   5 6",
            null,
            "C     3     6",
            "X       4 5 6"
        };

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946681/fstmerge_var1_18741798472128473
        index = newDirectory();
        RandomIndexWriter w = new RandomIndexWriter(random, index);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946681/fstmerge_base_3969251580511993617
        index = new RAMDirectory();
        IndexWriter writer = new IndexWriter(index, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
        index = new RAMDirectory();
        RandomIndexWriter w = new RandomIndexWriter(rnd, index);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946681/fstmerge_var2_4041053864461884256

        for (int i = 0; i < data.length; i++) {
            Document doc = new Document();
            doc.add(newField("id", String.valueOf(i), Field.Store.YES, Field.Index.NOT_ANALYZED));//Field.Keyword("id",String.valueOf(i)));
            doc.add(newField("all", "all", Field.Store.YES, Field.Index.NOT_ANALYZED));//Field.Keyword("all","all"));
            if (null != data[i]) {
                doc.add(newField("data", data[i], Field.Store.YES, Field.Index.ANALYZED));//Field.Text("data",data[i]));
            }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946681/fstmerge_base_3969251580511993617
            writer.addDocument(doc);
=======
            w.addDocument(doc);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946681/fstmerge_var2_4041053864461884256
        }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946681/fstmerge_base_3969251580511993617
        writer.optimize();
        writer.close();

        r = IndexReader.open(index, true);
=======
        r = w.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946681/fstmerge_var2_4041053864461884256
        s = new IndexSearcher(r);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946681/fstmerge_base_3969251580511993617

=======
        w.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946681/fstmerge_var2_4041053864461884256
//System.out.println("Set up " + getName());
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946685/fstmerge_var1_5201345963870789554
@Override
    public void tearDown() throws Exception {
      s.close();
      r.close();
      index.close();
      super.tearDown();
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946685/fstmerge_base_6303742431752819724
=======
@Override
    protected void tearDown() throws Exception {
      s.close();
      r.close();
      index.close();
      super.tearDown();
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946685/fstmerge_var2_1170907301734670179

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testRandomQueries() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946761/fstmerge_base_8961029134122025285
      final Random rnd = newRandom();

=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946761/fstmerge_var2_4601053463729290233
      String field="data";
      String[] vals = {"1","2","3","4","5","6","A","Z","B","Y","Z","X","foo"};
      int maxLev=4;

      // callback object to set a random setMinimumNumberShouldMatch
      TestBoolean2.Callback minNrCB = new TestBoolean2.Callback() {
        public void postCreate(BooleanQuery q) {
          BooleanClause[] c =q.getClauses();
          int opt=0;
          for (int i=0; i<c.length;i++) {
            if (c[i].getOccur() == BooleanClause.Occur.SHOULD) opt++;
          }
          q.setMinimumNumberShouldMatch(random.nextInt(opt+2));
        }
      };



      // increase number of iterations for more complete testing      
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946761/fstmerge_var1_7543594188360907692
      int num = 50 * RANDOM_MULTIPLIER;
      for (int i=0; i<num; i++) {
        int lev = random.nextInt(maxLev);
        final long seed = random.nextLong();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946761/fstmerge_base_8961029134122025285
      for (int i=0; i<50*_TestUtil.getRandomMultiplier(); i++) {
        int lev = rnd.nextInt(maxLev);
        final long seed = rnd.nextLong();
=======
      int num = 50 * RANDOM_MULTIPLIER;
      for (int i=0; i<num; i++) {
        int lev = rnd.nextInt(maxLev);
        final long seed = rnd.nextLong();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946761/fstmerge_var2_4601053463729290233
        BooleanQuery q1 = TestBoolean2.randBoolQuery(new Random(seed), true, lev, field, vals, null);
        // BooleanQuery q2 = TestBoolean2.randBoolQuery(new Random(seed), lev, field, vals, minNrCB);
        BooleanQuery q2 = TestBoolean2.randBoolQuery(new Random(seed), true, lev, field, vals, null);
        // only set minimumNumberShouldMatch on the top level query since setting
        // at a lower level can change the score.
        minNrCB.postCreate(q2);

        // Can't use Hits because normalized scores will mess things
        // up.  The non-sorting version of search() that returns TopDocs
        // will not normalize scores.
        TopDocs top1 = s.search(q1,null,100);
        TopDocs top2 = s.search(q2,null,100);
        if (i < 100) {
          QueryUtils.check(random, q1,s);
          QueryUtils.check(random, q2,s);
        }
        // The constrained query
        // should be a superset to the unconstrained query.
        if (top2.totalHits > top1.totalHits) {
          fail("Constrained results not a subset:\n"
                        + CheckHits.topdocsString(top1,0,0)
                        + CheckHits.topdocsString(top2,0,0)
                        + "for query:" + q2.toString());
        }

        for (int hit=0; hit<top2.totalHits; hit++) {
          int id = top2.scoreDocs[hit].doc;
          float score = top2.scoreDocs[hit].score;
          boolean found=false;
          // find this doc in other hits
          for (int other=0; other<top1.totalHits; other++) {
            if (top1.scoreDocs[other].doc == id) {
              found=true;
              float otherScore = top1.scoreDocs[other].score;
              // check if scores match
              if (Math.abs(otherScore-score)>1.0e-6f) {
                        fail("Doc " + id + " scores don't match\n"
                + CheckHits.topdocsString(top1,0,0)
                + CheckHits.topdocsString(top2,0,0)
                + "for query:" + q2.toString());
              }
            }
          }

          // check if subset
          if (!found) fail("Doc " + id + " not found\n"
                + CheckHits.topdocsString(top1,0,0)
                + CheckHits.topdocsString(top2,0,0)
                + "for query:" + q2.toString());
        }
      }
      // System.out.println("Total hits:"+tot);
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946794/fstmerge_var1_6920680122498414515
    directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946794/fstmerge_base_3415816934137009361
    
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946794/fstmerge_var2_3608285323060412373

    for (int i = 0; i < 5137; ++i) {
      Document doc = new Document();
      doc.add(newField(FIELD, "meaninglessnames", Field.Store.YES,
                        Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    { 
      Document doc = new Document();
      doc.add(newField(FIELD, "tangfulin", Field.Store.YES,
                        Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }

    for (int i = 5138; i < 11377; ++i) {
      Document doc = new Document();
      doc.add(newField(FIELD, "meaninglessnames", Field.Store.YES,
                        Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    {
      Document doc = new Document();
      doc.add(newField(FIELD, "tangfulin", Field.Store.YES,
                        Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946794/fstmerge_base_3415816934137009361
=======
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946794/fstmerge_var2_3608285323060412373
    writer.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestPrefixInBooleanQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testOutOfOrderCollection() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946852/fstmerge_var1_8124646347695408978
    Directory dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946852/fstmerge_base_8715148027308257692

    Directory dir = new RAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======

    Directory dir = new RAMDirectory();
    Random random = newRandom();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946852/fstmerge_var2_751027847636057572
    for (int i = 0; i < 10; i++) {
      writer.addDocument(new Document());
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946852/fstmerge_base_8715148027308257692
    writer.commit();
    writer.close();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946852/fstmerge_var2_751027847636057572
    
    boolean[] inOrder = new boolean[] { false, true };
    String[] actualTSDCClass = new String[] {
        "OutOfOrderTopScoreDocCollector", 
        "InOrderTopScoreDocCollector" 
    };
    
    BooleanQuery bq = new BooleanQuery();
    // Add a Query with SHOULD, since bw.scorer() returns BooleanScorer2
    // which delegates to BS if there are no mandatory clauses.
    bq.add(new MatchAllDocsQuery(), Occur.SHOULD);
    // Set minNrShouldMatch to 1 so that BQ will not optimize rewrite to return
    // the clause instead of BQ.
    bq.setMinimumNumberShouldMatch(1);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946852/fstmerge_base_8715148027308257692
    IndexSearcher searcher = new IndexSearcher(dir, true);
=======
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946852/fstmerge_var2_751027847636057572
    for (int i = 0; i < inOrder.length; i++) {
      TopDocsCollector<ScoreDoc> tdc = TopScoreDocCollector.create(3, inOrder[i]);
      assertEquals("org.apache.lucene.search.TopScoreDocCollector$" + actualTSDCClass[i], tdc.getClass().getName());
      
      searcher.search(new MatchAllDocsQuery(), tdc);
      
      ScoreDoc[] sd = tdc.topDocs().scoreDocs;
      assertEquals(3, sd.length);
      for (int j = 0; j < sd.length; j++) {
        assertEquals("expected doc Id " + j + " found " + sd[j].doc, j, sd[j].doc);
      }
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946852/fstmerge_base_8715148027308257692
=======
    writer.close();
    searcher.close();
    reader.close();
    dir.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946852/fstmerge_var2_751027847636057572
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestTopScoreDocCollector.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946861/fstmerge_var1_443376258156419253
    directory = newDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946861/fstmerge_base_3663397614432139418
    Random r = newRandom();
    NUM_DOCS = 1000 * _TestUtil.getRandomMultiplier();
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer= new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(500));
=======
    Random r = newRandom();
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(r, directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946861/fstmerge_var2_5544366714488014609
    long theLong = Long.MAX_VALUE;
    double theDouble = Double.MAX_VALUE;
    byte theByte = Byte.MAX_VALUE;
    short theShort = Short.MAX_VALUE;
    int theInt = Integer.MAX_VALUE;
    float theFloat = Float.MAX_VALUE;
    unicodeStrings = new String[NUM_DOCS];
    for (int i = 0; i < NUM_DOCS; i++){
      Document doc = new Document();
      doc.add(newField("theLong", String.valueOf(theLong--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(newField("theDouble", String.valueOf(theDouble--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(newField("theByte", String.valueOf(theByte--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(newField("theShort", String.valueOf(theShort--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(newField("theInt", String.valueOf(theInt--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(newField("theFloat", String.valueOf(theFloat--), Field.Store.NO, Field.Index.NOT_ANALYZED));

      // sometimes skip the field:
      if (random.nextInt(40) != 17) {
        String s = null;
        if (i > 0 && random.nextInt(3) == 1) {
          // reuse past string -- try to find one that's not null
          for(int iter=0;iter<10 && s==null;iter++) {
            s = unicodeStrings[random.nextInt(i)];
          }
          if (s == null) {
            s = _TestUtil.randomUnicodeString(random, 250);
          }
        } else {
          s = _TestUtil.randomUnicodeString(random, 250);
        }
        unicodeStrings[i] = s;
        doc.add(newField("theRandomUnicodeString", unicodeStrings[i], Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));
      }
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestFieldCache.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testFilterWorks() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946953/fstmerge_var1_5964267988641060762
    Directory dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946953/fstmerge_base_734127631166255170
    Directory dir = new RAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    Directory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946953/fstmerge_var2_2336986774449401349
    for (int i = 0; i < 500; i++) {
      Document document = new Document();
      document.add(newField("field", English.intToEnglish(i) + " equals " + English.intToEnglish(i),
              Field.Store.NO, Field.Index.ANALYZED));
      writer.addDocument(document);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946953/fstmerge_base_734127631166255170
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946953/fstmerge_var2_2336986774449401349
    writer.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946953/fstmerge_base_734127631166255170
    IndexReader reader = IndexReader.open(dir, true);

=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946953/fstmerge_var2_2336986774449401349
    SpanTermQuery query = new SpanTermQuery(new Term("field", English.intToEnglish(10).trim()));
    SpanQueryFilter filter = new SpanQueryFilter(query);
    SpanFilterResult result = filter.bitSpans(new SlowMultiReaderWrapper(reader));
    DocIdSet docIdSet = result.getDocIdSet();
    assertTrue("docIdSet is null and it shouldn't be", docIdSet != null);
    assertContainsDocId("docIdSet doesn't contain docId 10", docIdSet, 10);
    List<SpanFilterResult.PositionInfo> spans = result.getPositions();
    assertTrue("spans is null and it shouldn't be", spans != null);
    int size = getDocIdSetSize(docIdSet);
    assertTrue("spans Size: " + spans.size() + " is not: " + size, spans.size() == size);
    for (final SpanFilterResult.PositionInfo info: spans) {
      assertTrue("info is null and it shouldn't be", info != null);
      //The doc should indicate the bit is on
      assertContainsDocId("docIdSet doesn't contain docId " + info.getDoc(), docIdSet, info.getDoc());
      //There should be two positions in each
      assertTrue("info.getPositions() Size: " + info.getPositions().size() + " is not: " + 2, info.getPositions().size() == 2);
    }
    reader.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946953/fstmerge_base_734127631166255170
=======
    dir.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946953/fstmerge_var2_2336986774449401349
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestSpanQueryFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void beforeClass() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946963/fstmerge_var1_3265907539940184194
    directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
        .setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946963/fstmerge_base_8448436438490998890
    directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    directory = new RAMDirectory();
    Random random = newStaticRandom(TestNumericRangeQuery64.class);
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946963/fstmerge_var2_4744830833361107402
    
    NumericField
      field8 = new NumericField("field8", 8, Field.Store.YES, true),
      field6 = new NumericField("field6", 6, Field.Store.YES, true),
      field4 = new NumericField("field4", 4, Field.Store.YES, true),
      field2 = new NumericField("field2", 2, Field.Store.YES, true),
      fieldNoTrie = new NumericField("field"+Integer.MAX_VALUE, Integer.MAX_VALUE, Field.Store.YES, true),
      ascfield8 = new NumericField("ascfield8", 8, Field.Store.NO, true),
      ascfield6 = new NumericField("ascfield6", 6, Field.Store.NO, true),
      ascfield4 = new NumericField("ascfield4", 4, Field.Store.NO, true),
      ascfield2 = new NumericField("ascfield2", 2, Field.Store.NO, true);
    
    Document doc = new Document();
    // add fields, that have a distance to test general functionality
    doc.add(field8); doc.add(field6); doc.add(field4); doc.add(field2); doc.add(fieldNoTrie);
    // add ascending fields with a distance of 1, beginning at -noDocs/2 to test the correct splitting of range and inclusive/exclusive
    doc.add(ascfield8); doc.add(ascfield6); doc.add(ascfield4); doc.add(ascfield2);
    
    // Add a series of noDocs docs with increasing long values, by updating the fields
    for (int l=0; l<noDocs; l++) {
      long val=distance*l+startOffset;
      field8.setLongValue(val);
      field6.setLongValue(val);
      field4.setLongValue(val);
      field2.setLongValue(val);
      fieldNoTrie.setLongValue(val);

      val=l-(noDocs/2);
      ascfield8.setLongValue(val);
      ascfield6.setLongValue(val);
      ascfield4.setLongValue(val);
      ascfield2.setLongValue(val);
      writer.addDocument(doc);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946963/fstmerge_var1_3265907539940184194
    reader = writer.getReader();
    searcher=new IndexSearcher(reader);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946963/fstmerge_base_8448436438490998890
  
    writer.optimize();
=======
  
    reader = writer.getReader();
    searcher=new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946963/fstmerge_var2_4744830833361107402
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946963/fstmerge_base_8448436438490998890
    searcher=new IndexSearcher(directory, true);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627946963/fstmerge_var2_4744830833361107402
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java
Conflict type: LineBasedMCFd
Conflict body: 
private void testRandomTrieAndClassicRangeQuery(int precisionStep) throws Exception {
    String field="field"+precisionStep;
    int termCountT=0,termCountC=0;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947059/fstmerge_var1_117550056323439311
    int num = 10 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      long lower=(long)(random.nextDouble()*noDocs*distance)+startOffset;
      long upper=(long)(random.nextDouble()*noDocs*distance)+startOffset;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947059/fstmerge_base_9196795487455411699
    for (int i=0; i<10*_TestUtil.getRandomMultiplier(); i++) {
      long lower=(long)(rnd.nextDouble()*noDocs*distance)+startOffset;
      long upper=(long)(rnd.nextDouble()*noDocs*distance)+startOffset;
=======
    int num = 10 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      long lower=(long)(rnd.nextDouble()*noDocs*distance)+startOffset;
      long upper=(long)(rnd.nextDouble()*noDocs*distance)+startOffset;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947059/fstmerge_var2_787421760864226157
      if (lower>upper) {
        long a=lower; lower=upper; upper=a;
      }
      final BytesRef lowerBytes = new BytesRef(NumericUtils.BUF_SIZE_LONG), upperBytes = new BytesRef(NumericUtils.BUF_SIZE_LONG);
      NumericUtils.longToPrefixCoded(lower, 0, lowerBytes);
      NumericUtils.longToPrefixCoded(upper, 0, upperBytes);
      // TODO: when new TermRange ctors with BytesRef available, use them and do not convert to string!
      final String lowerString = lowerBytes.utf8ToString(), upperString = upperBytes.utf8ToString();
      
      // test inclusive range
      NumericRangeQuery<Long> tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, true);
      TermRangeQuery cq=new TermRangeQuery(field, lowerString, upperString, true, true);
      TopDocs tTopDocs = searcher.search(tq, 1);
      TopDocs cTopDocs = searcher.search(cq, 1);
      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
      termCountT += tq.getTotalNumberOfTerms();
      termCountC += cq.getTotalNumberOfTerms();
      // test exclusive range
      tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, false, false);
      cq=new TermRangeQuery(field, lowerString, upperString, false, false);
      tTopDocs = searcher.search(tq, 1);
      cTopDocs = searcher.search(cq, 1);
      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
      termCountT += tq.getTotalNumberOfTerms();
      termCountC += cq.getTotalNumberOfTerms();
      // test left exclusive range
      tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, false, true);
      cq=new TermRangeQuery(field, lowerString, upperString, false, true);
      tTopDocs = searcher.search(tq, 1);
      cTopDocs = searcher.search(cq, 1);
      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
      termCountT += tq.getTotalNumberOfTerms();
      termCountC += cq.getTotalNumberOfTerms();
      // test right exclusive range
      tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, false);
      cq=new TermRangeQuery(field, lowerString, upperString, true, false);
      tTopDocs = searcher.search(tq, 1);
      cTopDocs = searcher.search(cq, 1);
      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
      termCountT += tq.getTotalNumberOfTerms();
      termCountC += cq.getTotalNumberOfTerms();
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947059/fstmerge_base_9196795487455411699
    if (precisionStep == Integer.MAX_VALUE) {
=======
    if (precisionStep == Integer.MAX_VALUE && searcher.getIndexReader().getSequentialSubReaders().length == 1) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947059/fstmerge_var2_787421760864226157
      assertEquals("Total number of terms should be equal for unlimited precStep", termCountT, termCountC);
    } else if (VERBOSE) {
      System.out.println("Average number of terms during random search on '" + field + "':");
      System.out.println(" Trie query: " + (((double)termCountT)/(num * 4)));
      System.out.println(" Classical query: " + (((double)termCountC)/(num * 4)));
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java
Conflict type: LineBasedMCFd
Conflict body: 
private void testRangeSplit(int precisionStep) throws Exception {
    String field="ascfield"+precisionStep;
    // 10 random tests
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947087/fstmerge_var1_4404668605805622062
    int num = 10 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      long lower=(long)(random.nextDouble()*noDocs - noDocs/2);
      long upper=(long)(random.nextDouble()*noDocs - noDocs/2);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947087/fstmerge_base_79764500084772714
    for (int i=0; i<10*_TestUtil.getRandomMultiplier(); i++) {
      long lower=(long)(rnd.nextDouble()*noDocs - noDocs/2);
      long upper=(long)(rnd.nextDouble()*noDocs - noDocs/2);
=======
    int num = 10 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      long lower=(long)(rnd.nextDouble()*noDocs - noDocs/2);
      long upper=(long)(rnd.nextDouble()*noDocs - noDocs/2);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947087/fstmerge_var2_2889042292387474100
      if (lower>upper) {
        long a=lower; lower=upper; upper=a;
      }
      // test inclusive range
      Query tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, true);
      TopDocs tTopDocs = searcher.search(tq, 1);
      assertEquals("Returned count of range query must be equal to inclusive range length", upper-lower+1, tTopDocs.totalHits );
      // test exclusive range
      tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, false, false);
      tTopDocs = searcher.search(tq, 1);
      assertEquals("Returned count of range query must be equal to exclusive range length", Math.max(upper-lower-1, 0), tTopDocs.totalHits );
      // test left exclusive range
      tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, false, true);
      tTopDocs = searcher.search(tq, 1);
      assertEquals("Returned count of range query must be equal to half exclusive range length", upper-lower, tTopDocs.totalHits );
      // test right exclusive range
      tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, false);
      tTopDocs = searcher.search(tq, 1);
      assertEquals("Returned count of range query must be equal to half exclusive range length", upper-lower, tTopDocs.totalHits );
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java
Conflict type: LineBasedMCFd
Conflict body: 
private void testSorting(int precisionStep) throws Exception {
    String field="field"+precisionStep;
    // 10 random tests, the index order is ascending,
    // so using a reverse sort field should retun descending documents
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947131/fstmerge_var1_205049693186015697
    int num = 10 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      long lower=(long)(random.nextDouble()*noDocs*distance)+startOffset;
      long upper=(long)(random.nextDouble()*noDocs*distance)+startOffset;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947131/fstmerge_base_2961408517940864036
    for (int i=0; i<10*_TestUtil.getRandomMultiplier(); i++) {
      long lower=(long)(rnd.nextDouble()*noDocs*distance)+startOffset;
      long upper=(long)(rnd.nextDouble()*noDocs*distance)+startOffset;
=======
    int num = 10 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      long lower=(long)(rnd.nextDouble()*noDocs*distance)+startOffset;
      long upper=(long)(rnd.nextDouble()*noDocs*distance)+startOffset;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947131/fstmerge_var2_1499429672089738430
      if (lower>upper) {
        long a=lower; lower=upper; upper=a;
      }
      Query tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, true);
      TopDocs topDocs = searcher.search(tq, null, noDocs, new Sort(new SortField(field, SortField.LONG, true)));
      if (topDocs.totalHits==0) continue;
      ScoreDoc[] sd = topDocs.scoreDocs;
      assertNotNull(sd);
      long last=Long.parseLong(searcher.doc(sd[0].doc).get(field));
      for (int j=1; j<sd.length; j++) {
        long act=Long.parseLong(searcher.doc(sd[j].doc).get(field));
        assertTrue("Docs should be sorted backwards", last>act );
        last=act;
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947176/fstmerge_var1_6273727876360569041
  public void setUp() throws Exception {
    super.setUp();
    
    index = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, index,
        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
            .setSimilarity(sim));
    
    // hed is the most important field, dek is secondary
    
    // d1 is an "ok" match for: albino elephant
    {
      Document d1 = new Document();
      d1.add(newField("id", "d1", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d1"));
      d1
          .add(newField("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      d1
          .add(newField("dek", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("dek", "elephant"));
      writer.addDocument(d1);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947176/fstmerge_base_1729168745941847210
    protected void setUp() throws Exception {
        super.setUp();

        index = new RAMDirectory();
        IndexWriter writer = new IndexWriter(index, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setSimilarity(sim));

        // hed is the most important field, dek is secondary

        // d1 is an "ok" match for:  albino elephant
        {
            Document d1 = new Document();
            d1.add(new Field("id", "d1", Field.Store.YES, Field.Index.NOT_ANALYZED));//Field.Keyword("id", "d1"));
            d1.add(new Field("hed", "elephant", Field.Store.YES, Field.Index.ANALYZED));//Field.Text("hed", "elephant"));
            d1.add(new Field("dek", "elephant", Field.Store.YES, Field.Index.ANALYZED));//Field.Text("dek", "elephant"));
            writer.addDocument(d1);
        }

        // d2 is a "good" match for:  albino elephant
        {
            Document d2 = new Document();
            d2.add(new Field("id", "d2", Field.Store.YES, Field.Index.NOT_ANALYZED));//Field.Keyword("id", "d2"));
            d2.add(new Field("hed", "elephant", Field.Store.YES, Field.Index.ANALYZED));//Field.Text("hed", "elephant"));
            d2.add(new Field("dek", "albino", Field.Store.YES, Field.Index.ANALYZED));//Field.Text("dek", "albino"));
            d2.add(new Field("dek", "elephant", Field.Store.YES, Field.Index.ANALYZED));//Field.Text("dek", "elephant"));
            writer.addDocument(d2);
        }

        // d3 is a "better" match for:  albino elephant
        {
            Document d3 = new Document();
            d3.add(new Field("id", "d3", Field.Store.YES, Field.Index.NOT_ANALYZED));//Field.Keyword("id", "d3"));
            d3.add(new Field("hed", "albino", Field.Store.YES, Field.Index.ANALYZED));//Field.Text("hed", "albino"));
            d3.add(new Field("hed", "elephant", Field.Store.YES, Field.Index.ANALYZED));//Field.Text("hed", "elephant"));
            writer.addDocument(d3);
        }

        // d4 is the "best" match for:  albino elephant
        {
            Document d4 = new Document();
            d4.add(new Field("id", "d4", Field.Store.YES, Field.Index.NOT_ANALYZED));//Field.Keyword("id", "d4"));
            d4.add(new Field("hed", "albino", Field.Store.YES, Field.Index.ANALYZED));//Field.Text("hed", "albino"));
            d4.add(new Field("hed", "elephant", Field.Store.YES, Field.Index.ANALYZED));//Field.Text("hed", "elephant"));
            d4.add(new Field("dek", "albino", Field.Store.YES, Field.Index.ANALYZED));//Field.Text("dek", "albino"));
            writer.addDocument(d4);
        }

        writer.close();

        r = IndexReader.open(index, true);
        s = new IndexSearcher(r);
        s.setSimilarity(sim);
=======
  protected void setUp() throws Exception {
    super.setUp();
    
    index = new RAMDirectory();
    Random random = newRandom();
    RandomIndexWriter writer = new RandomIndexWriter(random, index,
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
            .setSimilarity(sim));
    
    // hed is the most important field, dek is secondary
    
    // d1 is an "ok" match for: albino elephant
    {
      Document d1 = new Document();
      d1.add(new Field("id", "d1", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d1"));
      d1
          .add(new Field("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      d1
          .add(new Field("dek", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("dek", "elephant"));
      writer.addDocument(d1);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947176/fstmerge_var2_4556535189252789846
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947176/fstmerge_var1_6273727876360569041
    
    // d2 is a "good" match for: albino elephant
    {
      Document d2 = new Document();
      d2.add(newField("id", "d2", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d2"));
      d2
          .add(newField("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      d2.add(newField("dek", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("dek",
                                                                                // "albino"));
      d2
          .add(newField("dek", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("dek", "elephant"));
      writer.addDocument(d2);
    }
    
    // d3 is a "better" match for: albino elephant
    {
      Document d3 = new Document();
      d3.add(newField("id", "d3", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d3"));
      d3.add(newField("hed", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("hed",
                                                                                // "albino"));
      d3
          .add(newField("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      writer.addDocument(d3);
    }
    
    // d4 is the "best" match for: albino elephant
    {
      Document d4 = new Document();
      d4.add(newField("id", "d4", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d4"));
      d4.add(newField("hed", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("hed",
                                                                                // "albino"));
      d4
          .add(newField("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      d4.add(newField("dek", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("dek",
                                                                                // "albino"));
      writer.addDocument(d4);
    }
    
    r = new SlowMultiReaderWrapper(writer.getReader());
    writer.close();
    s = new IndexSearcher(r);
    s.setSimilarity(sim);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947176/fstmerge_base_1729168745941847210
=======
    
    // d2 is a "good" match for: albino elephant
    {
      Document d2 = new Document();
      d2.add(new Field("id", "d2", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d2"));
      d2
          .add(new Field("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      d2.add(new Field("dek", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("dek",
                                                                                // "albino"));
      d2
          .add(new Field("dek", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("dek", "elephant"));
      writer.addDocument(d2);
    }
    
    // d3 is a "better" match for: albino elephant
    {
      Document d3 = new Document();
      d3.add(new Field("id", "d3", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d3"));
      d3.add(new Field("hed", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("hed",
                                                                                // "albino"));
      d3
          .add(new Field("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      writer.addDocument(d3);
    }
    
    // d4 is the "best" match for: albino elephant
    {
      Document d4 = new Document();
      d4.add(new Field("id", "d4", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d4"));
      d4.add(new Field("hed", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("hed",
                                                                                // "albino"));
      d4
          .add(new Field("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      d4.add(new Field("dek", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("dek",
                                                                                // "albino"));
      writer.addDocument(d4);
    }
    
    r = writer.getReader();
    writer.close();
    s = new IndexSearcher(r);
    s.setSimilarity(sim);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947176/fstmerge_var2_4556535189252789846

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947188/fstmerge_var1_2335493515894695600
@Override
  public void tearDown() throws Exception {
    s.close();
    r.close();
    index.close();
    super.tearDown();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947188/fstmerge_base_5745600856265443701
=======
@Override
  protected void tearDown() throws Exception {
    s.close();
    r.close();
    index.close();
    super.tearDown();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947188/fstmerge_var2_3055972814331730161

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testSkipToFirsttimeMiss() throws IOException {
    final DisjunctionMaxQuery dq = new DisjunctionMaxQuery(0.0f);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947192/fstmerge_var1_2782054193736705056
    dq.add(tq("id", "d1"));
    dq.add(tq("dek", "DOES_NOT_EXIST"));
    
    QueryUtils.check(random, dq, s);
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947192/fstmerge_base_5903678471354776476
    dq.add(tq("id","d1"));
    dq.add(tq("dek","DOES_NOT_EXIST"));

    QueryUtils.check(dq,s);

=======
    dq.add(tq("id", "d1"));
    dq.add(tq("dek", "DOES_NOT_EXIST"));
    
    QueryUtils.check(dq, s);
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947192/fstmerge_var2_797038669436295393
    final Weight dw = dq.weight(s);
    final Scorer ds = dw.scorer(s.getIndexReader(), true, false);
    final boolean skipOk = ds.advance(3) != DocIdSetIterator.NO_MORE_DOCS;
    if (skipOk) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947192/fstmerge_base_5903678471354776476
      fail("firsttime skipTo found a match? ... " + r.document(ds.docID()).get("id"));
=======
      fail("firsttime skipTo found a match? ... "
          + r.document(ds.docID()).get("id"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947192/fstmerge_var2_797038669436295393
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testSkipToFirsttimeHit() throws IOException {
    final DisjunctionMaxQuery dq = new DisjunctionMaxQuery(0.0f);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947196/fstmerge_var1_7880003980540170623
    dq.add(tq("dek", "albino"));
    dq.add(tq("dek", "DOES_NOT_EXIST"));
    
    QueryUtils.check(random, dq, s);
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947196/fstmerge_base_6592466470841473065
    dq.add(tq("dek","albino"));
    dq.add(tq("dek","DOES_NOT_EXIST"));

    QueryUtils.check(dq,s);

=======
    dq.add(tq("dek", "albino"));
    dq.add(tq("dek", "DOES_NOT_EXIST"));
    
    QueryUtils.check(dq, s);
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947196/fstmerge_var2_1361112898724830618
    final Weight dw = dq.weight(s);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947196/fstmerge_var1_7880003980540170623
    final Scorer ds = dw.scorer(s.getIndexReader(), true, false);
    assertTrue("firsttime skipTo found no match",
        ds.advance(3) != DocIdSetIterator.NO_MORE_DOCS);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947196/fstmerge_base_6592466470841473065
    final Scorer ds = dw.scorer(r, true, false);
    assertTrue("firsttime skipTo found no match", ds.advance(3) != DocIdSetIterator.NO_MORE_DOCS);
=======
    final Scorer ds = dw.scorer(r, true, false);
    assertTrue("firsttime skipTo found no match",
        ds.advance(3) != DocIdSetIterator.NO_MORE_DOCS);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947196/fstmerge_var2_1361112898724830618
    assertEquals("found wrong docid", "d4", r.document(ds.docID()).get("id"));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testSimpleEqualScores1() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_base_8986983576858440731

=======
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_var2_2220184170433992535
    DisjunctionMaxQuery q = new DisjunctionMaxQuery(0.0f);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_var1_8203475315218763200
    q.add(tq("hed", "albino"));
    q.add(tq("hed", "elephant"));
    QueryUtils.check(random, q, s);
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_base_8986983576858440731
    q.add(tq("hed","albino"));
    q.add(tq("hed","elephant"));
    QueryUtils.check(q,s);

=======
    q.add(tq("hed", "albino"));
    q.add(tq("hed", "elephant"));
    QueryUtils.check(q, s);
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_var2_2220184170433992535
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_base_8986983576858440731

=======
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_var2_2220184170433992535
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_base_8986983576858440731
      assertEquals("all docs should match " + q.toString(),
          4, h.length);

=======
      assertEquals("all docs should match " + q.toString(), 4, h.length);
      
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_var2_2220184170433992535
      float score = h[0].score;
      for (int i = 1; i < h.length; i++) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_base_8986983576858440731
        assertEquals("score #" + i + " is not the same",
            score, h[i].score, SCORE_COMP_THRESH);
=======
        assertEquals("score #" + i + " is not the same", score, h[i].score,
            SCORE_COMP_THRESH);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_var2_2220184170433992535
      }
    } catch (Error e) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_base_8986983576858440731
      printHits("testSimpleEqualScores1",h,s);
=======
      printHits("testSimpleEqualScores1", h, s);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_var2_2220184170433992535
      throw e;
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_base_8986983576858440731

=======
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947201/fstmerge_var2_2220184170433992535
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testSimpleEqualScores2() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947205/fstmerge_var1_3939029127408450600
    
    DisjunctionMaxQuery q = new DisjunctionMaxQuery(0.0f);
    q.add(tq("dek", "albino"));
    q.add(tq("dek", "elephant"));
    QueryUtils.check(random, q, s);
    
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
    
    try {
      assertEquals("3 docs should match " + q.toString(), 3, h.length);
      float score = h[0].score;
      for (int i = 1; i < h.length; i++) {
        assertEquals("score #" + i + " is not the same", score, h[i].score,
            SCORE_COMP_THRESH);
      }
    } catch (Error e) {
      printHits("testSimpleEqualScores2", h, s);
      throw e;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947205/fstmerge_base_8636676399609309857

        DisjunctionMaxQuery q = new DisjunctionMaxQuery(0.0f);
        q.add(tq("dek","albino"));
        q.add(tq("dek","elephant"));
        QueryUtils.check(q,s);


        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;

        try {
            assertEquals("3 docs should match " + q.toString(),
                         3, h.length);
            float score = h[0].score;
            for (int i = 1; i < h.length; i++) {
                assertEquals("score #" + i + " is not the same",
                             score, h[i].score, SCORE_COMP_THRESH);
            }
        } catch (Error e) {
            printHits("testSimpleEqualScores2",h, s);
            throw e;
        }

=======
    
    DisjunctionMaxQuery q = new DisjunctionMaxQuery(0.0f);
    q.add(tq("dek", "albino"));
    q.add(tq("dek", "elephant"));
    QueryUtils.check(q, s);
    
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
    
    try {
      assertEquals("3 docs should match " + q.toString(), 3, h.length);
      float score = h[0].score;
      for (int i = 1; i < h.length; i++) {
        assertEquals("score #" + i + " is not the same", score, h[i].score,
            SCORE_COMP_THRESH);
      }
    } catch (Error e) {
      printHits("testSimpleEqualScores2", h, s);
      throw e;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947205/fstmerge_var2_7320763870375204204
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947205/fstmerge_base_8636676399609309857
=======
    
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947205/fstmerge_var2_7320763870375204204

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testSimpleEqualScores3() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947209/fstmerge_var1_3318630641140922583
    
    DisjunctionMaxQuery q = new DisjunctionMaxQuery(0.0f);
    q.add(tq("hed", "albino"));
    q.add(tq("hed", "elephant"));
    q.add(tq("dek", "albino"));
    q.add(tq("dek", "elephant"));
    QueryUtils.check(random, q, s);
    
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
    
    try {
      assertEquals("all docs should match " + q.toString(), 4, h.length);
      float score = h[0].score;
      for (int i = 1; i < h.length; i++) {
        assertEquals("score #" + i + " is not the same", score, h[i].score,
            SCORE_COMP_THRESH);
      }
    } catch (Error e) {
      printHits("testSimpleEqualScores3", h, s);
      throw e;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947209/fstmerge_base_2554952486601918475

        DisjunctionMaxQuery q = new DisjunctionMaxQuery(0.0f);
        q.add(tq("hed","albino"));
        q.add(tq("hed","elephant"));
        q.add(tq("dek","albino"));
        q.add(tq("dek","elephant"));
        QueryUtils.check(q,s);


        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;

        try {
            assertEquals("all docs should match " + q.toString(),
                         4, h.length);
            float score = h[0].score;
            for (int i = 1; i < h.length; i++) {
                assertEquals("score #" + i + " is not the same",
                             score, h[i].score, SCORE_COMP_THRESH);
            }
        } catch (Error e) {
            printHits("testSimpleEqualScores3",h, s);
            throw e;
        }

=======
    
    DisjunctionMaxQuery q = new DisjunctionMaxQuery(0.0f);
    q.add(tq("hed", "albino"));
    q.add(tq("hed", "elephant"));
    q.add(tq("dek", "albino"));
    q.add(tq("dek", "elephant"));
    QueryUtils.check(q, s);
    
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
    
    try {
      assertEquals("all docs should match " + q.toString(), 4, h.length);
      float score = h[0].score;
      for (int i = 1; i < h.length; i++) {
        assertEquals("score #" + i + " is not the same", score, h[i].score,
            SCORE_COMP_THRESH);
      }
    } catch (Error e) {
      printHits("testSimpleEqualScores3", h, s);
      throw e;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947209/fstmerge_var2_1679978033082345761
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947209/fstmerge_base_2554952486601918475
=======
    
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947209/fstmerge_var2_1679978033082345761

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testSimpleTiebreaker() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947213/fstmerge_var1_955881970635613639
    
    DisjunctionMaxQuery q = new DisjunctionMaxQuery(0.01f);
    q.add(tq("dek", "albino"));
    q.add(tq("dek", "elephant"));
    QueryUtils.check(random, q, s);
    
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
    
    try {
      assertEquals("3 docs should match " + q.toString(), 3, h.length);
      assertEquals("wrong first", "d2", s.doc(h[0].doc).get("id"));
      float score0 = h[0].score;
      float score1 = h[1].score;
      float score2 = h[2].score;
      assertTrue("d2 does not have better score then others: " + score0
          + " >? " + score1, score0 > score1);
      assertEquals("d4 and d1 don't have equal scores", score1, score2,
          SCORE_COMP_THRESH);
    } catch (Error e) {
      printHits("testSimpleTiebreaker", h, s);
      throw e;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947213/fstmerge_base_698608142132444615

        DisjunctionMaxQuery q = new DisjunctionMaxQuery(0.01f);
        q.add(tq("dek","albino"));
        q.add(tq("dek","elephant"));
        QueryUtils.check(q,s);


        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;

        try {
            assertEquals("3 docs should match " + q.toString(),
                         3, h.length);
            assertEquals("wrong first",  "d2", s.doc(h[0].doc).get("id"));
            float score0 = h[0].score;
            float score1 = h[1].score;
            float score2 = h[2].score;
            assertTrue("d2 does not have better score then others: " +
                       score0 + " >? " + score1,
                       score0 > score1);
            assertEquals("d4 and d1 don't have equal scores",
                         score1, score2, SCORE_COMP_THRESH);
        } catch (Error e) {
            printHits("testSimpleTiebreaker",h, s);
            throw e;
        }
=======
    
    DisjunctionMaxQuery q = new DisjunctionMaxQuery(0.01f);
    q.add(tq("dek", "albino"));
    q.add(tq("dek", "elephant"));
    QueryUtils.check(q, s);
    
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
    
    try {
      assertEquals("3 docs should match " + q.toString(), 3, h.length);
      assertEquals("wrong first", "d2", s.doc(h[0].doc).get("id"));
      float score0 = h[0].score;
      float score1 = h[1].score;
      float score2 = h[2].score;
      assertTrue("d2 does not have better score then others: " + score0
          + " >? " + score1, score0 > score1);
      assertEquals("d4 and d1 don't have equal scores", score1, score2,
          SCORE_COMP_THRESH);
    } catch (Error e) {
      printHits("testSimpleTiebreaker", h, s);
      throw e;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947213/fstmerge_var2_9114392081211951110
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947213/fstmerge_base_698608142132444615
=======
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947213/fstmerge_var2_9114392081211951110

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testBooleanRequiredEqualScores() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947217/fstmerge_var1_3599962737935746826
    
    BooleanQuery q = new BooleanQuery();
    {
      DisjunctionMaxQuery q1 = new DisjunctionMaxQuery(0.0f);
      q1.add(tq("hed", "albino"));
      q1.add(tq("dek", "albino"));
      q.add(q1, BooleanClause.Occur.MUST);// true,false);
      QueryUtils.check(random, q1, s);
      
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947217/fstmerge_base_8282744282011520941

        BooleanQuery q = new BooleanQuery();
        {
            DisjunctionMaxQuery q1 = new DisjunctionMaxQuery(0.0f);
            q1.add(tq("hed","albino"));
            q1.add(tq("dek","albino"));
            q.add(q1,BooleanClause.Occur.MUST);//true,false);
            QueryUtils.check(q1,s);

        }
        {
            DisjunctionMaxQuery q2 = new DisjunctionMaxQuery(0.0f);
            q2.add(tq("hed","elephant"));
            q2.add(tq("dek","elephant"));
            q.add(q2, BooleanClause.Occur.MUST);//true,false);
           QueryUtils.check(q2,s);
        }

        QueryUtils.check(q,s);

        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;

        try {
            assertEquals("3 docs should match " + q.toString(),
                         3, h.length);
            float score = h[0].score;
            for (int i = 1; i < h.length; i++) {
                assertEquals("score #" + i + " is not the same",
                             score, h[i].score, SCORE_COMP_THRESH);
            }
        } catch (Error e) {
            printHits("testBooleanRequiredEqualScores1",h, s);
            throw e;
        }
=======
    
    BooleanQuery q = new BooleanQuery();
    {
      DisjunctionMaxQuery q1 = new DisjunctionMaxQuery(0.0f);
      q1.add(tq("hed", "albino"));
      q1.add(tq("dek", "albino"));
      q.add(q1, BooleanClause.Occur.MUST);// true,false);
      QueryUtils.check(q1, s);
      
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947217/fstmerge_var2_1083848307957779250
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947217/fstmerge_var1_3599962737935746826
    {
      DisjunctionMaxQuery q2 = new DisjunctionMaxQuery(0.0f);
      q2.add(tq("hed", "elephant"));
      q2.add(tq("dek", "elephant"));
      q.add(q2, BooleanClause.Occur.MUST);// true,false);
      QueryUtils.check(random, q2, s);
    }
    
    QueryUtils.check(random, q, s);
    
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
    
    try {
      assertEquals("3 docs should match " + q.toString(), 3, h.length);
      float score = h[0].score;
      for (int i = 1; i < h.length; i++) {
        assertEquals("score #" + i + " is not the same", score, h[i].score,
            SCORE_COMP_THRESH);
      }
    } catch (Error e) {
      printHits("testBooleanRequiredEqualScores1", h, s);
      throw e;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947217/fstmerge_base_8282744282011520941
=======
    {
      DisjunctionMaxQuery q2 = new DisjunctionMaxQuery(0.0f);
      q2.add(tq("hed", "elephant"));
      q2.add(tq("dek", "elephant"));
      q.add(q2, BooleanClause.Occur.MUST);// true,false);
      QueryUtils.check(q2, s);
    }
    
    QueryUtils.check(q, s);
    
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
    
    try {
      assertEquals("3 docs should match " + q.toString(), 3, h.length);
      float score = h[0].score;
      for (int i = 1; i < h.length; i++) {
        assertEquals("score #" + i + " is not the same", score, h[i].score,
            SCORE_COMP_THRESH);
      }
    } catch (Error e) {
      printHits("testBooleanRequiredEqualScores1", h, s);
      throw e;
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947217/fstmerge_var2_1083848307957779250

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testBooleanOptionalNoTiebreaker() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947221/fstmerge_base_2597911432451375960

        BooleanQuery q = new BooleanQuery();
        {
            DisjunctionMaxQuery q1 = new DisjunctionMaxQuery(0.0f);
            q1.add(tq("hed","albino"));
            q1.add(tq("dek","albino"));
            q.add(q1, BooleanClause.Occur.SHOULD);//false,false);
        }
        {
            DisjunctionMaxQuery q2 = new DisjunctionMaxQuery(0.0f);
            q2.add(tq("hed","elephant"));
            q2.add(tq("dek","elephant"));
            q.add(q2, BooleanClause.Occur.SHOULD);//false,false);
        }
        QueryUtils.check(q,s);


        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;

        try {
            assertEquals("4 docs should match " + q.toString(),
                         4, h.length);
            float score = h[0].score;
            for (int i = 1; i < h.length-1; i++) { /* note: -1 */
                assertEquals("score #" + i + " is not the same",
                             score, h[i].score, SCORE_COMP_THRESH);
            }
            assertEquals("wrong last", "d1", s.doc(h[h.length-1].doc).get("id"));
            float score1 = h[h.length-1].score;
            assertTrue("d1 does not have worse score then others: " +
                       score + " >? " + score1,
                       score > score1);
        } catch (Error e) {
            printHits("testBooleanOptionalNoTiebreaker",h, s);
            throw e;
        }
=======
    
    BooleanQuery q = new BooleanQuery();
    {
      DisjunctionMaxQuery q1 = new DisjunctionMaxQuery(0.0f);
      q1.add(tq("hed", "albino"));
      q1.add(tq("dek", "albino"));
      q.add(q1, BooleanClause.Occur.SHOULD);// false,false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947221/fstmerge_var2_2568749228126263250
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947221/fstmerge_var1_7860762730858701092
    {
      DisjunctionMaxQuery q2 = new DisjunctionMaxQuery(0.0f);
      q2.add(tq("hed", "elephant"));
      q2.add(tq("dek", "elephant"));
      q.add(q2, BooleanClause.Occur.SHOULD);// false,false);
    }
    QueryUtils.check(random, q, s);
    
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
    
    try {
      assertEquals("4 docs should match " + q.toString(), 4, h.length);
      float score = h[0].score;
      for (int i = 1; i < h.length - 1; i++) { /* note: -1 */
        assertEquals("score #" + i + " is not the same", score, h[i].score,
            SCORE_COMP_THRESH);
      }
      assertEquals("wrong last", "d1", s.doc(h[h.length - 1].doc).get("id"));
      float score1 = h[h.length - 1].score;
      assertTrue("d1 does not have worse score then others: " + score + " >? "
          + score1, score > score1);
    } catch (Error e) {
      printHits("testBooleanOptionalNoTiebreaker", h, s);
      throw e;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947221/fstmerge_base_2597911432451375960
=======
    {
      DisjunctionMaxQuery q2 = new DisjunctionMaxQuery(0.0f);
      q2.add(tq("hed", "elephant"));
      q2.add(tq("dek", "elephant"));
      q.add(q2, BooleanClause.Occur.SHOULD);// false,false);
    }
    QueryUtils.check(q, s);
    
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
    
    try {
      assertEquals("4 docs should match " + q.toString(), 4, h.length);
      float score = h[0].score;
      for (int i = 1; i < h.length - 1; i++) { /* note: -1 */
        assertEquals("score #" + i + " is not the same", score, h[i].score,
            SCORE_COMP_THRESH);
      }
      assertEquals("wrong last", "d1", s.doc(h[h.length - 1].doc).get("id"));
      float score1 = h[h.length - 1].score;
      assertTrue("d1 does not have worse score then others: " + score + " >? "
          + score1, score > score1);
    } catch (Error e) {
      printHits("testBooleanOptionalNoTiebreaker", h, s);
      throw e;
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947221/fstmerge_var2_2568749228126263250

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testBooleanOptionalWithTiebreaker() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947226/fstmerge_base_7673281012825156817

        BooleanQuery q = new BooleanQuery();
        {
            DisjunctionMaxQuery q1 = new DisjunctionMaxQuery(0.01f);
            q1.add(tq("hed","albino"));
            q1.add(tq("dek","albino"));
            q.add(q1, BooleanClause.Occur.SHOULD);//false,false);
        }
        {
            DisjunctionMaxQuery q2 = new DisjunctionMaxQuery(0.01f);
            q2.add(tq("hed","elephant"));
            q2.add(tq("dek","elephant"));
            q.add(q2, BooleanClause.Occur.SHOULD);//false,false);
        }
        QueryUtils.check(q,s);


        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;

        try {

            assertEquals("4 docs should match " + q.toString(),
                         4, h.length);

            float score0 = h[0].score;
            float score1 = h[1].score;
            float score2 = h[2].score;
            float score3 = h[3].score;

            String doc0 = s.doc(h[0].doc).get("id");
            String doc1 = s.doc(h[1].doc).get("id");
            String doc2 = s.doc(h[2].doc).get("id");
            String doc3 = s.doc(h[3].doc).get("id");            

            assertTrue("doc0 should be d2 or d4: " + doc0,
                       doc0.equals("d2") || doc0.equals("d4"));
            assertTrue("doc1 should be d2 or d4: " + doc0,
                       doc1.equals("d2") || doc1.equals("d4"));
            assertEquals("score0 and score1 should match",
                         score0, score1, SCORE_COMP_THRESH);
            assertEquals("wrong third", "d3", doc2);
            assertTrue("d3 does not have worse score then d2 and d4: " +
                       score1 + " >? " + score2,
                       score1 > score2);

            assertEquals("wrong fourth", "d1", doc3);
            assertTrue("d1 does not have worse score then d3: " +
                       score2 + " >? " + score3,
                       score2 > score3);

        } catch (Error e) {
            printHits("testBooleanOptionalWithTiebreaker",h, s);
            throw e;
        }

=======
    
    BooleanQuery q = new BooleanQuery();
    {
      DisjunctionMaxQuery q1 = new DisjunctionMaxQuery(0.01f);
      q1.add(tq("hed", "albino"));
      q1.add(tq("dek", "albino"));
      q.add(q1, BooleanClause.Occur.SHOULD);// false,false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947226/fstmerge_var2_6409277628851497923
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947226/fstmerge_var1_8728222148282132821
    {
      DisjunctionMaxQuery q2 = new DisjunctionMaxQuery(0.01f);
      q2.add(tq("hed", "elephant"));
      q2.add(tq("dek", "elephant"));
      q.add(q2, BooleanClause.Occur.SHOULD);// false,false);
    }
    QueryUtils.check(random, q, s);
    
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
    
    try {
      
      assertEquals("4 docs should match " + q.toString(), 4, h.length);
      
      float score0 = h[0].score;
      float score1 = h[1].score;
      float score2 = h[2].score;
      float score3 = h[3].score;
      
      String doc0 = s.doc(h[0].doc).get("id");
      String doc1 = s.doc(h[1].doc).get("id");
      String doc2 = s.doc(h[2].doc).get("id");
      String doc3 = s.doc(h[3].doc).get("id");
      
      assertTrue("doc0 should be d2 or d4: " + doc0, doc0.equals("d2")
          || doc0.equals("d4"));
      assertTrue("doc1 should be d2 or d4: " + doc0, doc1.equals("d2")
          || doc1.equals("d4"));
      assertEquals("score0 and score1 should match", score0, score1,
          SCORE_COMP_THRESH);
      assertEquals("wrong third", "d3", doc2);
      assertTrue("d3 does not have worse score then d2 and d4: " + score1
          + " >? " + score2, score1 > score2);
      
      assertEquals("wrong fourth", "d1", doc3);
      assertTrue("d1 does not have worse score then d3: " + score2 + " >? "
          + score3, score2 > score3);
      
    } catch (Error e) {
      printHits("testBooleanOptionalWithTiebreaker", h, s);
      throw e;
    }
    
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947226/fstmerge_base_7673281012825156817
=======
    {
      DisjunctionMaxQuery q2 = new DisjunctionMaxQuery(0.01f);
      q2.add(tq("hed", "elephant"));
      q2.add(tq("dek", "elephant"));
      q.add(q2, BooleanClause.Occur.SHOULD);// false,false);
    }
    QueryUtils.check(q, s);
    
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
    
    try {
      
      assertEquals("4 docs should match " + q.toString(), 4, h.length);
      
      float score0 = h[0].score;
      float score1 = h[1].score;
      float score2 = h[2].score;
      float score3 = h[3].score;
      
      String doc0 = s.doc(h[0].doc).get("id");
      String doc1 = s.doc(h[1].doc).get("id");
      String doc2 = s.doc(h[2].doc).get("id");
      String doc3 = s.doc(h[3].doc).get("id");
      
      assertTrue("doc0 should be d2 or d4: " + doc0, doc0.equals("d2")
          || doc0.equals("d4"));
      assertTrue("doc1 should be d2 or d4: " + doc0, doc1.equals("d2")
          || doc1.equals("d4"));
      assertEquals("score0 and score1 should match", score0, score1,
          SCORE_COMP_THRESH);
      assertEquals("wrong third", "d3", doc2);
      assertTrue("d3 does not have worse score then d2 and d4: " + score1
          + " >? " + score2, score1 > score2);
      
      assertEquals("wrong fourth", "d1", doc3);
      assertTrue("d1 does not have worse score then d3: " + score2 + " >? "
          + score3, score2 > score3);
      
    } catch (Error e) {
      printHits("testBooleanOptionalWithTiebreaker", h, s);
      throw e;
    }
    
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947226/fstmerge_var2_6409277628851497923

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testBooleanOptionalWithTiebreakerAndBoost() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947231/fstmerge_base_4164582161885421534

        BooleanQuery q = new BooleanQuery();
        {
            DisjunctionMaxQuery q1 = new DisjunctionMaxQuery(0.01f);
            q1.add(tq("hed","albino", 1.5f));
            q1.add(tq("dek","albino"));
            q.add(q1, BooleanClause.Occur.SHOULD);//false,false);
        }
        {
            DisjunctionMaxQuery q2 = new DisjunctionMaxQuery(0.01f);
            q2.add(tq("hed","elephant", 1.5f));
            q2.add(tq("dek","elephant"));
            q.add(q2, BooleanClause.Occur.SHOULD);//false,false);
        }
        QueryUtils.check(q,s);


        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;

        try {

            assertEquals("4 docs should match " + q.toString(),
                         4, h.length);

            float score0 = h[0].score;
            float score1 = h[1].score;
            float score2 = h[2].score;
            float score3 = h[3].score;

            String doc0 = s.doc(h[0].doc).get("id");
            String doc1 = s.doc(h[1].doc).get("id");
            String doc2 = s.doc(h[2].doc).get("id");
            String doc3 = s.doc(h[3].doc).get("id");            

            assertEquals("doc0 should be d4: ", "d4", doc0);
            assertEquals("doc1 should be d3: ", "d3", doc1);
            assertEquals("doc2 should be d2: ", "d2", doc2);
            assertEquals("doc3 should be d1: ", "d1", doc3);

            assertTrue("d4 does not have a better score then d3: " +
                       score0 + " >? " + score1,
                       score0 > score1);
            assertTrue("d3 does not have a better score then d2: " +
                       score1 + " >? " + score2,
                       score1 > score2);
            assertTrue("d3 does not have a better score then d1: " +
                       score2 + " >? " + score3,
                       score2 > score3);

        } catch (Error e) {
            printHits("testBooleanOptionalWithTiebreakerAndBoost",h, s);
            throw e;
        }
=======
    
    BooleanQuery q = new BooleanQuery();
    {
      DisjunctionMaxQuery q1 = new DisjunctionMaxQuery(0.01f);
      q1.add(tq("hed", "albino", 1.5f));
      q1.add(tq("dek", "albino"));
      q.add(q1, BooleanClause.Occur.SHOULD);// false,false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947231/fstmerge_var2_5119256462686266877
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947231/fstmerge_var1_5557522155883501604
    {
      DisjunctionMaxQuery q2 = new DisjunctionMaxQuery(0.01f);
      q2.add(tq("hed", "elephant", 1.5f));
      q2.add(tq("dek", "elephant"));
      q.add(q2, BooleanClause.Occur.SHOULD);// false,false);
    }
    QueryUtils.check(random, q, s);
    
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
    
    try {
      
      assertEquals("4 docs should match " + q.toString(), 4, h.length);
      
      float score0 = h[0].score;
      float score1 = h[1].score;
      float score2 = h[2].score;
      float score3 = h[3].score;
      
      String doc0 = s.doc(h[0].doc).get("id");
      String doc1 = s.doc(h[1].doc).get("id");
      String doc2 = s.doc(h[2].doc).get("id");
      String doc3 = s.doc(h[3].doc).get("id");
      
      assertEquals("doc0 should be d4: ", "d4", doc0);
      assertEquals("doc1 should be d3: ", "d3", doc1);
      assertEquals("doc2 should be d2: ", "d2", doc2);
      assertEquals("doc3 should be d1: ", "d1", doc3);
      
      assertTrue("d4 does not have a better score then d3: " + score0 + " >? "
          + score1, score0 > score1);
      assertTrue("d3 does not have a better score then d2: " + score1 + " >? "
          + score2, score1 > score2);
      assertTrue("d3 does not have a better score then d1: " + score2 + " >? "
          + score3, score2 > score3);
      
    } catch (Error e) {
      printHits("testBooleanOptionalWithTiebreakerAndBoost", h, s);
      throw e;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947231/fstmerge_base_4164582161885421534
=======
    {
      DisjunctionMaxQuery q2 = new DisjunctionMaxQuery(0.01f);
      q2.add(tq("hed", "elephant", 1.5f));
      q2.add(tq("dek", "elephant"));
      q.add(q2, BooleanClause.Occur.SHOULD);// false,false);
    }
    QueryUtils.check(q, s);
    
    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
    
    try {
      
      assertEquals("4 docs should match " + q.toString(), 4, h.length);
      
      float score0 = h[0].score;
      float score1 = h[1].score;
      float score2 = h[2].score;
      float score3 = h[3].score;
      
      String doc0 = s.doc(h[0].doc).get("id");
      String doc1 = s.doc(h[1].doc).get("id");
      String doc2 = s.doc(h[2].doc).get("id");
      String doc3 = s.doc(h[3].doc).get("id");
      
      assertEquals("doc0 should be d4: ", "d4", doc0);
      assertEquals("doc1 should be d3: ", "d3", doc1);
      assertEquals("doc2 should be d2: ", "d2", doc2);
      assertEquals("doc3 should be d1: ", "d1", doc3);
      
      assertTrue("d4 does not have a better score then d3: " + score0 + " >? "
          + score1, score0 > score1);
      assertTrue("d3 does not have a better score then d2: " + score1 + " >? "
          + score2, score1 > score2);
      assertTrue("d3 does not have a better score then d1: " + score2 + " >? "
          + score3, score2 > score3);
      
    } catch (Error e) {
      printHits("testBooleanOptionalWithTiebreakerAndBoost", h, s);
      throw e;
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947231/fstmerge_var2_5119256462686266877

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947270/fstmerge_var1_3452657744411116691
    directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(TEST_VERSION_CURRENT, new PayloadAnalyzer())
        .setSimilarity(similarity));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947270/fstmerge_base_106125504324989864
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new PayloadAnalyzer()).setSimilarity(similarity));
=======
    directory = new RAMDirectory();
    Random random = newRandom();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new PayloadAnalyzer())
        .setSimilarity(similarity));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947270/fstmerge_var2_8165348406932987054
    //writer.infoStream = System.out;
    for (int i = 0; i < 1000; i++) {
      Document doc = new Document();
      doc.add(newField("field", English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
      String txt = English.intToEnglish(i) +' '+English.intToEnglish(i+1);
      doc.add(newField("field2",  txt, Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947270/fstmerge_base_106125504324989864
    writer.optimize();
=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947270/fstmerge_var2_8165348406932987054
    writer.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947270/fstmerge_base_106125504324989864
    searcher = new IndexSearcher(directory, true);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947270/fstmerge_var2_8165348406932987054
    searcher.setSimilarity(similarity);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947275/fstmerge_var1_4279939955170695191
@Override
  public void tearDown() throws Exception {
    searcher.close();
    reader.close();
    directory.close();
    super.tearDown();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947275/fstmerge_base_174853626519322276
=======
@Override
  protected void tearDown() throws Exception {
    searcher.close();
    reader.close();
    directory.close();
    super.tearDown();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947275/fstmerge_var2_3030427686144104490

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947349/fstmerge_var1_3055978594162168041
    directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(TEST_VERSION_CURRENT, new PayloadAnalyzer())
        .setSimilarity(similarity));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947349/fstmerge_base_1842083239636944248
    directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new PayloadAnalyzer()).setSimilarity(
        similarity));
=======
    directory = new RAMDirectory();
    Random random = newRandom();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new PayloadAnalyzer())
        .setSimilarity(similarity));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947349/fstmerge_var2_5095488730537517000
    //writer.infoStream = System.out;
    for (int i = 0; i < 1000; i++) {
      Document doc = new Document();
      Field noPayloadField = newField(PayloadHelper.NO_PAYLOAD_FIELD, English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED);
      //noPayloadField.setBoost(0);
      doc.add(noPayloadField);
      doc.add(newField("field", English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
      doc.add(newField("multiField", English.intToEnglish(i) + "  " + English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947349/fstmerge_var1_3055978594162168041
    reader = new SlowMultiReaderWrapper(writer.getReader());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947349/fstmerge_base_1842083239636944248
    writer.optimize();
=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947349/fstmerge_var2_5095488730537517000
    writer.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947349/fstmerge_base_1842083239636944248
    searcher = new IndexSearcher(directory, true);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947349/fstmerge_var2_5095488730537517000
    searcher.setSimilarity(similarity);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947353/fstmerge_var1_4449105813840453463
@Override
  public void tearDown() throws Exception {
    searcher.close();
    reader.close();
    directory.close();
    super.tearDown();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947353/fstmerge_base_8807602176910848757
=======
@Override
  protected void tearDown() throws Exception {
    searcher.close();
    reader.close();
    directory.close();
    super.tearDown();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947353/fstmerge_var2_8184099654632343380

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  @Before
  public void setUp() throws Exception {
    super.setUp();
    if (VERBOSE) {
      System.out.println("TEST: setUp");
    }
    // prepare a small index with just a few documents.  
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947699/fstmerge_var1_1868398701379022720
    dir = newDirectory();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947699/fstmerge_base_2863798437030454668
    super.setUp();
    dir = new RAMDirectory();
=======
    dir = new RAMDirectory();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947699/fstmerge_var2_6823327857832754776
    anlzr = new MockAnalyzer();
    IndexWriterConfig iwc = newIndexWriterConfig( TEST_VERSION_CURRENT, anlzr);
    if (doMultiSegment) {
      iwc.setMaxBufferedDocs(_TestUtil.nextInt(random, 2, 7));
    }
    RandomIndexWriter iw = new RandomIndexWriter(random, dir, iwc);
    iw.w.setInfoStream(VERBOSE ? System.out : null);
    // add docs not exactly in natural ID order, to verify we do check the order of docs by scores
    int remaining = N_DOCS;
    boolean done[] = new boolean[N_DOCS];
    int i = 0;
    while (remaining > 0) {
      if (done[i]) {
        throw new Exception("to set this test correctly N_DOCS=" + N_DOCS + " must be primary and greater than 2!");
      }
      addDoc(iw, i);
      done[i] = true;
      i = (i + 4) % N_DOCS;
      remaining --;
    }
    if (!doMultiSegment) {
      if (VERBOSE) {
        System.out.println("TEST: setUp optimize");
      }
      iw.optimize();
    }
    iw.close();
    if (VERBOSE) {
      System.out.println("TEST: setUp done close");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/function/FunctionTestSetup.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947786/fstmerge_var1_7397900128494163935
    directory = newDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947786/fstmerge_base_5033088160397803977
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer= new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947786/fstmerge_var2_4457843959748809591
    for (int i = 0; i < docFields.length; i++) {
      Document doc = new Document();
      doc.add(newField(FIELD, docFields[i], Field.Store.NO, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947786/fstmerge_var1_7397900128494163935
    reader = new SlowMultiReaderWrapper(writer.getReader());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947786/fstmerge_base_5033088160397803977
=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947786/fstmerge_var2_4457843959748809591
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947786/fstmerge_base_5033088160397803977
    searcher = new IndexSearcher(directory, true);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627947786/fstmerge_var2_4457843959748809591
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948020/fstmerge_var1_7725618241379423176
    directory = newDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948020/fstmerge_base_7106344214523457482
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer= new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948020/fstmerge_var2_3035928425964328461
    
    writer.addDocument(doc(new Field[] { field("id", "0")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "james"),
                                         field("last",   "jones")     }));
                                               
    writer.addDocument(doc(new Field[] { field("id", "1")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "james"),
                                         field("last",   "smith")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "sally"),
                                         field("last",   "jones")     }));
    
    writer.addDocument(doc(new Field[] { field("id", "2")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "greta"),
                                         field("last",   "jones")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "sally"),
                                         field("last",   "smith")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "james"),
                                         field("last",   "jones")     }));
     
    writer.addDocument(doc(new Field[] { field("id", "3")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "lisa"),
                                         field("last",   "jones")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "bob"),
                                         field("last",   "costas")     }));
    
    writer.addDocument(doc(new Field[] { field("id", "4")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "sally"),
                                         field("last",   "smith")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "linda"),
                                         field("last",   "dixit")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "bubba"),
                                         field("last",   "jones")     }));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948020/fstmerge_base_7106344214523457482
    
=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948020/fstmerge_var2_3035928425964328461
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948020/fstmerge_base_7106344214523457482
    searcher = new IndexSearcher(directory, true);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948020/fstmerge_var2_3035928425964328461
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948111/fstmerge_var1_5677552907574774018
  public void setUp() throws Exception {
    super.setUp();
    
    // create test index
    final RandomIndexWriter writer = new RandomIndexWriter(random, mDirectory,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(
            MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true))
            .setOpenMode(OpenMode.APPEND));
    addDocument(writer, "A", "Should we, could we, would we?");
    addDocument(writer, "B", "It should.  Should it?");
    addDocument(writer, "C", "It shouldn't.");
    addDocument(writer, "D", "Should we, should we, should we.");
    reader2 = writer.getReader();
    writer.close();
    
    // re-open the searcher since we added more docs
    searcher2 = new IndexSearcher(reader2);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948111/fstmerge_base_2316987090457147234
    protected void setUp() throws Exception {
        super.setUp();

        // create test index
        final IndexWriter writer = new IndexWriter(mDirectory,
            new IndexWriterConfig(TEST_VERSION_CURRENT, 
                new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)).setOpenMode(
                    OpenMode.APPEND));
        addDocument(writer, "A", "Should we, could we, would we?");
        addDocument(writer, "B", "It should.  Should it?");
        addDocument(writer, "C", "It shouldn't.");
        addDocument(writer, "D", "Should we, should we, should we.");
        writer.close();

        // re-open the searcher since we added more docs
        searcher2 = new IndexSearcher(mDirectory, true);
    }
=======
  protected void setUp() throws Exception {
    super.setUp();
    
    // create test index
    final RandomIndexWriter writer = new RandomIndexWriter(random, mDirectory,
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(
            MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true))
            .setOpenMode(OpenMode.APPEND));
    addDocument(writer, "A", "Should we, could we, would we?");
    addDocument(writer, "B", "It should.  Should it?");
    addDocument(writer, "C", "It shouldn't.");
    addDocument(writer, "D", "Should we, should we, should we.");
    reader2 = writer.getReader();
    writer.close();
    
    // re-open the searcher since we added more docs
    searcher2 = new IndexSearcher(reader2);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948111/fstmerge_var2_1636021895335051113

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/spans/TestSpansAdvanced2.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948117/fstmerge_var1_7823197705222865209
@Override
  public void tearDown() throws Exception {
    searcher2.close();
    reader2.close();
    super.tearDown();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948117/fstmerge_base_4564646029997909287
=======
@Override
  protected void tearDown() throws Exception {
    searcher2.close();
    reader2.close();
    super.tearDown();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948117/fstmerge_var2_1900730742870784819

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/spans/TestSpansAdvanced2.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948143/fstmerge_var1_2600007057039668154
  public void setUp() throws Exception {
    super.setUp();
    // create test index
    mDirectory = newDirectory();
    final RandomIndexWriter writer = new RandomIndexWriter(random,
        mDirectory, new MockAnalyzer(MockTokenizer.SIMPLE, true,
                MockTokenFilter.ENGLISH_STOPSET, true));
    addDocument(writer, "1", "I think it should work.");
    addDocument(writer, "2", "I think it should work.");
    addDocument(writer, "3", "I think it should work.");
    addDocument(writer, "4", "I think it should work.");
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948143/fstmerge_base_1640859839421865968
    protected void setUp() throws Exception {
        super.setUp();

        // create test index
        mDirectory = new RAMDirectory();
        final IndexWriter writer = new IndexWriter(mDirectory,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));
        addDocument(writer, "1", "I think it should work.");
        addDocument(writer, "2", "I think it should work.");
        addDocument(writer, "3", "I think it should work.");
        addDocument(writer, "4", "I think it should work.");
        writer.close();
        searcher = new IndexSearcher(mDirectory, true);
    }
=======
  protected void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    // create test index
    mDirectory = new RAMDirectory();
    final RandomIndexWriter writer = new RandomIndexWriter(random,
        mDirectory, new MockAnalyzer(MockTokenizer.SIMPLE, true,
                MockTokenFilter.ENGLISH_STOPSET, true));
    addDocument(writer, "1", "I think it should work.");
    addDocument(writer, "2", "I think it should work.");
    addDocument(writer, "3", "I think it should work.");
    addDocument(writer, "4", "I think it should work.");
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948143/fstmerge_var2_679313097641389038

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/spans/TestSpansAdvanced.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948148/fstmerge_var1_523127320671714263
  public void tearDown() throws Exception {
    searcher.close();
    reader.close();
    mDirectory.close();
    mDirectory = null;
    super.tearDown();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948148/fstmerge_base_2419491432249170676
    protected void tearDown() throws Exception {
        searcher.close();
        mDirectory.close();
        mDirectory = null;
        super.tearDown();
    }
=======
  protected void tearDown() throws Exception {
    searcher.close();
    reader.close();
    mDirectory.close();
    mDirectory = null;
    super.tearDown();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948148/fstmerge_var2_6302098165848927309

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/spans/TestSpansAdvanced.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948152/fstmerge_var1_1686044800973785375
protected void addDocument(final RandomIndexWriter writer, final String id,
      final String text) throws IOException {
    
    final Document document = new Document();
    document.add(newField(FIELD_ID, id, Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    document.add(newField(FIELD_TEXT, text, Field.Store.YES,
        Field.Index.ANALYZED));
    writer.addDocument(document);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948152/fstmerge_base_4692524286252354914
=======
protected void addDocument(final RandomIndexWriter writer, final String id,
      final String text) throws IOException {
    
    final Document document = new Document();
    document.add(new Field(FIELD_ID, id, Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    document.add(new Field(FIELD_TEXT, text, Field.Store.YES,
        Field.Index.ANALYZED));
    writer.addDocument(document);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948152/fstmerge_var2_8797038264799185332

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/spans/TestSpansAdvanced.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948165/fstmerge_var1_3550645164061266987
protected static void assertHits(Searcher s, Query query,
      final String description, final String[] expectedIds,
      final float[] expectedScores) throws IOException {
    QueryUtils.check(random, query, s);
    
    final float tolerance = 1e-5f;
    
    // Hits hits = searcher.search(query);
    // hits normalizes and throws things off if one score is greater than 1.0
    TopDocs topdocs = s.search(query, null, 10000);
    
    /*****
     * // display the hits System.out.println(hits.length() +
     * " hits for search: \"" + description + '\"'); for (int i = 0; i <
     * hits.length(); i++) { System.out.println("  " + FIELD_ID + ':' +
     * hits.doc(i).get(FIELD_ID) + " (score:" + hits.score(i) + ')'); }
     *****/
    
    // did we get the hits we expected
    assertEquals(expectedIds.length, topdocs.totalHits);
    for (int i = 0; i < topdocs.totalHits; i++) {
      // System.out.println(i + " exp: " + expectedIds[i]);
      // System.out.println(i + " field: " + hits.doc(i).get(FIELD_ID));
      
      int id = topdocs.scoreDocs[i].doc;
      float score = topdocs.scoreDocs[i].score;
      Document doc = s.doc(id);
      assertEquals(expectedIds[i], doc.get(FIELD_ID));
      boolean scoreEq = Math.abs(expectedScores[i] - score) < tolerance;
      if (!scoreEq) {
        System.out.println(i + " warning, expected score: " + expectedScores[i]
            + ", actual " + score);
        System.out.println(s.explain(query, id));
      }
      assertEquals(expectedScores[i], score, tolerance);
      assertEquals(s.explain(query, id).getValue(), score, tolerance);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948165/fstmerge_base_6154139297647992266
protected static void assertHits(Searcher s, Query query, final String description, final String[] expectedIds,
            final float[] expectedScores) throws IOException {
        QueryUtils.check(query,s);

        final float tolerance = 1e-5f;

        // Hits hits = searcher.search(query);
        // hits normalizes and throws things off if one score is greater than 1.0
        TopDocs topdocs = s.search(query,null,10000);

        /*****
        // display the hits
        System.out.println(hits.length() + " hits for search: \"" + description + '\"');
        for (int i = 0; i < hits.length(); i++) {
            System.out.println("  " + FIELD_ID + ':' + hits.doc(i).get(FIELD_ID) + " (score:" + hits.score(i) + ')');
        }
        *****/

        // did we get the hits we expected
        assertEquals(expectedIds.length, topdocs.totalHits);
        for (int i = 0; i < topdocs.totalHits; i++) {
            //System.out.println(i + " exp: " + expectedIds[i]);
            //System.out.println(i + " field: " + hits.doc(i).get(FIELD_ID));

            int id = topdocs.scoreDocs[i].doc;
            float score = topdocs.scoreDocs[i].score;
            Document doc = s.doc(id);
            assertEquals(expectedIds[i], doc.get(FIELD_ID));
            boolean scoreEq = Math.abs(expectedScores[i] - score) < tolerance;
            if (!scoreEq) {
              System.out.println(i + " warning, expected score: " + expectedScores[i] + ", actual " + score);
              System.out.println(s.explain(query,id));
            }
            assertEquals(expectedScores[i], score, tolerance);
            assertEquals(s.explain(query,id).getValue(), score, tolerance);
        }
=======
protected static void assertHits(Searcher s, Query query,
      final String description, final String[] expectedIds,
      final float[] expectedScores) throws IOException {
    QueryUtils.check(query, s);
    
    final float tolerance = 1e-5f;
    
    // Hits hits = searcher.search(query);
    // hits normalizes and throws things off if one score is greater than 1.0
    TopDocs topdocs = s.search(query, null, 10000);
    
    /*****
     * // display the hits System.out.println(hits.length() +
     * " hits for search: \"" + description + '\"'); for (int i = 0; i <
     * hits.length(); i++) { System.out.println("  " + FIELD_ID + ':' +
     * hits.doc(i).get(FIELD_ID) + " (score:" + hits.score(i) + ')'); }
     *****/
    
    // did we get the hits we expected
    assertEquals(expectedIds.length, topdocs.totalHits);
    for (int i = 0; i < topdocs.totalHits; i++) {
      // System.out.println(i + " exp: " + expectedIds[i]);
      // System.out.println(i + " field: " + hits.doc(i).get(FIELD_ID));
      
      int id = topdocs.scoreDocs[i].doc;
      float score = topdocs.scoreDocs[i].score;
      Document doc = s.doc(id);
      assertEquals(expectedIds[i], doc.get(FIELD_ID));
      boolean scoreEq = Math.abs(expectedScores[i] - score) < tolerance;
      if (!scoreEq) {
        System.out.println(i + " warning, expected score: " + expectedScores[i]
            + ", actual " + score);
        System.out.println(s.explain(query, id));
      }
      assertEquals(expectedScores[i], score, tolerance);
      assertEquals(s.explain(query, id).getValue(), score, tolerance);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948165/fstmerge_var2_3880592083969876251
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948165/fstmerge_base_6154139297647992266
=======
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948165/fstmerge_var2_3880592083969876251

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/spans/TestSpansAdvanced.java
Conflict type: SameIdFd
Conflict body: 
~~FSTMerge~~ private static IndexReader reader; ##FSTMerge## ##FSTMerge## private IndexReader reader;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/spans/TestBasics.java
Conflict type: SameIdFd
Conflict body: 
~~FSTMerge~~ private static Directory directory; ##FSTMerge## ##FSTMerge## private Directory directory;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/spans/TestBasics.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948265/fstmerge_var1_2080573921657975022
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948265/fstmerge_base_4512580058998044468
@Override
  protected void setUp() throws Exception {
    super.setUp();
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));
    //writer.infoStream = System.out;
    for (int i = 0; i < 1000; i++) {
      Document doc = new Document();
      doc.add(new Field("field", English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }

    writer.close();

    searcher = new IndexSearcher(directory, true);
  }
=======
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new MockAnalyzer(MockTokenizer.SIMPLE, true));
    //writer.infoStream = System.out;
    for (int i = 0; i < 1000; i++) {
      Document doc = new Document();
      doc.add(new Field("field", English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948265/fstmerge_var2_4487199418104309586

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/spans/TestBasics.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948506/fstmerge_var1_8628219547641762804
    directory = newDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948506/fstmerge_base_5696662756679967126
    RAMDirectory directory = new RAMDirectory();
    IndexWriter writer= new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948506/fstmerge_var2_3063342999789053988
    for (int i = 0; i < docFields.length; i++) {
      Document doc = new Document();
      doc.add(newField(field, docFields[i], Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948506/fstmerge_base_5696662756679967126
=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948506/fstmerge_var2_3063342999789053988
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948506/fstmerge_base_5696662756679967126
    searcher = new IndexSearcher(directory, true);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948506/fstmerge_var2_3063342999789053988
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/spans/TestSpans.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948511/fstmerge_var1_1499483286496989325
@Override
  public void tearDown() throws Exception {
    searcher.close();
    reader.close();
    directory.close();
    super.tearDown();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948511/fstmerge_base_1080413102446579927
=======
@Override
  protected void tearDown() throws Exception {
    searcher.close();
    reader.close();
    directory.close();
    super.tearDown();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948511/fstmerge_var2_5201356045848309175

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/search/spans/TestSpans.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testReadSupplementaryChars() throws IOException {
    StringBuilder builder = new StringBuilder();
    // create random input
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948735/fstmerge_var1_8853541281303593206
    int num = 1024 + random.nextInt(1024);
    num *= RANDOM_MULTIPLIER;
    for (int i = 1; i < num; i++) {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948735/fstmerge_base_7237356321068553341
    int num = 1024 + newRandom.nextInt(1024);
    for (int i = 1; i < num*_TestUtil.getRandomMultiplier(); i++) {
=======
    int num = 1024 + newRandom.nextInt(1024);
    num *= RANDOM_MULTIPLIER;
    for (int i = 1; i < num; i++) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948735/fstmerge_var2_1807997253215171596
      builder.append("\ud801\udc1cabc");
      if((i % 10) == 0)
        builder.append(" ");
    }
    // internal buffer size is 1024 make sure we have a surrogate pair right at the border
    builder.insert(1023, "\ud801\udc1c");
    MockTokenizer tokenizer = new MockTokenizer(new StringReader(builder.toString()), MockTokenizer.SIMPLE, true);
    assertTokenStreamContents(tokenizer, builder.toString().toLowerCase().split(" "));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/analysis/TestCharTokenizers.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testCaching() throws IOException {
    Directory dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
    Document doc = new Document();
    TokenStream stream = new TokenStream() {
      private int index = 0;
      private CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
      private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
      
      @Override
      public boolean incrementToken() throws IOException {
        if (index == tokens.length) {
          return false;
        } else {
          clearAttributes();
          termAtt.append(tokens[index++]);
          offsetAtt.setOffset(0,0);
          return true;
        }        
      }
      
    };
    
    stream = new CachingTokenFilter(stream);
    
    doc.add(new Field("preanalyzed", stream, TermVector.NO));
    
    // 1) we consume all tokens twice before we add the doc to the index
    checkTokens(stream);
    stream.reset();  
    checkTokens(stream);
    
    // 2) now add the document to the index and verify if all tokens are indexed
    //    don't reset the stream here, the DocumentWriter should do that implicitly
    writer.addDocument(doc);
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948987/fstmerge_var1_1078581519182201612
    IndexReader reader = writer.getReader();
    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader,
                                                                          MultiFields.getDeletedDocs(reader),
                                                                          "preanalyzed",
                                                                          new BytesRef("term1"));
    assertTrue(termPositions.nextDoc() != termPositions.NO_MORE_DOCS);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948987/fstmerge_base_8928084461703638062
    IndexReader reader = IndexReader.open(dir, true);
    TermPositions termPositions = reader.termPositions(new Term("preanalyzed", "term1"));
    assertTrue(termPositions.next());
=======
    IndexReader reader = IndexReader.open(dir, true);
    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader,
                                                                          MultiFields.getDeletedDocs(reader),
                                                                          "preanalyzed",
                                                                          new BytesRef("term1"));
    assertTrue(termPositions.nextDoc() != termPositions.NO_MORE_DOCS);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948987/fstmerge_var2_7667563697899140968
    assertEquals(1, termPositions.freq());
    assertEquals(0, termPositions.nextPosition());

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948987/fstmerge_base_8928084461703638062
    termPositions.seek(new Term("preanalyzed", "term2"));
    assertTrue(termPositions.next());
=======
    termPositions = MultiFields.getTermPositionsEnum(reader,
                                                     MultiFields.getDeletedDocs(reader),
                                                     "preanalyzed",
                                                     new BytesRef("term2"));
    assertTrue(termPositions.nextDoc() != termPositions.NO_MORE_DOCS);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948987/fstmerge_var2_7667563697899140968
    assertEquals(2, termPositions.freq());
    assertEquals(1, termPositions.nextPosition());
    assertEquals(3, termPositions.nextPosition());
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948987/fstmerge_base_8928084461703638062
    termPositions.seek(new Term("preanalyzed", "term3"));
    assertTrue(termPositions.next());
=======
    termPositions = MultiFields.getTermPositionsEnum(reader,
                                                     MultiFields.getDeletedDocs(reader),
                                                     "preanalyzed",
                                                     new BytesRef("term3"));
    assertTrue(termPositions.nextDoc() != termPositions.NO_MORE_DOCS);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627948987/fstmerge_var2_7667563697899140968
    assertEquals(1, termPositions.freq());
    assertEquals(2, termPositions.nextPosition());
    reader.close();
    writer.close();
    // 3) reset stream and consume tokens again
    stream.reset();
    checkTokens(stream);
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949461/fstmerge_var1_781827021105802304
public void testRandomSplit() throws Exception {
    long num = 100L * RANDOM_MULTIPLIER;
    for (long i=0; i < num; i++) {
      executeOneRandomSplit(random);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949461/fstmerge_base_2836310504653779777
=======
public void testRandomSplit() throws Exception {
    final Random random = newRandom();
    long num = 100L * RANDOM_MULTIPLIER;
    for (long i=0; i < num; i++) {
      executeOneRandomSplit(random);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949461/fstmerge_var2_6435788833101526643

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/TestNumericUtils.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949566/fstmerge_var1_2106125151809075517
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949566/fstmerge_base_2498488911742563503
@Before
  public void setUp() throws Exception {
    savedUncaughtExceptionHandler = Thread.getDefaultUncaughtExceptionHandler();
    Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {
      public void uncaughtException(Thread t, Throwable e) {
        uncaughtExceptions.add(new UncaughtExceptionEntry(t, e));
        if (savedUncaughtExceptionHandler != null)
          savedUncaughtExceptionHandler.uncaughtException(t, e);
      }
    });
    
    ConcurrentMergeScheduler.setTestMode();
    savedBoolMaxClauseCount = BooleanQuery.getMaxClauseCount();
    seed = null;
  }
=======
@Before
  public void setUp() throws Exception {
    Assert.assertFalse("ensure your tearDown() calls super.tearDown()!!!", setup);
    setup = true;
    savedUncaughtExceptionHandler = Thread.getDefaultUncaughtExceptionHandler();
    Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {
      public void uncaughtException(Thread t, Throwable e) {
        uncaughtExceptions.add(new UncaughtExceptionEntry(t, e));
        if (savedUncaughtExceptionHandler != null)
          savedUncaughtExceptionHandler.uncaughtException(t, e);
      }
    });
    
    ConcurrentMergeScheduler.setTestMode();
    savedBoolMaxClauseCount = BooleanQuery.getMaxClauseCount();
    seed = null;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949566/fstmerge_var2_7864072454058278139

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/LuceneTestCaseJ4.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949580/fstmerge_var1_2808935315245429097
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949580/fstmerge_base_4485425936546276080
@After
  public void tearDown() throws Exception {
    BooleanQuery.setMaxClauseCount(savedBoolMaxClauseCount);
    try {

      if (!uncaughtExceptions.isEmpty()) {
        System.err.println("The following exceptions were thrown by threads:");
        for (UncaughtExceptionEntry entry : uncaughtExceptions) {
          System.err.println("*** Thread: " + entry.thread.getName() + " ***");
          entry.exception.printStackTrace(System.err);
        }
        fail("Some threads threw uncaught exceptions!");
      }

      // calling assertSaneFieldCaches here isn't as useful as having test 
      // classes call it directly from the scope where the index readers 
      // are used, because they could be gc'ed just before this tearDown 
      // method is called.
      //
      // But it's better then nothing.
      //
      // If you are testing functionality that you know for a fact 
      // "violates" FieldCache sanity, then you should either explicitly 
      // call purgeFieldCache at the end of your test method, or refactor
      // your Test class so that the inconsistant FieldCache usages are 
      // isolated in distinct test methods  
      assertSaneFieldCaches(getTestLabel());

      if (ConcurrentMergeScheduler.anyUnhandledExceptions()) {
        // Clear the failure so that we don't just keep
        // failing subsequent test cases
        ConcurrentMergeScheduler.clearUnhandledExceptions();
        fail("ConcurrentMergeScheduler hit unhandled exceptions");
      }
    } finally {
      purgeFieldCache(FieldCache.DEFAULT);
    }
    
    Thread.setDefaultUncaughtExceptionHandler(savedUncaughtExceptionHandler);
  }
=======
@After
  public void tearDown() throws Exception {
    Assert.assertTrue("ensure your setUp() calls super.setUp()!!!", setup);
    setup = false;
    BooleanQuery.setMaxClauseCount(savedBoolMaxClauseCount);
    try {

      if (!uncaughtExceptions.isEmpty()) {
        System.err.println("The following exceptions were thrown by threads:");
        for (UncaughtExceptionEntry entry : uncaughtExceptions) {
          System.err.println("*** Thread: " + entry.thread.getName() + " ***");
          entry.exception.printStackTrace(System.err);
        }
        fail("Some threads threw uncaught exceptions!");
      }

      // calling assertSaneFieldCaches here isn't as useful as having test 
      // classes call it directly from the scope where the index readers 
      // are used, because they could be gc'ed just before this tearDown 
      // method is called.
      //
      // But it's better then nothing.
      //
      // If you are testing functionality that you know for a fact 
      // "violates" FieldCache sanity, then you should either explicitly 
      // call purgeFieldCache at the end of your test method, or refactor
      // your Test class so that the inconsistant FieldCache usages are 
      // isolated in distinct test methods  
      assertSaneFieldCaches(getTestLabel());

      if (ConcurrentMergeScheduler.anyUnhandledExceptions()) {
        // Clear the failure so that we don't just keep
        // failing subsequent test cases
        ConcurrentMergeScheduler.clearUnhandledExceptions();
        fail("ConcurrentMergeScheduler hit unhandled exceptions");
      }
    } finally {
      purgeFieldCache(FieldCache.DEFAULT);
    }
    
    Thread.setDefaultUncaughtExceptionHandler(savedUncaughtExceptionHandler);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949580/fstmerge_var2_2033479252097955961

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/LuceneTestCaseJ4.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949600/fstmerge_var1_7082717829257481123
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949600/fstmerge_base_5865045940804124228
public Random newRandom() {
    if (seed != null) {
      throw new IllegalStateException("please call LuceneTestCaseJ4.newRandom only once per test");
    }
    return newRandom(seedRnd.nextLong());
  }
=======
public Random newRandom() {
    if (seed != null) {
      throw new IllegalStateException("please call LuceneTestCaseJ4.newRandom only once per test");
    }
    this.seed = Long.valueOf(seedRnd.nextLong());
    if (VERBOSE) {
      System.out.println("NOTE: random seed of testcase '" + getName() + "' is: " + this.seed);
    }
    return new Random(seed);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949600/fstmerge_var2_8513797293579736005

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/LuceneTestCaseJ4.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949604/fstmerge_var1_1212823765026057898
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949604/fstmerge_base_3137790785044454336
public Random newRandom(long seed) {
    if (this.seed != null) {
      throw new IllegalStateException("please call LuceneTestCaseJ4.newRandom only once per test");
    }
    this.seed = Long.valueOf(seed);
    return new Random(seed);
  }
=======
public Random newRandom(long seed) {
    if (this.seed != null) {
      throw new IllegalStateException("please call LuceneTestCaseJ4.newRandom only once per test");
    }
    System.out.println("WARNING: random seed of testcase '" + getName() + "' is fixed to: " + seed);
    this.seed = Long.valueOf(seed);
    return new Random(seed);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949604/fstmerge_var2_3686231234075671717

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/LuceneTestCaseJ4.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949617/fstmerge_var1_4627852299007533603
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949617/fstmerge_base_3561626313817737676
public void reportAdditionalFailureInfo() {
    if (seed != null) {
      System.out.println("NOTE: random seed of testcase '" + getName() + "' was: " + seed);
    }
  }
=======
public void reportAdditionalFailureInfo() {
    Long staticSeed = staticSeeds.get(getClass());
    if (staticSeed != null) {
      System.out.println("NOTE: random static seed of testclass '" + getName() + "' was: " + staticSeed);
    }
    
    if (TEST_CODEC.equals("random")) {
      System.out.println("NOTE: random codec of testcase '" + getName() + "' was: " + codec);
    }

    if (seed != null) {
      System.out.println("NOTE: random seed of testcase '" + getName() + "' was: " + seed);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949617/fstmerge_var2_2718070045167574417

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/LuceneTestCaseJ4.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949743/fstmerge_var1_4934737980232055472
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949743/fstmerge_base_7940816253850961551
@Override
  protected void setUp() throws Exception {
    super.setUp();
    
    savedUncaughtExceptionHandler = Thread.getDefaultUncaughtExceptionHandler();
    Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {
      public void uncaughtException(Thread t, Throwable e) {
        uncaughtExceptions.add(new UncaughtExceptionEntry(t, e));
        if (savedUncaughtExceptionHandler != null)
          savedUncaughtExceptionHandler.uncaughtException(t, e);
      }
    });
    
    ConcurrentMergeScheduler.setTestMode();
    savedBoolMaxClauseCount = BooleanQuery.getMaxClauseCount();
  }
=======
@Override
  protected void setUp() throws Exception {
    super.setUp();
    assertFalse("ensure your tearDown() calls super.tearDown()!!!", setup);
    setup = true;
    savedUncaughtExceptionHandler = Thread.getDefaultUncaughtExceptionHandler();
    Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {
      public void uncaughtException(Thread t, Throwable e) {
        uncaughtExceptions.add(new UncaughtExceptionEntry(t, e));
        if (savedUncaughtExceptionHandler != null)
          savedUncaughtExceptionHandler.uncaughtException(t, e);
      }
    });
    
    ConcurrentMergeScheduler.setTestMode();
    savedBoolMaxClauseCount = BooleanQuery.getMaxClauseCount();
    savedDefaultCodec = CodecProvider.getDefaultCodec();

    codec = TEST_CODEC;
    if (codec.equals("random"))
      codec = CodecProvider.CORE_CODECS[seedRnd.nextInt(CodecProvider.CORE_CODECS.length)];

    // If we're running w/ PreFlex codec we must swap in the
    // test-only PreFlexRW codec (since core PreFlex can
    // only read segments):
    if (codec.equals("PreFlex")) {
      preFlexSav = LuceneTestCaseJ4.installPreFlexRW();
    } 
    CodecProvider.setDefaultCodec(codec);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949743/fstmerge_var2_2675585665303237489

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/LuceneTestCase.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949756/fstmerge_var1_5448299552634433980
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949756/fstmerge_base_382016862388762169
@Override
  protected void tearDown() throws Exception {
    BooleanQuery.setMaxClauseCount(savedBoolMaxClauseCount);

    try {
      Thread.setDefaultUncaughtExceptionHandler(savedUncaughtExceptionHandler);
      if (!uncaughtExceptions.isEmpty()) {
        System.err.println("The following exceptions were thrown by threads:");
        for (UncaughtExceptionEntry entry : uncaughtExceptions) {
          System.err.println("*** Thread: " + entry.thread.getName() + " ***");
          entry.exception.printStackTrace(System.err);
        }
        fail("Some threads threw uncaught exceptions!");
      }

      // this isn't as useful as calling directly from the scope where the 
      // index readers are used, because they could be gc'ed just before
      // tearDown is called.
      // But it's better then nothing.
      assertSaneFieldCaches(getTestLabel());
      
      if (ConcurrentMergeScheduler.anyUnhandledExceptions()) {
        // Clear the failure so that we don't just keep
        // failing subsequent test cases
        ConcurrentMergeScheduler.clearUnhandledExceptions();
        fail("ConcurrentMergeScheduler hit unhandled exceptions");
      }
    } finally {
      purgeFieldCache(FieldCache.DEFAULT);
    }

    super.tearDown();
  }
=======
@Override
  protected void tearDown() throws Exception {
    assertTrue("ensure your setUp() calls super.setUp()!!!", setup);
    setup = false;
    BooleanQuery.setMaxClauseCount(savedBoolMaxClauseCount);
    // Restore read-only PreFlex codec:
    if (codec.equals("PreFlex")) {
      LuceneTestCaseJ4.restorePreFlex(preFlexSav);
    } 
    CodecProvider.setDefaultCodec(savedDefaultCodec);
    
    try {
      Thread.setDefaultUncaughtExceptionHandler(savedUncaughtExceptionHandler);
      if (!uncaughtExceptions.isEmpty()) {
        System.err.println("The following exceptions were thrown by threads:");
        for (UncaughtExceptionEntry entry : uncaughtExceptions) {
          System.err.println("*** Thread: " + entry.thread.getName() + " ***");
          entry.exception.printStackTrace(System.err);
        }
        fail("Some threads threw uncaught exceptions!");
      }

      // this isn't as useful as calling directly from the scope where the 
      // index readers are used, because they could be gc'ed just before
      // tearDown is called.
      // But it's better then nothing.
      assertSaneFieldCaches(getTestLabel());
      
      if (ConcurrentMergeScheduler.anyUnhandledExceptions()) {
        // Clear the failure so that we don't just keep
        // failing subsequent test cases
        ConcurrentMergeScheduler.clearUnhandledExceptions();
        fail("ConcurrentMergeScheduler hit unhandled exceptions");
      }
    } finally {
      purgeFieldCache(FieldCache.DEFAULT);
    }

    super.tearDown();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949756/fstmerge_var2_8330812505284019298

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/LuceneTestCase.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949775/fstmerge_var1_3492422368592196899
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949775/fstmerge_base_7185868147207582055
public Random newRandom() {
    if (seed != null) {
      throw new IllegalStateException("please call LuceneTestCase.newRandom only once per test");
    }
    return newRandom(seedRnd.nextLong());
  }
=======
public Random newRandom() {
    if (seed != null) {
      throw new IllegalStateException("please call LuceneTestCase.newRandom only once per test");
    }
    this.seed = Long.valueOf(seedRnd.nextLong());
    if (VERBOSE) {
      System.out.println("NOTE: random seed of testcase '" + getName() + "' is: " + this.seed);
    }
    return new Random(seed);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949775/fstmerge_var2_3333902378071788791

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/LuceneTestCase.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949779/fstmerge_var1_7974167644249104737
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949779/fstmerge_base_6295673271394721801
public Random newRandom(long seed) {
    if (this.seed != null) {
      throw new IllegalStateException("please call LuceneTestCase.newRandom only once per test");
    }
    this.seed = Long.valueOf(seed);
    return new Random(seed);
  }
=======
public Random newRandom(long seed) {
    if (this.seed != null) {
      throw new IllegalStateException("please call LuceneTestCase.newRandom only once per test");
    }
    System.out.println("WARNING: random seed of testcase '" + getName() + "' is fixed to: " + seed);
    this.seed = Long.valueOf(seed);
    return new Random(seed);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949779/fstmerge_var2_4555684079822844102

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/LuceneTestCase.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949787/fstmerge_var1_2863955555324376597
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949787/fstmerge_base_6729218143397226757
@Override
  public void runBare() throws Throwable {
    //long t0 = System.currentTimeMillis();
    try {
      seed = null;
      super.runBare();
    } catch (Throwable e) {
      if (seed != null) {
        System.out.println("NOTE: random seed of testcase '" + getName() + "' was: " + seed);
      }
      throw e;
    }
    //long t = System.currentTimeMillis() - t0;
    //System.out.println(t + " msec for " + getName());
  }
=======
@Override
  public void runBare() throws Throwable {
    //long t0 = System.currentTimeMillis();
    try {
      seed = null;
      super.runBare();
    } catch (Throwable e) {
      if (TEST_CODEC.equals("random")) {
        System.out.println("NOTE: random codec of testcase '" + getName() + "' was: " + codec);
      }
      if (seed != null) {
        System.out.println("NOTE: random seed of testcase '" + getName() + "' was: " + seed);
      }
      throw e;
    }
    //long t = System.currentTimeMillis() - t0;
    //System.out.println(t + " msec for " + getName());
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949787/fstmerge_var2_5357621809438647728

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/LuceneTestCase.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testFloatToByte() {
    // up iterations for more exhaustive test after changing something
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949802/fstmerge_var1_819716461131627654
    int num = 100000 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      float f = Float.intBitsToFloat(random.nextInt());
      if (Float.isNaN(f)) continue;    // skip NaN
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949802/fstmerge_base_8591087226032694683
    for (int i=0; i<100000*_TestUtil.getRandomMultiplier(); i++) {
      float f = Float.intBitsToFloat(rand.nextInt());
      if (f!=f) continue;    // skip NaN
=======
    int num = 100000 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      float f = Float.intBitsToFloat(rand.nextInt());
      if (Float.isNaN(f)) continue;    // skip NaN
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949802/fstmerge_var2_7532974003844564746
      byte b1 = orig_floatToByte(f);
      byte b2 = SmallFloat.floatToByte(f,3,15);
      byte b3 = SmallFloat.floatToByte315(f);
      assertEquals(b1,b2);
      assertEquals(b2,b3);

      byte b4 = SmallFloat.floatToByte(f,5,2);
      byte b5 = SmallFloat.floatToByte52(f);
      assertEquals(b4,b5);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/TestSmallFloat.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testCodePointCount() {
    BytesRef utf8 = new BytesRef(20);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949810/fstmerge_var1_9196718057198630706
    int num = 50000 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      final String s = _TestUtil.randomUnicodeString(random);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949810/fstmerge_base_2813372680548527710
    for(int i=0;i<50000*_TestUtil.getRandomMultiplier();i++) {
      final String s = _TestUtil.randomUnicodeString(r);
=======
    int num = 50000 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      final String s = _TestUtil.randomUnicodeString(r);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949810/fstmerge_var2_6407794032362102080
      UnicodeUtil.UTF16toUTF8(s, 0, s.length(), utf8);
      assertEquals(s.codePointCount(0, s.length()),
                   UnicodeUtil.codePointCount(utf8));
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/TestUnicodeUtil.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testUTF8toUTF32() {
    BytesRef utf8 = new BytesRef(20);
    IntsRef utf32 = new IntsRef(20);
    int[] codePoints = new int[20];
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949814/fstmerge_var1_6352232811285309847
    int num = 50000 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      final String s = _TestUtil.randomUnicodeString(random);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949814/fstmerge_base_9195740265949283267
    for(int i=0;i<50000*_TestUtil.getRandomMultiplier();i++) {
      final String s = _TestUtil.randomUnicodeString(r);
=======
    int num = 50000 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      final String s = _TestUtil.randomUnicodeString(r);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949814/fstmerge_var2_775690049187038872
      UnicodeUtil.UTF16toUTF8(s, 0, s.length(), utf8);
      UnicodeUtil.UTF8toUTF32(utf8, utf32);
      
      int charUpto = 0;
      int intUpto = 0;
      while(charUpto < s.length()) {
        final int cp = s.codePointAt(charUpto);
        codePoints[intUpto++] = cp;
        charUpto += Character.charCount(cp);
      }
      if (!ArrayUtil.equals(codePoints, 0, utf32.ints, utf32.offset, intUpto)) {
        System.out.println("FAILED");
        for(int j=0;j<s.length();j++) {
          System.out.println("  char[" + j + "]=" + Integer.toHexString(s.charAt(j)));
        }
        System.out.println();
        assertEquals(intUpto, utf32.length);
        for(int j=0;j<intUpto;j++) {
          System.out.println("  " + Integer.toHexString(utf32.ints[j]) + " vs " + Integer.toHexString(codePoints[j]));
        }
        fail("mismatch");
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/TestUnicodeUtil.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testSmall() {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949869/fstmerge_var1_5023170626426452526
    doRandomSets(1200 * RANDOM_MULTIPLIER, 1000 * RANDOM_MULTIPLIER, 1);
    doRandomSets(1200 * RANDOM_MULTIPLIER, 1000 * RANDOM_MULTIPLIER, 2);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949869/fstmerge_base_4620517894324930849
    rand = newRandom();
    doRandomSets(1200*_TestUtil.getRandomMultiplier(),1000*_TestUtil.getRandomMultiplier(), 1);
    doRandomSets(1200*_TestUtil.getRandomMultiplier(),1000*_TestUtil.getRandomMultiplier(), 2);
=======
    rand = newRandom();
    doRandomSets(1200 * RANDOM_MULTIPLIER, 1000 * RANDOM_MULTIPLIER, 1);
    doRandomSets(1200 * RANDOM_MULTIPLIER, 1000 * RANDOM_MULTIPLIER, 2);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627949869/fstmerge_var2_7302307798497134920
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/TestOpenBitSet.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950128/fstmerge_var1_3704978259355251092
public static CodecProvider alwaysCodec(final Codec c) {
    CodecProvider p = new CodecProvider() {
      @Override
      public Codec lookup(String name) {
        // can't do this until we fix PreFlexRW to not
        //impersonate PreFlex:
        if (name.equals(c.name)) {
          return c;
        } else {
          return CodecProvider.getDefault().lookup(name);
        }
      }
    };
    p.setDefaultFieldCodec(c.name);
    return p;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950128/fstmerge_base_8965166047633844758
=======
public static CodecProvider alwaysCodec(final Codec c) {
    return new CodecProvider() {
      @Override
      public Codec getWriter(SegmentWriteState state) {
        return c;
      }

      @Override
      public Codec lookup(String name) {
        // can't do this until we fix PreFlexRW to not
        //impersonate PreFlex:
        if (name.equals(c.name)) {
          return c;
        } else {
          return CodecProvider.getDefault().lookup(name);
        }
      }
    };
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950128/fstmerge_var2_152382414347987938

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/_TestUtil.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testPQ() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950150/fstmerge_var1_3054793000118234046
        testPQ(10000 * RANDOM_MULTIPLIER, random);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950150/fstmerge_base_6785991571380123201
        testPQ(10000*_TestUtil.getRandomMultiplier(), newRandom());
=======
        testPQ(10000 * RANDOM_MULTIPLIER, newRandom());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950150/fstmerge_var2_1186224287395625123
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/TestPriorityQueue.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testInvalidElementSizes() {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950183/fstmerge_var1_742023654055052941
    int num = 10000 * RANDOM_MULTIPLIER;
    for (int iter = 0; iter < num; iter++) {
      final int minTargetSize = random.nextInt(Integer.MAX_VALUE);
      final int elemSize = random.nextInt(11);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950183/fstmerge_base_2625929230655097558
    final Random r = newRandom();
    for(int iter=0;iter<10000*_TestUtil.getRandomMultiplier();iter++) {
      final int minTargetSize = r.nextInt(Integer.MAX_VALUE);
      final int elemSize = r.nextInt(11);
=======
    final Random r = newRandom();
    int num = 10000 * RANDOM_MULTIPLIER;
    for (int iter = 0; iter < num; iter++) {
      final int minTargetSize = r.nextInt(Integer.MAX_VALUE);
      final int elemSize = r.nextInt(11);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950183/fstmerge_var2_4206444002483140866
      final int v = ArrayUtil.oversize(minTargetSize, elemSize);
      assertTrue(v >= minTargetSize);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/TestArrayUtil.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950202/fstmerge_var1_6373788724379425599
public void testLexicon() throws Exception {
    int num = 3 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950202/fstmerge_base_6366405709501398883
public void testLexicon() {
    random = newRandom();
    for (int i = 0; i < 3*_TestUtil.getRandomMultiplier(); i++) {
=======
public void testLexicon() throws Exception {
    random = newRandom();
    int num = 3 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950202/fstmerge_var2_5226526468304764214
      automata.clear();
      terms.clear();
      for (int j = 0; j < 5000; j++) {
        String randomString = _TestUtil.randomUnicodeString(random);
        terms.add(randomString);
        automata.add(BasicAutomata.makeString(randomString));
      }
      assertLexicon();
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/automaton/TestDeterminizeLexicon.java
Conflict type: LineBasedMCFd
Conflict body: 
public static String randomRegexp(Random r) {
    while (true) {
      String regexp = randomRegexpString(r);
      // we will also generate some undefined unicode queries
      if (!UnicodeUtil.validUTF16String(regexp))
        continue;
      try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950259/fstmerge_var1_7515121175313052219
        new RegExp(regexp, RegExp.NONE);
        return regexp;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950259/fstmerge_base_7417513329637616567
        return new RegExp(regexp, RegExp.NONE);
=======
        // NOTE: we parse-tostring-parse again, because we are
        // really abusing RegExp.toString() here (its just for debugging)
        return new RegExp(new RegExp(regexp, RegExp.NONE).toString(), RegExp.NONE);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950259/fstmerge_var2_1382142323628761940
      } catch (Exception e) {}
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/automaton/AutomatonTestUtil.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950267/fstmerge_var1_864666889606035753
private static int getRandomCodePoint(final Random r, final Transition t) {
    final int code;
    if (t.max < UnicodeUtil.UNI_SUR_HIGH_START ||
        t.min > UnicodeUtil.UNI_SUR_HIGH_END) {
      // easy: entire range is before or after surrogates
      code = t.min+r.nextInt(t.max-t.min+1);
    } else if (t.min >= UnicodeUtil.UNI_SUR_HIGH_START) {
      if (t.max > UnicodeUtil.UNI_SUR_LOW_END) {
        // after surrogates
        code = 1+UnicodeUtil.UNI_SUR_LOW_END+r.nextInt(t.max-UnicodeUtil.UNI_SUR_LOW_END);
      } else {
        throw new IllegalArgumentException("transition accepts only surrogates: " + t);
      }
    } else if (t.max <= UnicodeUtil.UNI_SUR_LOW_END) {
      if (t.min < UnicodeUtil.UNI_SUR_HIGH_START) {
        // before surrogates
        code = t.min + r.nextInt(UnicodeUtil.UNI_SUR_HIGH_START - t.min);
      } else {
        throw new IllegalArgumentException("transition accepts only surrogates: " + t);
      }
    } else {
      // range includes all surrogates
      int gap1 = UnicodeUtil.UNI_SUR_HIGH_START - t.min;
      int gap2 = t.max - UnicodeUtil.UNI_SUR_LOW_END;
      int c = r.nextInt(gap1+gap2);
      if (c < gap1) {
        code = t.min + c;
      } else {
        code = UnicodeUtil.UNI_SUR_LOW_END + c - gap1 + 1;
      }
    }

    assert code >= t.min && code <= t.max && (code < UnicodeUtil.UNI_SUR_HIGH_START || code > UnicodeUtil.UNI_SUR_LOW_END):
      "code=" + code + " min=" + t.min + " max=" + t.max;
    return code;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950267/fstmerge_base_2859866955245694305
=======
private static int getRandomCodePoint(final Random r, final Transition t) {
    final int code;
    if (t.max < UnicodeUtil.UNI_SUR_HIGH_START ||
        t.min > UnicodeUtil.UNI_SUR_HIGH_END) {
      // easy: entire range is before or after surrogates
      code = t.min+r.nextInt(t.max-t.min+1);
    } else if (t.min >= UnicodeUtil.UNI_SUR_HIGH_START) {
      if (t.max > UnicodeUtil.UNI_SUR_LOW_END) {
        // after surrogates
        code = 1+UnicodeUtil.UNI_SUR_LOW_END+r.nextInt(t.max-UnicodeUtil.UNI_SUR_LOW_END+1);
      } else {
        throw new IllegalArgumentException("transition accepts only surrogates: " + t);
      }
    } else if (t.max <= UnicodeUtil.UNI_SUR_LOW_END) {
      if (t.min < UnicodeUtil.UNI_SUR_HIGH_START) {
        // before surrogates
        code = t.min + r.nextInt(UnicodeUtil.UNI_SUR_HIGH_START - t.min);
      } else {
        throw new IllegalArgumentException("transition accepts only surrogates: " + t);
      }
    } else {
      // range includes all surrogates
      int gap1 = UnicodeUtil.UNI_SUR_HIGH_START - t.min;
      int gap2 = t.max - UnicodeUtil.UNI_SUR_LOW_END;
      int c = r.nextInt(gap1+gap2);
      if (c < gap1) {
        code = t.min + c;
      } else {
        code = UnicodeUtil.UNI_SUR_LOW_END + c - gap1 + 1;
      }
    }

    assert code >= t.min && code <= t.max && (code < UnicodeUtil.UNI_SUR_HIGH_START || code > UnicodeUtil.UNI_SUR_LOW_END):
      "code=" + code + " min=" + t.min + " max=" + t.max;
    return code;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950267/fstmerge_var2_5412795382385362389

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/automaton/AutomatonTestUtil.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testGetRandomAcceptedString() throws Throwable {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950307/fstmerge_var1_1381354076825941392
    final int ITER1 = 100 * RANDOM_MULTIPLIER;
    final int ITER2 = 100 * RANDOM_MULTIPLIER;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950307/fstmerge_base_956765656525734942
    final Random r = newRandom();
    final int ITER1 = 100*_TestUtil.getRandomMultiplier();
    final int ITER2 = 100*_TestUtil.getRandomMultiplier();
=======
    final Random r = newRandom();
    final int ITER1 = 100 * RANDOM_MULTIPLIER;
    final int ITER2 = 100 * RANDOM_MULTIPLIER;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950307/fstmerge_var2_1275807767974071366
    for(int i=0;i<ITER1;i++) {

      final RegExp re = new RegExp(AutomatonTestUtil.randomRegexp(random), RegExp.NONE);
      final Automaton a = re.toAutomaton();
      assertFalse(BasicOperations.isEmpty(a));

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950307/fstmerge_base_956765656525734942
      final BasicOperations.RandomAcceptedStrings rx = new BasicOperations.RandomAcceptedStrings(a);
=======
      final AutomatonTestUtil.RandomAcceptedStrings rx = new AutomatonTestUtil.RandomAcceptedStrings(a);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950307/fstmerge_var2_1275807767974071366
      for(int j=0;j<ITER2;j++) {
        int[] acc = null;
        try {
          acc = rx.getRandomAcceptedString(random);
          final String s = UnicodeUtil.newString(acc, 0, acc.length);
          assertTrue(BasicOperations.run(a, s));
        } catch (Throwable t) {
          System.out.println("regexp: " + re);
          if (acc != null) {
            System.out.println("fail acc re=" + re + " count=" + acc.length);
            for(int k=0;k<acc.length;k++) {
              System.out.println("  " + Integer.toHexString(acc[k]));
            }
          }
          throw t;
        }
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/automaton/TestBasicOperations.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testRandomRegexes() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950351/fstmerge_var1_4985221870318529382
    int num = 250 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      assertAutomaton(new RegExp(AutomatonTestUtil.randomRegexp(random), RegExp.NONE).toAutomaton());
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950351/fstmerge_base_3754133913016173022
    for (int i = 0; i < 250*_TestUtil.getRandomMultiplier(); i++)
      assertAutomaton(AutomatonTestUtil.randomRegexp(random).toAutomaton());
=======
    int num = 250 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
      assertAutomaton(AutomatonTestUtil.randomRegexp(random).toAutomaton());
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950351/fstmerge_var2_8143273305591986818
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/automaton/TestUTF32ToUTF8.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testRegexps() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950365/fstmerge_var1_4973367321671224349
      int num = 500 * RANDOM_MULTIPLIER;
      for (int i = 0; i < num; i++)
        assertAutomaton(new RegExp(AutomatonTestUtil.randomRegexp(random), RegExp.NONE).toAutomaton());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950365/fstmerge_base_3291818566137217360
      for (int i = 0; i < 500*_TestUtil.getRandomMultiplier(); i++)
        assertAutomaton(AutomatonTestUtil.randomRegexp(random).toAutomaton());
=======
      int num = 500 * RANDOM_MULTIPLIER;
      for (int i = 0; i < num; i++)
        assertAutomaton(AutomatonTestUtil.randomRegexp(random).toAutomaton());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950365/fstmerge_var2_9177006978614135990
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/automaton/TestDeterminism.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testPackedInts() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950383/fstmerge_var1_524785795698220927
    int num = 5 * RANDOM_MULTIPLIER;
    for (int iter = 0; iter < num; iter++) {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950383/fstmerge_base_1016572049859187908
    rnd = newRandom();
    for(int iter=0;iter<5*_TestUtil.getRandomMultiplier();iter++) {
=======
    rnd = newRandom();
    int num = 5 * RANDOM_MULTIPLIER;
    for (int iter = 0; iter < num; iter++) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950383/fstmerge_var2_5015580319827289190
      long ceil = 2;
      for(int nbits=1;nbits<63;nbits++) {
        final int valueCount = 100+random.nextInt(500);
        final Directory d = newDirectory();

        IndexOutput out = d.createOutput("out.bin");
        PackedInts.Writer w = PackedInts.getWriter(
                out, valueCount, nbits);

        final long[] values = new long[valueCount];
        for(int i=0;i<valueCount;i++) {
          long v = random.nextLong() % ceil;
          if (v < 0) {
            v = -v;
          }
          values[i] = v;
          w.add(values[i]);
        }
        w.finish();
        final long fp = out.getFilePointer();
        out.close();
        {// test reader
          IndexInput in = d.openInput("out.bin");
          PackedInts.Reader r = PackedInts.getReader(in);
          assertEquals(fp, in.getFilePointer());
          for(int i=0;i<valueCount;i++) {
            assertEquals("index=" + i + " ceil=" + ceil + " valueCount="
                    + valueCount + " nbits=" + nbits + " for "
                    + r.getClass().getSimpleName(), values[i], r.get(i));
          }
          in.close();
        }
        { // test reader iterator next
          IndexInput in = d.openInput("out.bin");
          PackedInts.ReaderIterator r = PackedInts.getReaderIterator(in);
          for(int i=0;i<valueCount;i++) {
            assertEquals("index=" + i + " ceil=" + ceil + " valueCount="
                    + valueCount + " nbits=" + nbits + " for "
                    + r.getClass().getSimpleName(), values[i], r.next());
          }
          assertEquals(fp, in.getFilePointer());
          in.close();
        }
        { // test reader iterator next vs. advance
          IndexInput in = d.openInput("out.bin");
          PackedInts.ReaderIterator intsEnum = PackedInts.getReaderIterator(in);
          for (int i = 0; i < valueCount; i += 
            1 + ((valueCount - i) <= 20 ? random.nextInt(valueCount - i)
              : random.nextInt(20))) {
            final String msg = "index=" + i + " ceil=" + ceil + " valueCount="
                + valueCount + " nbits=" + nbits + " for "
                + intsEnum.getClass().getSimpleName();
            if (i - intsEnum.ord() == 1 && random.nextBoolean()) {
              assertEquals(msg, values[i], intsEnum.next());
            } else {
              assertEquals(msg, values[i], intsEnum.advance(i));
            }
            assertEquals(msg, i, intsEnum.ord());
          }
          if (intsEnum.ord() < valueCount - 1)
            assertEquals(values[valueCount - 1], intsEnum
                .advance(valueCount - 1));
          assertEquals(valueCount - 1, intsEnum.ord());
          assertEquals(fp, in.getFilePointer());
          in.close();
        }
        ceil *= 2;
        d.close();
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/util/packed/TestPackedInts.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testBinaryFieldInIndex()
    throws Exception
  {
    Fieldable binaryFldStored = new Field("binaryStored", binaryValStored.getBytes());
    Fieldable stringFldStored = new Field("stringStored", binaryValStored, Field.Store.YES, Field.Index.NO, Field.TermVector.NO);

    Document doc = new Document();
    
    doc.add(binaryFldStored);
    
    doc.add(stringFldStored);

    /** test for field count */
    assertEquals(2, doc.fields.size());
    
    /** add the doc to a ram index */
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950427/fstmerge_var1_3629649541193800479
    Directory dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950427/fstmerge_base_1770799477962415096
    MockRAMDirectory dir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    MockRAMDirectory dir = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950427/fstmerge_var2_2840686971917666309
    writer.addDocument(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950427/fstmerge_base_1770799477962415096
    writer.close();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950427/fstmerge_var2_2840686971917666309
    
    /** open a reader and fetch the document */ 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950427/fstmerge_base_1770799477962415096
    IndexReader reader = IndexReader.open(dir, false);
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950427/fstmerge_var2_2840686971917666309
    Document docFromReader = reader.document(0);
    assertTrue(docFromReader != null);
    
    /** fetch the binary stored field and compare it's content with the original one */
    String binaryFldStoredTest = new String(docFromReader.getBinaryValue("binaryStored"));
    assertTrue(binaryFldStoredTest.equals(binaryValStored));
    
    /** fetch the string field and compare it's content with the original one */
    String stringFldStoredTest = docFromReader.get("stringStored");
    assertTrue(stringFldStoredTest.equals(binaryValStored));
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950427/fstmerge_base_1770799477962415096
=======
    writer.close();    
    reader.close();
    
    reader = IndexReader.open(dir, false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950427/fstmerge_var2_2840686971917666309
    /** delete the document from index */
    reader.deleteDocument(0);
    assertEquals(0, reader.numDocs());
    
    reader.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/document/TestBinaryDocument.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testCompressionTools() throws Exception {
    Fieldable binaryFldCompressed = new Field("binaryCompressed", CompressionTools.compress(binaryValCompressed.getBytes()));
    Fieldable stringFldCompressed = new Field("stringCompressed", CompressionTools.compressString(binaryValCompressed));
    
    Document doc = new Document();
    
    doc.add(binaryFldCompressed);
    doc.add(stringFldCompressed);
    
    /** add the doc to a ram index */
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950432/fstmerge_var1_2249855044016784964
    Directory dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950432/fstmerge_base_4360954485628560647
    MockRAMDirectory dir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    MockRAMDirectory dir = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950432/fstmerge_var2_1528789547222888609
    writer.addDocument(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950432/fstmerge_base_4360954485628560647
    writer.close();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950432/fstmerge_var2_1528789547222888609
    
    /** open a reader and fetch the document */ 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950432/fstmerge_base_4360954485628560647
    IndexReader reader = IndexReader.open(dir, false);
=======
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950432/fstmerge_var2_1528789547222888609
    Document docFromReader = reader.document(0);
    assertTrue(docFromReader != null);
    
    /** fetch the binary compressed field and compare it's content with the original one */
    String binaryFldCompressedTest = new String(CompressionTools.decompress(docFromReader.getBinaryValue("binaryCompressed")));
    assertTrue(binaryFldCompressedTest.equals(binaryValCompressed));
    assertTrue(CompressionTools.decompressString(docFromReader.getBinaryValue("stringCompressed")).equals(binaryValCompressed));

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950432/fstmerge_base_4360954485628560647
=======
    writer.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950432/fstmerge_var2_1528789547222888609
    reader.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/document/TestBinaryDocument.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testGetValuesForIndexedDocument() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950473/fstmerge_var1_7210000626526316334
    Directory dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
    writer.addDocument(makeDocumentWithFields());
    IndexReader reader = writer.getReader();
    
    Searcher searcher = new IndexSearcher(reader);
    
    // search for something that does exists
    Query query = new TermQuery(new Term("keyword", "test1"));
    
    // ensure that queries return expected results without DateFilter first
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    
    doAssert(searcher.doc(hits[0].doc), true);
    writer.close();
    searcher.close();
    reader.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950473/fstmerge_base_2924623431077077958
        RAMDirectory dir = new RAMDirectory();
        IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
        writer.addDocument(makeDocumentWithFields());
        writer.close();

        Searcher searcher = new IndexSearcher(dir, true);

	// search for something that does exists
	Query query = new TermQuery(new Term("keyword", "test1"));

	// ensure that queries return expected results without DateFilter first
        ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
  assertEquals(1, hits.length);

         doAssert(searcher.doc(hits[0].doc), true);
         searcher.close();
    }
=======
    RAMDirectory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
    writer.addDocument(makeDocumentWithFields());
    IndexReader reader = writer.getReader();
    
    Searcher searcher = new IndexSearcher(reader);
    
    // search for something that does exists
    Query query = new TermQuery(new Term("keyword", "test1"));
    
    // ensure that queries return expected results without DateFilter first
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    
    doAssert(searcher.doc(hits[0].doc), true);
    writer.close();
    searcher.close();
    reader.close();
    dir.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950473/fstmerge_var2_6589749221249275556

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/document/TestDocument.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testFieldSetValue() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950487/fstmerge_var1_6977713926624535081
    
    Field field = new Field("id", "id1", Field.Store.YES,
        Field.Index.NOT_ANALYZED);
    Document doc = new Document();
    doc.add(field);
    doc.add(new Field("keyword", "test", Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    
    Directory dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
    writer.addDocument(doc);
    field.setValue("id2");
    writer.addDocument(doc);
    field.setValue("id3");
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    Searcher searcher = new IndexSearcher(reader);
    
    Query query = new TermQuery(new Term("keyword", "test"));
    
    // ensure that queries return expected results without DateFilter first
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    int result = 0;
    for (int i = 0; i < 3; i++) {
      Document doc2 = searcher.doc(hits[i].doc);
      Field f = doc2.getField("id");
      if (f.stringValue().equals("id1")) result |= 1;
      else if (f.stringValue().equals("id2")) result |= 2;
      else if (f.stringValue().equals("id3")) result |= 4;
      else fail("unexpected id field");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950487/fstmerge_base_310481784732388171

      Field field = new Field("id", "id1", Field.Store.YES, Field.Index.NOT_ANALYZED);
      Document doc = new Document();
      doc.add(field);
      doc.add(new Field("keyword", "test", Field.Store.YES, Field.Index.NOT_ANALYZED));

      RAMDirectory dir = new RAMDirectory();
      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
      writer.addDocument(doc);
      field.setValue("id2");
      writer.addDocument(doc);
      field.setValue("id3");
      writer.addDocument(doc);
      writer.close();

      Searcher searcher = new IndexSearcher(dir, true);

      Query query = new TermQuery(new Term("keyword", "test"));

      // ensure that queries return expected results without DateFilter first
      ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
      assertEquals(3, hits.length);
      int result = 0;
      for(int i=0;i<3;i++) {
        Document doc2 = searcher.doc(hits[i].doc);
        Field f = doc2.getField("id");
        if (f.stringValue().equals("id1"))
          result |= 1;
        else if (f.stringValue().equals("id2"))
          result |= 2;
        else if (f.stringValue().equals("id3"))
          result |= 4;
        else
          fail("unexpected id field");
      }
      searcher.close();
      dir.close();
      assertEquals("did not see all IDs", 7, result);
=======
    
    Field field = new Field("id", "id1", Field.Store.YES,
        Field.Index.NOT_ANALYZED);
    Document doc = new Document();
    doc.add(field);
    doc.add(new Field("keyword", "test", Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    
    RAMDirectory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
    writer.addDocument(doc);
    field.setValue("id2");
    writer.addDocument(doc);
    field.setValue("id3");
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    Searcher searcher = new IndexSearcher(reader);
    
    Query query = new TermQuery(new Term("keyword", "test"));
    
    // ensure that queries return expected results without DateFilter first
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    int result = 0;
    for (int i = 0; i < 3; i++) {
      Document doc2 = searcher.doc(hits[i].doc);
      Field f = doc2.getField("id");
      if (f.stringValue().equals("id1")) result |= 1;
      else if (f.stringValue().equals("id2")) result |= 2;
      else if (f.stringValue().equals("id3")) result |= 4;
      else fail("unexpected id field");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950487/fstmerge_var2_5505599342021311618
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950487/fstmerge_base_310481784732388171
=======
    writer.close();
    searcher.close();
    reader.close();
    dir.close();
    assertEquals("did not see all IDs", 7, result);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950487/fstmerge_var2_5505599342021311618

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/document/TestDocument.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testBasic() throws IOException {
    Set<String> fileExtensions = new HashSet<String>();
    fileExtensions.add(IndexFileNames.FIELDS_EXTENSION);
    fileExtensions.add(IndexFileNames.FIELDS_INDEX_EXTENSION);
    
    Directory primaryDir = new MockDirectoryWrapper(random, new RAMDirectory());
    Directory secondaryDir = new MockDirectoryWrapper(random, new RAMDirectory());
    
    FileSwitchDirectory fsd = new FileSwitchDirectory(fileExtensions, primaryDir, secondaryDir, true);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950522/fstmerge_var1_9118086215475193966
    IndexWriter writer = new IndexWriter(
        fsd,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
            setMergePolicy(newLogMergePolicy(false))
    );
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950522/fstmerge_base_2555478913230787008
    IndexWriter writer = new IndexWriter(fsd, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
=======
    IndexWriter writer = new IndexWriter(fsd, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627950522/fstmerge_var2_4167577392502738888
    TestIndexWriterReader.createIndexNoClose(true, "ram", writer);
    IndexReader reader = IndexReader.open(writer);
    assertEquals(100, reader.maxDoc());
    writer.commit();
    // we should see only fdx,fdt files here
    String[] files = primaryDir.listAll();
    assertTrue(files.length > 0);
    for (int x=0; x < files.length; x++) {
      String ext = FileSwitchDirectory.getExtension(files[x]);
      assertTrue(fileExtensions.contains(ext));
    }
    files = secondaryDir.listAll();
    assertTrue(files.length > 0);
    // we should not see fdx,fdt files here
    for (int x=0; x < files.length; x++) {
      String ext = FileSwitchDirectory.getExtension(files[x]);
      assertFalse(fileExtensions.contains(ext));
    }
    reader.close();
    writer.close();

    files = fsd.listAll();
    for(int i=0;i<files.length;i++) {
      assertNotNull(files[i]);
    }
    fsd.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/store/TestFileSwitchDirectory.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951175/fstmerge_var1_2443196527411675649
private void doTestOperationsOnDiskFull(boolean updates) throws IOException {

    Term searchTerm = new Term("content", "aaa");
    int START_COUNT = 157;
    int END_COUNT = 144;

    // First build up a starting index:
    MockDirectoryWrapper startDir = newDirectory();
    // TODO: find the resource leak that only occurs sometimes here.
    startDir.setNoDeleteOpenFile(false);
    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
    for (int i = 0; i < 157; i++) {
      Document d = new Document();
      d.add(newField("id", Integer.toString(i), Field.Store.YES,
                      Field.Index.NOT_ANALYZED));
      d.add(newField("content", "aaa " + i, Field.Store.NO,
                      Field.Index.ANALYZED));
      writer.addDocument(d);
    }
    writer.close();

    long diskUsage = startDir.sizeInBytes();
    long diskFree = diskUsage + 10;

    IOException err = null;

    boolean done = false;

    // Iterate w/ ever increasing free disk space:
    while (!done) {
      if (VERBOSE) {
        System.out.println("TEST: cycle");
      }
      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));
      dir.setPreventDoubleWrite(false);
      IndexWriter modifier = new IndexWriter(dir,
                                             newIndexWriterConfig(
                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false))
                                             .setMaxBufferedDocs(1000)
                                             .setMaxBufferedDeleteTerms(1000)
                                             .setMergeScheduler(new ConcurrentMergeScheduler()));
      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();
      modifier.setInfoStream(VERBOSE ? System.out : null);

      // For each disk size, first try to commit against
      // dir that will hit random IOExceptions & disk
      // full; after, give it infinite disk space & turn
      // off random IOExceptions & retry w/ same reader:
      boolean success = false;

      for (int x = 0; x < 2; x++) {
        if (VERBOSE) {
          System.out.println("TEST: x=" + x);
        }

        double rate = 0.1;
        double diskRatio = ((double)diskFree) / diskUsage;
        long thisDiskFree;
        String testName;

        if (0 == x) {
          thisDiskFree = diskFree;
          if (diskRatio >= 2.0) {
            rate /= 2;
          }
          if (diskRatio >= 4.0) {
            rate /= 2;
          }
          if (diskRatio >= 6.0) {
            rate = 0.0;
          }
          if (VERBOSE) {
            System.out.println("\ncycle: " + diskFree + " bytes");
          }
          testName = "disk full during reader.close() @ " + thisDiskFree
            + " bytes";
        } else {
          thisDiskFree = 0;
          rate = 0.0;
          if (VERBOSE) {
            System.out.println("\ncycle: same writer: unlimited disk space");
          }
          testName = "reader re-use after disk full";
        }

        dir.setMaxSizeInBytes(thisDiskFree);
        dir.setRandomIOExceptionRate(rate);

        try {
          if (0 == x) {
            int docId = 12;
            for (int i = 0; i < 13; i++) {
              if (updates) {
                Document d = new Document();
                d.add(newField("id", Integer.toString(i), Field.Store.YES,
                                Field.Index.NOT_ANALYZED));
                d.add(newField("content", "bbb " + i, Field.Store.NO,
                                Field.Index.ANALYZED));
                modifier.updateDocument(new Term("id", Integer.toString(docId)), d);
              } else { // deletes
                modifier.deleteDocuments(new Term("id", Integer.toString(docId)));
                // modifier.setNorm(docId, "contents", (float)2.0);
              }
              docId += 12;
            }
          }
          modifier.close();
          success = true;
          if (0 == x) {
            done = true;
          }
        }
        catch (IOException e) {
          if (VERBOSE) {
            System.out.println("  hit IOException: " + e);
            e.printStackTrace(System.out);
          }
          err = e;
          if (1 == x) {
            e.printStackTrace();
            fail(testName + " hit IOException after disk space was freed up");
          }
        }

        if (!success) {
          // Must force the close else the writer can have
          // open files which cause exc in MockRAMDir.close
          modifier.rollback();
        }

        // If the close() succeeded, make sure there are
        // no unreferenced files.
        if (success) {
          _TestUtil.checkIndex(dir);
          TestIndexWriter.assertNoUnreferencedFiles(dir, "after writer.close");
        }

        // Finally, verify index is not corrupt, and, if
        // we succeeded, we see all docs changed, and if
        // we failed, we see either all docs or no docs
        // changed (transactional semantics):
        IndexReader newReader = null;
        try {
          newReader = IndexReader.open(dir, true);
        }
        catch (IOException e) {
          e.printStackTrace();
          fail(testName
               + ":exception when creating IndexReader after disk full during close: "
               + e);
        }

        IndexSearcher searcher = new IndexSearcher(newReader);
        ScoreDoc[] hits = null;
        try {
          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
        }
        catch (IOException e) {
          e.printStackTrace();
          fail(testName + ": exception when searching: " + e);
        }
        int result2 = hits.length;
        if (success) {
          if (x == 0 && result2 != END_COUNT) {
            fail(testName
                 + ": method did not throw exception but hits.length for search on term 'aaa' is "
                 + result2 + " instead of expected " + END_COUNT);
          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {
            // It's possible that the first exception was
            // "recoverable" wrt pending deletes, in which
            // case the pending deletes are retained and
            // then re-flushing (with plenty of disk
            // space) will succeed in flushing the
            // deletes:
            fail(testName
                 + ": method did not throw exception but hits.length for search on term 'aaa' is "
                 + result2 + " instead of expected " + START_COUNT + " or " + END_COUNT);
          }
        } else {
          // On hitting exception we still may have added
          // all docs:
          if (result2 != START_COUNT && result2 != END_COUNT) {
            err.printStackTrace();
            fail(testName
                 + ": method did throw exception but hits.length for search on term 'aaa' is "
                 + result2 + " instead of expected " + START_COUNT + " or " + END_COUNT);
          }
        }
        searcher.close();
        newReader.close();
        if (result2 == END_COUNT) {
          break;
        }
      }
      dir.close();
      modifier.close();

      // Try again with 10 more bytes of free space:
      diskFree += 10;
    }
    startDir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951175/fstmerge_base_5629268149814107873
=======
private void doTestOperationsOnDiskFull(boolean updates) throws IOException {

    Term searchTerm = new Term("content", "aaa");
    int START_COUNT = 157;
    int END_COUNT = 144;

    // First build up a starting index:
    MockRAMDirectory startDir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
    for (int i = 0; i < 157; i++) {
      Document d = new Document();
      d.add(new Field("id", Integer.toString(i), Field.Store.YES,
                      Field.Index.NOT_ANALYZED));
      d.add(new Field("content", "aaa " + i, Field.Store.NO,
                      Field.Index.ANALYZED));
      writer.addDocument(d);
    }
    writer.close();

    long diskUsage = startDir.sizeInBytes();
    long diskFree = diskUsage + 10;

    IOException err = null;

    boolean done = false;

    // Iterate w/ ever increasing free disk space:
    while (!done) {
      MockRAMDirectory dir = new MockRAMDirectory(startDir);
      dir.setPreventDoubleWrite(false);
      IndexWriter modifier = new IndexWriter(dir, new IndexWriterConfig(
          TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setMaxBufferedDocs(1000)
          .setMaxBufferedDeleteTerms(1000));

      // For each disk size, first try to commit against
      // dir that will hit random IOExceptions & disk
      // full; after, give it infinite disk space & turn
      // off random IOExceptions & retry w/ same reader:
      boolean success = false;

      for (int x = 0; x < 2; x++) {

        double rate = 0.1;
        double diskRatio = ((double)diskFree) / diskUsage;
        long thisDiskFree;
        String testName;

        if (0 == x) {
          thisDiskFree = diskFree;
          if (diskRatio >= 2.0) {
            rate /= 2;
          }
          if (diskRatio >= 4.0) {
            rate /= 2;
          }
          if (diskRatio >= 6.0) {
            rate = 0.0;
          }
          if (VERBOSE) {
            System.out.println("\ncycle: " + diskFree + " bytes");
          }
          testName = "disk full during reader.close() @ " + thisDiskFree
            + " bytes";
        } else {
          thisDiskFree = 0;
          rate = 0.0;
          if (VERBOSE) {
            System.out.println("\ncycle: same writer: unlimited disk space");
          }
          testName = "reader re-use after disk full";
        }

        dir.setMaxSizeInBytes(thisDiskFree);
        dir.setRandomIOExceptionRate(rate, diskFree);

        try {
          if (0 == x) {
            int docId = 12;
            for (int i = 0; i < 13; i++) {
              if (updates) {
                Document d = new Document();
                d.add(new Field("id", Integer.toString(i), Field.Store.YES,
                                Field.Index.NOT_ANALYZED));
                d.add(new Field("content", "bbb " + i, Field.Store.NO,
                                Field.Index.ANALYZED));
                modifier.updateDocument(new Term("id", Integer.toString(docId)), d);
              } else { // deletes
                modifier.deleteDocuments(new Term("id", Integer.toString(docId)));
                // modifier.setNorm(docId, "contents", (float)2.0);
              }
              docId += 12;
            }
          }
          modifier.close();
          success = true;
          if (0 == x) {
            done = true;
          }
        }
        catch (IOException e) {
          if (VERBOSE) {
            System.out.println("  hit IOException: " + e);
            e.printStackTrace(System.out);
          }
          err = e;
          if (1 == x) {
            e.printStackTrace();
            fail(testName + " hit IOException after disk space was freed up");
          }
        }

        // If the close() succeeded, make sure there are
        // no unreferenced files.
        if (success)
          TestIndexWriter.assertNoUnreferencedFiles(dir, "after writer.close");

        // Finally, verify index is not corrupt, and, if
        // we succeeded, we see all docs changed, and if
        // we failed, we see either all docs or no docs
        // changed (transactional semantics):
        IndexReader newReader = null;
        try {
          newReader = IndexReader.open(dir, true);
        }
        catch (IOException e) {
          e.printStackTrace();
          fail(testName
               + ":exception when creating IndexReader after disk full during close: "
               + e);
        }

        IndexSearcher searcher = new IndexSearcher(newReader);
        ScoreDoc[] hits = null;
        try {
          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
        }
        catch (IOException e) {
          e.printStackTrace();
          fail(testName + ": exception when searching: " + e);
        }
        int result2 = hits.length;
        if (success) {
          if (x == 0 && result2 != END_COUNT) {
            fail(testName
                 + ": method did not throw exception but hits.length for search on term 'aaa' is "
                 + result2 + " instead of expected " + END_COUNT);
          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {
            // It's possible that the first exception was
            // "recoverable" wrt pending deletes, in which
            // case the pending deletes are retained and
            // then re-flushing (with plenty of disk
            // space) will succeed in flushing the
            // deletes:
            fail(testName
                 + ": method did not throw exception but hits.length for search on term 'aaa' is "
                 + result2 + " instead of expected " + START_COUNT + " or " + END_COUNT);
          }
        } else {
          // On hitting exception we still may have added
          // all docs:
          if (result2 != START_COUNT && result2 != END_COUNT) {
            err.printStackTrace();
            fail(testName
                 + ": method did throw exception but hits.length for search on term 'aaa' is "
                 + result2 + " instead of expected " + START_COUNT + " or " + END_COUNT);
          }
        }

        searcher.close();
        newReader.close();

        if (result2 == END_COUNT) {
          break;
        }
      }

      dir.close();

      // Try again with 10 more bytes of free space:
      diskFree += 10;
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951175/fstmerge_var2_2365492196838923053

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
Conflict type: LineBasedMCFd
Conflict body: 
private void assertTermDocsCount(String msg,
                                     IndexReader reader,
                                     Term term,
                                     int expected)
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951261/fstmerge_var1_4556944530771486789
    throws IOException {
        DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,
                                                     MultiFields.getDeletedDocs(reader),
                                                     term.field(),
                                                     new BytesRef(term.text()));
        int count = 0;
        if (tdocs != null) {
          while(tdocs.nextDoc()!= DocIdSetIterator.NO_MORE_DOCS) {
            count++;
          }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951261/fstmerge_base_7778539954759334625
    throws IOException
    {
        TermDocs tdocs = null;

        try {
            tdocs = reader.termDocs(term);
            assertNotNull(msg + ", null TermDocs", tdocs);
            int count = 0;
            while(tdocs.next()) {
                count++;
            }
            assertEquals(msg + ", count mismatch", expected, count);

        } finally {
            if (tdocs != null)
                tdocs.close();
=======
    throws IOException
    {
        DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,
                                                     MultiFields.getDeletedDocs(reader),
                                                     term.field(),
                                                     new BytesRef(term.text()));
        int count = 0;
        if (tdocs != null) {
          while(tdocs.nextDoc()!= tdocs.NO_MORE_DOCS) {
            count++;
          }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951261/fstmerge_var2_2876454413405264421
        }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951261/fstmerge_base_7778539954759334625

=======
        assertEquals(msg + ", count mismatch", expected, count);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951261/fstmerge_var2_2876454413405264421
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testWritingNormsNoReader() throws IOException {
        Directory dir = newDirectory();
        IndexWriter writer = null;
        IndexReader reader = null;
        Term searchTerm = new Term("content", "aaa");

        //  add 1 documents with term : aaa
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951289/fstmerge_var1_305966996461751327
        writer  = new IndexWriter(
            dir,
            newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
                setMergePolicy(newLogMergePolicy(false))
        );
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951289/fstmerge_base_631452790195974758
        writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
=======
        writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951289/fstmerge_var2_551426904161711447
        addDoc(writer, searchTerm.text());
        writer.close();

        //  now open reader & set norm for doc 0 (writes to
        //  _0_1.s0)
        reader = IndexReader.open(dir, false);
        reader.setNorm(0, "content", (float) 2.0);
        reader.close();
        
        //  now open reader again & set norm for doc 0 (writes to _0_2.s0)
        reader = IndexReader.open(dir, false);
        reader.setNorm(0, "content", (float) 2.0);
        reader.close();
        assertFalse("failed to remove first generation norms file on writing second generation",
                    dir.fileExists("_0_1.s0"));
        
        dir.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
public static void assertIndexEquals(IndexReader index1, IndexReader index2) throws IOException {
      assertEquals("IndexReaders have different values for numDocs.", index1.numDocs(), index2.numDocs());
      assertEquals("IndexReaders have different values for maxDoc.", index1.maxDoc(), index2.maxDoc());
      assertEquals("Only one IndexReader has deletions.", index1.hasDeletions(), index2.hasDeletions());
      assertEquals("Only one index is optimized.", index1.isOptimized(), index2.isOptimized());
      
      // check field names
      Collection<String> fields1 = index1.getFieldNames(FieldOption.ALL);
      Collection<String> fields2 = index1.getFieldNames(FieldOption.ALL);
      assertEquals("IndexReaders have different numbers of fields.", fields1.size(), fields2.size());
      Iterator<String> it1 = fields1.iterator();
      Iterator<String> it2 = fields1.iterator();
      while (it1.hasNext()) {
        assertEquals("Different field names.", it1.next(), it2.next());
      }
      
      // check norms
      it1 = fields1.iterator();
      while (it1.hasNext()) {
        String curField = it1.next();
        byte[] norms1 = index1.norms(curField);
        byte[] norms2 = index2.norms(curField);
        if (norms1 != null && norms2 != null)
        {
          assertEquals(norms1.length, norms2.length);
	        for (int i = 0; i < norms1.length; i++) {
	          assertEquals("Norm different for doc " + i + " and field '" + curField + "'.", norms1[i], norms2[i]);
	        }
        }
        else
        {
          assertSame(norms1, norms2);
        }
      }
      
      // check deletions
      final Bits delDocs1 = MultiFields.getDeletedDocs(index1);
      final Bits delDocs2 = MultiFields.getDeletedDocs(index2);
      for (int i = 0; i < index1.maxDoc(); i++) {
        assertEquals("Doc " + i + " only deleted in one index.",
                     delDocs1 == null || delDocs1.get(i),
                     delDocs2 == null || delDocs2.get(i));
      }
      
      // check stored fields
      for (int i = 0; i < index1.maxDoc(); i++) {
        if (delDocs1 == null || !delDocs1.get(i)) {
          Document doc1 = index1.document(i);
          Document doc2 = index2.document(i);
          List<Fieldable> fieldable1 = doc1.getFields();
          List<Fieldable> fieldable2 = doc2.getFields();
          assertEquals("Different numbers of fields for doc " + i + ".", fieldable1.size(), fieldable2.size());
          Iterator<Fieldable> itField1 = fieldable1.iterator();
          Iterator<Fieldable> itField2 = fieldable2.iterator();
          while (itField1.hasNext()) {
            Field curField1 = (Field) itField1.next();
            Field curField2 = (Field) itField2.next();
            assertEquals("Different fields names for doc " + i + ".", curField1.name(), curField2.name());
            assertEquals("Different field values for doc " + i + ".", curField1.stringValue(), curField2.stringValue());
          }          
        }
      }
      
      // check dictionary and posting lists
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951399/fstmerge_var1_1694664756297958351
      FieldsEnum fenum1 = MultiFields.getFields(index1).iterator();
      FieldsEnum fenum2 = MultiFields.getFields(index1).iterator();
      String field1 = null;
      Bits delDocs = MultiFields.getDeletedDocs(index1);
      while((field1=fenum1.next()) != null) {
        assertEquals("Different fields", field1, fenum2.next());
        TermsEnum enum1 = fenum1.terms();
        TermsEnum enum2 = fenum2.terms();
        while(enum1.next() != null) {
          assertEquals("Different terms", enum1.term(), enum2.next());
          DocsAndPositionsEnum tp1 = enum1.docsAndPositions(delDocs, null);
          DocsAndPositionsEnum tp2 = enum2.docsAndPositions(delDocs, null);

          while(tp1.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
            assertTrue(tp2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
            assertEquals("Different doc id in postinglist of term " + enum1.term() + ".", tp1.docID(), tp2.docID());
            assertEquals("Different term frequence in postinglist of term " + enum1.term() + ".", tp1.freq(), tp2.freq());
            for (int i = 0; i < tp1.freq(); i++) {
              assertEquals("Different positions in postinglist of term " + enum1.term() + ".", tp1.nextPosition(), tp2.nextPosition());
            }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951399/fstmerge_base_6990630420459433082
      TermEnum enum1 = index1.terms();
      TermEnum enum2 = index2.terms();
      TermPositions tp1 = index1.termPositions();
      TermPositions tp2 = index2.termPositions();
      while(enum1.next()) {
        assertTrue(enum2.next());
        assertEquals("Different term in dictionary.", enum1.term(), enum2.term());
        tp1.seek(enum1.term());
        tp2.seek(enum1.term());
        while(tp1.next()) {
          assertTrue(tp2.next());
          assertEquals("Different doc id in postinglist of term " + enum1.term() + ".", tp1.doc(), tp2.doc());
          assertEquals("Different term frequence in postinglist of term " + enum1.term() + ".", tp1.freq(), tp2.freq());
          for (int i = 0; i < tp1.freq(); i++) {
            assertEquals("Different positions in postinglist of term " + enum1.term() + ".", tp1.nextPosition(), tp2.nextPosition());
=======
      FieldsEnum fenum1 = MultiFields.getFields(index1).iterator();
      FieldsEnum fenum2 = MultiFields.getFields(index1).iterator();
      String field1 = null;
      Bits delDocs = MultiFields.getDeletedDocs(index1);
      while((field1=fenum1.next()) != null) {
        assertEquals("Different fields", field1, fenum2.next());
        TermsEnum enum1 = fenum1.terms();
        TermsEnum enum2 = fenum2.terms();
        while(enum1.next() != null) {
          assertEquals("Different terms", enum1.term(), enum2.next());
          DocsAndPositionsEnum tp1 = enum1.docsAndPositions(delDocs, null);
          DocsAndPositionsEnum tp2 = enum2.docsAndPositions(delDocs, null);

          while(tp1.nextDoc() != DocsEnum.NO_MORE_DOCS) {
            assertTrue(tp2.nextDoc() != DocsEnum.NO_MORE_DOCS);
            assertEquals("Different doc id in postinglist of term " + enum1.term() + ".", tp1.docID(), tp2.docID());
            assertEquals("Different term frequence in postinglist of term " + enum1.term() + ".", tp1.freq(), tp2.freq());
            for (int i = 0; i < tp1.freq(); i++) {
              assertEquals("Different positions in postinglist of term " + enum1.term() + ".", tp1.nextPosition(), tp2.nextPosition());
            }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951399/fstmerge_var2_1413126065279253135
          }
        }
      }
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testUniqueTermCount() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951451/fstmerge_var1_5833694432166149969
    Directory dir = newDirectory();
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951451/fstmerge_base_665987975011720337
    Directory dir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    Directory dir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951451/fstmerge_var2_4409386930277938231
    Document doc = new Document();
    doc.add(newField("field", "a b c d e f g h i j k l m n o p q r s t u v w x y z", Field.Store.NO, Field.Index.ANALYZED));
    doc.add(newField("number", "0 1 2 3 4 5 6 7 8 9", Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
    writer.addDocument(doc);
    writer.commit();

    IndexReader r = IndexReader.open(dir, false);
    IndexReader r1 = getOnlySegmentReader(r);
    assertEquals(36, r1.getUniqueTermCount());
    writer.addDocument(doc);
    writer.commit();
    IndexReader r2 = r.reopen();
    r.close();
    try {
      r2.getUniqueTermCount();
      fail("expected exception");
    } catch (UnsupportedOperationException uoe) {
      // expected
    }
    IndexReader[] subs = r2.getSequentialSubReaders();
    for(int i=0;i<subs.length;i++) {
      assertEquals(36, subs[i].getUniqueTermCount());
    }
    r2.close();
    writer.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testNoTermsIndex() throws Throwable {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951456/fstmerge_var1_3171976417261244734
    Directory dir = newDirectory();
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951456/fstmerge_base_3392757181507861477
    Directory dir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    Directory dir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951456/fstmerge_var2_553808758466311470
    Document doc = new Document();
    doc.add(newField("field", "a b c d e f g h i j k l m n o p q r s t u v w x y z", Field.Store.NO, Field.Index.ANALYZED));
    doc.add(newField("number", "0 1 2 3 4 5 6 7 8 9", Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
    writer.addDocument(doc);
    writer.close();

    IndexReader r = IndexReader.open(dir, null, true, -1);
    try {
      r.docFreq(new Term("field", "f"));
      fail("did not hit expected exception");
    } catch (IllegalStateException ise) {
      // expected
    }

    assertEquals(-1, ((SegmentReader) r.getSequentialSubReaders()[0]).getTermInfosIndexDivisor());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951456/fstmerge_var1_3171976417261244734
    writer = new IndexWriter(
        dir,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
            setCodecProvider(_TestUtil.alwaysCodec("Standard")).
            setMergePolicy(newLogMergePolicy(10))
    );
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951456/fstmerge_base_3392757181507861477
    writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951456/fstmerge_var2_553808758466311470
    writer.addDocument(doc);
    writer.close();

    // LUCENE-1718: ensure re-open carries over no terms index:
    IndexReader r2 = r.reopen();
    r.close();
    IndexReader[] subReaders = r2.getSequentialSubReaders();
    assertEquals(2, subReaders.length);
    for(int i=0;i<2;i++) {
      try {
        subReaders[i].docFreq(new Term("field", "f"));
        fail("did not hit expected exception");
      } catch (IllegalStateException ise) {
        // expected
      }
    }
    r2.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951496/fstmerge_var1_3807771475740020797
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951496/fstmerge_base_4969162450278093027
private void createIndex(Directory dir) throws IOException {
    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.CREATE)
        .setMaxBufferedDocs(5).setSimilarity(similarityOne));
    LogMergePolicy lmp = (LogMergePolicy) iw.getConfig().getMergePolicy();
    lmp.setMergeFactor(3);
    lmp.setUseCompoundFile(true);
    lmp.setUseCompoundDocStore(true);
    iw.close();
  }
=======
private void createIndex(Directory dir) throws IOException {
    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.CREATE)
        .setMaxBufferedDocs(5).setSimilarity(similarityOne));
    LogMergePolicy lmp = (LogMergePolicy) iw.getConfig().getMergePolicy();
    lmp.setMergeFactor(3);
    lmp.setUseCompoundFile(true);
    iw.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951496/fstmerge_var2_7197639155083623081

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestNorms.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951509/fstmerge_var1_552592947122338293
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951509/fstmerge_base_8171100743417676199
private void addDocs(Directory dir, int ndocs, boolean compound) throws IOException {
    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.APPEND)
        .setMaxBufferedDocs(5).setSimilarity(similarityOne));
    LogMergePolicy lmp = (LogMergePolicy) iw.getConfig().getMergePolicy();
    lmp.setMergeFactor(3);
    lmp.setUseCompoundFile(compound);
    lmp.setUseCompoundDocStore(compound);
    for (int i = 0; i < ndocs; i++) {
      iw.addDocument(newDoc());
    }
    iw.close();
  }
=======
private void addDocs(Directory dir, int ndocs, boolean compound) throws IOException {
    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.APPEND)
        .setMaxBufferedDocs(5).setSimilarity(similarityOne));
    LogMergePolicy lmp = (LogMergePolicy) iw.getConfig().getMergePolicy();
    lmp.setMergeFactor(3);
    lmp.setUseCompoundFile(compound);
    for (int i = 0; i < ndocs; i++) {
      iw.addDocument(newDoc());
    }
    iw.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951509/fstmerge_var2_3939062090469591534

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestNorms.java
Conflict type: LineBasedMCFd
Conflict body: 
private Directory makeIndex() throws Exception { 
    Directory dir = newDirectory();
    try {
      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
          TEST_VERSION_CURRENT, new MockAnalyzer()));
      LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();
      lmp.setUseCompoundFile(false);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951523/fstmerge_var1_4369143426935745141

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951523/fstmerge_base_7602754298116701825
      lmp.setUseCompoundDocStore(false);
      
=======
      
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951523/fstmerge_var2_2603954713965500279
      for (int d = 1; d <= NUM_DOCS; d++) {
        Document doc = new Document();
        for (int f = 1; f <= NUM_FIELDS; f++ ) {
          doc.add(newField("f"+f, 
                            data[f % data.length] 
                            + '#' + data[random.nextInt(data.length)], 
                            Field.Store.YES, 
                            Field.Index.ANALYZED));
        }
        writer.addDocument(doc);
      }
      writer.close();
    } catch (Exception e) {
      throw new RuntimeException(e);
    }
    return dir;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestLazyBug.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testThreadSafety() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951692/fstmerge_var1_7860813406717806581
    final Directory dir = newDirectory();
    final int n = 30 * RANDOM_MULTIPLIER;
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951692/fstmerge_base_4753517108933586070
    final Directory dir = new MockRAMDirectory();
    final int n = 30*_TestUtil.getRandomMultiplier();

    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
=======
    final Directory dir = new MockRAMDirectory();
    final int n = 30 * RANDOM_MULTIPLIER;

    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951692/fstmerge_var2_8004096150523446197
        TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < n; i++) {
      writer.addDocument(createDocument(i, 3));
    }
    writer.optimize();
    writer.close();

    final TestReopen test = new TestReopen() {      
      @Override
      protected void modifyIndex(int i) throws IOException {
        if (i % 3 == 0) {
          IndexReader modifier = IndexReader.open(dir, false);
          modifier.setNorm(i, "field1", 50);
          modifier.close();
        } else if (i % 3 == 1) {
          IndexReader modifier = IndexReader.open(dir, false);
          modifier.deleteDocument(i % modifier.maxDoc());
          modifier.close();
        } else {
          IndexWriter modifier = new IndexWriter(dir, new IndexWriterConfig(
              TEST_VERSION_CURRENT, new MockAnalyzer()));
          modifier.addDocument(createDocument(n + i, 6));
          modifier.close();
        }
      }

      @Override
      protected IndexReader openReader() throws IOException {
        return IndexReader.open(dir, false);
      }      
    };
    
    final List<ReaderCouple> readers = Collections.synchronizedList(new ArrayList<ReaderCouple>());
    IndexReader firstReader = IndexReader.open(dir, false);
    IndexReader reader = firstReader;
    final Random rnd = random;
    
    ReaderThread[] threads = new ReaderThread[n];
    final Set<IndexReader> readersToClose = Collections.synchronizedSet(new HashSet<IndexReader>());
    
    for (int i = 0; i < n; i++) {
      if (i % 2 == 0) {
        IndexReader refreshed = reader.reopen();
        if (refreshed != reader) {
          readersToClose.add(reader);
        }
        reader = refreshed;
      }
      final IndexReader r = reader;
      
      final int index = i;    
      
      ReaderThreadTask task;
      
      if (i < 4 || (i >=10 && i < 14) || i > 18) {
        task = new ReaderThreadTask() {
          
          @Override
          public void run() throws Exception {
            while (!stopped) {
              if (index % 2 == 0) {
                // refresh reader synchronized
                ReaderCouple c = (refreshReader(r, test, index, true));
                readersToClose.add(c.newReader);
                readersToClose.add(c.refreshedReader);
                readers.add(c);
                // prevent too many readers
                break;
              } else {
                // not synchronized
                IndexReader refreshed = r.reopen();
                
                IndexSearcher searcher = new IndexSearcher(refreshed);
                ScoreDoc[] hits = searcher.search(
                    new TermQuery(new Term("field1", "a" + rnd.nextInt(refreshed.maxDoc()))),
                    null, 1000).scoreDocs;
                if (hits.length > 0) {
                  searcher.doc(hits[0].doc);
                }
                
                if (refreshed != r) {
                  refreshed.close();
                }
              }
              synchronized(this) {
                wait(_TestUtil.nextInt(random, 1, 100));
              }
            }
          }
          
        };
      } else {
        task = new ReaderThreadTask() {
          @Override
          public void run() throws Exception {
            while (!stopped) {
              int numReaders = readers.size();
              if (numReaders > 0) {
                ReaderCouple c =  readers.get(rnd.nextInt(numReaders));
                TestIndexReader.assertIndexEquals(c.newReader, c.refreshedReader);
              }
              
              synchronized(this) {
                wait(_TestUtil.nextInt(random, 1, 100));
              }
            }
          }
        };
      }
      
      threads[i] = new ReaderThread(task);
      threads[i].start();
    }
    
    synchronized(this) {
      wait(1000);
    }
    
    for (int i = 0; i < n; i++) {
      if (threads[i] != null) {
        threads[i].stopThread();
      }
    }
    
    for (int i = 0; i < n; i++) {
      if (threads[i] != null) {
        threads[i].join();
        if (threads[i].error != null) {
          String msg = "Error occurred in thread " + threads[i].getName() + ":\n" + threads[i].error.getMessage();
          fail(msg);
        }
      }
      
    }
    
    for (final IndexReader readerToClose : readersToClose) {
      readerToClose.close();
    }
    
    firstReader.close();
    reader.close();
    
    for (final IndexReader readerToClose : readersToClose) {
      assertReaderClosed(readerToClose, true, true);
    }

    assertReaderClosed(reader, true, true);
    assertReaderClosed(firstReader, true, true);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951692/fstmerge_base_4753517108933586070
    FlexTestUtil.verifyFlexVsPreFlex(rnd, dir);

=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951692/fstmerge_var2_8004096150523446197
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexReaderReopen.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testOmitTermFreqAndPositions() throws Exception {
    Directory ram = newDirectory();
    Analyzer analyzer = new MockAnalyzer();
    IndexWriter writer = new IndexWriter(ram, newIndexWriterConfig( TEST_VERSION_CURRENT, analyzer));
    Document d = new Document();
        
    // this field will have Tf
    Field f1 = newField("f1", "This field has term freqs", Field.Store.NO, Field.Index.ANALYZED);
    d.add(f1);
       
    // this field will NOT have Tf
    Field f2 = newField("f2", "This field has NO Tf in all docs", Field.Store.NO, Field.Index.ANALYZED);
    f2.setOmitTermFreqAndPositions(true);
    d.add(f2);
        
    writer.addDocument(d);
    writer.optimize();
    // now we add another document which has term freq for field f2 and not for f1 and verify if the SegmentMerger
    // keep things constant
    d = new Document();
        
    // Reverse
    f1.setOmitTermFreqAndPositions(true);
    d.add(f1);
        
    f2.setOmitTermFreqAndPositions(false);        
    d.add(f2);
        
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951870/fstmerge_base_8081962206108262415
    Random rnd = newRandom();

=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951870/fstmerge_var2_7069134490492454256
    writer.addDocument(d);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951870/fstmerge_base_8081962206108262415
    FlexTestUtil.verifyFlexVsPreFlex(rnd, writer);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951870/fstmerge_var2_7069134490492454256

    // force merge
    writer.optimize();
    // flush
    writer.close();
    _TestUtil.checkIndex(ram);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951870/fstmerge_var1_3901644833775450743
    SegmentReader reader = getOnlySegmentReader(IndexReader.open(ram, false));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951870/fstmerge_base_8081962206108262415
    FlexTestUtil.verifyFlexVsPreFlex(rnd, ram);

    SegmentReader reader = SegmentReader.getOnlySegmentReader(ram);
=======
    SegmentReader reader = SegmentReader.getOnlySegmentReader(ram);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951870/fstmerge_var2_7069134490492454256
    FieldInfos fi = reader.fieldInfos();
    assertTrue("OmitTermFreqAndPositions field bit should be set.", fi.fieldInfo("f1").omitTermFreqAndPositions);
    assertTrue("OmitTermFreqAndPositions field bit should be set.", fi.fieldInfo("f2").omitTermFreqAndPositions);
        
    reader.close();
    ram.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestOmitTf.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testRandomIWReader() throws Throwable {
    Directory dir = newDirectory();
    
    // TODO: verify equals using IW.getReader
    DocsAndWriter dw = indexRandomIWReader(5, 3, 100, dir);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951939/fstmerge_base_1077734169039401770
    IndexReader r = dw.writer.getReader();
=======
    IndexReader reader = dw.writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951939/fstmerge_var2_158877841414595414
    dw.writer.commit();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951939/fstmerge_var1_5867205663530361093
    verifyEquals(random, reader, dir, "id");
    reader.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951939/fstmerge_base_1077734169039401770
    verifyEquals(r, dir, "id");
    FlexTestUtil.verifyFlexVsPreFlex(this.r, r);
    FlexTestUtil.verifyFlexVsPreFlex(this.r, dir);
    r.close();
=======
    verifyEquals(r, reader, dir, "id");
    reader.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951939/fstmerge_var2_158877841414595414
    dw.writer.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestStressIndexing2.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testRandom() throws Throwable {
    Directory dir1 = newDirectory();
    Directory dir2 = newDirectory();
    // mergeFactor=2; maxBufferedDocs=2; Map docs = indexRandom(1, 3, 2, dir1);
    int maxThreadStates = 1+random.nextInt(10);
    boolean doReaderPooling = random.nextBoolean();
    Map<String,Document> docs = indexRandom(5, 3, 100, dir1, maxThreadStates, doReaderPooling);
    indexSerial(random, docs, dir2);

    // verifying verify
    // verifyEquals(dir1, dir1, "id");
    // verifyEquals(dir2, dir2, "id");

    verifyEquals(dir1, dir2, "id");
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951944/fstmerge_var1_5824414889482021278
    dir1.close();
    dir2.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951944/fstmerge_base_7626667570876834853
    FlexTestUtil.verifyFlexVsPreFlex(r, dir1);
    FlexTestUtil.verifyFlexVsPreFlex(r, dir2);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951944/fstmerge_var2_4716735589064711849
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestStressIndexing2.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testMultiConfig() throws Throwable {
    // test lots of smaller different params together

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951948/fstmerge_var1_2282143503587054003
    int num = 3 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) { // increase iterations for better testing
      if (VERBOSE) {
        System.out.println("\n\nTEST: top iter=" + i);
      }
      sameFieldOrder=random.nextBoolean();
      mergeFactor=random.nextInt(3)+2;
      maxBufferedDocs=random.nextInt(3)+2;
      int maxThreadStates = 1+random.nextInt(10);
      boolean doReaderPooling = random.nextBoolean();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951948/fstmerge_base_9204640652904378318
    r = newRandom();

    for (int i=0; i<3*_TestUtil.getRandomMultiplier(); i++) {  // increase iterations for better testing
      sameFieldOrder=r.nextBoolean();
      mergeFactor=r.nextInt(3)+2;
      maxBufferedDocs=r.nextInt(3)+2;
      int maxThreadStates = 1+r.nextInt(10);
      boolean doReaderPooling = r.nextBoolean();
=======
    r = newRandom();

    int num = 3 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) { // increase iterations for better testing
      sameFieldOrder=r.nextBoolean();
      mergeFactor=r.nextInt(3)+2;
      maxBufferedDocs=r.nextInt(3)+2;
      int maxThreadStates = 1+r.nextInt(10);
      boolean doReaderPooling = r.nextBoolean();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951948/fstmerge_var2_5010344415939583437
      seed++;

      int nThreads=random.nextInt(5)+1;
      int iter=random.nextInt(5)+1;
      int range=random.nextInt(20)+1;
      Directory dir1 = newDirectory();
      Directory dir2 = newDirectory();
      if (VERBOSE) {
        System.out.println("  nThreads=" + nThreads + " iter=" + iter + " range=" + range + " doPooling=" + doReaderPooling + " maxThreadStates=" + maxThreadStates + " sameFieldOrder=" + sameFieldOrder + " mergeFactor=" + mergeFactor);
      }
      Map<String,Document> docs = indexRandom(nThreads, iter, range, dir1, maxThreadStates, doReaderPooling);
      if (VERBOSE) {
        System.out.println("TEST: index serial");
      }
      indexSerial(random, docs, dir2);
      if (VERBOSE) {
        System.out.println("TEST: verify");
      }
      verifyEquals(dir1, dir2, "id");
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951948/fstmerge_var1_2282143503587054003
      dir1.close();
      dir2.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951948/fstmerge_base_9204640652904378318

      FlexTestUtil.verifyFlexVsPreFlex(r, dir1);
      FlexTestUtil.verifyFlexVsPreFlex(r, dir2);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627951948/fstmerge_var2_5010344415939583437
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestStressIndexing2.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testExpirationTimeDeletionPolicy() throws IOException, InterruptedException {

    final double SECONDS = 2.0;

    Directory dir = newDirectory();
    ExpirationTimeDeletionPolicy policy = new ExpirationTimeDeletionPolicy(dir, SECONDS);
    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,
        new MockAnalyzer())
        .setIndexDeletionPolicy(policy);
    LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952129/fstmerge_var1_8761349987345340031
    lmp.setUseCompoundFile(true);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952129/fstmerge_base_1529561864895254719
    lmp.setUseCompoundFile(useCompoundFile);
    lmp.setUseCompoundDocStore(useCompoundFile);
=======
    lmp.setUseCompoundFile(useCompoundFile);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952129/fstmerge_var2_6520315773935728667
    IndexWriter writer = new IndexWriter(dir, conf);
    writer.close();

    final int ITER = 9;

    long lastDeleteTime = 0;
    for(int i=0;i<ITER;i++) {
      // Record last time when writer performed deletes of
      // past commits
      lastDeleteTime = System.currentTimeMillis();
      conf = newIndexWriterConfig(TEST_VERSION_CURRENT,
          new MockAnalyzer()).setOpenMode(
          OpenMode.APPEND).setIndexDeletionPolicy(policy);
      lmp = (LogMergePolicy) conf.getMergePolicy();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952129/fstmerge_var1_8761349987345340031
      lmp.setUseCompoundFile(true);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952129/fstmerge_base_1529561864895254719
      lmp.setUseCompoundFile(useCompoundFile);
      lmp.setUseCompoundDocStore(useCompoundFile);
=======
      lmp.setUseCompoundFile(useCompoundFile);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952129/fstmerge_var2_6520315773935728667
      writer = new IndexWriter(dir, conf);
      for(int j=0;j<17;j++) {
        addDoc(writer);
      }
      writer.close();

      if (i < ITER-1) {
        // Make sure to sleep long enough so that some commit
        // points will be deleted:
        Thread.sleep((int) (1000.0*(SECONDS/5.0)));
      }
    }

    // First, make sure the policy in fact deleted something:
    assertTrue("no commits were deleted", policy.numDelete > 0);

    // Then simplistic check: just verify that the
    // segments_N's that still exist are in fact within SECONDS
    // seconds of the last one's mod time, and, that I can
    // open a reader on each:
    long gen = SegmentInfos.getCurrentSegmentGeneration(dir);
    
    String fileName = IndexFileNames.fileNameFromGeneration(IndexFileNames.SEGMENTS,
                                                            "",
                                                            gen);
    dir.deleteFile(IndexFileNames.SEGMENTS_GEN);

    boolean oneSecondResolution = true;

    while(gen > 0) {
      try {
        IndexReader reader = IndexReader.open(dir, true);
        reader.close();
        fileName = IndexFileNames.fileNameFromGeneration(IndexFileNames.SEGMENTS,
                                                         "",
                                                         gen);

        // if we are on a filesystem that seems to have only
        // 1 second resolution, allow +1 second in commit
        // age tolerance:
        long modTime = dir.fileModified(fileName);
        oneSecondResolution &= (modTime % 1000) == 0;
        final long leeway = (long) ((SECONDS + (oneSecondResolution ? 1.0:0.0))*1000);

        assertTrue("commit point was older than " + SECONDS + " seconds (" + (lastDeleteTime - modTime) + " msec) but did not get deleted ", lastDeleteTime - modTime <= leeway);
      } catch (IOException e) {
        // OK
        break;
      }
      
      dir.deleteFile(IndexFileNames.fileNameFromGeneration(IndexFileNames.SEGMENTS, "", gen));
      gen--;
    }

    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestDeletionPolicy.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testKeepAllDeletionPolicy() throws IOException {
    for(int pass=0;pass<2;pass++) {

      boolean useCompoundFile = (pass % 2) != 0;

      // Never deletes a commit
      KeepAllDeletionPolicy policy = new KeepAllDeletionPolicy();

      Directory dir = newDirectory();
      policy.dir = dir;

      IndexWriterConfig conf = newIndexWriterConfig(
          TEST_VERSION_CURRENT, new MockAnalyzer())
          .setIndexDeletionPolicy(policy).setMaxBufferedDocs(10)
          .setMergeScheduler(new SerialMergeScheduler());
      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
      lmp.setUseCompoundFile(useCompoundFile);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952134/fstmerge_var1_5288991882401450941
      lmp.setMergeFactor(10);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952134/fstmerge_base_6443043201950413830
      lmp.setUseCompoundDocStore(useCompoundFile);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952134/fstmerge_var2_7490653806977583166
      IndexWriter writer = new IndexWriter(dir, conf);
      for(int i=0;i<107;i++) {
        addDoc(writer);
      }
      writer.close();

      conf = newIndexWriterConfig(TEST_VERSION_CURRENT,
          new MockAnalyzer()).setOpenMode(
          OpenMode.APPEND).setIndexDeletionPolicy(policy);
      lmp = (LogMergePolicy) conf.getMergePolicy();
      lmp.setUseCompoundFile(useCompoundFile);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952134/fstmerge_base_6443043201950413830
      lmp.setUseCompoundDocStore(useCompoundFile);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952134/fstmerge_var2_7490653806977583166
      writer = new IndexWriter(dir, conf);
      writer.optimize();
      writer.close();

      assertEquals(1, policy.numOnInit);

      // If we are not auto committing then there should
      // be exactly 2 commits (one per close above):
      assertEquals(2, policy.numOnCommit);

      // Test listCommits
      Collection<IndexCommit> commits = IndexReader.listCommits(dir);
      // 2 from closing writer
      assertEquals(2, commits.size());

      // Make sure we can open a reader on each commit:
      for (final IndexCommit commit : commits) {
        IndexReader r = IndexReader.open(commit, null, false);
        r.close();
      }

      // Simplistic check: just verify all segments_N's still
      // exist, and, I can open a reader on each:
      dir.deleteFile(IndexFileNames.SEGMENTS_GEN);
      long gen = SegmentInfos.getCurrentSegmentGeneration(dir);
      while(gen > 0) {
        IndexReader reader = IndexReader.open(dir, true);
        reader.close();
        dir.deleteFile(IndexFileNames.fileNameFromGeneration(IndexFileNames.SEGMENTS, "", gen));
        gen--;

        if (gen > 0) {
          // Now that we've removed a commit point, which
          // should have orphan'd at least one index file.
          // Open & close a writer and assert that it
          // actually removed something:
          int preCount = dir.listAll().length;
          writer = new IndexWriter(dir, newIndexWriterConfig(
              TEST_VERSION_CURRENT,
              new MockAnalyzer()).setOpenMode(
              OpenMode.APPEND).setIndexDeletionPolicy(policy));
          writer.close();
          int postCount = dir.listAll().length;
          assertTrue(postCount < preCount);
        }
      }

      dir.close();
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestDeletionPolicy.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952205/fstmerge_var1_8692189825228487777
public void testRollbackIntegrityWithBufferFlush() throws Exception {
    Directory dir = newDirectory();
    RandomIndexWriter rw = new RandomIndexWriter(random, dir);
    for (int i = 0; i < 5; i++) {
      Document doc = new Document();
      doc.add(newField("pk", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));
      rw.addDocument(doc);
    }
    rw.close();

    // If buffer size is small enough to cause a flush, errors ensue...
    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));

    Term pkTerm = new Term("pk", "");
    for (int i = 0; i < 3; i++) {
      Document doc = new Document();
      String value = Integer.toString(i);
      doc.add(newField("pk", value, Store.YES, Index.ANALYZED_NO_NORMS));
      doc.add(newField("text", "foo", Store.YES, Index.ANALYZED_NO_NORMS));
      w.updateDocument(pkTerm.createTerm(value), doc);
    }
    w.rollback();

    IndexReader r = IndexReader.open(dir, true);
    assertEquals("index should contain same number of docs post rollback", 5, r.numDocs());
    r.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952205/fstmerge_base_7815497287619781731
=======
public void testRollbackIntegrityWithBufferFlush() throws Exception {
    Directory dir = new MockRAMDirectory();
    RandomIndexWriter rw = new RandomIndexWriter(newRandom(), dir);
    for (int i = 0; i < 5; i++) {
      Document doc = new Document();
      doc.add(new Field("pk", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));
      rw.addDocument(doc);
    }
    rw.close();

    // If buffer size is small enough to cause a flush, errors ensue...
    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));

    Term pkTerm = new Term("pk", "");
    for (int i = 0; i < 3; i++) {
      Document doc = new Document();
      String value = Integer.toString(i);
      doc.add(new Field("pk", value, Store.YES, Index.ANALYZED_NO_NORMS));
      doc.add(new Field("text", "foo", Store.YES, Index.ANALYZED_NO_NORMS));
      w.updateDocument(pkTerm.createTerm(value), doc);
    }
    w.rollback();

    IndexReader r = IndexReader.open(dir, true);
    assertEquals("index should contain same number of docs post rollback", 5, r.numDocs());
    r.close();
    dir.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952205/fstmerge_var2_7205590720044340574

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestRollback.java
Conflict type: LineBasedMCFd
Conflict body: 
private void createIndex(int numHits) throws IOException {
        int numDocs = 500;
        
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952214/fstmerge_var1_5990388715305002294
        Directory directory = new SeekCountingDirectory(new RAMDirectory());
        IndexWriter writer = new IndexWriter(
            directory,
            newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, true, false)).
                setMaxBufferedDocs(10).
                setMergePolicy(newLogMergePolicy(false))
        );
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952214/fstmerge_base_8140020338722150265
        Directory directory = new SeekCountingDirectory();
        IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
=======
        Directory directory = new SeekCountingDirectory();
        IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952214/fstmerge_var2_5229835661450734541
        for (int i = 0; i < numDocs; i++) {
            Document doc = new Document();
            String content;
            if (i % (numDocs / numHits) == 0) {
                // add a document that matches the query "term1 term2"
                content = this.term1 + " " + this.term2;
            } else if (i % 15 == 0) {
                // add a document that only contains term1
                content = this.term1 + " " + this.term1;
            } else {
                // add a document that contains term2 but not term 1
                content = this.term3 + " " + this.term2;
            }

            doc.add(newField(this.field, content, Field.Store.YES, Field.Index.ANALYZED));
            writer.addDocument(doc);
        }
        
        // make sure the index has only a single segment
        writer.optimize();
        writer.close();

      SegmentReader reader = getOnlySegmentReader(IndexReader.open(directory, false));

        this.searcher = new IndexSearcher(reader);        
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testTokenReuse() throws IOException {
    Analyzer analyzer = new Analyzer() {
      @Override
      public TokenStream tokenStream(String fieldName, Reader reader) {
        return new TokenFilter(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false)) {
          boolean first=true;
          AttributeSource.State state;

          @Override
          public boolean incrementToken() throws IOException {
            if (state != null) {
              restoreState(state);
              payloadAtt.setPayload(null);
              posIncrAtt.setPositionIncrement(0);
              termAtt.setEmpty().append("b");
              state = null;
              return true;
            }

            boolean hasNext = input.incrementToken();
            if (!hasNext) return false;
            if (Character.isDigit(termAtt.buffer()[0])) {
              posIncrAtt.setPositionIncrement(termAtt.buffer()[0] - '0');
            }
            if (first) {
              // set payload on first position only
              payloadAtt.setPayload(new Payload(new byte[]{100}));
              first = false;
            }

            // index a "synonym" for every token
            state = captureState();
            return true;

          }

          CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
          PayloadAttribute payloadAtt = addAttribute(PayloadAttribute.class);
          PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);          
        };
      }
    };

    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));

    Document doc = new Document();
    doc.add(newField("f1", "a 5 a a", Field.Store.YES, Field.Index.ANALYZED));

    writer.addDocument(doc);
    writer.commit();
    SegmentInfo info = writer.newestSegment();
    writer.close();
    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952293/fstmerge_base_6628602344749076853
    TermPositions termPositions = reader.termPositions(new Term("f1", "a"));
    assertTrue(termPositions.next());
=======
    DocsAndPositionsEnum termPositions = reader.fields().terms("f1").docsAndPositions(reader.getDeletedDocs(), new BytesRef("a"), null);
    assertTrue(termPositions.nextDoc() != termPositions.NO_MORE_DOCS);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952293/fstmerge_var2_1254223217818382496
    int freq = termPositions.freq();
    assertEquals(3, freq);
    assertEquals(0, termPositions.nextPosition());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952293/fstmerge_base_6628602344749076853
    assertEquals(true, termPositions.isPayloadAvailable());
=======
    assertEquals(true, termPositions.hasPayload());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952293/fstmerge_var2_1254223217818382496
    assertEquals(6, termPositions.nextPosition());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952293/fstmerge_base_6628602344749076853
    assertEquals(false, termPositions.isPayloadAvailable());
=======
    assertEquals(false, termPositions.hasPayload());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952293/fstmerge_var2_1254223217818382496
    assertEquals(7, termPositions.nextPosition());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952293/fstmerge_var1_1965313499865608022
    assertEquals(false, termPositions.hasPayload());
    reader.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952293/fstmerge_base_6628602344749076853
    assertEquals(false, termPositions.isPayloadAvailable());
=======
    assertEquals(false, termPositions.hasPayload());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952293/fstmerge_var2_1254223217818382496
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestDocumentWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testRandom() throws Exception {

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_var1_3780742793987329642
    int num = 2 * RANDOM_MULTIPLIER;
    for (int iter = 0; iter < num; iter++) {
      Directory dir = newDirectory();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_base_6445121564037765267
    for(int iter=0;iter<2*_TestUtil.getRandomMultiplier();iter++) {
      Directory dir = new MockRAMDirectory();
      IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
=======
    Random r = newRandom();

    int num = 2 * RANDOM_MULTIPLIER;
    for (int iter = 0; iter < num; iter++) {
      Directory dir = new MockRAMDirectory();

      IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_var2_7771380838755964321

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_var1_3780742793987329642
      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_base_6445121564037765267
      Random r = new Random();

=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_var2_7771380838755964321
      Map<BytesRef,List<Integer>> docs = new HashMap<BytesRef,List<Integer>>();
      Set<Integer> deleted = new HashSet<Integer>();
      List<BytesRef> terms = new ArrayList<BytesRef>();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_var1_3780742793987329642
      int numDocs = _TestUtil.nextInt(random, 1, 100 * RANDOM_MULTIPLIER);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_base_6445121564037765267
      int numDocs = r.nextInt(100*_TestUtil.getRandomMultiplier());
=======
      int numDocs = _TestUtil.nextInt(r, 1, 100 * RANDOM_MULTIPLIER);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_var2_7771380838755964321
      Document doc = new Document();
      Field f = newField("field", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
      doc.add(f);
      Field id = newField("id", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
      doc.add(id);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_var1_3780742793987329642
      boolean onlyUniqueTerms = random.nextBoolean();
      Set<BytesRef> uniqueTerms = new HashSet<BytesRef>();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_base_6445121564037765267
      boolean onlyUniqueTerms = r.nextBoolean();

=======
      boolean onlyUniqueTerms = r.nextBoolean();
      Set<BytesRef> uniqueTerms = new HashSet<BytesRef>();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_var2_7771380838755964321
      for(int i=0;i<numDocs;i++) {

        if (!onlyUniqueTerms && random.nextBoolean() && terms.size() > 0) {
          // re-use existing term
          BytesRef term = terms.get(random.nextInt(terms.size()));
          docs.get(term).add(i);
          f.setValue(term.utf8ToString());
        } else {
          String s = _TestUtil.randomUnicodeString(random, 10);
          BytesRef term = new BytesRef(s);
          if (!docs.containsKey(term)) {
            docs.put(term, new ArrayList<Integer>());
          }
          docs.get(term).add(i);
          terms.add(term);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_base_6445121564037765267
=======
          uniqueTerms.add(term);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_var2_7771380838755964321
          f.setValue(s);
        }
        id.setValue(""+i);
        w.addDocument(doc);
        if (random.nextInt(4) == 1) {
          w.commit();
        }
        if (i > 0 && random.nextInt(20) == 1) {
          int delID = random.nextInt(i);
          deleted.add(delID);
          w.deleteDocuments(new Term("id", ""+delID));
        }
      }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_base_6445121564037765267
=======
      if (VERBOSE) {
        List<BytesRef> termsList = new ArrayList<BytesRef>(uniqueTerms);
        Collections.sort(termsList, BytesRef.getUTF8SortedAsUTF16Comparator());
        System.out.println("UTF16 order:");
        for(BytesRef b : termsList) {
          System.out.println("  " + UnicodeUtil.toHexString(b.utf8ToString()));
        }
      }

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_var2_7771380838755964321
      IndexReader reader = w.getReader();
      w.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_base_6445121564037765267
=======
      //System.out.println("TEST reader=" + reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_var2_7771380838755964321

      Bits delDocs = MultiFields.getDeletedDocs(reader);
      for(int delDoc : deleted) {
        assertTrue(delDocs.get(delDoc));
      }
      Terms terms2 = MultiFields.getTerms(reader, "field");

      for(int i=0;i<100;i++) {
        BytesRef term = terms.get(random.nextInt(terms.size()));
        
        DocsEnum docsEnum = terms2.docs(delDocs, term, null);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_base_6445121564037765267
        int count = 0;
=======
        assertNotNull(docsEnum);

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_var2_7771380838755964321
        for(int docID : docs.get(term)) {
          if (!deleted.contains(docID)) {
            assertEquals(docID, docsEnum.nextDoc());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_base_6445121564037765267
            count++;
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_var2_7771380838755964321
          }
        }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_base_6445121564037765267
        //System.out.println("c=" + count + " t=" + term);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952311/fstmerge_var2_7771380838755964321
        assertEquals(docsEnum.NO_MORE_DOCS, docsEnum.nextDoc());
      }

      reader.close();
      dir.close();
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestMultiFields.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952317/fstmerge_var1_6015303547277614169
public void testSeparateEnums() throws Exception {
    Directory dir = newDirectory();
    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document d = new Document();
    d.add(newField("f", "j", Field.Store.NO, Field.Index.NOT_ANALYZED));
    w.addDocument(d);
    w.commit();
    w.addDocument(d);
    IndexReader r = w.getReader();
    w.close();
    DocsEnum d1 = MultiFields.getTermDocsEnum(r, null, "f", new BytesRef("j"));
    DocsEnum d2 = MultiFields.getTermDocsEnum(r, null, "f", new BytesRef("j"));
    assertEquals(0, d1.nextDoc());
    assertEquals(0, d2.nextDoc());
    r.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952317/fstmerge_base_7312575204151380984
=======
public void testSeparateEnums() throws Exception {
    Directory dir = new MockRAMDirectory();
    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document d = new Document();
    d.add(new Field("f", "j", Field.Store.NO, Field.Index.NOT_ANALYZED));
    w.addDocument(d);
    w.commit();
    w.addDocument(d);
    IndexReader r = w.getReader();
    w.close();
    DocsEnum d1 = MultiFields.getTermDocsEnum(r, null, "f", new BytesRef("j"));
    DocsEnum d2 = MultiFields.getTermDocsEnum(r, null, "f", new BytesRef("j"));
    assertEquals(0, d1.nextDoc());
    assertEquals(0, d2.nextDoc());
    r.close();
    dir.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952317/fstmerge_var2_7233933774307125830

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestMultiFields.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testCloseStoredFields() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952475/fstmerge_var1_1104283937837394231
    final Directory dir = newDirectory();
    IndexWriter w = new IndexWriter(
        dir,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
            setMergePolicy(newLogMergePolicy(false))
    );
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952475/fstmerge_base_1896953115929910130
    final Directory dir = new MockRAMDirectory();
    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
    ((LogMergePolicy) w.getConfig().getMergePolicy()).setUseCompoundFile(false);
    ((LogMergePolicy) w.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
=======
    final Directory dir = new MockRAMDirectory();
    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
    ((LogMergePolicy) w.getConfig().getMergePolicy()).setUseCompoundFile(false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952475/fstmerge_var2_5987139387705718771
    Document doc = new Document();
    doc.add(newField("field", "yes it's stored", Field.Store.YES, Field.Index.ANALYZED));
    w.addDocument(doc);
    w.close();
    IndexReader r1 = IndexReader.open(dir, false);
    IndexReader r2 = r1.clone(false);
    r1.close();
    r2.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexReaderClone.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testPrevTermAtEnd() throws IOException
  {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952484/fstmerge_var1_2691014538413226618
    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952484/fstmerge_base_6774548162521278355
    Directory dir = new MockRAMDirectory();
    IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    Directory dir = new MockRAMDirectory();
    IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952484/fstmerge_var2_2344034406060253340
    addDoc(writer, "aaa bbb");
    writer.close();
    SegmentReader reader = getOnlySegmentReader(IndexReader.open(dir, false));
    TermsEnum terms = reader.fields().terms("content").iterator();
    assertNotNull(terms.next());
    assertEquals("aaa", terms.term().utf8ToString());
    assertNotNull(terms.next());
    long ordB = terms.ord();
    assertEquals("bbb", terms.term().utf8ToString());
    assertNull(terms.next());

    assertEquals(TermsEnum.SeekStatus.FOUND, terms.seek(ordB));
    assertEquals("bbb", terms.term().utf8ToString());
    reader.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestSegmentTermEnum.java
Conflict type: LineBasedMCFd
Conflict body: 
private void verifyDocFreq()
      throws IOException
  {
      IndexReader reader = IndexReader.open(dir, true);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_base_5488282013209493970
      TermEnum termEnum = null;
=======
      TermsEnum termEnum = MultiFields.getTerms(reader, "content").iterator();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_var2_7599382301663375677

    // create enumeration of all terms
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_base_5488282013209493970
    termEnum = reader.terms();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_var2_7599382301663375677
    // go to the first term (aaa)
    termEnum.next();
    // assert that term is 'aaa'
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_base_5488282013209493970
    assertEquals("aaa", termEnum.term().text());
=======
    assertEquals("aaa", termEnum.term().utf8ToString());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_var2_7599382301663375677
    assertEquals(200, termEnum.docFreq());
    // go to the second term (bbb)
    termEnum.next();
    // assert that term is 'bbb'
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_base_5488282013209493970
    assertEquals("bbb", termEnum.term().text());
=======
    assertEquals("bbb", termEnum.term().utf8ToString());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_var2_7599382301663375677
    assertEquals(100, termEnum.docFreq());

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_base_5488282013209493970
    termEnum.close();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_var2_7599382301663375677

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_base_5488282013209493970

    // create enumeration of terms after term 'aaa', including 'aaa'
    termEnum = reader.terms(new Term("content", "aaa"));
=======
    // create enumeration of terms after term 'aaa',
    // including 'aaa'
    termEnum.seek(new BytesRef("aaa"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_var2_7599382301663375677
    // assert that term is 'aaa'
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_base_5488282013209493970
    assertEquals("aaa", termEnum.term().text());
=======
    assertEquals("aaa", termEnum.term().utf8ToString());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_var2_7599382301663375677
    assertEquals(200, termEnum.docFreq());
    // go to term 'bbb'
    termEnum.next();
    // assert that term is 'bbb'
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_base_5488282013209493970
    assertEquals("bbb", termEnum.term().text());
=======
    assertEquals("bbb", termEnum.term().utf8ToString());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_var2_7599382301663375677
    assertEquals(100, termEnum.docFreq());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_var1_581454276948982920
    reader.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_base_5488282013209493970

    termEnum.close();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952489/fstmerge_var2_7599382301663375677
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestSegmentTermEnum.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testFixedPostings() throws Throwable {
    final int NUM_TERMS = 100;
    final TermData[] terms = new TermData[NUM_TERMS];
    for(int i=0;i<NUM_TERMS;i++) {
      final int[] docs = new int[] {i};
      final String text = Integer.toString(i, Character.MAX_RADIX);
      terms[i] = new TermData(text, docs, null);
    }

    final FieldInfos fieldInfos = new FieldInfos();

    final FieldData field = new FieldData("field", fieldInfos, terms, true, false);
    final FieldData[] fields = new FieldData[] {field};

    final Directory dir = newDirectory();
    this.write(fieldInfos, dir, fields);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952741/fstmerge_var1_9090213157175705870
    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952741/fstmerge_base_8199127934801523308
    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));
=======
    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, CodecProvider.getDefault().getWriter(null));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952741/fstmerge_var2_1519065916359643034
    si.setHasProx(false);

    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));

    final FieldsEnum fieldsEnum = reader.iterator();
    assertNotNull(fieldsEnum.next());
    final TermsEnum termsEnum = fieldsEnum.terms();

    DocsEnum docsEnum = null;
    for(int i=0;i<NUM_TERMS;i++) {
      final BytesRef term = termsEnum.next();
      assertNotNull(term);
      assertEquals(terms[i].text2, term.utf8ToString());

      // do this twice to stress test the codec's reuse, ie,
      // make sure it properly fully resets (rewinds) its
      // internal state:
      for(int iter=0;iter<2;iter++) {
        docsEnum = termsEnum.docs(null,  docsEnum);
        assertEquals(terms[i].docs[0], docsEnum.nextDoc());
        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());
      }
    }
    assertNull(termsEnum.next());

    for(int i=0;i<NUM_TERMS;i++) {
      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);
    }

    assertNull(fieldsEnum.next());
    reader.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestCodecs.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testRandomPostings() throws Throwable {
    final FieldInfos fieldInfos = new FieldInfos();

    final FieldData[] fields = new FieldData[NUM_FIELDS];
    for(int i=0;i<NUM_FIELDS;i++) {
      final boolean omitTF = 0==(i%3);
      final boolean storePayloads = 1==(i%3);
      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);
    }

    final Directory dir = newDirectory();

    this.write(fieldInfos, dir, fields);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952745/fstmerge_var1_3906902615485481553
    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952745/fstmerge_base_1656776789035739525
    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));
=======
    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, CodecProvider.getDefault().getWriter(null));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952745/fstmerge_var2_417471700391337502

    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));

    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];
    for(int i=0;i<NUM_TEST_THREADS-1;i++) {
      threads[i] = new Verify(fields, terms);
      threads[i].setDaemon(true);
      threads[i].start();
    }

    new Verify(fields, terms).run();

    for(int i=0;i<NUM_TEST_THREADS-1;i++) {
      threads[i].join();
      assert !threads[i].failed;
    }

    terms.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestCodecs.java
Conflict type: LineBasedMCFd
Conflict body: 
private void write(final FieldInfos fieldInfos, final Directory dir, final FieldData[] fields) throws Throwable {

    final int termIndexInterval = this.nextInt(13, 27);
    final SegmentCodecs codecInfo = SegmentCodecs.build(fieldInfos, CodecProvider.getDefault());
    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, 10000, termIndexInterval, codecInfo);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952790/fstmerge_var1_9055705215669291376
    final FieldsConsumer consumer = state.segmentCodecs.codec().fieldsConsumer(state);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952790/fstmerge_base_20345981490436408
    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, null, 10000, 10000, termIndexInterval,
                                                    CodecProvider.getDefault());

    final FieldsConsumer consumer = state.codec.fieldsConsumer(state);
=======
    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, 10000, termIndexInterval,
                                                    CodecProvider.getDefault());

    final FieldsConsumer consumer = state.codec.fieldsConsumer(state);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952790/fstmerge_var2_4086796008424917503
    Arrays.sort(fields);
    for (final FieldData field : fields) {
      field.write(consumer);
    }
    consumer.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestCodecs.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952952/fstmerge_var1_3780942248917565303
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952952/fstmerge_base_1802941140745775974
public void testSimulatedCrashedWriter() throws IOException {
        Directory dir = new RAMDirectory();

        IndexWriter writer = null;

        writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));

        // add 100 documents
        for (int i = 0; i < 100; i++) {
            addDoc(writer);
        }

        // close
        writer.close();

        long gen = SegmentInfos.getCurrentSegmentGeneration(dir);
        assertTrue("segment generation should be > 0 but got " + gen, gen > 0);

        // Make the next segments file, with last byte
        // missing, to simulate a writer that crashed while
        // writing segments file:
        String fileNameIn = SegmentInfos.getCurrentSegmentFileName(dir);
        String fileNameOut = IndexFileNames.fileNameFromGeneration(IndexFileNames.SEGMENTS,
                                                                   "",
                                                                   1+gen);
        IndexInput in = dir.openInput(fileNameIn);
        IndexOutput out = dir.createOutput(fileNameOut);
        long length = in.length();
        for(int i=0;i<length-1;i++) {
          out.writeByte(in.readByte());
        }
        in.close();
        out.close();

        IndexReader reader = null;
        try {
          reader = IndexReader.open(dir, true);
        } catch (Exception e) {
          fail("reader failed to open on a crashed index");
        }
        reader.close();

        try {
          writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
        } catch (Exception e) {
          fail("writer failed to open on a crashed index");
        }

        // add 100 documents
        for (int i = 0; i < 100; i++) {
            addDoc(writer);
        }

        // close
        writer.close();
    }
=======
public void testSimulatedCrashedWriter() throws IOException {
        Directory dir = new RAMDirectory();

        IndexWriter writer = null;

        writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));

        // add 100 documents
        for (int i = 0; i < 100; i++) {
            addDoc(writer);
        }

        // close
        writer.close();

        long gen = SegmentInfos.getCurrentSegmentGeneration(dir);
        assertTrue("segment generation should be > 0 but got " + gen, gen > 0);

        // Make the next segments file, with last byte
        // missing, to simulate a writer that crashed while
        // writing segments file:
        String fileNameIn = SegmentInfos.getCurrentSegmentFileName(dir);
        String fileNameOut = IndexFileNames.fileNameFromGeneration(IndexFileNames.SEGMENTS,
                                                                   "",
                                                                   1+gen);
        IndexInput in = dir.openInput(fileNameIn);
        IndexOutput out = dir.createOutput(fileNameOut);
        long length = in.length();
        for(int i=0;i<length-1;i++) {
          out.writeByte(in.readByte());
        }
        in.close();
        out.close();

        IndexReader reader = null;
        try {
          reader = IndexReader.open(dir, true);
        } catch (Exception e) {
          fail("reader failed to open on a crashed index");
        }
        reader.close();

        try {
          writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
        } catch (Exception e) {
          e.printStackTrace(System.out);
          fail("writer failed to open on a crashed index");
        }

        // add 100 documents
        for (int i = 0; i < 100; i++) {
            addDoc(writer);
        }

        // close
        writer.close();
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627952952/fstmerge_var2_5089118349555742373

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953086/fstmerge_var1_5795111699917102077
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953086/fstmerge_base_2494753779433434852
public void testExceptionFromTokenStream() throws IOException {
    RAMDirectory dir = new MockRAMDirectory();
    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new Analyzer() {

      @Override
      public TokenStream tokenStream(String fieldName, Reader reader) {
        return new TokenFilter(new MockTokenizer(reader, MockTokenizer.SIMPLE, true)) {
          private int count = 0;

          @Override
          public boolean incrementToken() throws IOException {
            if (count++ == 5) {
              throw new IOException();
            }
            return input.incrementToken();
          }
        };
      }

    });
    IndexWriter writer = new IndexWriter(dir, conf);

    Document doc = new Document();
    String contents = "aa bb cc dd ee ff gg hh ii jj kk";
    doc.add(new Field("content", contents, Field.Store.NO,
        Field.Index.ANALYZED));
    try {
      writer.addDocument(doc);
      fail("did not hit expected exception");
    } catch (Exception e) {
    }

    // Make sure we can add another normal document
    doc = new Document();
    doc.add(new Field("content", "aa bb cc dd", Field.Store.NO,
        Field.Index.ANALYZED));
    writer.addDocument(doc);

    // Make sure we can add another normal document
    doc = new Document();
    doc.add(new Field("content", "aa bb cc dd", Field.Store.NO,
        Field.Index.ANALYZED));
    writer.addDocument(doc);

    writer.close();
    IndexReader reader = IndexReader.open(dir, true);
    final Term t = new Term("content", "aa");
    assertEquals(reader.docFreq(t), 3);

    // Make sure the doc that hit the exception was marked
    // as deleted:
    TermDocs tdocs = reader.termDocs(t);
    int count = 0;
    while(tdocs.next()) {
      count++;
    }
    assertEquals(2, count);

    assertEquals(reader.docFreq(new Term("content", "gg")), 0);
    reader.close();
    dir.close();
  }
=======
public void testExceptionFromTokenStream() throws IOException {
    RAMDirectory dir = new MockRAMDirectory();
    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new Analyzer() {

      @Override
      public TokenStream tokenStream(String fieldName, Reader reader) {
        return new TokenFilter(new MockTokenizer(reader, MockTokenizer.SIMPLE, true)) {
          private int count = 0;

          @Override
          public boolean incrementToken() throws IOException {
            if (count++ == 5) {
              throw new IOException();
            }
            return input.incrementToken();
          }
        };
      }

    });
    IndexWriter writer = new IndexWriter(dir, conf);

    Document doc = new Document();
    String contents = "aa bb cc dd ee ff gg hh ii jj kk";
    doc.add(new Field("content", contents, Field.Store.NO,
        Field.Index.ANALYZED));
    try {
      writer.addDocument(doc);
      fail("did not hit expected exception");
    } catch (Exception e) {
    }

    // Make sure we can add another normal document
    doc = new Document();
    doc.add(new Field("content", "aa bb cc dd", Field.Store.NO,
        Field.Index.ANALYZED));
    writer.addDocument(doc);

    // Make sure we can add another normal document
    doc = new Document();
    doc.add(new Field("content", "aa bb cc dd", Field.Store.NO,
        Field.Index.ANALYZED));
    writer.addDocument(doc);

    writer.close();
    IndexReader reader = IndexReader.open(dir, true);
    final Term t = new Term("content", "aa");
    assertEquals(reader.docFreq(t), 3);

    // Make sure the doc that hit the exception was marked
    // as deleted:
    DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,
                                              MultiFields.getDeletedDocs(reader),
                                              t.field(),
                                              new BytesRef(t.text()));

    int count = 0;
    while(tdocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
      count++;
    }
    assertEquals(2, count);

    assertEquals(reader.docFreq(new Term("content", "gg")), 0);
    reader.close();
    dir.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953086/fstmerge_var2_5015744358820609045

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953100/fstmerge_var1_4546598660750655604
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953100/fstmerge_base_57158272056139118
@Override
    public void eval(MockRAMDirectory dir)  throws IOException {
      if (doFail) {
        StackTraceElement[] trace = new Exception().getStackTrace();
        boolean sawAppend = false;
        boolean sawFlush = false;
        for (int i = 0; i < trace.length; i++) {
          if ("org.apache.lucene.index.FreqProxTermsWriter".equals(trace[i].getClassName()) && "appendPostings".equals(trace[i].getMethodName()))
            sawAppend = true;
          if ("doFlush".equals(trace[i].getMethodName()))
            sawFlush = true;
        }

        if (sawAppend && sawFlush && count++ >= 30) {
          doFail = false;
          throw new IOException("now failing during flush");
        }
      }
    }
=======
@Override
    public void eval(MockRAMDirectory dir)  throws IOException {
      if (doFail) {
        StackTraceElement[] trace = new Exception().getStackTrace();
        boolean sawAppend = false;
        boolean sawFlush = false;
        for (int i = 0; i < trace.length; i++) {
          if ("org.apache.lucene.index.FreqProxTermsWriterPerField".equals(trace[i].getClassName()) && "flush".equals(trace[i].getMethodName()))
            sawAppend = true;
          if ("flushSegment".equals(trace[i].getMethodName()))
            sawFlush = true;
        }

        if (sawAppend && sawFlush && count++ >= 30) {
          doFail = false;
          throw new IOException("now failing during flush");
        }
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953100/fstmerge_var2_6622188431397292505

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953155/fstmerge_var1_1717064742372157238
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953155/fstmerge_base_7850605207984921305
public void testCloseWithThreads() throws Exception {
    int NUM_THREADS = 3;

    for(int iter=0;iter<7;iter++) {
      MockRAMDirectory dir = new MockRAMDirectory();
      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);
      // We expect AlreadyClosedException
      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();
      IndexWriter writer = new IndexWriter(dir, conf);
      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);

      IndexerThread[] threads = new IndexerThread[NUM_THREADS];

      for(int i=0;i<NUM_THREADS;i++)
        threads[i] = new IndexerThread(writer, false);

      for(int i=0;i<NUM_THREADS;i++)
        threads[i].start();

      boolean done = false;
      while(!done) {
        Thread.sleep(100);
        for(int i=0;i<NUM_THREADS;i++)
          // only stop when at least one thread has added a doc
          if (threads[i].addCount > 0) {
            done = true;
            break;
          }
      }

      writer.close(false);

      // Make sure threads that are adding docs are not hung:
      for(int i=0;i<NUM_THREADS;i++) {
        // Without fix for LUCENE-1130: one of the
        // threads will hang
        threads[i].join();
        if (threads[i].isAlive())
          fail("thread seems to be hung");
      }

      // Quick test to make sure index is not corrupt:
      IndexReader reader = IndexReader.open(dir, true);
      TermDocs tdocs = reader.termDocs(new Term("field", "aaa"));
      int count = 0;
      while(tdocs.next()) {
        count++;
      }
      assertTrue(count > 0);
      reader.close();
      
      dir.close();
    }
  }
=======
public void testCloseWithThreads() throws Exception {
    int NUM_THREADS = 3;

    for(int iter=0;iter<7;iter++) {
      MockRAMDirectory dir = new MockRAMDirectory();
      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);
      // We expect AlreadyClosedException
      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();
      IndexWriter writer = new IndexWriter(dir, conf);
      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);

      IndexerThread[] threads = new IndexerThread[NUM_THREADS];

      for(int i=0;i<NUM_THREADS;i++)
        threads[i] = new IndexerThread(writer, false);

      for(int i=0;i<NUM_THREADS;i++)
        threads[i].start();

      boolean done = false;
      while(!done) {
        Thread.sleep(100);
        for(int i=0;i<NUM_THREADS;i++)
          // only stop when at least one thread has added a doc
          if (threads[i].addCount > 0) {
            done = true;
            break;
          }
      }

      writer.close(false);

      // Make sure threads that are adding docs are not hung:
      for(int i=0;i<NUM_THREADS;i++) {
        // Without fix for LUCENE-1130: one of the
        // threads will hang
        threads[i].join();
        if (threads[i].isAlive())
          fail("thread seems to be hung");
      }

      // Quick test to make sure index is not corrupt:
      IndexReader reader = IndexReader.open(dir, true);
      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,
                                                  MultiFields.getDeletedDocs(reader),
                                                  "field",
                                                  new BytesRef("aaa"));
      int count = 0;
      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {
        count++;
      }
      assertTrue(count > 0);
      reader.close();
      
      dir.close();
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953155/fstmerge_var2_4956559272576269514

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953175/fstmerge_var1_1971204530334515791
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953175/fstmerge_base_6256165654644998707
@Override
    public void eval(MockRAMDirectory dir)  throws IOException {
      if (doFail) {
        StackTraceElement[] trace = new Exception().getStackTrace();
        for (int i = 0; i < trace.length; i++) {
          if ("abort".equals(trace[i].getMethodName()) ||
              "flushDocument".equals(trace[i].getMethodName())) {
            if (onlyOnce)
              doFail = false;
            //System.out.println(Thread.currentThread().getName() + ": now fail");
            //new Throwable().printStackTrace(System.out);
            throw new IOException("now failing on purpose");
          }
        }
      }
    }
=======
@Override
    public void eval(MockRAMDirectory dir)  throws IOException {
      if (doFail) {
        StackTraceElement[] trace = new Exception().getStackTrace();
        for (int i = 0; i < trace.length; i++) {
          if ("abort".equals(trace[i].getMethodName()) ||
              "finishDocument".equals(trace[i].getMethodName())) {
            if (onlyOnce)
              doFail = false;
            //System.out.println(Thread.currentThread().getName() + ": now fail");
            //new Throwable().printStackTrace(System.out);
            throw new IOException("now failing on purpose");
          }
        }
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953175/fstmerge_var2_8429774460399073294

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953183/fstmerge_var1_4940214941613997646
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953183/fstmerge_base_773189779615171289
public void _testMultipleThreadsFailure(MockRAMDirectory.Failure failure) throws Exception {

    int NUM_THREADS = 3;

    for(int iter=0;iter<2;iter++) {
      MockRAMDirectory dir = new MockRAMDirectory();
      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT,
          new MockAnalyzer()).setMaxBufferedDocs(2);
      // We expect disk full exceptions in the merge threads
      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();
      IndexWriter writer = new IndexWriter(dir, conf);
      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);

      IndexerThread[] threads = new IndexerThread[NUM_THREADS];

      for(int i=0;i<NUM_THREADS;i++)
        threads[i] = new IndexerThread(writer, true);

      for(int i=0;i<NUM_THREADS;i++)
        threads[i].start();

      Thread.sleep(10);

      dir.failOn(failure);
      failure.setDoFail();

      for(int i=0;i<NUM_THREADS;i++) {
        threads[i].join();
        assertTrue("hit unexpected Throwable", threads[i].error == null);
      }

      boolean success = false;
      try {
        writer.close(false);
        success = true;
      } catch (IOException ioe) {
        failure.clearDoFail();
        writer.close(false);
      }

      if (success) {
        IndexReader reader = IndexReader.open(dir, true);
        for(int j=0;j<reader.maxDoc();j++) {
          if (!reader.isDeleted(j)) {
            reader.document(j);
            reader.getTermFreqVectors(j);
          }
        }
        reader.close();
      }

      dir.close();
    }
  }
=======
public void _testMultipleThreadsFailure(MockRAMDirectory.Failure failure) throws Exception {

    int NUM_THREADS = 3;

    for(int iter=0;iter<2;iter++) {
      MockRAMDirectory dir = new MockRAMDirectory();
      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT,
          new MockAnalyzer()).setMaxBufferedDocs(2);
      // We expect disk full exceptions in the merge threads
      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();
      IndexWriter writer = new IndexWriter(dir, conf);
      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);

      IndexerThread[] threads = new IndexerThread[NUM_THREADS];

      for(int i=0;i<NUM_THREADS;i++)
        threads[i] = new IndexerThread(writer, true);

      for(int i=0;i<NUM_THREADS;i++)
        threads[i].start();

      Thread.sleep(10);

      dir.failOn(failure);
      failure.setDoFail();

      for(int i=0;i<NUM_THREADS;i++) {
        threads[i].join();
        assertTrue("hit unexpected Throwable ", threads[i].error == null);
      }

      boolean success = false;
      try {
        writer.close(false);
        success = true;
      } catch (IOException ioe) {
        failure.clearDoFail();
        writer.close(false);
      }

      if (success) {
        IndexReader reader = IndexReader.open(dir, true);
        for(int j=0;j<reader.maxDoc();j++) {
          if (!reader.isDeleted(j)) {
            reader.document(j);
            reader.getTermFreqVectors(j);
          }
        }
        reader.close();
      }

      dir.close();
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953183/fstmerge_var2_896061285868624849

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953210/fstmerge_var1_2214295940666469068
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953210/fstmerge_base_8524155922318716277
@Override
    public void eval(MockRAMDirectory dir)  throws IOException {
      if (doFail) {
        StackTraceElement[] trace = new Exception().getStackTrace();
        for (int i = 0; i < trace.length; i++) {
          if ("closeDocStore".equals(trace[i].getMethodName())) {
            if (onlyOnce)
              doFail = false;
            throw new IOException("now failing on purpose");
          }
        }
      }
    }
=======
@Override
    public void eval(MockRAMDirectory dir)  throws IOException {
      if (doFail) {
        StackTraceElement[] trace = new Exception().getStackTrace();
        for (int i = 0; i < trace.length; i++) {
          if ("finishDocument".equals(trace[i].getMethodName())
              && "org.apache.lucene.index.DocFieldProcessor".equals(trace[i].getClassName())) {
            if (onlyOnce)
              doFail = false;
            throw new IOException("now failing on purpose");
          }
        }
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953210/fstmerge_var2_5187229828335484207

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953313/fstmerge_var1_4894520553767144797
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953313/fstmerge_base_1829958573476762615
@Override
    boolean testPoint(String name) {
      if (doFail && name.equals("DocumentsWriter.ThreadState.init start"))
        throw new RuntimeException("intentionally failing");
      return true;
    }
=======
@Override
    boolean testPoint(String name) {
      if (doFail && name.equals("DocumentsWriterPerThread.init start"))
        throw new RuntimeException("intentionally failing");
      return true;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953313/fstmerge_var2_7274200177452711919

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953318/fstmerge_var1_5862014152006480866
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953318/fstmerge_base_6502199717634821881
public void testExceptionDocumentsWriterInit() throws IOException {
    MockRAMDirectory dir = new MockRAMDirectory();
    MockIndexWriter w = new MockIndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    doc.add(new Field("field", "a field", Field.Store.YES,
                      Field.Index.ANALYZED));
    w.addDocument(doc);
    w.doFail = true;
    try {
      w.addDocument(doc);
      fail("did not hit exception");
    } catch (RuntimeException re) {
      // expected
    }
    w.close();
    _TestUtil.checkIndex(dir);
    dir.close();
  }
=======
public void testExceptionDocumentsWriterInit() throws IOException {
    MockRAMDirectory dir = new MockRAMDirectory();
    MockIndexWriter w = new MockIndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    doc.add(new Field("field", "a field", Field.Store.YES,
                      Field.Index.ANALYZED));

    w.doFail = true;
    try {
      w.addDocument(doc);
      fail("did not hit exception");
    } catch (RuntimeException re) {
      // expected
    }
    w.close();
    _TestUtil.checkIndex(dir);
    dir.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953318/fstmerge_var2_6209738867049364141

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testNegativePositions() throws Throwable {
    final TokenStream tokens = new TokenStream() {
      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
      
      final Iterator<String> terms = Arrays.asList("a","b","c").iterator();
      boolean first = true;
      
      @Override
      public boolean incrementToken() {
        if (!terms.hasNext()) return false;
        clearAttributes();
        termAtt.append(terms.next());
        posIncrAtt.setPositionIncrement(first ? 0 : 1);
        first = false;
        return true;
      }
    };

    Directory dir = newDirectory();
    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    doc.add(new Field("field", tokens));
    w.addDocument(doc);
    w.commit();

    IndexSearcher s = new IndexSearcher(dir, false);
    PhraseQuery pq = new PhraseQuery();
    pq.add(new Term("field", "a"));
    pq.add(new Term("field", "b"));
    pq.add(new Term("field", "c"));
    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;
    assertEquals(1, hits.length);

    Query q = new SpanTermQuery(new Term("field", "a"));
    hits = s.search(q, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953409/fstmerge_var1_559554648600743109

    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),
                                                                MultiFields.getDeletedDocs(s.getIndexReader()),
                                                                "field",
                                                                new BytesRef("a"));

    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953409/fstmerge_base_7105523441645681428
    TermPositions tps = s.getIndexReader().termPositions(new Term("field", "a"));
    assertTrue(tps.next());
=======

    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),
                                                                MultiFields.getDeletedDocs(s.getIndexReader()),
                                                                "field",
                                                                new BytesRef("a"));

    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953409/fstmerge_var2_4337141293346626149
    assertEquals(1, tps.freq());
    assertEquals(0, tps.nextPosition());
    w.close();

    _TestUtil.checkIndex(dir);
    s.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testIndexStoreCombos() throws Exception {
    Directory dir = newDirectory();
    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
    byte[] b = new byte[50];
    for(int i=0;i<50;i++)
      b[i] = (byte) (i+77);

    Document doc = new Document();
    Field f = new Field("binary", b, 10, 17);
    f.setTokenStream(new MockTokenizer(new StringReader("doc1field1"), MockTokenizer.WHITESPACE, false));
    Field f2 = newField("string", "value", Field.Store.YES,Field.Index.ANALYZED);
    f2.setTokenStream(new MockTokenizer(new StringReader("doc1field2"), MockTokenizer.WHITESPACE, false));
    doc.add(f);
    doc.add(f2);
    w.addDocument(doc);
    
    // add 2 docs to test in-memory merging
    f.setTokenStream(new MockTokenizer(new StringReader("doc2field1"), MockTokenizer.WHITESPACE, false));
    f2.setTokenStream(new MockTokenizer(new StringReader("doc2field2"), MockTokenizer.WHITESPACE, false));
    w.addDocument(doc);
  
    // force segment flush so we can force a segment merge with doc3 later.
    w.commit();

    f.setTokenStream(new MockTokenizer(new StringReader("doc3field1"), MockTokenizer.WHITESPACE, false));
    f2.setTokenStream(new MockTokenizer(new StringReader("doc3field2"), MockTokenizer.WHITESPACE, false));

    w.addDocument(doc);
    w.commit();
    w.optimize();   // force segment merge.
    w.close();

    IndexReader ir = IndexReader.open(dir, true);
    doc = ir.document(0);
    f = doc.getField("binary");
    b = f.getBinaryValue();
    assertTrue(b != null);
    assertEquals(17, b.length, 17);
    assertEquals(87, b[0]);

    assertTrue(ir.document(0).getFieldable("binary").isBinary());
    assertTrue(ir.document(1).getFieldable("binary").isBinary());
    assertTrue(ir.document(2).getFieldable("binary").isBinary());
    
    assertEquals("value", ir.document(0).get("string"));
    assertEquals("value", ir.document(1).get("string"));
    assertEquals("value", ir.document(2).get("string"));


    // test that the terms were indexed.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953603/fstmerge_var1_5234314520600878796
    assertTrue(MultiFields.getTermDocsEnum(ir, null, "binary", new BytesRef("doc1field1")).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
    assertTrue(MultiFields.getTermDocsEnum(ir, null, "binary", new BytesRef("doc2field1")).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
    assertTrue(MultiFields.getTermDocsEnum(ir, null, "binary", new BytesRef("doc3field1")).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
    assertTrue(MultiFields.getTermDocsEnum(ir, null, "string", new BytesRef("doc1field2")).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
    assertTrue(MultiFields.getTermDocsEnum(ir, null, "string", new BytesRef("doc2field2")).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
    assertTrue(MultiFields.getTermDocsEnum(ir, null, "string", new BytesRef("doc3field2")).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953603/fstmerge_base_7837907848216739800
    assertTrue(ir.termDocs(new Term("binary","doc1field1")).next());
    assertTrue(ir.termDocs(new Term("binary","doc2field1")).next());
    assertTrue(ir.termDocs(new Term("binary","doc3field1")).next());
    assertTrue(ir.termDocs(new Term("string","doc1field2")).next());
    assertTrue(ir.termDocs(new Term("string","doc2field2")).next());
    assertTrue(ir.termDocs(new Term("string","doc3field2")).next());
=======
    assertTrue(MultiFields.getTermDocsEnum(ir, null, "binary", new BytesRef("doc1field1")).nextDoc() != DocsEnum.NO_MORE_DOCS);
    assertTrue(MultiFields.getTermDocsEnum(ir, null, "binary", new BytesRef("doc2field1")).nextDoc() != DocsEnum.NO_MORE_DOCS);
    assertTrue(MultiFields.getTermDocsEnum(ir, null, "binary", new BytesRef("doc3field1")).nextDoc() != DocsEnum.NO_MORE_DOCS);
    assertTrue(MultiFields.getTermDocsEnum(ir, null, "string", new BytesRef("doc1field2")).nextDoc() != DocsEnum.NO_MORE_DOCS);
    assertTrue(MultiFields.getTermDocsEnum(ir, null, "string", new BytesRef("doc2field2")).nextDoc() != DocsEnum.NO_MORE_DOCS);
    assertTrue(MultiFields.getTermDocsEnum(ir, null, "string", new BytesRef("doc3field2")).nextDoc() != DocsEnum.NO_MORE_DOCS);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953603/fstmerge_var2_7279349469513941170

    ir.close();
    dir.close();

  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testTermUTF16SortOrder() throws Throwable {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953643/fstmerge_var1_6148636020969257636
    Random rnd = random;
    Directory dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rnd, dir);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953643/fstmerge_base_3168603295753921488
    Directory dir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new MockAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);
=======
    Random rnd = newRandom();
    Directory dir = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rnd, dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953643/fstmerge_var2_850452091569601778
    Document d = new Document();
    // Single segment
    Field f = newField("f", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
    d.add(f);
    char[] chars = new char[2];
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953643/fstmerge_base_3168603295753921488
    Random rnd = newRandom();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953643/fstmerge_var2_850452091569601778
    final Set<String> allTerms = new HashSet<String>();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953643/fstmerge_base_3168603295753921488
    for(int i=0;i<200*_TestUtil.getRandomMultiplier();i++) {
=======
    int num = 200 * RANDOM_MULTIPLIER;
    for (int i = 0; i < num; i++) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953643/fstmerge_var2_850452091569601778

      final String s;
      if (rnd.nextBoolean()) {
        // Single char
        if (rnd.nextBoolean()) {
          // Above surrogates
          chars[0] = (char) getInt(rnd, 1+UnicodeUtil.UNI_SUR_LOW_END, 0xffff);
        } else {
          // Below surrogates
          chars[0] = (char) getInt(rnd, 0, UnicodeUtil.UNI_SUR_HIGH_START-1);
        }
        s = new String(chars, 0, 1);
      } else {
        // Surrogate pair
        chars[0] = (char) getInt(rnd, UnicodeUtil.UNI_SUR_HIGH_START, UnicodeUtil.UNI_SUR_HIGH_END);
        assertTrue(((int) chars[0]) >= UnicodeUtil.UNI_SUR_HIGH_START && ((int) chars[0]) <= UnicodeUtil.UNI_SUR_HIGH_END);
        chars[1] = (char) getInt(rnd, UnicodeUtil.UNI_SUR_LOW_START, UnicodeUtil.UNI_SUR_LOW_END);
        s = new String(chars, 0, 2);
      }
      allTerms.add(s);
      f.setValue(s);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953643/fstmerge_base_3168603295753921488
      //System.out.println("add " + termDesc(s));
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953643/fstmerge_var2_850452091569601778
      writer.addDocument(d);

      if ((1+i) % 42 == 0) {
        writer.commit();
      }
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953643/fstmerge_base_3168603295753921488
    
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953643/fstmerge_var2_850452091569601778
    IndexReader r = writer.getReader();

    // Test each sub-segment
    final IndexReader[] subs = r.getSequentialSubReaders();
    for(int i=0;i<subs.length;i++) {
      checkTermsOrder(subs[i], allTerms, false);
    }
    checkTermsOrder(r, allTerms, true);

    // Test multi segment
    r.close();

    writer.optimize();

    // Test optimized single segment
    r = writer.getReader();
    checkTermsOrder(r, allTerms, true);
    r.close();

    writer.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testEmptyDirRollback() throws Exception {
    // Tests that if IW is created over an empty Directory, some documents are
    // indexed, flushed (but not committed) and then IW rolls back, then no 
    // files are left in the Directory.
    Directory dir = newDirectory();
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer())
        .setMaxBufferedDocs(2));
    String[] files = dir.listAll();

    // Creating over empty dir should not create any files,
    // or, at most the write.lock file
    final int extraFileCount;
    if (files.length == 1) {
      assertEquals("write.lock", files[0]);
      extraFileCount = 1;
    } else {
      assertEquals(0, files.length);
      extraFileCount = 0;
    }

    Document doc = new Document();
    // create as many files as possible
    doc.add(newField("c", "val", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);
    // Adding just one document does not call flush yet.
    assertEquals("only the stored and term vector files should exist in the directory", 5 + extraFileCount, dir.listAll().length);
    
    doc = new Document();
    doc.add(newField("c", "val", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);
    // The second document should cause a flush.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953679/fstmerge_var1_5738038157907637318
    assertTrue("flush should have occurred and files created", dir.listAll().length > 5 + extraFileCount);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953679/fstmerge_base_5874442738406115545
    assertTrue("flush should have occurred and files created", dir.listAll().length > 5);
=======
    assertTrue("flush should have occurred and files created", dir.listAll().length > 0);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953679/fstmerge_var2_7176705693483358379
   
    // After rollback, IW should remove all files
    writer.rollback();
    assertEquals("no files should exist in the directory after rollback", 0, dir.listAll().length);

    // Since we rolled-back above, that close should be a no-op
    writer.close();
    assertEquals("expected a no-op close after IW.rollback()", 0, dir.listAll().length);
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953684/fstmerge_var1_4269896498475592430
public void testNoSegmentFile() throws IOException {
    Directory dir = newDirectory();
    dir.setLockFactory(NoLockFactory.getNoLockFactory());
    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
    
    Document doc = new Document();
    doc.add(newField("c", "val", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
    w.addDocument(doc);
    w.addDocument(doc);
    IndexWriter w2 = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2)
        .setOpenMode(OpenMode.CREATE));
    
    w2.close();
    // If we don't do that, the test fails on Windows
    w.rollback();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953684/fstmerge_base_7559179084727161662
=======
public void testNoSegmentFile() throws IOException {
    File tempDir = _TestUtil.getTempDir("noSegmentFile");
    try {
      Directory dir = FSDirectory.open(tempDir);
      dir.setLockFactory(NoLockFactory.getNoLockFactory());
      IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(
          TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));

      Document doc = new Document();
      doc.add(new Field("c", "val", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
      w.addDocument(doc);
      w.addDocument(doc);
      IndexWriter w2 = new IndexWriter(dir, new IndexWriterConfig(
          TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2)
          .setOpenMode(OpenMode.CREATE));

      w2.close();
      // If we don't do that, the test fails on Windows
      w.rollback();
      dir.close();
    } finally {
      _TestUtil.rmDir(tempDir);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953684/fstmerge_var2_4833951530252553629

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953688/fstmerge_var1_5933246689851206611
public void testFutureCommit() throws Exception {
    Directory dir = newDirectory();

    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE));
    Document doc = new Document();
    w.addDocument(doc);

    // commit to "first"
    Map<String,String> commitData = new HashMap<String,String>();
    commitData.put("tag", "first");
    w.commit(commitData);

    // commit to "second"
    w.addDocument(doc);
    commitData.put("tag", "second");
    w.commit(commitData);
    w.close();

    // open "first" with IndexWriter
    IndexCommit commit = null;
    for(IndexCommit c : IndexReader.listCommits(dir)) {
      if (c.getUserData().get("tag").equals("first")) {
        commit = c;
        break;
      }
    }

    assertNotNull(commit);

    w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE).setIndexCommit(commit));

    assertEquals(1, w.numDocs());
    
    // commit IndexWriter to "third"
    w.addDocument(doc);
    commitData.put("tag", "third");
    w.commit(commitData);
    w.close();

    // make sure "second" commit is still there
    commit = null;
    for(IndexCommit c : IndexReader.listCommits(dir)) {
      if (c.getUserData().get("tag").equals("second")) {
        commit = c;
        break;
      }
    }

    assertNotNull(commit);

    IndexReader r = IndexReader.open(commit, true);
    assertEquals(2, r.numDocs());
    r.close();

    // open "second", w/ writeable IndexReader & commit
    r = IndexReader.open(commit, NoDeletionPolicy.INSTANCE, false);
    assertEquals(2, r.numDocs());
    r.deleteDocument(0);
    r.deleteDocument(1);
    commitData.put("tag", "fourth");
    r.commit(commitData);
    r.close();

    // make sure "third" commit is still there
    commit = null;
    for(IndexCommit c : IndexReader.listCommits(dir)) {
      if (c.getUserData().get("tag").equals("third")) {
        commit = c;
        break;
      }
    }
    assertNotNull(commit);

    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953688/fstmerge_base_3115682589575235826
=======
public void testFutureCommit() throws Exception {
    Directory dir = new MockRAMDirectory();

    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE));
    Document doc = new Document();
    w.addDocument(doc);

    // commit to "first"
    Map<String,String> commitData = new HashMap<String,String>();
    commitData.put("tag", "first");
    w.commit(commitData);

    // commit to "second"
    w.addDocument(doc);
    commitData.put("tag", "second");
    w.commit(commitData);
    w.close();

    // open "first" with IndexWriter
    IndexCommit commit = null;
    for(IndexCommit c : IndexReader.listCommits(dir)) {
      if (c.getUserData().get("tag").equals("first")) {
        commit = c;
        break;
      }
    }

    assertNotNull(commit);

    w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE).setIndexCommit(commit));

    assertEquals(1, w.numDocs());
    
    // commit IndexWriter to "third"
    w.addDocument(doc);
    commitData.put("tag", "third");
    w.commit(commitData);
    w.close();

    // make sure "second" commit is still there
    commit = null;
    for(IndexCommit c : IndexReader.listCommits(dir)) {
      if (c.getUserData().get("tag").equals("second")) {
        commit = c;
        break;
      }
    }

    assertNotNull(commit);

    IndexReader r = IndexReader.open(commit, true);
    assertEquals(2, r.numDocs());
    r.close();

    // open "second", w/ writeable IndexReader & commit
    r = IndexReader.open(commit, NoDeletionPolicy.INSTANCE, false);
    assertEquals(2, r.numDocs());
    r.deleteDocument(0);
    r.deleteDocument(1);
    commitData.put("tag", "fourth");
    r.commit(commitData);
    r.close();

    // make sure "third" commit is still there
    commit = null;
    for(IndexCommit c : IndexReader.listCommits(dir)) {
      if (c.getUserData().get("tag").equals("third")) {
        commit = c;
        break;
      }
    }
    assertNotNull(commit);

    dir.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953688/fstmerge_var2_3402082093188230358

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953693/fstmerge_var1_7945387998966472324
public void testIndexingThenDeleting() throws Exception {
    final Random r = random;

    Directory dir = newDirectory();
    FlushCountingIndexWriter w = new FlushCountingIndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, true, false)).setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMaxBufferedDeleteTerms(-1));
    w.setInfoStream(VERBOSE ? System.out : null);
    Document doc = new Document();
    doc.add(newField("field", "go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20", Field.Store.NO, Field.Index.ANALYZED));
    int num = 6 * RANDOM_MULTIPLIER;
    for (int iter = 0; iter < num; iter++) {
      int count = 0;

      final boolean doIndexing = r.nextBoolean();
      if (VERBOSE) {
        System.out.println("TEST: iter doIndexing=" + doIndexing);
      }
      if (doIndexing) {
        // Add docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.addDocument(doc);
          count++;
        }
      } else {
        // Delete docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.deleteDocuments(new Term("foo", ""+count));
          count++;
        }
      }
      assertTrue("flush happened too quickly during " + (doIndexing ? "indexing" : "deleting") + " count=" + count, count > 2500);
    }
    w.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953693/fstmerge_base_6910506233151913461
public void testIndexingThenDeleting() throws Exception {
    final Random r = newRandom();

    Directory dir = new MockRAMDirectory();
    FlushCountingIndexWriter w = new FlushCountingIndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));
    //w.setInfoStream(System.out);
    Document doc = new Document();
    doc.add(new Field("field", "go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20", Field.Store.NO, Field.Index.ANALYZED));
    for(int iter=0;iter<6*_TestUtil.getRandomMultiplier();iter++) {
      int count = 0;

      final boolean doIndexing = r.nextBoolean();
      if (doIndexing) {
        // Add docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.addDocument(doc);
          count++;
        }
      } else {
        // Delete docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.deleteDocuments(new Term("foo", ""+count));
          count++;
        }
      }
      assertTrue("flush happened too quickly during " + (doIndexing ? "indexing" : "deleting") + " count=" + count, count > 2500);
    }
    w.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953693/fstmerge_var2_5916907248695525665

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testPayloadFieldBit() throws Exception {
        Directory ram = newDirectory();
        PayloadAnalyzer analyzer = new PayloadAnalyzer();
        IndexWriter writer = new IndexWriter(ram, newIndexWriterConfig( TEST_VERSION_CURRENT, analyzer));
        Document d = new Document();
        // this field won't have any payloads
        d.add(newField("f1", "This field has no payloads", Field.Store.NO, Field.Index.ANALYZED));
        // this field will have payloads in all docs, however not for all term positions,
        // so this field is used to check if the DocumentWriter correctly enables the payloads bit
        // even if only some term positions have payloads
        d.add(newField("f2", "This field has payloads in all docs", Field.Store.NO, Field.Index.ANALYZED));
        d.add(newField("f2", "This field has payloads in all docs", Field.Store.NO, Field.Index.ANALYZED));
        // this field is used to verify if the SegmentMerger enables payloads for a field if it has payloads 
        // enabled in only some documents
        d.add(newField("f3", "This field has payloads in some docs", Field.Store.NO, Field.Index.ANALYZED));
        // only add payload data for field f2
        analyzer.setPayloadData("f2", 1, "somedata".getBytes(), 0, 1);
        writer.addDocument(d);
        // flush
        writer.close();

      SegmentReader reader = getOnlySegmentReader(IndexReader.open(ram, false));
        FieldInfos fi = reader.fieldInfos();
        assertFalse("Payload field bit should not be set.", fi.fieldInfo("f1").storePayloads);
        assertTrue("Payload field bit should be set.", fi.fieldInfo("f2").storePayloads);
        assertFalse("Payload field bit should not be set.", fi.fieldInfo("f3").storePayloads);
        reader.close();
        
        // now we add another document which has payloads for field f3 and verify if the SegmentMerger
        // enabled payloads for that field
        writer = new IndexWriter(ram, newIndexWriterConfig( TEST_VERSION_CURRENT,
            analyzer).setOpenMode(OpenMode.CREATE));
        d = new Document();
        d.add(newField("f1", "This field has no payloads", Field.Store.NO, Field.Index.ANALYZED));
        d.add(newField("f2", "This field has payloads in all docs", Field.Store.NO, Field.Index.ANALYZED));
        d.add(newField("f2", "This field has payloads in all docs", Field.Store.NO, Field.Index.ANALYZED));
        d.add(newField("f3", "This field has payloads in some docs", Field.Store.NO, Field.Index.ANALYZED));
        // add payload data for field f2 and f3
        analyzer.setPayloadData("f2", "somedata".getBytes(), 0, 1);
        analyzer.setPayloadData("f3", "somedata".getBytes(), 0, 3);
        writer.addDocument(d);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953703/fstmerge_base_5125254998944200365
        FlexTestUtil.verifyFlexVsPreFlex(rnd, writer);

=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953703/fstmerge_var2_5658291975833945114
        // force merge
        writer.optimize();
        // flush
        writer.close();

      reader = getOnlySegmentReader(IndexReader.open(ram, false));
        fi = reader.fieldInfos();
        assertFalse("Payload field bit should not be set.", fi.fieldInfo("f1").storePayloads);
        assertTrue("Payload field bit should be set.", fi.fieldInfo("f2").storePayloads);
        assertTrue("Payload field bit should be set.", fi.fieldInfo("f3").storePayloads);
        reader.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953703/fstmerge_var1_4666995839051396380
        ram.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953703/fstmerge_base_5125254998944200365
        FlexTestUtil.verifyFlexVsPreFlex(rnd, ram);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953703/fstmerge_var2_5658291975833945114
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestPayloads.java
Conflict type: LineBasedMCFd
Conflict body: 
private void performTest(Directory dir) throws Exception {
        PayloadAnalyzer analyzer = new PayloadAnalyzer();
        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
            TEST_VERSION_CURRENT, analyzer)
            .setOpenMode(OpenMode.CREATE));
        
        // should be in sync with value in TermInfosWriter
        final int skipInterval = 16;
        
        final int numTerms = 5;
        final String fieldName = "f1";
        
        int numDocs = skipInterval + 1; 
        // create content for the test documents with just a few terms
        Term[] terms = generateTerms(fieldName, numTerms);
        StringBuilder sb = new StringBuilder();
        for (int i = 0; i < terms.length; i++) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
            sb.append(terms[i].text);
=======
            sb.append(terms[i].text());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
            sb.append(" ");
        }
        String content = sb.toString();
        
        
        int payloadDataLength = numTerms * numDocs * 2 + numTerms * numDocs * (numDocs - 1) / 2;
        byte[] payloadData = generateRandomData(payloadDataLength);
        
        Document d = new Document();
        d.add(newField(fieldName, content, Field.Store.NO, Field.Index.ANALYZED));
        // add the same document multiple times to have the same payload lengths for all
        // occurrences within two consecutive skip intervals
        int offset = 0;
        for (int i = 0; i < 2 * numDocs; i++) {
            analyzer.setPayloadData(fieldName, payloadData, offset, 1);
            offset += numTerms;
            writer.addDocument(d);
        }
        
        // make sure we create more than one segment to test merging
        writer.commit();
        
        // now we make sure to have different payload lengths next at the next skip point        
        for (int i = 0; i < numDocs; i++) {
            analyzer.setPayloadData(fieldName, payloadData, offset, i);
            offset += i * numTerms;
            writer.addDocument(d);
        }
        
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        FlexTestUtil.verifyFlexVsPreFlex(rnd, writer);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        writer.optimize();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        FlexTestUtil.verifyFlexVsPreFlex(rnd, writer);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        // flush
        writer.close();
        
        
        /*
         * Verify the index
         * first we test if all payloads are stored correctly
         */        
        IndexReader reader = IndexReader.open(dir, true);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        byte[] verifyPayloadData = new byte[payloadDataLength];
        offset = 0;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        TermPositions[] tps = new TermPositions[numTerms];
=======
        DocsAndPositionsEnum[] tps = new DocsAndPositionsEnum[numTerms];
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        for (int i = 0; i < numTerms; i++) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
            tps[i] = reader.termPositions(terms[i]);
=======
          tps[i] = MultiFields.getTermPositionsEnum(reader,
                                                    MultiFields.getDeletedDocs(reader),
                                                    terms[i].field(),
                                                    new BytesRef(terms[i].text()));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        }
        
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var1_537438588169066867
        while (tps[0].nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        while (tps[0].next()) {
=======
        while (tps[0].nextDoc() != DocsEnum.NO_MORE_DOCS) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
            for (int i = 1; i < numTerms; i++) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
                tps[i].next();
=======
                tps[i].nextDoc();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
            }
            int freq = tps[0].freq();

            for (int i = 0; i < freq; i++) {
                for (int j = 0; j < numTerms; j++) {
                    tps[j].nextPosition();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var1_537438588169066867
                    if (tps[j].hasPayload()) {
                      BytesRef br = tps[j].getPayload();
                      System.arraycopy(br.bytes, br.offset, verifyPayloadData, offset, br.length);
                      offset += br.length;
                    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
                    tps[j].getPayload(verifyPayloadData, offset);
                    offset += tps[j].getPayloadLength();
=======
                    BytesRef br = tps[j].getPayload();
                    System.arraycopy(br.bytes, br.offset, verifyPayloadData, offset, br.length);
                    offset += br.length;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
                }
            }
        }
        
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        for (int i = 0; i < numTerms; i++) {
            tps[i].close();
        }
        
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        assertByteArrayEquals(payloadData, verifyPayloadData);
        
        /*
         *  test lazy skipping
         */        
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        TermPositions tp = reader.termPositions(terms[0]);
        tp.next();
=======
        DocsAndPositionsEnum tp = MultiFields.getTermPositionsEnum(reader,
                                                                   MultiFields.getDeletedDocs(reader),
                                                                   terms[0].field(),
                                                                   new BytesRef(terms[0].text()));
        tp.nextDoc();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        tp.nextPosition();
        // NOTE: prior rev of this test was failing to first
        // call next here:
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        tp.next();
=======
        tp.nextDoc();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        // now we don't read this payload
        tp.nextPosition();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        assertEquals("Wrong payload length.", 1, tp.getPayloadLength());
        byte[] payload = tp.getPayload(null, 0);
        assertEquals(payload[0], payloadData[numTerms]);
        // NOTE: prior rev of this test was failing to first
        // call next here:
        tp.next();
=======
        BytesRef payload = tp.getPayload();
        assertEquals("Wrong payload length.", 1, payload.length);
        assertEquals(payload.bytes[payload.offset], payloadData[numTerms]);
        tp.nextDoc();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        tp.nextPosition();
        
        // we don't read this payload and skip to a different document
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        tp.skipTo(5);
=======
        tp.advance(5);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        tp.nextPosition();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        assertEquals("Wrong payload length.", 1, tp.getPayloadLength());
        payload = tp.getPayload(null, 0);
        assertEquals(payload[0], payloadData[5 * numTerms]);
=======
        payload = tp.getPayload();
        assertEquals("Wrong payload length.", 1, payload.length);
        assertEquals(payload.bytes[payload.offset], payloadData[5 * numTerms]);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
                
        
        /*
         * Test different lengths at skip points
         */
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        tp.seek(terms[1]);
        tp.next();
        tp.nextPosition();
        assertEquals("Wrong payload length.", 1, tp.getPayloadLength());
        tp.skipTo(skipInterval - 1);
=======
        tp = MultiFields.getTermPositionsEnum(reader,
                                              MultiFields.getDeletedDocs(reader),
                                              terms[1].field(),
                                              new BytesRef(terms[1].text()));
        tp.nextDoc();
        tp.nextPosition();
        assertEquals("Wrong payload length.", 1, tp.getPayload().length);
        tp.advance(skipInterval - 1);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        tp.nextPosition();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        assertEquals("Wrong payload length.", 1, tp.getPayloadLength());
        tp.skipTo(2 * skipInterval - 1);
=======
        assertEquals("Wrong payload length.", 1, tp.getPayload().length);
        tp.advance(2 * skipInterval - 1);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        tp.nextPosition();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        assertEquals("Wrong payload length.", 1, tp.getPayloadLength());
        tp.skipTo(3 * skipInterval - 1);
=======
        assertEquals("Wrong payload length.", 1, tp.getPayload().length);
        tp.advance(3 * skipInterval - 1);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        tp.nextPosition();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        assertEquals("Wrong payload length.", 3 * skipInterval - 2 * numDocs - 1, tp.getPayloadLength());
=======
        assertEquals("Wrong payload length.", 3 * skipInterval - 2 * numDocs - 1, tp.getPayload().length);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        
        /*
         * Test multiple call of getPayload()
         */
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        tp.getPayload(null, 0);
=======
        assertFalse(tp.hasPayload());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        
        reader.close();
        
        // test long payload
        analyzer = new PayloadAnalyzer();
        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT,
            analyzer).setOpenMode(OpenMode.CREATE));
        String singleTerm = "lucene";
        
        d = new Document();
        d.add(newField(fieldName, singleTerm, Field.Store.NO, Field.Index.ANALYZED));
        // add a payload whose length is greater than the buffer size of BufferedIndexOutput
        payloadData = generateRandomData(2000);
        analyzer.setPayloadData(fieldName, payloadData, 100, 1500);
        writer.addDocument(d);

        
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        FlexTestUtil.verifyFlexVsPreFlex(rnd, writer);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        writer.optimize();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        FlexTestUtil.verifyFlexVsPreFlex(rnd, writer);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        // flush
        writer.close();
        
        reader = IndexReader.open(dir, true);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        tp = reader.termPositions(new Term(fieldName, singleTerm));
        tp.next();
=======
        tp = MultiFields.getTermPositionsEnum(reader,
                                              MultiFields.getDeletedDocs(reader),
                                              fieldName,
                                              new BytesRef(singleTerm));
        tp.nextDoc();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        tp.nextPosition();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540

        verifyPayloadData = new byte[tp.getPayloadLength()];
        tp.getPayload(verifyPayloadData, 0);
=======
        
        BytesRef br = tp.getPayload();
        verifyPayloadData = new byte[br.length];
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        byte[] portion = new byte[1500];
        System.arraycopy(payloadData, 100, portion, 0, 1500);
        
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_base_2927820508880977540
        assertByteArrayEquals(portion, verifyPayloadData);
=======
        assertByteArrayEquals(portion, br.bytes, br.offset, br.length);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953712/fstmerge_var2_5769394094783848413
        reader.close();
        
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestPayloads.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testThreadSafety() throws Exception {
        final int numThreads = 5;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953773/fstmerge_base_5672329993292782941
        final int numDocs = 50* _TestUtil.getRandomMultiplier();
=======
        final int numDocs = 50 * RANDOM_MULTIPLIER;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953773/fstmerge_var2_51311333636342509
        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);
        
        Directory dir = newDirectory();
        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
            TEST_VERSION_CURRENT, new MockAnalyzer()));
        final String field = "test";
        
        Thread[] ingesters = new Thread[numThreads];
        for (int i = 0; i < numThreads; i++) {
            ingesters[i] = new Thread() {
                @Override
                public void run() {
                    try {
                        for (int j = 0; j < numDocs; j++) {
                            Document d = new Document();
                            d.add(new Field(field, new PoolingPayloadTokenStream(pool)));
                            writer.addDocument(d);
                        }
                    } catch (Exception e) {
                        e.printStackTrace();
                        fail(e.toString());
                    }
                }
            };
            ingesters[i].start();
        }
        
        for (int i = 0; i < numThreads; i++) {
          ingesters[i].join();
        }
        writer.close();
        IndexReader reader = IndexReader.open(dir, true);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953773/fstmerge_var1_3182837147425097826
        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator();
        Bits delDocs = MultiFields.getDeletedDocs(reader);
        DocsAndPositionsEnum tp = null;
        while (terms.next() != null) {
          String termText = terms.term().utf8ToString();
          tp = terms.docsAndPositions(delDocs, tp);
          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
            int freq = tp.freq();
            for (int i = 0; i < freq; i++) {
              tp.nextPosition();
              final BytesRef payload = tp.getPayload();
              assertEquals(termText, pool.bytesToString(payload.bytes, payload.offset, payload.length));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953773/fstmerge_base_5672329993292782941
        TermEnum terms = reader.terms();
        while (terms.next()) {
            TermPositions tp = reader.termPositions(terms.term());
            while(tp.next()) {
                int freq = tp.freq();
                for (int i = 0; i < freq; i++) {
                    tp.nextPosition();
                    assertEquals(pool.bytesToString(tp.getPayload(new byte[5], 0)), terms.term().text);
                }
=======
        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator();
        Bits delDocs = MultiFields.getDeletedDocs(reader);
        DocsAndPositionsEnum tp = null;
        while (terms.next() != null) {
          String termText = terms.term().utf8ToString();
          tp = terms.docsAndPositions(delDocs, tp);
          while(tp.nextDoc() != DocsEnum.NO_MORE_DOCS) {
            int freq = tp.freq();
            for (int i = 0; i < freq; i++) {
              tp.nextPosition();
              final BytesRef payload = tp.getPayload();
              assertEquals(termText, pool.bytesToString(payload.bytes, payload.offset, payload.length));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953773/fstmerge_var2_51311333636342509
            }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953773/fstmerge_base_5672329993292782941
            tp.close();
=======
          }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953773/fstmerge_var2_51311333636342509
        }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953773/fstmerge_base_5672329993292782941
        terms.close();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953773/fstmerge_var2_51311333636342509
        reader.close();
        dir.close();
        assertEquals(pool.size(), numThreads);
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestPayloads.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
    /*
    for (int i = 0; i < testFields.length; i++) {
      fieldInfos.add(testFields[i], true, true, testFieldsStorePos[i], testFieldsStoreOff[i]);
    }
    */

    Arrays.sort(testTerms);
    int tokenUpto = 0;
    for (int i = 0; i < testTerms.length; i++) {
      positions[i] = new int[TERM_FREQ];
      offsets[i] = new TermVectorOffsetInfo[TERM_FREQ];
      // first position must be 0
      for (int j = 0; j < TERM_FREQ; j++) {
        // positions are always sorted in increasing order
        positions[i][j] = (int) (j * 10 + Math.random() * 10);
        // offsets are always sorted in increasing order
        offsets[i][j] = new TermVectorOffsetInfo(j * 10, j * 10 + testTerms[i].length());
        TestToken token = tokens[tokenUpto++] = new TestToken();
        token.text = testTerms[i];
        token.pos = positions[i][j];
        token.startOffset = offsets[i][j].getStartOffset();
        token.endOffset = offsets[i][j].getEndOffset();
      }
    }
    Arrays.sort(tokens);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953824/fstmerge_var1_7650841387500120590
    dir = newDirectory();
    IndexWriter writer = new IndexWriter(
        dir,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MyAnalyzer()).
            setMaxBufferedDocs(-1).
            setMergePolicy(newLogMergePolicy(false, 10))
    );

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953824/fstmerge_base_7307414488393361321
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MyAnalyzer()));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
=======
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MyAnalyzer()));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953824/fstmerge_var2_373514307411576636
    Document doc = new Document();
    for(int i=0;i<testFields.length;i++) {
      final Field.TermVector tv;
      if (testFieldsStorePos[i] && testFieldsStoreOff[i])
        tv = Field.TermVector.WITH_POSITIONS_OFFSETS;
      else if (testFieldsStorePos[i] && !testFieldsStoreOff[i])
        tv = Field.TermVector.WITH_POSITIONS;
      else if (!testFieldsStorePos[i] && testFieldsStoreOff[i])
        tv = Field.TermVector.WITH_OFFSETS;
      else
        tv = Field.TermVector.YES;
      doc.add(new Field(testFields[i], "", Field.Store.NO, Field.Index.ANALYZED, tv));
    }

    //Create 5 documents for testing, they all have the same
    //terms
    for(int j=0;j<5;j++)
      writer.addDocument(doc);
    writer.commit();
    seg = writer.newestSegment().name;
    writer.close();

    fieldInfos = new FieldInfos(dir, IndexFileNames.segmentFileName(seg, "", IndexFileNames.FIELD_INFOS_EXTENSION));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestTermVectorsReader.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testSimpleSkip() throws IOException {
    Directory dir = new CountingRAMDirectory(new RAMDirectory());
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new PayloadAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
    Term term = new Term("test", "a");
    for (int i = 0; i < 5000; i++) {
      Document d1 = new Document();
      d1.add(newField(term.field(), term.text(), Store.NO, Index.ANALYZED));
      writer.addDocument(d1);
    }
    writer.commit();
    writer.optimize();
    writer.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953988/fstmerge_var1_9164773717376755295
    IndexReader reader = getOnlySegmentReader(IndexReader.open(dir));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953988/fstmerge_base_9162716890590809912
    IndexReader reader = SegmentReader.getOnlySegmentReader(dir);
    TermPositions tp = reader.termPositions();
=======
    IndexReader reader = SegmentReader.getOnlySegmentReader(dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953988/fstmerge_var2_2817679870965098646
    
    for (int i = 0; i < 2; i++) {
      counter = 0;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953988/fstmerge_base_9162716890590809912
      tp.seek(term);
=======
      DocsAndPositionsEnum tp = reader.termPositionsEnum(reader.getDeletedDocs(),
                                                         term.field(),
                                                         new BytesRef(term.text()));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953988/fstmerge_var2_2817679870965098646

      checkSkipTo(tp, 14, 185); // no skips
      checkSkipTo(tp, 17, 190); // one skip on level 0
      checkSkipTo(tp, 287, 200); // one skip on level 1, two on level 0
    
      // this test would fail if we had only one skip level,
      // because than more bytes would be read from the freqStream
      checkSkipTo(tp, 4800, 250);// one skip on level 2
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953994/fstmerge_var1_8773391893489504552
public void checkSkipTo(DocsAndPositionsEnum tp, int target, int maxCounter) throws IOException {
    tp.advance(target);
    if (maxCounter < counter) {
      fail("Too many bytes read: " + counter + " vs " + maxCounter);
    }

    assertEquals("Wrong document " + tp.docID() + " after skipTo target " + target, target, tp.docID());
    assertEquals("Frequency is not 1: " + tp.freq(), 1,tp.freq());
    tp.nextPosition();
    BytesRef b = tp.getPayload();
    assertEquals(1, b.length);
    assertEquals("Wrong payload for the target " + target + ": " + b.bytes[b.offset], (byte) target, b.bytes[b.offset]);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953994/fstmerge_base_6819636614758042486
=======
public void checkSkipTo(DocsAndPositionsEnum tp, int target, int maxCounter) throws IOException {
    tp.advance(target);
    if (maxCounter < counter) {
      fail("Too many bytes read: " + counter);
    }

    assertEquals("Wrong document " + tp.docID() + " after skipTo target " + target, target, tp.docID());
    assertEquals("Frequency is not 1: " + tp.freq(), 1,tp.freq());
    tp.nextPosition();
    BytesRef b = tp.getPayload();
    assertEquals(1, b.length);
    assertEquals("Wrong payload for the target " + target + ": " + b.bytes[b.offset], (byte) target, b.bytes[b.offset]);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627953994/fstmerge_var2_2441429752944790909

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testTermOrd() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954098/fstmerge_var1_6206042284713748719
    Directory d = newDirectory();
    IndexWriter w = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
                                                             new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954098/fstmerge_base_4132933879811452126
    Directory d = new MockRAMDirectory();
    IndexWriter w = new IndexWriter(d, new MockAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);
=======
    Directory d = new MockRAMDirectory();
    IndexWriter w = new IndexWriter(d, new IndexWriterConfig(TEST_VERSION_CURRENT,
                                                             new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954098/fstmerge_var2_3892859061565996074
    Document doc = new Document();
    doc.add(newField("f", "a b c", Field.Store.NO, Field.Index.ANALYZED));
    w.addDocument(doc);
    IndexReader r = w.getReader();
    TermsEnum terms = r.getSequentialSubReaders()[0].fields().terms("f").iterator();
    assertTrue(terms.next() != null);
    assertEquals(0, terms.ord());
    r.close();
    w.close();
    d.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestFlex.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testFilterIndexReader() throws Exception {
    Directory directory = newDirectory();
    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));

    Document d1 = new Document();
    d1.add(newField("default","one two", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(d1);

    Document d2 = new Document();
    d2.add(newField("default","one three", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(d2);

    Document d3 = new Document();
    d3.add(newField("default","two four", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(d3);

    writer.close();

    Directory target = newDirectory();
    writer = new IndexWriter(target, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    IndexReader reader = new TestReader(IndexReader.open(directory, true));
    writer.addIndexes(reader);
    writer.close();
    reader.close();
    reader = IndexReader.open(target, true);
    
    TermsEnum terms = MultiFields.getTerms(reader, "default").iterator();
    while (terms.next() != null) {
      assertTrue(terms.term().utf8ToString().indexOf('e') != -1);
    }
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954163/fstmerge_var1_9193991003614617264
    assertEquals(TermsEnum.SeekStatus.FOUND, terms.seek(new BytesRef("one")));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954163/fstmerge_base_6533938065414617602
    TermEnum terms = reader.terms();
    while (terms.next()) {
      assertTrue(terms.term().text().indexOf('e') != -1);
    }
    terms.close();
=======
    TermsEnum terms = MultiFields.getTerms(reader, "default").iterator();
    while (terms.next() != null) {
      assertTrue(terms.term().utf8ToString().indexOf('e') != -1);
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954163/fstmerge_var2_289302033146991517
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954163/fstmerge_var1_9193991003614617264
    DocsAndPositionsEnum positions = terms.docsAndPositions(MultiFields.getDeletedDocs(reader),
                                                            null);
    while (positions.nextDoc() != DocsEnum.NO_MORE_DOCS) {
      assertTrue((positions.docID() % 2) == 1);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954163/fstmerge_base_6533938065414617602
    TermPositions positions = reader.termPositions(new Term("default", "one"));
    while (positions.next()) {
      assertTrue((positions.doc() % 2) == 1);
=======
    assertEquals(TermsEnum.SeekStatus.FOUND, terms.seek(new BytesRef("one")));
    
    DocsAndPositionsEnum positions = terms.docsAndPositions(MultiFields.getDeletedDocs(reader),
                                                            null);
    while (positions.nextDoc() != DocsEnum.NO_MORE_DOCS) {
      assertTrue((positions.docID() % 2) == 1);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954163/fstmerge_var2_289302033146991517
    }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954163/fstmerge_base_6533938065414617602
    int NUM_DOCS = 3;

    TermDocs td = reader.termDocs(null);
    for(int i=0;i<NUM_DOCS;i++) {
      assertTrue(td.next());
      assertEquals(i, td.doc());
      assertEquals(1, td.freq());
    }
    td.close();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954163/fstmerge_var2_289302033146991517
    reader.close();
    directory.close();
    target.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestFilterIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954247/fstmerge_var1_899375567957593882
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954247/fstmerge_base_8573526935712929703
@Override
    public void eval(MockRAMDirectory dir)  throws IOException {
      if (doFail && Thread.currentThread().getName().equals("main")) {
        StackTraceElement[] trace = new Exception().getStackTrace();
        for (int i = 0; i < trace.length; i++) {
          if ("doFlush".equals(trace[i].getMethodName())) {
            hitExc = true;
            throw new IOException("now failing during flush");
          }
        }
      }
    }
=======
@Override
    public void eval(MockRAMDirectory dir)  throws IOException {
      if (doFail && Thread.currentThread().getName().equals("main")) {
        StackTraceElement[] trace = new Exception().getStackTrace();
        for (int i = 0; i < trace.length; i++) {
          if ("flush".equals(trace[i].getMethodName())) {
            hitExc = true;
            throw new IOException("now failing during flush");
          }
        }
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954247/fstmerge_var2_5095578157483089034

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java
Conflict type: LineBasedMCFd
Conflict body: 
private SegmentInfo merge(SegmentInfo si1, SegmentInfo si2, String merged, boolean useCompoundFile)
   throws Exception {
      SegmentReader r1 = SegmentReader.get(true, si1, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);
      SegmentReader r2 = SegmentReader.get(true, si2, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);

      SegmentMerger merger = new SegmentMerger(si1.dir, IndexWriterConfig.DEFAULT_TERM_INDEX_INTERVAL, merged, null, CodecProvider.getDefault(), null, new FieldInfos());

      merger.add(r1);
      merger.add(r2);
      merger.merge();
      r1.close();
      r2.close();
      
      final SegmentInfo info = new SegmentInfo(merged, si1.docCount + si2.docCount, si1.dir,
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954398/fstmerge_var1_8435437921645842869
                                               useCompoundFile, merger.fieldInfos().hasProx(), merger.getSegmentCodecs(),
                                               merger.fieldInfos().hasVectors());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954398/fstmerge_base_1592345706332548743
                                               useCompoundFile, -1, null, false, merger.hasProx(), merger.getCodec());
=======
                                               useCompoundFile, merger.hasProx(), merger.getCodec());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954398/fstmerge_var2_1017635587950609058
      
      if (useCompoundFile) {
        Collection<String> filesToDelete = merger.createCompoundFile(merged + ".cfs", info);
        for (final String fileToDelete : filesToDelete) 
          si1.dir.deleteFile(fileToDelete);
      }

      return info;
   }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestDoc.java
Conflict type: LineBasedMCFd
Conflict body: 
private void printSegment(PrintWriter out, SegmentInfo si)
   throws Exception {
      SegmentReader reader = SegmentReader.get(true, si, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);

      for (int i = 0; i < reader.numDocs(); i++)
        out.println(reader.document(i));

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954402/fstmerge_base_9028852280238627590
      TermEnum tis = reader.terms();
      while (tis.next()) {
        out.print(tis.term());
        out.println(" DF=" + tis.docFreq());
=======
      FieldsEnum fis = reader.fields().iterator();
      String field = fis.next();
      while(field != null)  {
        TermsEnum tis = fis.terms();
        while(tis.next() != null) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954402/fstmerge_var2_6269966852724588597

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954402/fstmerge_var1_7325050363505352279
          out.print("  term=" + field + ":" + tis.term());
          out.println("    DF=" + tis.docFreq());

          DocsAndPositionsEnum positions = tis.docsAndPositions(reader.getDeletedDocs(), null);

          while (positions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
            out.print(" doc=" + positions.docID());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954402/fstmerge_base_9028852280238627590
        TermPositions positions = reader.termPositions(tis.term());
        try {
          while (positions.next()) {
            out.print(" doc=" + positions.doc());
=======
          out.print("  term=" + field + ":" + tis.term());
          out.println("    DF=" + tis.docFreq());

          DocsAndPositionsEnum positions = tis.docsAndPositions(reader.getDeletedDocs(), null);

          while (positions.nextDoc() != positions.NO_MORE_DOCS) {
            out.print(" doc=" + positions.docID());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954402/fstmerge_var2_6269966852724588597
            out.print(" TF=" + positions.freq());
            out.print(" pos=");
            out.print(positions.nextPosition());
            for (int j = 1; j < positions.freq(); j++)
              out.print("," + positions.nextPosition());
            out.println("");
          }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954402/fstmerge_base_9028852280238627590
        } finally {
          positions.close();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954402/fstmerge_var2_6269966852724588597
        }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954402/fstmerge_base_9028852280238627590
=======
        field = fis.next();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954402/fstmerge_var2_6269966852724588597
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954402/fstmerge_base_9028852280238627590
      tis.close();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954402/fstmerge_var2_6269966852724588597
      reader.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestDoc.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954437/fstmerge_var1_7524914324175078153
public void testUnsupportedOldIndexes() throws Exception {
    for(int i=0;i<unsupportedNames.length;i++) {
      if (VERBOSE) {
        System.out.println("TEST: index " + unsupportedNames[i]);
      }
      unzip(getDataFile("unsupported." + unsupportedNames[i] + ".zip"), unsupportedNames[i]);

      String fullPath = fullDir(unsupportedNames[i]);
      Directory dir = newFSDirectory(new File(fullPath));

      IndexReader reader = null;
      IndexWriter writer = null;
      try {
        reader = IndexReader.open(dir);
        fail("IndexReader.open should not pass for "+unsupportedNames[i]);
      } catch (IndexFormatTooOldException e) {
        // pass
      } finally {
        if (reader != null) reader.close();
        reader = null;
      }

      try {
        writer = new IndexWriter(dir, newIndexWriterConfig(
          TEST_VERSION_CURRENT, new MockAnalyzer())
          .setMergeScheduler(new SerialMergeScheduler()) // no threads!
        );
        // TODO: Make IndexWriter fail on open!
        if (random.nextBoolean()) {
          writer.optimize();
        } else {
          reader = writer.getReader();
        }
        fail("IndexWriter creation should not pass for "+unsupportedNames[i]);
      } catch (IndexFormatTooOldException e) {
        // pass
        if (VERBOSE) {
          System.out.println("TEST: got expected exc:");
          e.printStackTrace(System.out);
        }
      } finally {
        if (reader != null) reader.close();
        reader = null;
        if (writer != null) {
          try {
            writer.close();
          } catch (IndexFormatTooOldException e) {
            // OK -- since IW gives merge scheduler a chance
            // to merge at close, it's possible and fine to
            // hit this exc here
            writer.close(false);
          }
        }
        writer = null;
      }
      
      ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);
      CheckIndex checker = new CheckIndex(dir);
      checker.setInfoStream(new PrintStream(bos));
      CheckIndex.Status indexStatus = checker.checkIndex();
      assertFalse(indexStatus.clean);
      assertTrue(bos.toString().contains(IndexFormatTooOldException.class.getName()));

      dir.close();
      rmDir(unsupportedNames[i]);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954437/fstmerge_base_6920486497877060256
=======
public void testUnsupportedOldIndexes() throws Exception {
    final Random rnd = newRandom();
    for(int i=0;i<unsupportedNames.length;i++) {
      unzip(getDataFile("unsupported." + unsupportedNames[i] + ".zip"), unsupportedNames[i]);

      String fullPath = fullDir(unsupportedNames[i]);
      Directory dir = FSDirectory.open(new File(fullPath));

      IndexReader reader = null;
      IndexWriter writer = null;
      try {
        reader = IndexReader.open(dir);
        fail("IndexReader.open should not pass for "+unsupportedNames[i]);
      } catch (IndexFormatTooOldException e) {
        // pass
      } finally {
        if (reader != null) reader.close();
        reader = null;
      }

      try {
        writer = new IndexWriter(dir, new IndexWriterConfig(
          TEST_VERSION_CURRENT, new MockAnalyzer())
          .setMergeScheduler(new SerialMergeScheduler()) // no threads!
        );
        // TODO: Make IndexWriter fail on open!
        if (rnd.nextBoolean()) {
          writer.optimize();
        } else {
          reader = writer.getReader();
        }
        fail("IndexWriter creation should not pass for "+unsupportedNames[i]);
      } catch (IndexFormatTooOldException e) {
        // pass
      } finally {
        if (reader != null) reader.close();
        reader = null;
        if (writer != null) writer.close();
        writer = null;
      }
      
      ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);
      CheckIndex checker = new CheckIndex(dir);
      checker.setInfoStream(new PrintStream(bos));
      CheckIndex.Status indexStatus = checker.checkIndex();
      assertFalse(indexStatus.clean);
      assertTrue(bos.toString().contains(IndexFormatTooOldException.class.getName()));

      dir.close();
      rmDir(unsupportedNames[i]);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954437/fstmerge_var2_6290039075631694379

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testOptimizeOldIndex() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954442/fstmerge_base_1091908062769341625
    Random rand = newRandom();
    
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954442/fstmerge_var2_853258057558900825
    for(int i=0;i<oldNames.length;i++) {
      unzip(getDataFile("index." + oldNames[i] + ".zip"), oldNames[i]);

      String fullPath = fullDir(oldNames[i]);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954442/fstmerge_var1_2014177444617870304
      Directory dir = newFSDirectory(new File(fullPath));

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954442/fstmerge_base_1091908062769341625
      Directory dir = FSDirectory.open(new File(fullPath));

      FlexTestUtil.verifyFlexVsPreFlex(rand, dir);

=======
      Directory dir = FSDirectory.open(new File(fullPath));

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954442/fstmerge_var2_853258057558900825
      IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(
          TEST_VERSION_CURRENT, new MockAnalyzer()));
      w.optimize();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954442/fstmerge_base_1091908062769341625
      FlexTestUtil.verifyFlexVsPreFlex(rand, w);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954442/fstmerge_var2_853258057558900825
      w.close();

      _TestUtil.checkIndex(dir);
      
      dir.close();
      rmDir(oldNames[i]);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
Conflict type: LineBasedMCFd
Conflict body: 
public void searchIndex(String dirName, String oldName) throws IOException {
    //QueryParser parser = new QueryParser("contents", new MockAnalyzer());
    //Query query = parser.parse("handle:1");

    dirName = fullDir(dirName);

    Directory dir = newFSDirectory(new File(dirName));
    IndexSearcher searcher = new IndexSearcher(dir, true);
    IndexReader reader = searcher.getIndexReader();

    _TestUtil.checkIndex(dir);

    final Bits delDocs = MultiFields.getDeletedDocs(reader);

    for(int i=0;i<35;i++) {
      if (!delDocs.get(i)) {
        Document d = reader.document(i);
        List<Fieldable> fields = d.getFields();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954469/fstmerge_var1_8548594490209912573
        if (d.getField("content3") == null) {
          final int numFields = 5;
          assertEquals(numFields, fields.size());
          Field f =  d.getField("id");
          assertEquals(""+i, f.stringValue());

          f = d.getField("utf8");
          assertEquals("Lu\uD834\uDD1Ece\uD834\uDD60ne \u0000 \u2620 ab\ud917\udc17cd", f.stringValue());

          f =  d.getField("autf8");
          assertEquals("Lu\uD834\uDD1Ece\uD834\uDD60ne \u0000 \u2620 ab\ud917\udc17cd", f.stringValue());
      
          f = d.getField("content2");
          assertEquals("here is more content with aaa aaa aaa", f.stringValue());

          f = d.getField("fie\u2C77ld");
          assertEquals("field with non-ascii name", f.stringValue());
        }

        TermFreqVector tfv = reader.getTermFreqVector(i, "utf8");
        assertNotNull("docID=" + i + " index=" + dirName, tfv);
        assertTrue(tfv instanceof TermPositionVector);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954469/fstmerge_base_5915600031093012930
        if (!oldName.startsWith("19.") &&
            !oldName.startsWith("20.") &&
            !oldName.startsWith("21.") &&
            !oldName.startsWith("22.")) {

          if (d.getField("content3") == null) {
            final int numFields = 5;
            assertEquals(numFields, fields.size());
            Field f =  d.getField("id");
            assertEquals(""+i, f.stringValue());

            f = d.getField("utf8");
            assertEquals("Lu\uD834\uDD1Ece\uD834\uDD60ne \u0000 \u2620 ab\ud917\udc17cd", f.stringValue());

            f =  d.getField("autf8");
            assertEquals("Lu\uD834\uDD1Ece\uD834\uDD60ne \u0000 \u2620 ab\ud917\udc17cd", f.stringValue());
        
            f = d.getField("content2");
            assertEquals("here is more content with aaa aaa aaa", f.stringValue());

            f = d.getField("fie\u2C77ld");
            assertEquals("field with non-ascii name", f.stringValue());
          }
        }       
=======
        if (d.getField("content3") == null) {
          final int numFields = 5;
          assertEquals(numFields, fields.size());
          Field f =  d.getField("id");
          assertEquals(""+i, f.stringValue());

          f = d.getField("utf8");
          assertEquals("Lu\uD834\uDD1Ece\uD834\uDD60ne \u0000 \u2620 ab\ud917\udc17cd", f.stringValue());

          f =  d.getField("autf8");
          assertEquals("Lu\uD834\uDD1Ece\uD834\uDD60ne \u0000 \u2620 ab\ud917\udc17cd", f.stringValue());
      
          f = d.getField("content2");
          assertEquals("here is more content with aaa aaa aaa", f.stringValue());

          f = d.getField("fie\u2C77ld");
          assertEquals("field with non-ascii name", f.stringValue());
        }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954469/fstmerge_var2_4432879776219621973
      } else
        // Only ID 7 is deleted
        assertEquals(7, i);
    }
    
    ScoreDoc[] hits = searcher.search(new TermQuery(new Term("content", "aaa")), null, 1000).scoreDocs;

    // First document should be #21 since it's norm was
    // increased:
    Document d = searcher.doc(hits[0].doc);
    assertEquals("didn't get the right document first", "21", d.get("id"));

    doTestHits(hits, 34, searcher.getIndexReader());

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954469/fstmerge_base_5915600031093012930
    if (!oldName.startsWith("19.") &&
        !oldName.startsWith("20.") &&
        !oldName.startsWith("21.") &&
        !oldName.startsWith("22.")) {
      // Test on indices >= 2.3
      hits = searcher.search(new TermQuery(new Term("utf8", "\u0000")), null, 1000).scoreDocs;
      assertEquals(34, hits.length);
      hits = searcher.search(new TermQuery(new Term("utf8", "Lu\uD834\uDD1Ece\uD834\uDD60ne")), null, 1000).scoreDocs;
      assertEquals(34, hits.length);
      hits = searcher.search(new TermQuery(new Term("utf8", "ab\ud917\udc17cd")), null, 1000).scoreDocs;
      assertEquals(34, hits.length);
    }
=======
    hits = searcher.search(new TermQuery(new Term("utf8", "\u0000")), null, 1000).scoreDocs;
    assertEquals(34, hits.length);
    hits = searcher.search(new TermQuery(new Term("utf8", "Lu\uD834\uDD1Ece\uD834\uDD60ne")), null, 1000).scoreDocs;
    assertEquals(34, hits.length);
    hits = searcher.search(new TermQuery(new Term("utf8", "ab\ud917\udc17cd")), null, 1000).scoreDocs;
    assertEquals(34, hits.length);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954469/fstmerge_var2_4432879776219621973

    searcher.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954488/fstmerge_var1_2350184650194882985
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954488/fstmerge_base_6393893157293785528
public void createIndex(String dirName, boolean doCFS) throws IOException {

    rmDir(dirName);

    dirName = fullDir(dirName);

    Directory dir = FSDirectory.open(new File(dirName));
    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);
    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);
    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);
    IndexWriter writer = new IndexWriter(dir, conf);
    
    for(int i=0;i<35;i++) {
      addDoc(writer, i);
    }
    assertEquals("wrong doc count", 35, writer.maxDoc());
    writer.close();

    // open fresh writer so we get no prx file in the added segment
    conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);
    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);
    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);
    writer = new IndexWriter(dir, conf);
    addNoProxDoc(writer);
    writer.close();

    // Delete one doc so we get a .del file:
    IndexReader reader = IndexReader.open(dir, false);
    Term searchTerm = new Term("id", "7");
    int delCount = reader.deleteDocuments(searchTerm);
    assertEquals("didn't delete the right number of documents", 1, delCount);

    // Set one norm so we get a .s0 file:
    reader.setNorm(21, "content", (float) 1.5);
    reader.close();
  }
=======
public void createIndex(String dirName, boolean doCFS) throws IOException {

    rmDir(dirName);

    dirName = fullDir(dirName);

    Directory dir = FSDirectory.open(new File(dirName));
    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);
    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);
    IndexWriter writer = new IndexWriter(dir, conf);
    
    for(int i=0;i<35;i++) {
      addDoc(writer, i);
    }
    assertEquals("wrong doc count", 35, writer.maxDoc());
    writer.close();

    // open fresh writer so we get no prx file in the added segment
    conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);
    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);
    writer = new IndexWriter(dir, conf);
    addNoProxDoc(writer);
    writer.close();

    // Delete one doc so we get a .del file:
    IndexReader reader = IndexReader.open(dir, false);
    Term searchTerm = new Term("id", "7");
    int delCount = reader.deleteDocuments(searchTerm);
    assertEquals("didn't delete the right number of documents", 1, delCount);

    // Set one norm so we get a .s0 file:
    reader.setNorm(21, "content", (float) 1.5);
    reader.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954488/fstmerge_var2_2131596430485114963

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testIndexing() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954620/fstmerge_var1_6895375467984283449
    Directory mainDir = newDirectory();
    IndexWriter writer = new IndexWriter(
        mainDir,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
            setMaxBufferedDocs(10).
            setMergePolicy(newLogMergePolicy(false,2))
    );
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954620/fstmerge_base_5115650098050010893
    Directory mainDir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(mainDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
=======
    Directory mainDir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(mainDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954620/fstmerge_var2_5527072438438880589
    IndexReader reader = writer.getReader(); // start pooling readers
    reader.close();
    RunThread[] indexThreads = new RunThread[4];
    for (int x=0; x < indexThreads.length; x++) {
      indexThreads[x] = new RunThread(x % 2, writer);
      indexThreads[x].setName("Thread " + x);
      indexThreads[x].start();
    }    
    long startTime = System.currentTimeMillis();
    long duration = 1000;
    while ((System.currentTimeMillis() - startTime) < duration) {
      Thread.sleep(100);
    }
    int delCount = 0;
    int addCount = 0;
    for (int x=0; x < indexThreads.length; x++) {
      indexThreads[x].run = false;
      assertNull("Exception thrown: "+indexThreads[x].ex, indexThreads[x].ex);
      addCount += indexThreads[x].addCount;
      delCount += indexThreads[x].delCount;
    }
    for (int x=0; x < indexThreads.length; x++) {
      indexThreads[x].join();
    }
    for (int x=0; x < indexThreads.length; x++) {
      assertNull("Exception thrown: "+indexThreads[x].ex, indexThreads[x].ex);
    }
    //System.out.println("addCount:"+addCount);
    //System.out.println("delCount:"+delCount);
    writer.close();
    mainDir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestNRTReaderWithThreads.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testDeleteLeftoverFiles() throws IOException {
    MockDirectoryWrapper dir = newDirectory();
    dir.setPreventDoubleWrite(false);

    LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);
    mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS

    IndexWriter writer = new IndexWriter(
        dir,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
            setMaxBufferedDocs(10).
            setMergePolicy(mergePolicy)
    );

    int i;
    for(i=0;i<35;i++) {
      addDoc(writer, i);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954636/fstmerge_var1_714215448525109718
    mergePolicy.setUseCompoundFile(false);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954636/fstmerge_base_4374589360009014267
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
=======
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954636/fstmerge_var2_1685705511542107724
    for(;i<45;i++) {
      addDoc(writer, i);
    }
    writer.close();

    // Delete one doc so we get a .del file:
    IndexReader reader = IndexReader.open(dir, false);
    Term searchTerm = new Term("id", "7");
    int delCount = reader.deleteDocuments(searchTerm);
    assertEquals("didn't delete the right number of documents", 1, delCount);

    // Set one norm so we get a .s0 file:
    reader.setNorm(21, "content", (float) 1.5);
    reader.close();

    // Now, artificially create an extra .del file & extra
    // .s0 file:
    String[] files = dir.listAll();

    /*
    for(int j=0;j<files.length;j++) {
      System.out.println(j + ": " + files[j]);
    }
    */

    // The numbering of fields can vary depending on which
    // JRE is in use.  On some JREs we see content bound to
    // field 0; on others, field 1.  So, here we have to
    // figure out which field number corresponds to
    // "content", and then set our expected file names below
    // accordingly:
    CompoundFileReader cfsReader = new CompoundFileReader(dir, "_2.cfs");
    FieldInfos fieldInfos = new FieldInfos(cfsReader, "_2.fnm");
    int contentFieldIndex = -1;
    for(i=0;i<fieldInfos.size();i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.name.equals("content")) {
        contentFieldIndex = i;
        break;
      }
    }
    cfsReader.close();
    assertTrue("could not locate the 'content' field number in the _2.cfs segment", contentFieldIndex != -1);

    String normSuffix = "s" + contentFieldIndex;

    // Create a bogus separate norms file for a
    // segment/field that actually has a separate norms file
    // already:
    copyFile(dir, "_2_1." + normSuffix, "_2_2." + normSuffix);

    // Create a bogus separate norms file for a
    // segment/field that actually has a separate norms file
    // already, using the "not compound file" extension:
    copyFile(dir, "_2_1." + normSuffix, "_2_2.f" + contentFieldIndex);

    // Create a bogus separate norms file for a
    // segment/field that does not have a separate norms
    // file already:
    copyFile(dir, "_2_1." + normSuffix, "_1_1." + normSuffix);

    // Create a bogus separate norms file for a
    // segment/field that does not have a separate norms
    // file already using the "not compound file" extension:
    copyFile(dir, "_2_1." + normSuffix, "_1_1.f" + contentFieldIndex);

    // Create a bogus separate del file for a
    // segment that already has a separate del file: 
    copyFile(dir, "_0_1.del", "_0_2.del");

    // Create a bogus separate del file for a
    // segment that does not yet have a separate del file:
    copyFile(dir, "_0_1.del", "_1_1.del");

    // Create a bogus separate del file for a
    // non-existent segment:
    copyFile(dir, "_0_1.del", "_188_1.del");

    // Create a bogus segment file:
    copyFile(dir, "_0.cfs", "_188.cfs");

    // Create a bogus fnm file when the CFS already exists:
    copyFile(dir, "_0.cfs", "_0.fnm");
    
    // Create some old segments file:
    copyFile(dir, "segments_2", "segments");
    copyFile(dir, "segments_2", "segments_1");

    // Create a bogus cfs file shadowing a non-cfs segment:
    copyFile(dir, "_1.cfs", "_2.cfs");
    
    String[] filesPre = dir.listAll();

    // Open & close a writer: it should delete the above 4
    // files and nothing more:
    writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
    writer.close();

    String[] files2 = dir.listAll();
    dir.close();

    Arrays.sort(files);
    Arrays.sort(files2);
    
    Set<String> dif = difFiles(files, files2);
    
    if (!Arrays.equals(files, files2)) {
      fail("IndexFileDeleter failed to delete unreferenced extra files: should have deleted " + (filesPre.length-files.length) + " files but only deleted " + (filesPre.length - files2.length) + "; expected files:\n    " + asString(files) + "\n  actual files:\n    " + asString(files2)+"\ndif: "+dif);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexFileDeleter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954658/fstmerge_var1_1809072100357517971
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954658/fstmerge_base_3012482357959729362
@Override
    synchronized byte[] getByteBlock() {
      final int size = freeByteBlocks.size();
      final byte[] b;
      if (0 == size)
        b = new byte[DocumentsWriter.BYTE_BLOCK_SIZE];
      else
        b =  freeByteBlocks.remove(size-1);
      return b;
    }
=======
@Override
    synchronized byte[] getByteBlock() {
      final int size = freeByteBlocks.size();
      final byte[] b;
      if (0 == size)
        b = new byte[DocumentsWriterRAMAllocator.BYTE_BLOCK_SIZE];
      else
        b =  freeByteBlocks.remove(size-1);
      return b;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954658/fstmerge_var2_5125374660932564080

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestByteSlices.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testBasic() throws Throwable {
    ByteBlockPool pool = new ByteBlockPool(new RecyclingByteBlockAllocator(ByteBlockPool.BYTE_BLOCK_SIZE, Integer.MAX_VALUE));

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954671/fstmerge_base_6325472027891070063
    final int NUM_STREAM = 25;
=======
    final int NUM_STREAM = 100 * RANDOM_MULTIPLIER;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954671/fstmerge_var2_3052641092621036889

    ByteSliceWriter writer = new ByteSliceWriter(pool);

    int[] starts = new int[NUM_STREAM];
    int[] uptos = new int[NUM_STREAM];
    int[] counters = new int[NUM_STREAM];

    ByteSliceReader reader = new ByteSliceReader();

    for(int ti=0;ti<100;ti++) {

      for(int stream=0;stream<NUM_STREAM;stream++) {
        starts[stream] = -1;
        counters[stream] = 0;
      }
      
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954671/fstmerge_var1_3423486957948718781
      int num = 10000 * RANDOM_MULTIPLIER;
      for (int iter = 0; iter < num; iter++) {
        int stream = random.nextInt(NUM_STREAM);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954671/fstmerge_base_6325472027891070063
      for(int iter=0;iter<10000*_TestUtil.getRandomMultiplier();iter++) {
        int stream = r.nextInt(NUM_STREAM);
=======
      int num = 10000 * RANDOM_MULTIPLIER;
      for (int iter = 0; iter < num; iter++) {
        int stream = r.nextInt(NUM_STREAM);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954671/fstmerge_var2_3052641092621036889
        if (VERBOSE)
          System.out.println("write stream=" + stream);

        if (starts[stream] == -1) {
          final int spot = pool.newSlice(ByteBlockPool.FIRST_LEVEL_SIZE);
          starts[stream] = uptos[stream] = spot + pool.byteOffset;
          if (VERBOSE)
            System.out.println("  init to " + starts[stream]);
        }

        writer.init(uptos[stream]);
        int numValue = random.nextInt(20);
        for(int j=0;j<numValue;j++) {
          if (VERBOSE)
            System.out.println("    write " + (counters[stream]+j));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954671/fstmerge_var1_3423486957948718781
          // write some large (incl. negative) ints:
          writer.writeVInt(random.nextInt());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954671/fstmerge_base_6325472027891070063
=======
          // write some large (incl. negative) ints:
          writer.writeVInt(r.nextInt());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954671/fstmerge_var2_3052641092621036889
          writer.writeVInt(counters[stream]+j);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954671/fstmerge_base_6325472027891070063
          //writer.writeVInt(ti);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954671/fstmerge_var2_3052641092621036889
        }
        counters[stream] += numValue;
        uptos[stream] = writer.getAddress();
        if (VERBOSE)
          System.out.println("    addr now " + uptos[stream]);
      }
    
      for(int stream=0;stream<NUM_STREAM;stream++) {
        if (VERBOSE)
          System.out.println("  stream=" + stream + " count=" + counters[stream]);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954671/fstmerge_base_6325472027891070063
        if (starts[stream] != uptos[stream]) {
=======
        if (starts[stream] != -1 && starts[stream] != uptos[stream]) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954671/fstmerge_var2_3052641092621036889
          reader.init(pool, starts[stream], uptos[stream]);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954671/fstmerge_base_6325472027891070063
          for(int j=0;j<counters[stream];j++) 
            assertEquals(j, reader.readVInt());
            //assertEquals(ti, reader.readVInt());
=======
          for(int j=0;j<counters[stream];j++) {
            reader.readVInt();
            assertEquals(j, reader.readVInt()); 
          }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954671/fstmerge_var2_3052641092621036889
        }
      }

      pool.reset();
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestByteSlices.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954677/fstmerge_var1_6437938152972031220
public MockIndexWriter(Random r,Directory dir, IndexWriterConfig conf) throws IOException {
      super(dir, conf);
      // must make a private random since our methods are
      // called from different threads; else test failures may
      // not be reproducible from the original seed
      this.r = new Random(r.nextInt());
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954677/fstmerge_base_5026811180605050473
=======
public MockIndexWriter(Random r,Directory dir, IndexWriterConfig conf) throws IOException {
      super(dir, conf);
      this.r = r;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954677/fstmerge_var2_7594439698886084202

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/RandomIndexWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954686/fstmerge_var1_117933018629721740
public RandomIndexWriter(Random r, Directory dir) throws IOException {
    this(r, dir, LuceneTestCase.newIndexWriterConfig(r, LuceneTestCase.TEST_VERSION_CURRENT, new MockAnalyzer()));
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954686/fstmerge_base_4252762859318190724
=======
public RandomIndexWriter(Random r, Directory dir) throws IOException {
    this(r, dir, LuceneTestCaseJ4.newIndexWriterConfig(r, LuceneTestCaseJ4.TEST_VERSION_CURRENT, new MockAnalyzer()));
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954686/fstmerge_var2_4880027521886024795

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/RandomIndexWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954691/fstmerge_var1_2346504386612299032
public RandomIndexWriter(Random r, Directory dir, Analyzer a) throws IOException {
    this(r, dir, LuceneTestCase.newIndexWriterConfig(r, LuceneTestCase.TEST_VERSION_CURRENT, a));
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954691/fstmerge_base_954524426966626560
=======
public RandomIndexWriter(Random r, Directory dir, Analyzer a) throws IOException {
    this(r, dir, LuceneTestCaseJ4.newIndexWriterConfig(r, LuceneTestCaseJ4.TEST_VERSION_CURRENT, a));
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954691/fstmerge_var2_4884202186039259049

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/RandomIndexWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954696/fstmerge_var1_1947715475587474460
public RandomIndexWriter(Random r, Directory dir, Version v, Analyzer a) throws IOException {
    this(r, dir, LuceneTestCase.newIndexWriterConfig(r, v, a));
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954696/fstmerge_base_4678835367587788187
=======
public RandomIndexWriter(Random r, Directory dir, Version v, Analyzer a) throws IOException {
    this(r, dir, LuceneTestCaseJ4.newIndexWriterConfig(r, v, a));
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954696/fstmerge_var2_6648539847019731905

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/RandomIndexWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954700/fstmerge_var1_7636114243071268192
public RandomIndexWriter(Random r, Directory dir, IndexWriterConfig c) throws IOException {
    this.r = r;
    w = new MockIndexWriter(r, dir, c);
    flushAt = _TestUtil.nextInt(r, 10, 1000);
    if (LuceneTestCase.VERBOSE) {
      System.out.println("RIW config=" + w.getConfig());
      System.out.println("codec default=" + w.getConfig().getCodecProvider().getDefaultFieldCodec());
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954700/fstmerge_base_4021617546067448262
=======
public RandomIndexWriter(Random r, Directory dir, IndexWriterConfig c) throws IOException {
    this.r = r;
    w = new MockIndexWriter(r, dir, c);
    flushAt = _TestUtil.nextInt(r, 10, 1000);
    if (LuceneTestCaseJ4.VERBOSE) {
      System.out.println("RIW config=" + w.getConfig());
      System.out.println("codec default=" + CodecProvider.getDefaultCodec());
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954700/fstmerge_var2_3040164254380043876

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/RandomIndexWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954705/fstmerge_var1_6737519602987593130
public void addDocument(Document doc) throws IOException {
    w.addDocument(doc);
    if (docCount++ == flushAt) {
      if (LuceneTestCase.VERBOSE) {
        System.out.println("RIW.addDocument: now doing a commit");
      }
      w.commit();
      flushAt += _TestUtil.nextInt(r, 10, 1000);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954705/fstmerge_base_6479296645191369123
=======
public void addDocument(Document doc) throws IOException {
    w.addDocument(doc);
    if (docCount++ == flushAt) {
      w.commit();
      flushAt += _TestUtil.nextInt(r, 10, 1000);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954705/fstmerge_var2_6988597700582259633

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/RandomIndexWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954727/fstmerge_var1_4419436432841631280
public IndexReader getReader() throws IOException {
    getReaderCalled = true;
    if (r.nextInt(4) == 2)
      w.optimize();
    // If we are writing with PreFlexRW, force a full
    // IndexReader.open so terms are sorted in codepoint
    // order during searching:
    if (!w.codecs.getDefaultFieldCodec().equals("PreFlex") && r.nextBoolean()) {
      if (LuceneTestCase.VERBOSE) {
        System.out.println("RIW.getReader: use NRT reader");
      }
      return w.getReader();
    } else {
      if (LuceneTestCase.VERBOSE) {
        System.out.println("RIW.getReader: open new reader");
      }
      w.commit();
      return IndexReader.open(w.getDirectory(), new KeepOnlyLastCommitDeletionPolicy(), r.nextBoolean(), _TestUtil.nextInt(r, 1, 10));
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954727/fstmerge_base_2816110581436780098
=======
public IndexReader getReader() throws IOException {
    // If we are writing with PreFlexRW, force a full
    // IndexReader.open so terms are sorted in codepoint
    // order during searching:
    if (!w.codecs.getWriter(null).name.equals("PreFlex") && r.nextBoolean()) {
      if (LuceneTestCaseJ4.VERBOSE) {
        System.out.println("RIW.getReader: use NRT reader");
      }
      return w.getReader();
    } else {
      if (LuceneTestCaseJ4.VERBOSE) {
        System.out.println("RIW.getReader: open new reader");
      }
      w.commit();
      return IndexReader.open(w.getDirectory(), new KeepOnlyLastCommitDeletionPolicy(), r.nextBoolean(), _TestUtil.nextInt(r, 1, 10));
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954727/fstmerge_var2_3530171433900586044

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/RandomIndexWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954730/fstmerge_var1_161489878368727766
public void close() throws IOException {
    // if someone isn't using getReader() API, we want to be sure to
    // maybeOptimize since presumably they might open a reader on the dir.
    if (getReaderCalled == false && r.nextInt(4) == 2) {
      w.optimize();
    }
    w.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954730/fstmerge_base_5544786735036053924
=======
public void close() throws IOException {
    if (r.nextInt(4) == 2) {
      w.optimize();
    }
    w.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627954730/fstmerge_var2_7922302538537997519

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/RandomIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testMerge() throws IOException {                             
    SegmentMerger merger = new SegmentMerger(mergedDir, IndexWriterConfig.DEFAULT_TERM_INDEX_INTERVAL, mergedSegment, null, CodecProvider.getDefault(), null, new FieldInfos());
    merger.add(reader1);
    merger.add(reader2);
    int docsMerged = merger.merge();
    assertTrue(docsMerged == 2);
    //Should be able to open a new SegmentReader against the new directory
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955060/fstmerge_var1_7626177637768424676
    SegmentReader mergedReader = SegmentReader.get(false, mergedDir, new SegmentInfo(mergedSegment, docsMerged, mergedDir, false, merger.fieldInfos().hasProx(),
                                                                                     merger.getSegmentCodecs(), merger.fieldInfos().hasVectors()),
                                                   BufferedIndexInput.BUFFER_SIZE, true, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955060/fstmerge_base_8326720379673732888
    SegmentReader mergedReader = SegmentReader.get(false, mergedDir, new SegmentInfo(mergedSegment, docsMerged, mergedDir, false, -1,
        null, false, merger.hasProx(), merger.getCodec()), BufferedIndexInput.BUFFER_SIZE, true, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, null);
=======
    SegmentReader mergedReader = SegmentReader.get(false, mergedDir, new SegmentInfo(mergedSegment, docsMerged, mergedDir, false, 
        merger.hasProx(), merger.getCodec()), BufferedIndexInput.BUFFER_SIZE, true, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, null);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955060/fstmerge_var2_475427624452582799

    assertTrue(mergedReader != null);
    assertTrue(mergedReader.numDocs() == 2);
    Document newDoc1 = mergedReader.document(0);
    assertTrue(newDoc1 != null);
    //There are 2 unstored fields on the document
    assertTrue(DocHelper.numFields(newDoc1) == DocHelper.numFields(doc1) - DocHelper.unstored.size());
    Document newDoc2 = mergedReader.document(1);
    assertTrue(newDoc2 != null);
    assertTrue(DocHelper.numFields(newDoc2) == DocHelper.numFields(doc2) - DocHelper.unstored.size());
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955060/fstmerge_base_8326720379673732888
    TermDocs termDocs = mergedReader.termDocs(new Term(DocHelper.TEXT_FIELD_2_KEY, "field"));
=======
    DocsEnum termDocs = MultiFields.getTermDocsEnum(mergedReader,
                                                    MultiFields.getDeletedDocs(mergedReader),
                                                    DocHelper.TEXT_FIELD_2_KEY,
                                                    new BytesRef("field"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955060/fstmerge_var2_475427624452582799
    assertTrue(termDocs != null);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955060/fstmerge_base_8326720379673732888
    assertTrue(termDocs.next() == true);
=======
    assertTrue(termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955060/fstmerge_var2_475427624452582799
    
    Collection<String> stored = mergedReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);
    assertTrue(stored != null);
    //System.out.println("stored size: " + stored.size());
    assertTrue("We do not have 3 fields that were indexed with term vector",stored.size() == 3);
    
    TermFreqVector vector = mergedReader.getTermFreqVector(0, DocHelper.TEXT_FIELD_2_KEY);
    assertTrue(vector != null);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955060/fstmerge_base_8326720379673732888
    String [] terms = vector.getTerms();
=======
    BytesRef [] terms = vector.getTerms();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955060/fstmerge_var2_475427624452582799
    assertTrue(terms != null);
    //System.out.println("Terms size: " + terms.length);
    assertTrue(terms.length == 3);
    int [] freqs = vector.getTermFrequencies();
    assertTrue(freqs != null);
    //System.out.println("Freqs size: " + freqs.length);
    assertTrue(vector instanceof TermPositionVector == true);
    
    for (int i = 0; i < terms.length; i++) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955060/fstmerge_base_8326720379673732888
      String term = terms[i];
=======
      String term = terms[i].utf8ToString();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955060/fstmerge_var2_475427624452582799
      int freq = freqs[i];
      //System.out.println("Term: " + term + " Freq: " + freq);
      assertTrue(DocHelper.FIELD_2_TEXT.indexOf(term) != -1);
      assertTrue(DocHelper.FIELD_2_FREQS[i] == freq);
    }

    TestSegmentReader.checkNorms(mergedReader);
    mergedReader.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestSegmentMerger.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955097/fstmerge_var1_3395909868009521774
public void testLatentFields() throws Exception {
    assertTrue(dir != null);
    assertTrue(fieldInfos != null);
    FieldsReader reader = new FieldsReader(dir, TEST_SEGMENT_NAME, fieldInfos);
    assertTrue(reader.size() == 1);
    Set<String> loadFieldNames = new HashSet<String>();
    loadFieldNames.add(DocHelper.TEXT_FIELD_1_KEY);
    loadFieldNames.add(DocHelper.TEXT_FIELD_UTF1_KEY);
    Set<String> lazyFieldNames = new HashSet<String>();
    //new String[]{DocHelper.LARGE_LAZY_FIELD_KEY, DocHelper.LAZY_FIELD_KEY, DocHelper.LAZY_FIELD_BINARY_KEY};
    lazyFieldNames.add(DocHelper.LARGE_LAZY_FIELD_KEY);
    lazyFieldNames.add(DocHelper.LAZY_FIELD_KEY);
    lazyFieldNames.add(DocHelper.LAZY_FIELD_BINARY_KEY);
    lazyFieldNames.add(DocHelper.TEXT_FIELD_UTF2_KEY);

    // Use LATENT instead of LAZY
    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(loadFieldNames, lazyFieldNames) {
        @Override
        public FieldSelectorResult accept(String fieldName) {
          final FieldSelectorResult result = super.accept(fieldName);
          if (result == FieldSelectorResult.LAZY_LOAD) {
            return FieldSelectorResult.LATENT;
          } else {
            return result;
          }
        }
      };

    Document doc = reader.doc(0, fieldSelector);
    assertTrue("doc is null and it shouldn't be", doc != null);
    Fieldable field = doc.getFieldable(DocHelper.LAZY_FIELD_KEY);
    assertTrue("field is null and it shouldn't be", field != null);
    assertTrue("field is not lazy and it should be", field.isLazy());
    String value = field.stringValue();
    assertTrue("value is null and it shouldn't be", value != null);
    assertTrue(value + " is not equal to " + DocHelper.LAZY_FIELD_TEXT, value.equals(DocHelper.LAZY_FIELD_TEXT) == true);
    assertTrue("calling stringValue() twice should give different references", field.stringValue() != field.stringValue());

    field = doc.getFieldable(DocHelper.TEXT_FIELD_1_KEY);
    assertTrue("field is null and it shouldn't be", field != null);
    assertTrue("Field is lazy and it should not be", field.isLazy() == false);
    assertTrue("calling stringValue() twice should give same reference", field.stringValue() == field.stringValue());

    field = doc.getFieldable(DocHelper.TEXT_FIELD_UTF1_KEY);
    assertTrue("field is null and it shouldn't be", field != null);
    assertTrue("Field is lazy and it should not be", field.isLazy() == false);
    assertTrue(field.stringValue() + " is not equal to " + DocHelper.FIELD_UTF1_TEXT, field.stringValue().equals(DocHelper.FIELD_UTF1_TEXT) == true);
    assertTrue("calling stringValue() twice should give same reference", field.stringValue() == field.stringValue());

    field = doc.getFieldable(DocHelper.TEXT_FIELD_UTF2_KEY);
    assertTrue("field is null and it shouldn't be", field != null);
    assertTrue("Field is lazy and it should not be", field.isLazy() == true);
    assertTrue(field.stringValue() + " is not equal to " + DocHelper.FIELD_UTF2_TEXT, field.stringValue().equals(DocHelper.FIELD_UTF2_TEXT) == true);
    assertTrue("calling stringValue() twice should give different references", field.stringValue() != field.stringValue());

    field = doc.getFieldable(DocHelper.LAZY_FIELD_BINARY_KEY);
    assertTrue("field is null and it shouldn't be", field != null);
    assertTrue("stringValue isn't null for lazy binary field", field.stringValue() == null);
    assertTrue("calling binaryValue() twice should give different references", field.getBinaryValue() != field.getBinaryValue());

    byte [] bytes = field.getBinaryValue();
    assertTrue("bytes is null and it shouldn't be", bytes != null);
    assertTrue("", DocHelper.LAZY_FIELD_BINARY_BYTES.length == bytes.length);
    for (int i = 0; i < bytes.length; i++) {
      assertTrue("byte[" + i + "] is mismatched", bytes[i] == DocHelper.LAZY_FIELD_BINARY_BYTES[i]);

    }
    reader.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955097/fstmerge_base_204659442348242258
=======
public void testLatentFields() throws Exception {
    assertTrue(dir != null);
    assertTrue(fieldInfos != null);
    FieldsReader reader = new FieldsReader(dir, TEST_SEGMENT_NAME, fieldInfos);
    assertTrue(reader != null);
    assertTrue(reader.size() == 1);
    Set<String> loadFieldNames = new HashSet<String>();
    loadFieldNames.add(DocHelper.TEXT_FIELD_1_KEY);
    loadFieldNames.add(DocHelper.TEXT_FIELD_UTF1_KEY);
    Set<String> lazyFieldNames = new HashSet<String>();
    //new String[]{DocHelper.LARGE_LAZY_FIELD_KEY, DocHelper.LAZY_FIELD_KEY, DocHelper.LAZY_FIELD_BINARY_KEY};
    lazyFieldNames.add(DocHelper.LARGE_LAZY_FIELD_KEY);
    lazyFieldNames.add(DocHelper.LAZY_FIELD_KEY);
    lazyFieldNames.add(DocHelper.LAZY_FIELD_BINARY_KEY);
    lazyFieldNames.add(DocHelper.TEXT_FIELD_UTF2_KEY);

    // Use LATENT instead of LAZY
    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(loadFieldNames, lazyFieldNames) {
        public FieldSelectorResult accept(String fieldName) {
          final FieldSelectorResult result = super.accept(fieldName);
          if (result == FieldSelectorResult.LAZY_LOAD) {
            return FieldSelectorResult.LATENT;
          } else {
            return result;
          }
        }
      };

    Document doc = reader.doc(0, fieldSelector);
    assertTrue("doc is null and it shouldn't be", doc != null);
    Fieldable field = doc.getFieldable(DocHelper.LAZY_FIELD_KEY);
    assertTrue("field is null and it shouldn't be", field != null);
    assertTrue("field is not lazy and it should be", field.isLazy());
    String value = field.stringValue();
    assertTrue("value is null and it shouldn't be", value != null);
    assertTrue(value + " is not equal to " + DocHelper.LAZY_FIELD_TEXT, value.equals(DocHelper.LAZY_FIELD_TEXT) == true);
    assertTrue("calling stringValue() twice should give different references", field.stringValue() != field.stringValue());

    field = doc.getFieldable(DocHelper.TEXT_FIELD_1_KEY);
    assertTrue("field is null and it shouldn't be", field != null);
    assertTrue("Field is lazy and it should not be", field.isLazy() == false);
    assertTrue("calling stringValue() twice should give same reference", field.stringValue() == field.stringValue());

    field = doc.getFieldable(DocHelper.TEXT_FIELD_UTF1_KEY);
    assertTrue("field is null and it shouldn't be", field != null);
    assertTrue("Field is lazy and it should not be", field.isLazy() == false);
    assertTrue(field.stringValue() + " is not equal to " + DocHelper.FIELD_UTF1_TEXT, field.stringValue().equals(DocHelper.FIELD_UTF1_TEXT) == true);
    assertTrue("calling stringValue() twice should give same reference", field.stringValue() == field.stringValue());

    field = doc.getFieldable(DocHelper.TEXT_FIELD_UTF2_KEY);
    assertTrue("field is null and it shouldn't be", field != null);
    assertTrue("Field is lazy and it should not be", field.isLazy() == true);
    assertTrue(field.stringValue() + " is not equal to " + DocHelper.FIELD_UTF2_TEXT, field.stringValue().equals(DocHelper.FIELD_UTF2_TEXT) == true);
    assertTrue("calling stringValue() twice should give different references", field.stringValue() != field.stringValue());

    field = doc.getFieldable(DocHelper.LAZY_FIELD_BINARY_KEY);
    assertTrue("field is null and it shouldn't be", field != null);
    assertTrue("stringValue isn't null for lazy binary field", field.stringValue() == null);
    assertTrue("calling binaryValue() twice should give different references", field.getBinaryValue() != field.getBinaryValue());

    byte [] bytes = field.getBinaryValue();
    assertTrue("bytes is null and it shouldn't be", bytes != null);
    assertTrue("", DocHelper.LAZY_FIELD_BINARY_BYTES.length == bytes.length);
    for (int i = 0; i < bytes.length; i++) {
      assertTrue("byte[" + i + "] is mismatched", bytes[i] == DocHelper.LAZY_FIELD_BINARY_BYTES[i]);

    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955097/fstmerge_var2_1958390677005817631

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestFieldsReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955239/fstmerge_var1_3516103846082129048
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955239/fstmerge_base_2095766371353316115
private void createIndex(Directory dir) throws IOException {
    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.CREATE)
        .setMaxBufferedDocs(5).setSimilarity(similarityOne));
    LogMergePolicy lmp = (LogMergePolicy) iw.getConfig().getMergePolicy();
    lmp.setMergeFactor(3);
    lmp.setUseCompoundFile(true);
    lmp.setUseCompoundDocStore(true);
    iw.close();
  }
=======
private void createIndex(Directory dir) throws IOException {
    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.CREATE)
        .setMaxBufferedDocs(5).setSimilarity(similarityOne));
    LogMergePolicy lmp = (LogMergePolicy) iw.getConfig().getMergePolicy();
    lmp.setMergeFactor(3);
    lmp.setUseCompoundFile(true);
    iw.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955239/fstmerge_var2_4229337522148344870

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955257/fstmerge_var1_4083422315364388674
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955257/fstmerge_base_8578553030837152525
private void addDocs(Directory dir, int ndocs, boolean compound)
      throws IOException {
    IndexWriterConfig conf = new IndexWriterConfig(
            TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.APPEND)
            .setMaxBufferedDocs(5).setSimilarity(similarityOne);
    LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
    lmp.setMergeFactor(3);
    lmp.setUseCompoundFile(compound);
    lmp.setUseCompoundDocStore(compound);
    IndexWriter iw = new IndexWriter(dir, conf);
    for (int i = 0; i < ndocs; i++) {
      iw.addDocument(newDoc());
    }
    iw.close();
  }
=======
private void addDocs(Directory dir, int ndocs, boolean compound)
      throws IOException {
    IndexWriterConfig conf = new IndexWriterConfig(
            TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.APPEND)
            .setMaxBufferedDocs(5).setSimilarity(similarityOne);
    LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
    lmp.setMergeFactor(3);
    lmp.setUseCompoundFile(compound);
    IndexWriter iw = new IndexWriter(dir, conf);
    for (int i = 0; i < ndocs; i++) {
      iw.addDocument(newDoc());
    }
    iw.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955257/fstmerge_var2_5682993028171543670

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testSimpleCase() throws IOException {
    // main directory
    Directory dir = newDirectory();
    // two auxiliary directories
    Directory aux = newDirectory();
    Directory aux2 = newDirectory();

    IndexWriter writer = null;

    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,
        new MockAnalyzer())
        .setOpenMode(OpenMode.CREATE));
    // add 100 documents
    addDocs(writer, 100);
    assertEquals(100, writer.maxDoc());
    writer.close();
    _TestUtil.checkIndex(dir);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955270/fstmerge_var1_2413598311457841555
    writer = newWriter(
        aux,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
            setOpenMode(OpenMode.CREATE).
            setMergePolicy(newLogMergePolicy(false))
    );
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955270/fstmerge_base_4716105201550223639
    writer = newWriter(aux, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
=======
    writer = newWriter(aux, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955270/fstmerge_var2_1141610592214666957
    // add 40 documents in separate files
    addDocs(writer, 40);
    assertEquals(40, writer.maxDoc());
    writer.close();

    writer = newWriter(aux2, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
    // add 40 documents in compound files
    addDocs2(writer, 50);
    assertEquals(50, writer.maxDoc());
    writer.close();

    // test doc count before segments are merged
    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
    assertEquals(100, writer.maxDoc());
    writer.addIndexes(aux, aux2);
    assertEquals(190, writer.maxDoc());
    writer.close();
    _TestUtil.checkIndex(dir);

    // make sure the old index is correct
    verifyNumDocs(aux, 40);

    // make sure the new index is correct
    verifyNumDocs(dir, 190);

    // now add another set in.
    Directory aux3 = newDirectory();
    writer = newWriter(aux3, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    // add 40 documents
    addDocs(writer, 40);
    assertEquals(40, writer.maxDoc());
    writer.close();

    // test doc count before segments are merged/index is optimized
    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
    assertEquals(190, writer.maxDoc());
    writer.addIndexes(aux3);
    assertEquals(230, writer.maxDoc());
    writer.close();

    // make sure the new index is correct
    verifyNumDocs(dir, 230);

    verifyTermDocs(dir, new Term("content", "aaa"), 180);

    verifyTermDocs(dir, new Term("content", "bbb"), 50);

    // now optimize it.
    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
    writer.optimize();
    writer.close();

    // make sure the new index is correct
    verifyNumDocs(dir, 230);

    verifyTermDocs(dir, new Term("content", "aaa"), 180);

    verifyTermDocs(dir, new Term("content", "bbb"), 50);

    // now add a single document
    Directory aux4 = newDirectory();
    writer = newWriter(aux4, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    addDocs2(writer, 1);
    writer.close();

    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
    assertEquals(230, writer.maxDoc());
    writer.addIndexes(aux4);
    assertEquals(231, writer.maxDoc());
    writer.close();

    verifyNumDocs(dir, 231);

    verifyTermDocs(dir, new Term("content", "bbb"), 51);
    dir.close();
    aux.close();
    aux2.close();
    aux3.close();
    aux4.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testWithPendingDeletes() throws IOException {
    // main directory
    Directory dir = newDirectory();
    // auxiliary directory
    Directory aux = newDirectory();

    setUpDirs(dir, aux);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955276/fstmerge_var1_1606221621516704297
    IndexWriter writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
    writer.addIndexes(aux);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955276/fstmerge_base_8838752446894471543
    IndexWriter writer = newWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));

    writer.addIndexes(new Directory[] {aux});
=======
    IndexWriter writer = newWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
    writer.addIndexes(new Directory[] {aux});
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955276/fstmerge_var2_8175629484733528181

    // Adds 10 docs, then replaces them with another 10
    // docs, so 10 pending deletes:
    for (int i = 0; i < 20; i++) {
      Document doc = new Document();
      doc.add(newField("id", "" + (i % 10), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(newField("content", "bbb " + i, Field.Store.NO,
                        Field.Index.ANALYZED));
      writer.updateDocument(new Term("id", "" + (i%10)), doc);
    }
    // Deletes one of the 10 added docs, leaving 9:
    PhraseQuery q = new PhraseQuery();
    q.add(new Term("content", "bbb"));
    q.add(new Term("content", "14"));
    writer.deleteDocuments(q);

    writer.optimize();
    writer.commit();

    verifyNumDocs(dir, 1039);
    verifyTermDocs(dir, new Term("content", "aaa"), 1030);
    verifyTermDocs(dir, new Term("content", "bbb"), 9);

    writer.close();
    dir.close();
    aux.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testAddSelf() throws IOException {
    // main directory
    Directory dir = newDirectory();
    // auxiliary directory
    Directory aux = newDirectory();

    IndexWriter writer = null;

    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    // add 100 documents
    addDocs(writer, 100);
    assertEquals(100, writer.maxDoc());
    writer.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955290/fstmerge_var1_5880198352363860691
    writer = newWriter(
        aux,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
            setOpenMode(OpenMode.CREATE).
            setMaxBufferedDocs(1000).
            setMergePolicy(newLogMergePolicy(false))
    );
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955290/fstmerge_base_7071810938552254598
    writer = newWriter(aux, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(1000));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
=======
    writer = newWriter(aux, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(1000));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955290/fstmerge_var2_7780176044431772954
    // add 140 documents in separate files
    addDocs(writer, 40);
    writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955290/fstmerge_var1_5880198352363860691
    writer = newWriter(
        aux,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
            setOpenMode(OpenMode.CREATE).
            setMaxBufferedDocs(1000).
            setMergePolicy(newLogMergePolicy(false))
    );
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955290/fstmerge_base_7071810938552254598
    writer = newWriter(aux, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(1000));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
=======
    writer = newWriter(aux, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(1000));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955290/fstmerge_var2_7780176044431772954
    addDocs(writer, 100);
    writer.close();

    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
    try {
      // cannot add self
      writer.addIndexes(aux, dir);
      assertTrue(false);
    }
    catch (IllegalArgumentException e) {
      assertEquals(100, writer.maxDoc());
    }
    writer.close();

    // make sure the index is correct
    verifyNumDocs(dir, 100);
    dir.close();
    aux.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
Conflict type: LineBasedMCFd
Conflict body: 
private void setUpDirs(Directory dir, Directory aux) throws IOException {
    IndexWriter writer = null;

    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(1000));
    // add 1000 documents in 1 segment
    addDocs(writer, 1000);
    assertEquals(1000, writer.maxDoc());
    assertEquals(1, writer.getSegmentCount());
    writer.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955357/fstmerge_var1_5538790104602973612
    writer = newWriter(
        aux,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
            setOpenMode(OpenMode.CREATE).
            setMaxBufferedDocs(1000).
            setMergePolicy(newLogMergePolicy(false, 10))
    );
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955357/fstmerge_base_3362276901298841556
    writer = newWriter(aux, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(100));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
=======
    writer = newWriter(aux, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(100));
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955357/fstmerge_var2_7549753718916374683
    // add 30 documents in 3 segments
    for (int i = 0; i < 3; i++) {
      addDocs(writer, 10);
      writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955357/fstmerge_var1_5538790104602973612
      writer = newWriter(
          aux,
          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
              setOpenMode(OpenMode.APPEND).
              setMaxBufferedDocs(1000).
              setMergePolicy(newLogMergePolicy(false, 10))
      );
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955357/fstmerge_base_3362276901298841556
      writer = newWriter(aux, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(100));
      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
=======
      writer = newWriter(aux, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(100));
      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955357/fstmerge_var2_7549753718916374683
    }
    assertEquals(30, writer.maxDoc());
    assertEquals(3, writer.getSegmentCount());
    writer.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testEmptySimpleIntBlocks() throws Exception {
    Directory dir = newDirectory();

    IntStreamFactory f = new MockFixedIntBlockCodec(128).getIntFactory();
    IntIndexOutput out = f.createOutput(dir, "test");

    // write no ints
    out.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955437/fstmerge_var1_4324071703928632269
    IntIndexInput in = f.openInput(dir, "test");
    in.reader();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955437/fstmerge_base_7763094800926130583
    IntIndexInput in = new SimpleIntBlockIndexInput(dir, "test", 128);
    IntIndexInput.Reader r = in.reader();
=======
    IntIndexInput in = new SimpleIntBlockIndexInput(dir, "test", 128);
    in.reader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955437/fstmerge_var2_660061075704155747
    // read no ints
    in.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/codecs/intblock/TestIntBlockCodec.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955449/fstmerge_var1_4974919963188962814
@Override
  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {

    // Whenever IW opens readers, eg for merging, we have to
    // keep terms order in UTF16:

    return new PreFlexFields(state.dir, state.fieldInfos, state.segmentInfo, state.readBufferSize, state.termsIndexDivisor) {
      @Override
      protected boolean sortTermsByUnicode() {
        // We carefully peek into stack track above us: if
        // we are part of a "merge", we must sort by UTF16:
        boolean unicodeSortOrder = true;

        StackTraceElement[] trace = new Exception().getStackTrace();
        for (int i = 0; i < trace.length; i++) {
          //System.out.println(trace[i].getClassName());
          if ("merge".equals(trace[i].getMethodName())) {
            unicodeSortOrder = false;
            if (LuceneTestCase.VERBOSE) {
              System.out.println("NOTE: PreFlexRW codec: forcing legacy UTF16 term sort order");
            }
            break;
          }
        }

        return unicodeSortOrder;
      }
    };
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955449/fstmerge_base_3439388470640634977
=======
@Override
  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {

    // Whenever IW opens readers, eg for merging, we have to
    // keep terms order in UTF16:

    return new PreFlexFields(state.dir, state.fieldInfos, state.segmentInfo, state.readBufferSize, state.termsIndexDivisor) {
      @Override
      protected boolean sortTermsByUnicode() {
        // We carefully peek into stack track above us: if
        // we are part of a "merge", we must sort by UTF16:
        boolean unicodeSortOrder = true;

        StackTraceElement[] trace = new Exception().getStackTrace();
        for (int i = 0; i < trace.length; i++) {
          //System.out.println(trace[i].getClassName());
          if ("merge".equals(trace[i].getMethodName())) {
            unicodeSortOrder = false;
            if (LuceneTestCaseJ4.VERBOSE) {
              System.out.println("NOTE: PreFlexRW codec: forcing legacy UTF16 term sort order");
            }
            break;
          }
        }

        return unicodeSortOrder;
      }
    };
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955449/fstmerge_var2_7771678946525268721

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/codecs/preflexrw/PreFlexRWCodec.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955580/fstmerge_var1_5452412793320485702
@Test
  public void testSurrogatesOrder() throws Exception {
    Directory dir = newDirectory();
    RandomIndexWriter w = new RandomIndexWriter(random,
                                                dir,
                                                newIndexWriterConfig( TEST_VERSION_CURRENT,
                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));

    final int numField = _TestUtil.nextInt(random, 2, 5);

    int uniqueTermCount = 0;

    int tc = 0;

    List<Term> fieldTerms = new ArrayList<Term>();

    for(int f=0;f<numField;f++) {
      String field = "f" + f;
      final int numTerms = 10000 * RANDOM_MULTIPLIER;

      final Set<String> uniqueTerms = new HashSet<String>();

      for(int i=0;i<numTerms;i++) {
        String term = getRandomString(random) + "_ " + (tc++);
        uniqueTerms.add(term);
        fieldTerms.add(new Term(field, term));
        Document doc = new Document();
        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));
        w.addDocument(doc);
      }
      uniqueTermCount += uniqueTerms.size();
    }

    IndexReader reader = w.getReader();

    if (VERBOSE) {
      Collections.sort(fieldTerms, termAsUTF16Comparator);

      System.out.println("\nTEST: UTF16 order");
      for(Term t: fieldTerms) {
        System.out.println("  " + toHexString(t));
      }
    }

    // sorts in code point order:
    Collections.sort(fieldTerms);

    if (VERBOSE) {
      System.out.println("\nTEST: codepoint order");
      for(Term t: fieldTerms) {
        System.out.println("  " + toHexString(t));
      }
    }

    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);

    //SegmentInfo si = makePreFlexSegment(r, "_0", dir, fieldInfos, codec, fieldTerms);

    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));
    //assertNotNull(fields);

    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);
    doTestSeekExists(random, fieldTerms, reader);
    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);

    reader.close();
    w.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955580/fstmerge_base_2209781519873545260
=======
@Test
  public void testSurrogatesOrder() throws Exception {
    Random r = newRandom();

    Directory dir = new MockRAMDirectory();
    RandomIndexWriter w = new RandomIndexWriter(r,
                                                dir,
                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,
                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));

    final int numField = _TestUtil.nextInt(r, 2, 5);

    int uniqueTermCount = 0;

    int tc = 0;

    List<Term> fieldTerms = new ArrayList<Term>();

    for(int f=0;f<numField;f++) {
      String field = "f" + f;
      final int numTerms = 10000 * RANDOM_MULTIPLIER;

      final Set<String> uniqueTerms = new HashSet<String>();

      for(int i=0;i<numTerms;i++) {
        String term = getRandomString(r) + "_ " + (tc++);
        uniqueTerms.add(term);
        fieldTerms.add(new Term(field, term));
        Document doc = new Document();
        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));
        w.addDocument(doc);
      }
      uniqueTermCount += uniqueTerms.size();
    }

    IndexReader reader = w.getReader();

    if (VERBOSE) {
      Collections.sort(fieldTerms, termAsUTF16Comparator);

      System.out.println("\nTEST: UTF16 order");
      for(Term t: fieldTerms) {
        System.out.println("  " + toHexString(t));
      }
    }

    // sorts in code point order:
    Collections.sort(fieldTerms);

    if (VERBOSE) {
      System.out.println("\nTEST: codepoint order");
      for(Term t: fieldTerms) {
        System.out.println("  " + toHexString(t));
      }
    }

    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);

    //SegmentInfo si = makePreFlexSegment(r, "_0", dir, fieldInfos, codec, fieldTerms);

    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));
    //assertNotNull(fields);

    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);
    doTestSeekExists(r, fieldTerms, reader);
    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);

    reader.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627955580/fstmerge_var2_5426566140967509956

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {
      if (termArrays.size() == 0)                  // optimize zero-term case
        return null;

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_var1_7165644428044877187
      final Bits delDocs = reader.getDeletedDocs();
      
      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];

      for (int pos=0; pos<postingsFreqs.length; pos++) {
        Term[] terms = termArrays.get(pos);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_base_4219901606959183647
      DocsAndPositionsEnum[] postings = new DocsAndPositionsEnum[termArrays.size()];
      for (int i=0; i<postings.length; i++) {
        Term[] terms = termArrays.get(i);
=======
      final Bits delDocs = MultiFields.getDeletedDocs(reader);
      
      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];

      for (int i=0; i<postingsFreqs.length; i++) {
        Term[] terms = termArrays.get(i);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_var2_7082322368123525540

        final DocsAndPositionsEnum postingsEnum;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_base_4219901606959183647
=======
        int docFreq;

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_var2_7082322368123525540
        if (terms.length > 1) {
          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_var1_7165644428044877187

          // coarse -- this overcounts since a given doc can
          // have more than one terms:
          docFreq = 0;
          for(int termIdx=0;termIdx<terms.length;termIdx++) {
            docFreq += reader.docFreq(terms[termIdx]);
          }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_base_4219901606959183647
=======

          // coarse -- this overcounts since a given doc can
          // have more than one terms:
          docFreq = 0;
          for(int j=0;j<terms.length;j++) {
            docFreq += reader.docFreq(terms[i]);
          }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_var2_7082322368123525540
        } else {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_var1_7165644428044877187
          final Term term = terms[0];
          postingsEnum = reader.termPositionsEnum(delDocs,
                                                  term.field(),
                                                  term.bytes());

          if (postingsEnum == null) {
            if (reader.termDocsEnum(delDocs, term.field(), term.bytes()) != null) {
              // term does exist, but has no positions
              throw new IllegalStateException("field \"" + term.field() + "\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=" + term.text() + ")");
            } else {
              // term does not exist
              return null;
            }
          }

          docFreq = reader.docFreq(term.field(), term.bytes());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_base_4219901606959183647
          postingsEnum = reader.termPositionsEnum(MultiFields.getDeletedDocs(reader),
                                                  terms[0].field(),
                                                  new BytesRef(terms[0].text()));
=======
          final BytesRef text = new BytesRef(terms[0].text());
          postingsEnum = reader.termPositionsEnum(delDocs,
                                                  terms[0].field(),
                                                  text);

          if (postingsEnum == null) {
            if (MultiFields.getTermDocsEnum(reader, delDocs, terms[0].field(), text) != null) {
              // term does exist, but has no positions
              throw new IllegalStateException("field \"" + terms[0].field() + "\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=" + terms[0].text() + ")");
            } else {
              // term does not exist
              return null;
            }
          }

          docFreq = reader.docFreq(terms[0].field(), text);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_var2_7082322368123525540
        }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_var1_7165644428044877187
        postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(pos).intValue());
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_base_4219901606959183647
        if (postingsEnum == null) {
          return null;
        }
=======
        postingsFreqs[i] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(i).intValue());
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_var2_7082322368123525540

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_var1_7165644428044877187
      // sort by increasing docFreq order
      if (slop == 0) {
        ArrayUtil.quickSort(postingsFreqs);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_base_4219901606959183647
        postings[i] = postingsEnum;
=======
      // sort by increasing docFreq order
      if (slop == 0) {
        Arrays.sort(postingsFreqs);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_var2_7082322368123525540
      }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_base_4219901606959183647
      if (slop == 0)
        return new ExactPhraseScorer(this, postings, getPositions(), similarity,
                                     reader.norms(field));
      else
        return new SloppyPhraseScorer(this, postings, getPositions(), similarity,
=======
      if (slop == 0) {
        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,
                                                    reader.norms(field));
        if (s.noDocs) {
          return null;
        } else {
          return s;
        }
      } else {
        return new SloppyPhraseScorer(this, postingsFreqs, similarity,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_var2_7082322368123525540
                                      slop, reader.norms(field));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_base_4219901606959183647
=======
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956067/fstmerge_var2_7082322368123525540
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public Explanation explain(IndexReader reader, int doc)
      throws IOException {
      ComplexExplanation result = new ComplexExplanation();
      result.setDescription("weight("+getQuery()+" in "+doc+"), product of:");

      Explanation idfExpl = new Explanation(idf, "idf("+getQuery()+")");

      // explain query weight
      Explanation queryExpl = new Explanation();
      queryExpl.setDescription("queryWeight(" + getQuery() + "), product of:");

      Explanation boostExpl = new Explanation(getBoost(), "boost");
      if (getBoost() != 1.0f)
        queryExpl.addDetail(boostExpl);

      queryExpl.addDetail(idfExpl);

      Explanation queryNormExpl = new Explanation(queryNorm,"queryNorm");
      queryExpl.addDetail(queryNormExpl);

      queryExpl.setValue(boostExpl.getValue() *
                         idfExpl.getValue() *
                         queryNormExpl.getValue());

      result.addDetail(queryExpl);

      // explain field weight
      ComplexExplanation fieldExpl = new ComplexExplanation();
      fieldExpl.setDescription("fieldWeight("+getQuery()+" in "+doc+
                               "), product of:");

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956073/fstmerge_var1_3029415023005608240
      Scorer scorer = scorer(reader, true, false);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956073/fstmerge_base_2590570571727134028
      PhraseScorer scorer = (PhraseScorer) scorer(reader, true, false);
=======
      Scorer scorer = (Scorer) scorer(reader, true, false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956073/fstmerge_var2_1440512078790482890
      if (scorer == null) {
        return new Explanation(0.0f, "no matching docs");
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956073/fstmerge_base_2590570571727134028
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956073/fstmerge_var2_1440512078790482890
      Explanation tfExplanation = new Explanation();
      int d = scorer.advance(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956073/fstmerge_var1_3029415023005608240
      float phraseFreq;
      if (d == doc) {
        phraseFreq = scorer.freq();
      } else {
        phraseFreq = 0.0f;
      }

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956073/fstmerge_base_2590570571727134028
      float phraseFreq = (d == doc) ? scorer.currentFreq() : 0.0f;
=======
      float phraseFreq;
      if (d == doc) {
        if (slop == 0) {
          phraseFreq = ((ExactPhraseScorer) scorer).currentFreq();
        } else {
          phraseFreq = ((SloppyPhraseScorer) scorer).currentFreq();
        }
      } else {
        phraseFreq = 0.0f;
      }

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956073/fstmerge_var2_1440512078790482890
      tfExplanation.setValue(similarity.tf(phraseFreq));
      tfExplanation.setDescription("tf(phraseFreq=" + phraseFreq + ")");
      fieldExpl.addDetail(tfExplanation);
      fieldExpl.addDetail(idfExpl);

      Explanation fieldNormExpl = new Explanation();
      byte[] fieldNorms = reader.norms(field);
      float fieldNorm =
        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;
      fieldNormExpl.setValue(fieldNorm);
      fieldNormExpl.setDescription("fieldNorm(field="+field+", doc="+doc+")");
      fieldExpl.addDetail(fieldNormExpl);

      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));
      fieldExpl.setValue(tfExplanation.getValue() *
                         idfExpl.getValue() *
                         fieldNormExpl.getValue());

      result.addDetail(fieldExpl);
      result.setMatch(fieldExpl.getMatch());

      // combine them
      result.setValue(queryExpl.getValue() * fieldExpl.getValue());

      if (queryExpl.getValue() == 1.0f)
        return fieldExpl;

      return result;
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public UnionDocsAndPositionsEnum(IndexReader indexReader, Term[] terms) throws IOException {
    List<DocsAndPositionsEnum> docsEnums = new LinkedList<DocsAndPositionsEnum>();
    final Bits delDocs = indexReader.getDeletedDocs();
    for (int i = 0; i < terms.length; i++) {
      DocsAndPositionsEnum postings = indexReader.termPositionsEnum(delDocs,
                                                                    terms[i].field(),
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956150/fstmerge_base_6096424126606306815
                                                                    new BytesRef(terms[i].text()));
=======
                                                                    terms[i].bytes());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956150/fstmerge_var2_6285042599934979931
      if (postings != null) {
        docsEnums.add(postings);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956150/fstmerge_var1_4478183194924206962
      } else {
        if (indexReader.termDocsEnum(delDocs, terms[i].field(), terms[i].bytes()) != null) {
          // term does exist, but has no positions
          throw new IllegalStateException("field \"" + terms[i].field() + "\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=" + terms[i].text() + ")");
        }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956150/fstmerge_base_6096424126606306815
=======
      } else {
        if (MultiFields.getTermDocsEnum(indexReader, delDocs, terms[i].field(), terms[i].bytes()) != null) {
          // term does exist, but has no positions
          throw new IllegalStateException("field \"" + terms[i].field() + "\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=" + terms[i].text() + ")");
        }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956150/fstmerge_var2_6285042599934979931
      }
    }

    _queue = new DocsQueue(docsEnums);
    _posList = new IntQueue();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956463/fstmerge_var1_7405576536597611738
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956463/fstmerge_base_1017012476688339768
public SingleTermsEnum(IndexReader reader, Term singleTerm) throws IOException {
    super(reader, singleTerm.field());
    singleRef = new BytesRef(singleTerm.text());
    setInitialSeekTerm(singleRef);
  }
=======
public SingleTermsEnum(IndexReader reader, Term singleTerm) throws IOException {
    super(reader, singleTerm.field());
    singleRef = singleTerm.bytes();
    setInitialSeekTerm(singleRef);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627956463/fstmerge_var2_4860071127225285072

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/SingleTermsEnum.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957185/fstmerge_var1_1091109672274714181
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957185/fstmerge_base_9207712515678879535
AutomatonTermsEnum(ByteRunAutomaton runAutomaton,
                     String field, IndexReader reader,
                     boolean finite, BytesRef commonSuffixRef)
      throws IOException {
    super(reader, field);
    this.automaton = runAutomaton.getAutomaton();
    this.finite = finite;

    this.runAutomaton = runAutomaton;
    if (finite) {
      // don't use suffix w/ finite DFAs
      this.commonSuffixRef = null;
    } else if (commonSuffixRef == null) {
      // compute now
      this.commonSuffixRef = SpecialOperations.getCommonSuffixBytesRef(automaton);
    } else {
      // precomputed
      this.commonSuffixRef = commonSuffixRef;
    }

    // build a cache of sorted transitions for every state
    allTransitions = new Transition[runAutomaton.getSize()][];
    for (State state : this.automaton.getNumberedStates()) {
      state.sortTransitions(Transition.CompareByMinMaxThenDestUTF8InUTF16Order);
      state.trimTransitionsArray();
      allTransitions[state.getNumber()] = state.transitionsArray;
    }
    // used for path tracking, where each bit is a numbered state.
    visited = new long[runAutomaton.getSize()];

    setUseTermsCache(finite);
    termComp = getComparator();
  }
=======
AutomatonTermsEnum(ByteRunAutomaton runAutomaton,
                     String field, IndexReader reader,
                     boolean finite, BytesRef commonSuffixRef)
      throws IOException {
    super(reader, field);
    this.automaton = runAutomaton.getAutomaton();
    this.finite = finite;

    this.runAutomaton = runAutomaton;
    if (finite) {
      // don't use suffix w/ finite DFAs
      this.commonSuffixRef = null;
    } else if (commonSuffixRef == null) {
      // compute now
      this.commonSuffixRef = SpecialOperations.getCommonSuffixBytesRef(automaton);
    } else {
      // precomputed
      this.commonSuffixRef = commonSuffixRef;
    }

    // build a cache of sorted transitions for every state
    allTransitions = new Transition[runAutomaton.getSize()][];
    for (State state : this.automaton.getNumberedStates()) {
      state.sortTransitions(Transition.CompareByMinMaxThenDest);
      state.trimTransitionsArray();
      allTransitions[state.getNumber()] = state.transitionsArray;
    }
    // used for path tracking, where each bit is a numbered state.
    visited = new long[runAutomaton.getSize()];

    setUseTermsCache(finite);
    termComp = getComparator();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957185/fstmerge_var2_5943818432966836746

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/AutomatonTermsEnum.java
Conflict type: LineBasedMCFd
Conflict body: 
private void setLinear(int position) {
    int state = runAutomaton.getInitialState();
    int maxInterval = 0xff;
    for (int i = 0; i < position; i++) {
      state = runAutomaton.step(state, seekBytesRef.bytes[i] & 0xff);
      assert state >= 0: "state=" + state;
    }
    for (int i = 0; i < allTransitions[state].length; i++) {
      Transition t = allTransitions[state][i];
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957204/fstmerge_base_4100345352959561555
      if (compareToUTF16(t.getMin(), (seekBytesRef.bytes[position] & 0xff)) <= 0 && 
          compareToUTF16((seekBytesRef.bytes[position] & 0xff), t.getMax()) <= 0) {
=======
      if (t.getMin() <= (seekBytesRef.bytes[position] & 0xff) && 
          (seekBytesRef.bytes[position] & 0xff) <= t.getMax()) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957204/fstmerge_var2_5957213339527949478
        maxInterval = t.getMax();
        break;
      }
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957204/fstmerge_var1_8428724148783426046
    // 0xff terms don't get the optimization... not worth the trouble.
    if (maxInterval != 0xff)
      maxInterval++;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957204/fstmerge_base_4100345352959561555
    // 0xef terms don't get the optimization... not worth the trouble.
    if (maxInterval != 0xef)
      maxInterval = incrementUTF16(maxInterval);
=======
    // 0xff terms don't get the optimization... not worth the trouble.
    if (maxInterval != 0xff)
      maxInterval = incrementUTF8(maxInterval);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957204/fstmerge_var2_5957213339527949478
    int length = position + 1; /* position + maxTransition */
    if (linearUpperBound.bytes.length < length)
      linearUpperBound.bytes = new byte[length];
    System.arraycopy(seekBytesRef.bytes, 0, linearUpperBound.bytes, 0, position);
    linearUpperBound.bytes[position] = (byte) maxInterval;
    linearUpperBound.length = length;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/AutomatonTermsEnum.java
Conflict type: LineBasedMCFd
Conflict body: 
private boolean nextString(int state, int position) {
    /* 
     * the next lexicographic character must be greater than the existing
     * character, if it exists.
     */
    int c = 0;
    if (position < seekBytesRef.length) {
      c = seekBytesRef.bytes[position] & 0xff;
      // if the next byte is 0xff and is not part of the useful portion,
      // then by definition it puts us in a reject state, and therefore this
      // path is dead. there cannot be any higher transitions. backtrack.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957212/fstmerge_var1_2541319263059294775
      if (c++ == 0xff)
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957212/fstmerge_base_3438145549337198396
      c = incrementUTF16(c);
      if (c == -1)
=======
      c = incrementUTF8(c);
      if (c == -1)
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957212/fstmerge_var2_5142878438542601887
        return false;
    }

    seekBytesRef.length = position;
    visited[state] = curGen;

    Transition transitions[] = allTransitions[state];

    // find the minimal path (lexicographic order) that is >= c
    
    for (int i = 0; i < transitions.length; i++) {
      Transition transition = transitions[i];
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957212/fstmerge_base_3438145549337198396
      if (compareToUTF16(transition.getMax(), c) >= 0) {
        int nextChar = compareToUTF16(c, transition.getMin()) > 0 ? c : transition.getMin();
=======
      if (transition.getMax() >= c) {
        int nextChar = Math.max(c, transition.getMin());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957212/fstmerge_var2_5142878438542601887
        // append either the next sequential char, or the minimum transition
        seekBytesRef.grow(seekBytesRef.length + 1);
        seekBytesRef.length++;
        seekBytesRef.bytes[seekBytesRef.length - 1] = (byte) nextChar;
        state = transition.getDest().getNumber();
        /* 
         * as long as is possible, continue down the minimal path in
         * lexicographic order. if a loop or accept state is encountered, stop.
         */
        while (visited[state] != curGen && !runAutomaton.isAccept(state)) {
          visited[state] = curGen;
          /* 
           * Note: we work with a DFA with no transitions to dead states.
           * so the below is ok, if it is not an accept state,
           * then there MUST be at least one transition.
           */
          transition = allTransitions[state][0];
          state = transition.getDest().getNumber();
          // we found a loop, record it for faster enumeration
          if (!finite && !linear && visited[state] == curGen) {
            linear = true;
            infinitePosition = seekBytesRef.length;
          }
          // append the minimum transition
          seekBytesRef.grow(seekBytesRef.length + 1);
          seekBytesRef.length++;
          seekBytesRef.bytes[seekBytesRef.length - 1] = (byte) transition.getMin();
        }
        return true;
      }
    }
    return false;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/AutomatonTermsEnum.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957217/fstmerge_var1_4063670112641672018
private int backtrack(int position) {
    while (position-- > 0) {
      int nextChar = seekBytesRef.bytes[position] & 0xff;
      // if a character is 0xff its a dead-end too,
      // because there is no higher character in binary sort order.
      if (nextChar++ != 0xff) {
        seekBytesRef.bytes[position] = (byte) nextChar;
        seekBytesRef.length = position+1;
        return position;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957217/fstmerge_base_6602910464114684153
private boolean backtrack(int position) {
    while (position > 0) {
      int nextChar = seekBytesRef.bytes[position - 1] & 0xff;
      // if a character is 0xef its a dead-end too,
      // because there is no higher character in UTF-16 sort order.
      nextChar = incrementUTF16(nextChar);
      if (nextChar != -1) {
        seekBytesRef.bytes[position - 1] = (byte) nextChar;
        seekBytesRef.length = position;
        return true;
=======
private boolean backtrack(int position) {
    while (position > 0) {
      int nextChar = seekBytesRef.bytes[position - 1] & 0xff;
      // if a character is 0xff its a dead-end too,
      // because there is no higher character in UTF-8 sort order.
      nextChar = incrementUTF8(nextChar);
      if (nextChar != -1) {
        seekBytesRef.bytes[position - 1] = (byte) nextChar;
        seekBytesRef.length = position;
        return true;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957217/fstmerge_var2_2428309536704914818
      }
    }
    return -1; /* all solutions exhausted */
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/AutomatonTermsEnum.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957331/fstmerge_var1_8295325659658774843
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957331/fstmerge_base_7243301135628576863
@Override  
  protected TermsEnum getTermsEnum(IndexReader reader) throws IOException {
    if (prefix.text().length() == 0) {
      // no prefix -- match all terms for this field:
      final Terms terms = MultiFields.getTerms(reader, getField());
      return (terms != null) ? terms.iterator() : TermsEnum.EMPTY;
    }
    return new PrefixTermsEnum(reader, prefix);
  }
=======
@Override  
  protected TermsEnum getTermsEnum(IndexReader reader) throws IOException {
    if (prefix.bytes().length == 0) {
      // no prefix -- match all terms for this field:
      final Terms terms = MultiFields.getTerms(reader, getField());
      return (terms != null) ? terms.iterator() : TermsEnum.EMPTY;
    }
    return new PrefixTermsEnum(reader, prefix);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957331/fstmerge_var2_38436853144480522

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/PrefixQuery.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957361/fstmerge_var1_8325057702565319972
private void processTerms(BytesRef[] queryTerms) {
    if (queryTerms != null) {
      ArrayUtil.quickSort(queryTerms);
      Map<BytesRef,Integer> tmpSet = new HashMap<BytesRef,Integer>(queryTerms.length);
      //filter out duplicates
      List<BytesRef> tmpList = new ArrayList<BytesRef>(queryTerms.length);
      List<Integer> tmpFreqs = new ArrayList<Integer>(queryTerms.length);
      int j = 0;
      for (int i = 0; i < queryTerms.length; i++) {
        BytesRef term = queryTerms[i];
        Integer position = tmpSet.get(term);
        if (position == null) {
          tmpSet.put(term, Integer.valueOf(j++));
          tmpList.add(term);
          tmpFreqs.add(Integer.valueOf(1));
        }       
        else {
          Integer integer = tmpFreqs.get(position.intValue());
          tmpFreqs.set(position.intValue(), Integer.valueOf(integer.intValue() + 1));          
        }
      }
      terms = tmpList.toArray(terms);
      //termFreqs = (int[])tmpFreqs.toArray(termFreqs);
      termFreqs = new int[tmpFreqs.size()];
      int i = 0;
      for (final Integer integer : tmpFreqs) {
        termFreqs[i++] = integer.intValue();
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957361/fstmerge_base_5879466332085037037
=======
private void processTerms(BytesRef[] queryTerms) {
    if (queryTerms != null) {
      Arrays.sort(queryTerms);
      Map<BytesRef,Integer> tmpSet = new HashMap<BytesRef,Integer>(queryTerms.length);
      //filter out duplicates
      List<BytesRef> tmpList = new ArrayList<BytesRef>(queryTerms.length);
      List<Integer> tmpFreqs = new ArrayList<Integer>(queryTerms.length);
      int j = 0;
      for (int i = 0; i < queryTerms.length; i++) {
        BytesRef term = queryTerms[i];
        Integer position = tmpSet.get(term);
        if (position == null) {
          tmpSet.put(term, Integer.valueOf(j++));
          tmpList.add(term);
          tmpFreqs.add(Integer.valueOf(1));
        }       
        else {
          Integer integer = tmpFreqs.get(position.intValue());
          tmpFreqs.set(position.intValue(), Integer.valueOf(integer.intValue() + 1));          
        }
      }
      terms = tmpList.toArray(terms);
      //termFreqs = (int[])tmpFreqs.toArray(termFreqs);
      termFreqs = new int[tmpFreqs.size()];
      int i = 0;
      for (final Integer integer : tmpFreqs) {
        termFreqs[i++] = integer.intValue();
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957361/fstmerge_var2_1672702419072634545

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/QueryTermVector.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957438/fstmerge_var1_1443336305033583921
      DocsEnum docs = reader.termDocsEnum(reader.getDeletedDocs(),
                                          term.field(),
                                          term.bytes());

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957438/fstmerge_base_2433571459472652009
      // NOTE: debateably, the caller should never pass in a
      // multi reader...
      DocsEnum docs = MultiFields.getTermDocsEnum(reader, MultiFields.getDeletedDocs(reader), term.field(), new BytesRef(term.text()));
=======
      // NOTE: debateably, the caller should never pass in a
      // multi reader...
      DocsEnum docs = MultiFields.getTermDocsEnum(reader, MultiFields.getDeletedDocs(reader), term.field(), term.bytes());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957438/fstmerge_var2_7808548960479641966
      if (docs == null) {
        return null;
      }

      return new TermScorer(this, docs, similarity, reader.norms(term.field()));
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/TermQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public Explanation explain(IndexReader reader, int doc)
      throws IOException {

      ComplexExplanation result = new ComplexExplanation();
      result.setDescription("weight("+getQuery()+" in "+doc+"), product of:");

      Explanation expl = new Explanation(idf, idfExp.explain());

      // explain query weight
      Explanation queryExpl = new Explanation();
      queryExpl.setDescription("queryWeight(" + getQuery() + "), product of:");

      Explanation boostExpl = new Explanation(getBoost(), "boost");
      if (getBoost() != 1.0f)
        queryExpl.addDetail(boostExpl);
      queryExpl.addDetail(expl);

      Explanation queryNormExpl = new Explanation(queryNorm,"queryNorm");
      queryExpl.addDetail(queryNormExpl);

      queryExpl.setValue(boostExpl.getValue() *
                         expl.getValue() *
                         queryNormExpl.getValue());

      result.addDetail(queryExpl);

      // explain field weight
      String field = term.field();
      ComplexExplanation fieldExpl = new ComplexExplanation();
      fieldExpl.setDescription("fieldWeight("+term+" in "+doc+
                               "), product of:");

      Explanation tfExplanation = new Explanation();
      int tf = 0;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957443/fstmerge_var1_923989310564388871
      DocsEnum docs = reader.termDocsEnum(reader.getDeletedDocs(), term.field(), term.bytes());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957443/fstmerge_base_6443050253101137642
      DocsEnum docs = reader.termDocsEnum(MultiFields.getDeletedDocs(reader), term.field(), new BytesRef(term.text()));
=======
      DocsEnum docs = reader.termDocsEnum(MultiFields.getDeletedDocs(reader), term.field(), term.bytes());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957443/fstmerge_var2_6837992501677174082
      if (docs != null) {
          int newDoc = docs.advance(doc);
          if (newDoc == doc) {
            tf = docs.freq();
          }
        tfExplanation.setValue(similarity.tf(tf));
        tfExplanation.setDescription("tf(termFreq("+term+")="+tf+")");
      } else {
        tfExplanation.setValue(0.0f);
        tfExplanation.setDescription("no matching term");
      }
      fieldExpl.addDetail(tfExplanation);
      fieldExpl.addDetail(expl);

      Explanation fieldNormExpl = new Explanation();
      byte[] fieldNorms = reader.norms(field);
      float fieldNorm =
        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;
      fieldNormExpl.setValue(fieldNorm);
      fieldNormExpl.setDescription("fieldNorm(field="+field+", doc="+doc+")");
      fieldExpl.addDetail(fieldNormExpl);
      
      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));
      fieldExpl.setValue(tfExplanation.getValue() *
                         expl.getValue() *
                         fieldNormExpl.getValue());

      result.addDetail(fieldExpl);
      result.setMatch(fieldExpl.getMatch());
      
      // combine them
      result.setValue(queryExpl.getValue() * fieldExpl.getValue());

      if (queryExpl.getValue() == 1.0f)
        return fieldExpl;

      return result;
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/TermQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957686/fstmerge_var1_5943795202096682323
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957686/fstmerge_base_2395728445293361035
public PrefixTermsEnum(IndexReader reader, Term prefix) throws IOException {
    super(reader, prefix.field());
    setInitialSeekTerm(prefixRef = new BytesRef(prefix.text()));
  }
=======
public PrefixTermsEnum(IndexReader reader, Term prefix) throws IOException {
    super(reader, prefix.field());
    setInitialSeekTerm(prefixRef = prefix.bytes());
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627957686/fstmerge_var2_6631796574225458277

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/PrefixTermsEnum.java
Conflict type: LineBasedMCFd
Conflict body: 
private List<ByteRunAutomaton> initAutomata(int maxDistance) {
    final List<ByteRunAutomaton> runAutomata = dfaAtt.automata();
    if (runAutomata.size() <= maxDistance && 
        maxDistance <= LevenshteinAutomata.MAXIMUM_SUPPORTED_DISTANCE) {
      LevenshteinAutomata builder = 
        new LevenshteinAutomata(UnicodeUtil.newString(termText, realPrefixLength, termText.length - realPrefixLength));

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958299/fstmerge_var1_3542691853503098224
      for (int i = runAutomata.size(); i <= maxDistance; i++) {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958299/fstmerge_base_3004609966098897496
      runAutomata = new ArrayList<ByteRunAutomaton>(maxDistance);
      for (int i = 0; i <= maxDistance; i++) {
=======
      final ByteRunAutomaton[] ra = new ByteRunAutomaton[maxDistance + 1];
      for (int i = 0; i <= maxDistance; i++) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958299/fstmerge_var2_586192421686504162
        Automaton a = builder.toAutomaton(i);
        // constant prefix
        if (realPrefixLength > 0) {
          Automaton prefix = BasicAutomata.makeString(
            UnicodeUtil.newString(termText, 0, realPrefixLength));
          a = BasicOperations.concatenate(prefix, a);
        }
        ra[i] = new ByteRunAutomaton(a);
      }
      runAutomata = Arrays.asList(ra);
    }
    return runAutomata;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/FuzzyTermsEnum.java
Conflict type: SameIdFd
Conflict body: 
~~FSTMerge~~ boolean bottomSameReader; ##FSTMerge## ##FSTMerge## private boolean bottomSameReader;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/FieldComparator.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public int compareBottom(int doc) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958895/fstmerge_var1_6996061617442801656
      throw new UnsupportedOperationException();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958895/fstmerge_base_4138056750997141277
      assert bottomSlot != -1;
      int order = termsIndex.getOrd(doc);
      final int cmp = bottomOrd - order;
      if (cmp != 0) {
        return cmp;
      }

      if (bottomValue == null) {
        if (order == 0) {
          // unset
          return 0;
        }
        // bottom wins
        return -1;
      } else if (order == 0) {
        // doc wins
        return 1;
      }
      termsIndex.lookup(order, tempBR);
      return bottomValue.compareTo(tempBR);
=======
      assert bottomSlot != -1;
      if (bottomSameReader) {
        // ord is precisely comparable, even in the equal case
        return bottomOrd - (int) currentDocToOrd.get(doc);
      } else {
        // ord is only approx comparable: if they are not
        // equal, we can use that; if they are equal, we
        // must fallback to compare by value
        final int order = (int) currentDocToOrd.get(doc);
        final int cmp = bottomOrd - order;
        if (cmp != 0) {
          return cmp;
        }

        if (bottomValue == null) {
          if (order == 0) {
            // unset
            return 0;
          }
          // bottom wins
          return -1;
        } else if (order == 0) {
          // doc wins
          return 1;
        }
        termsIndex.lookup(order, tempBR);
        return bottomValue.compareTo(tempBR);
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958895/fstmerge_var2_4095226398203776955
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/FieldComparator.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public void copy(int slot, int doc) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958900/fstmerge_var1_3820291336271753063
      throw new UnsupportedOperationException();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958900/fstmerge_base_8923309398261581216
      final int ord = termsIndex.getOrd(doc);
      if (ord == 0) {
        values[slot] = null;
      } else {
        ords[slot] = ord;
        assert ord >= 0;
        if (values[slot] == null) {
          values[slot] = new BytesRef();
        }
        termsIndex.lookup(ord, values[slot]);
      }
      readerGen[slot] = currentReaderGen;
=======
      final int ord = (int) currentDocToOrd.get(doc);
      if (ord == 0) {
        values[slot] = null;
      } else {
        ords[slot] = ord;
        assert ord >= 0;
        if (values[slot] == null) {
          values[slot] = new BytesRef();
        }
        termsIndex.lookup(ord, values[slot]);
      }
      readerGen[slot] = currentReaderGen;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958900/fstmerge_var2_6629669731841248925
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/FieldComparator.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public FieldComparator setNextReader(IndexReader reader, int docBase) throws IOException {
      termsIndex = FieldCache.DEFAULT.getTermsIndex(reader, field);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958904/fstmerge_var1_4296805561774385388
      final PackedInts.Reader docToOrd = termsIndex.getDocToOrd();
      FieldComparator perSegComp;
      if (docToOrd instanceof Direct8) {
        perSegComp = new ByteOrdComparator(((Direct8) docToOrd).getArray(), termsIndex, docBase);
      } else if (docToOrd instanceof Direct16) {
        perSegComp = new ShortOrdComparator(((Direct16) docToOrd).getArray(), termsIndex, docBase);
      } else if (docToOrd instanceof Direct32) {
        perSegComp = new IntOrdComparator(((Direct32) docToOrd).getArray(), termsIndex, docBase);
      } else {
        perSegComp = new AnyOrdComparator(docToOrd, termsIndex, docBase);
      }

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958904/fstmerge_base_6256315775153759327
=======
      currentDocToOrd = termsIndex.getDocToOrd();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958904/fstmerge_var2_4675042052867232077
      currentReaderGen++;
      if (bottomSlot != -1) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958904/fstmerge_var1_4296805561774385388
        perSegComp.setBottom(bottomSlot);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958904/fstmerge_base_6256315775153759327
        convert(bottomSlot);
        bottomOrd = ords[bottomSlot];
=======
        setBottom(bottomSlot);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958904/fstmerge_var2_4675042052867232077
      }

      return perSegComp;
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/FieldComparator.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public void setBottom(final int bottom) {
      bottomSlot = bottom;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958908/fstmerge_var1_7214170830928982688

      bottomValue = values[bottomSlot];
      if (currentReaderGen == readerGen[bottomSlot]) {
        bottomOrd = ords[bottomSlot];
        bottomSameReader = true;
      } else {
        if (bottomValue == null) {
          // 0 ord is null for all segments
          assert ords[bottomSlot] == 0;
          bottomOrd = 0;
          bottomSameReader = true;
          readerGen[bottomSlot] = currentReaderGen;
        } else {
          final int index = binarySearch(tempBR, termsIndex, bottomValue);
          if (index < 0) {
            bottomOrd = -index - 2;
            bottomSameReader = false;
          } else {
            bottomOrd = index;
            // exact value match
            bottomSameReader = true;
            readerGen[bottomSlot] = currentReaderGen;            
            ords[bottomSlot] = bottomOrd;
          }
        }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958908/fstmerge_base_2839445466337801531
      if (readerGen[bottom] != currentReaderGen) {
        convert(bottomSlot);
=======

      bottomValue = values[bottomSlot];
      if (bottomValue == null) {
        // 0 ord is null for all segments
        assert ords[bottomSlot] == 0;
        bottomOrd = 0;
        bottomSameReader = true;
      } else {
        final int index = binarySearch(tempBR, termsIndex, bottomValue);
        if (index < 0) {
          bottomOrd = -index - 2;
          bottomSameReader = false;
        } else {
          bottomOrd = index;
          // exact value match
          bottomSameReader = true;
        }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958908/fstmerge_var2_8681669067740413925
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958908/fstmerge_base_2839445466337801531
      bottomOrd = ords[bottom];
      bottomValue = values[bottom];
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627958908/fstmerge_var2_8681669067740413925
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/FieldComparator.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959534/fstmerge_var1_7156279340961915354
ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,
                    Similarity similarity, byte[] norms) throws IOException {
    super(similarity, weight);
    this.norms = norms;
    this.value = weight.getValue();

    chunkStates = new ChunkState[postings.length];

    endMinus1 = postings.length-1;

    for(int i=0;i<postings.length;i++) {

      // Coarse optimization: advance(target) is fairly
      // costly, so, if the relative freq of the 2nd
      // rarest term is not that much (> 1/5th) rarer than
      // the first term, then we just use .nextDoc() when
      // ANDing.  This buys ~15% gain for phrases where
      // freq of rarest 2 terms is close:
      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;
      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);
      if (i > 0 && postings[i].postings.nextDoc() == DocsEnum.NO_MORE_DOCS) {
        noDocs = true;
        return;
      }
    }

    for (int i = 0; i < SCORE_CACHE_SIZE; i++) {
      scoreCache[i] = getSimilarity().tf((float) i) * value;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959534/fstmerge_base_4066059067919163576
=======
ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,
                    Similarity similarity, byte[] norms) throws IOException {
    super(similarity);
    this.weight = weight;
    this.norms = norms;
    this.value = weight.getValue();

    chunkStates = new ChunkState[postings.length];

    endMinus1 = postings.length-1;

    for(int i=0;i<postings.length;i++) {

      // Coarse optimization: advance(target) is fairly
      // costly, so, if the relative freq of the 2nd
      // rarest term is not that much (> 1/5th) rarer than
      // the first term, then we just use .nextDoc() when
      // ANDing.  This buys ~15% gain for phrases where
      // freq of rarest 2 terms is close:
      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;
      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);
      if (i > 0 && postings[i].postings.nextDoc() == DocsEnum.NO_MORE_DOCS) {
        noDocs = true;
        return;
      }
    }

    for (int i = 0; i < SCORE_CACHE_SIZE; i++) {
      scoreCache[i] = getSimilarity().tf((float) i) * value;
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959534/fstmerge_var2_192842951076428681

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/ExactPhraseScorer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {
      if (terms.size() == 0)			  // optimize zero-term case
        return null;

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_var1_4839766031446684007
      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.size()];
      final Bits delDocs = reader.getDeletedDocs();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_base_5185989295211044615
      DocsAndPositionsEnum[] postings = new DocsAndPositionsEnum[terms.size()];
      final Bits delDocs = MultiFields.getDeletedDocs(reader);
=======
      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.size()];
      final Bits delDocs = MultiFields.getDeletedDocs(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_var2_8791212717108370645
      for (int i = 0; i < terms.size(); i++) {
        final Term t = terms.get(i);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_var1_4839766031446684007
        DocsAndPositionsEnum postingsEnum = reader.termPositionsEnum(delDocs,
                                                                     t.field(),
                                                                     t.bytes());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_base_5185989295211044615
        final BytesRef text = new BytesRef(t.text());
        DocsAndPositionsEnum postingsEnum = MultiFields.getTermPositionsEnum(reader,
                                                                             delDocs,
                                                                             t.field(),
                                                                             text);
=======
        DocsAndPositionsEnum postingsEnum = MultiFields.getTermPositionsEnum(reader,
                                                                             delDocs,
                                                                             t.field(),
                                                                             t.bytes());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_var2_8791212717108370645
        // PhraseQuery on a field that did not index
        // positions.
        if (postingsEnum == null) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_var1_4839766031446684007
          if (reader.termDocsEnum(delDocs, t.field(), t.bytes()) != null) {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_base_5185989295211044615
          if (MultiFields.getTermDocsEnum(reader, delDocs, t.field(), text) != null) {
=======
          if (MultiFields.getTermDocsEnum(reader, delDocs, t.field(), t.bytes()) != null) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_var2_8791212717108370645
            // term does exist, but has no positions
            throw new IllegalStateException("field \"" + t.field() + "\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=" + t.text() + ")");
          } else {
            // term does not exist
            return null;
          }
        }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_base_5185989295211044615
        postings[i] = postingsEnum;
=======
        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, reader.docFreq(t.field(), t.bytes()), positions.get(i).intValue());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_var2_8791212717108370645
      }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_var1_4839766031446684007
      // sort by increasing docFreq order
      if (slop == 0) {
        ArrayUtil.quickSort(postingsFreqs);
      }

      if (slop == 0) {				  // optimize exact case
        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,
                                                    reader.norms(field));
        if (s.noDocs) {
          return null;
        } else {
          return s;
        }
      } else {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_base_5185989295211044615
      if (slop == 0)				  // optimize exact case
        return new ExactPhraseScorer(this, postings, getPositions(), similarity,
                                     reader.norms(field));
      else
=======
      // sort by increasing docFreq order
      if (slop == 0) {
        Arrays.sort(postingsFreqs);
      }

      if (slop == 0) {				  // optimize exact case
        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,
                                                    reader.norms(field));
        if (s.noDocs) {
          return null;
        } else {
          return s;
        }
      } else {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_var2_8791212717108370645
        return
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_base_5185989295211044615
          new SloppyPhraseScorer(this, postings, getPositions(), similarity, slop,
=======
          new SloppyPhraseScorer(this, postingsFreqs, similarity, slop,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_var2_8791212717108370645
                                 reader.norms(field));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_base_5185989295211044615

=======
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959765/fstmerge_var2_8791212717108370645
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/PhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public Explanation explain(IndexReader reader, int doc)
      throws IOException {

      Explanation result = new Explanation();
      result.setDescription("weight("+getQuery()+" in "+doc+"), product of:");

      StringBuilder docFreqs = new StringBuilder();
      StringBuilder query = new StringBuilder();
      query.append('\"');
      docFreqs.append(idfExp.explain());
      for (int i = 0; i < terms.size(); i++) {
        if (i != 0) {
          query.append(" ");
        }

        Term term = terms.get(i);

        query.append(term.text());
      }
      query.append('\"');

      Explanation idfExpl =
        new Explanation(idf, "idf(" + field + ":" + docFreqs + ")");

      // explain query weight
      Explanation queryExpl = new Explanation();
      queryExpl.setDescription("queryWeight(" + getQuery() + "), product of:");

      Explanation boostExpl = new Explanation(getBoost(), "boost");
      if (getBoost() != 1.0f)
        queryExpl.addDetail(boostExpl);
      queryExpl.addDetail(idfExpl);

      Explanation queryNormExpl = new Explanation(queryNorm,"queryNorm");
      queryExpl.addDetail(queryNormExpl);

      queryExpl.setValue(boostExpl.getValue() *
                         idfExpl.getValue() *
                         queryNormExpl.getValue());

      result.addDetail(queryExpl);

      // explain field weight
      Explanation fieldExpl = new Explanation();
      fieldExpl.setDescription("fieldWeight("+field+":"+query+" in "+doc+
                               "), product of:");

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959771/fstmerge_var1_8580138697629396080
      Scorer scorer = scorer(reader, true, false);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959771/fstmerge_base_3562705257656811629
      PhraseScorer scorer = (PhraseScorer) scorer(reader, true, false);
=======
      Scorer scorer = (Scorer) scorer(reader, true, false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959771/fstmerge_var2_7429557120668050985
      if (scorer == null) {
        return new Explanation(0.0f, "no matching docs");
      }
      Explanation tfExplanation = new Explanation();
      int d = scorer.advance(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959771/fstmerge_var1_8580138697629396080
      float phraseFreq;
      if (d == doc) {
        phraseFreq = scorer.freq();
      } else {
        phraseFreq = 0.0f;
      }

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959771/fstmerge_base_3562705257656811629
      float phraseFreq = (d == doc) ? scorer.currentFreq() : 0.0f;
=======
      float phraseFreq;
      if (d == doc) {
        if (slop == 0) {
          phraseFreq = ((ExactPhraseScorer) scorer).currentFreq();
        } else {
          phraseFreq = ((SloppyPhraseScorer) scorer).currentFreq();
        }
      } else {
        phraseFreq = 0.0f;
      }

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627959771/fstmerge_var2_7429557120668050985
      tfExplanation.setValue(similarity.tf(phraseFreq));
      tfExplanation.setDescription("tf(phraseFreq=" + phraseFreq + ")");
      
      fieldExpl.addDetail(tfExplanation);
      fieldExpl.addDetail(idfExpl);

      Explanation fieldNormExpl = new Explanation();
      byte[] fieldNorms = reader.norms(field);
      float fieldNorm =
        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;
      fieldNormExpl.setValue(fieldNorm);
      fieldNormExpl.setDescription("fieldNorm(field="+field+", doc="+doc+")");
      fieldExpl.addDetail(fieldNormExpl);

      fieldExpl.setValue(tfExplanation.getValue() *
                         idfExpl.getValue() *
                         fieldNormExpl.getValue());

      result.addDetail(fieldExpl);

      // combine them
      result.setValue(queryExpl.getValue() * fieldExpl.getValue());

      if (queryExpl.getValue() == 1.0f)
        return fieldExpl;

      return result;
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/PhraseQuery.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960356/fstmerge_var1_2923127207142550340
PhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,
      Similarity similarity, byte[] norms) {
    super(similarity, weight);
    this.norms = norms;
    this.value = weight.getValue();

    // convert tps to a list of phrase positions.
    // note: phrase-position differs from term-position in that its position
    // reflects the phrase offset: pp.pos = tp.pos - offset.
    // this allows to easily identify a matching (exact) phrase 
    // when all PhrasePositions have exactly the same position.
    for (int i = 0; i < postings.length; i++) {
      PhrasePositions pp = new PhrasePositions(postings[i].postings, postings[i].position);
      if (last != null) {			  // add next to end of list
        last.next = pp;
      } else {
        first = pp;
      }
      last = pp;
    }

    pq = new PhraseQueue(postings.length);             // construct empty pq
    first.doc = -1;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960356/fstmerge_base_486029534122723911
=======
PhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,
      Similarity similarity, byte[] norms) {
    super(similarity);
    this.norms = norms;
    this.weight = weight;
    this.value = weight.getValue();

    // convert tps to a list of phrase positions.
    // note: phrase-position differs from term-position in that its position
    // reflects the phrase offset: pp.pos = tp.pos - offset.
    // this allows to easily identify a matching (exact) phrase 
    // when all PhrasePositions have exactly the same position.
    for (int i = 0; i < postings.length; i++) {
      PhrasePositions pp = new PhrasePositions(postings[i].postings, postings[i].position);
      if (last != null) {			  // add next to end of list
        last.next = pp;
      } else {
        first = pp;
      }
      last = pp;
    }

    pq = new PhraseQueue(postings.length);             // construct empty pq
    first.doc = -1;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960356/fstmerge_var2_1796965082176263644

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/PhraseScorer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960516/fstmerge_var1_5870641190240169240
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960516/fstmerge_base_8897502356394487125
protected final int collectTerms(IndexReader reader, MultiTermQuery query, TermCollector collector) throws IOException {

      if (query.hasNewAPI) {

        if (query.field == null) {
          throw new NullPointerException("If you implement getTermsEnum(), you must specify a non-null field in the constructor of MultiTermQuery.");
        }

        final Fields fields = MultiFields.getFields(reader);
        if (fields == null) {
          // reader has no fields
          return 0;
        }

        final Terms terms = fields.terms(query.field);
        if (terms == null) {
          // field does not exist
          return 0;
        }

        final TermsEnum termsEnum = query.getTermsEnum(reader);
        assert termsEnum != null;

        if (termsEnum == TermsEnum.EMPTY)
          return 0;
        final BoostAttribute boostAtt =
          termsEnum.attributes().addAttribute(BoostAttribute.class);
        collector.boostAtt = boostAtt;
        int count = 0;
        BytesRef term;
        final Term placeholderTerm = new Term(query.field);
        while ((term = termsEnum.next()) != null) {
          if (collector.collect(placeholderTerm.createTerm(term.utf8ToString()), boostAtt.getBoost())) {
            count++;
          } else {
            break;
          }
        }
        collector.boostAtt = null;
        return count;
      } else {
        // deprecated case
        final FilteredTermEnum enumerator = query.getEnum(reader);
        int count = 0;
        try {
          do {
            Term t = enumerator.term();
            if (t != null) {
              if (collector.collect(t, enumerator.difference())) {
                count++;
              } else {
                break;
              }
            }
          } while (enumerator.next());    
        } finally {
          enumerator.close();
        }
        return count;
      }
    }
=======
protected final int collectTerms(IndexReader reader, MultiTermQuery query, TermCollector collector) throws IOException {
      final Fields fields = MultiFields.getFields(reader);
      if (fields == null) {
        // reader has no fields
        return 0;
      }

      final Terms terms = fields.terms(query.field);
      if (terms == null) {
        // field does not exist
        return 0;
      }

      final TermsEnum termsEnum = query.getTermsEnum(reader);
      assert termsEnum != null;

      if (termsEnum == TermsEnum.EMPTY)
        return 0;
      final BoostAttribute boostAtt =
        termsEnum.attributes().addAttribute(BoostAttribute.class);
      collector.boostAtt = boostAtt;
      int count = 0;
      BytesRef bytes;
      while ((bytes = termsEnum.next()) != null) {
        if (collector.collect(bytes, boostAtt.getBoost())) {
          count++;
        } else {
          break;
        }
      }
      collector.boostAtt = null;
      return count;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960516/fstmerge_var2_3422388335623294156

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/MultiTermQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960521/fstmerge_var1_915849508502718935
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960521/fstmerge_base_7973453756787940587
protected final void setMaxNonCompetitiveBoost(float maxNonCompetitiveBoost) {
        if (boostAtt != null) boostAtt.setMaxNonCompetitiveBoost(maxNonCompetitiveBoost);
      }
=======
protected final void setMaxNonCompetitiveBoost(float maxNonCompetitiveBoost) {
        assert boostAtt != null;
        boostAtt.setMaxNonCompetitiveBoost(maxNonCompetitiveBoost);
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960521/fstmerge_var2_1779281295281799786

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/MultiTermQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960525/fstmerge_var1_5957824996034828893
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960525/fstmerge_base_4925233956415491723
@Override
    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {
      final BooleanQuery result = new BooleanQuery(true);
      query.incTotalNumberOfTerms(collectTerms(reader, query, new TermCollector() {
        public boolean collect(Term t, float boost) {
          TermQuery tq = new TermQuery(t); // found a match
          tq.setBoost(query.getBoost() * boost); // set the boost
          result.add(tq, BooleanClause.Occur.SHOULD); // add to query
          return true;
        }
      }));
      return result;
    }
=======
@Override
    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {
      final BooleanQuery result = new BooleanQuery(true);
      final Term placeholderTerm = new Term(query.field);
      query.incTotalNumberOfTerms(collectTerms(reader, query, new TermCollector() {
        public boolean collect(BytesRef bytes, float boost) {
          // add new TQ, we must clone the term, else it may get overwritten!
          TermQuery tq = new TermQuery(placeholderTerm.createTerm(new BytesRef(bytes)));
          tq.setBoost(query.getBoost() * boost); // set the boost
          result.add(tq, BooleanClause.Occur.SHOULD); // add to query
          return true;
        }
      }));
      return result;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960525/fstmerge_var2_7851709623529463170

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/MultiTermQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960544/fstmerge_var1_306920362155168831
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960544/fstmerge_base_8438644381373276670
@Override
    public Query rewrite(IndexReader reader, MultiTermQuery query) throws IOException {
      final int maxSize = Math.min(size, BooleanQuery.getMaxClauseCount());
      final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();
      collectTerms(reader, query, new TermCollector() {
        public boolean collect(Term t, float boost) {
          // ignore uncompetetive hits
          if (stQueue.size() >= maxSize && boost <= stQueue.peek().boost)
            return true;
          // add new entry in PQ
          st.term = t;
          st.boost = boost;
          stQueue.offer(st);
          // possibly drop entries from queue
          st = (stQueue.size() > maxSize) ? stQueue.poll() : new ScoreTerm();
          setMaxNonCompetitiveBoost((stQueue.size() >= maxSize) ? stQueue.peek().boost : Float.NEGATIVE_INFINITY);
          return true;
        }
        
        // reusable instance
        private ScoreTerm st = new ScoreTerm();
      });
      
      final BooleanQuery bq = new BooleanQuery(true);
      for (final ScoreTerm st : stQueue) {
        Query tq = getQuery(st.term);    // found a match
        tq.setBoost(query.getBoost() * st.boost); // set the boost
        bq.add(tq, BooleanClause.Occur.SHOULD);   // add to query
      }
      query.incTotalNumberOfTerms(bq.clauses().size());
      return bq;
    }
=======
@Override
    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {
      final int maxSize = Math.min(size, BooleanQuery.getMaxClauseCount());
      final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();
      collectTerms(reader, query, new TermCollector() {
        public boolean collect(BytesRef bytes, float boost) {
          // ignore uncompetetive hits
          if (stQueue.size() >= maxSize && boost <= stQueue.peek().boost)
            return true;
          // add new entry in PQ, we must clone the term, else it may get overwritten!
          st.bytes.copy(bytes);
          st.boost = boost;
          stQueue.offer(st);
          // possibly drop entries from queue
          st = (stQueue.size() > maxSize) ? stQueue.poll() : new ScoreTerm();
          setMaxNonCompetitiveBoost((stQueue.size() >= maxSize) ? stQueue.peek().boost : Float.NEGATIVE_INFINITY);
          return true;
        }
        
        // reusable instance
        private ScoreTerm st = new ScoreTerm();
      });
      
      final Term placeholderTerm = new Term(query.field);
      final BooleanQuery bq = new BooleanQuery(true);
      for (final ScoreTerm st : stQueue) {
        // add new query, we must clone the term, else it may get overwritten!
        Query tq = getQuery(placeholderTerm.createTerm(st.bytes));
        tq.setBoost(query.getBoost() * st.boost); // set the boost
        bq.add(tq, BooleanClause.Occur.SHOULD);   // add to query
      }
      query.incTotalNumberOfTerms(bq.clauses().size());
      return bq;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960544/fstmerge_var2_6511199315050869090

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/MultiTermQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960556/fstmerge_var1_8414977203998810195
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960556/fstmerge_base_8190848691410185064
public int compareTo(ScoreTerm other) {
        if (this.boost == other.boost)
          return other.term.compareTo(this.term);
        else
          return Float.compare(this.boost, other.boost);
      }
=======
public int compareTo(ScoreTerm other) {
        if (this.boost == other.boost)
          // TODO: is it OK to use default compare here?
          return other.bytes.compareTo(this.bytes);
        else
          return Float.compare(this.boost, other.boost);
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960556/fstmerge_var2_2566978299467046239

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/MultiTermQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960606/fstmerge_var1_4475881501232701059
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960606/fstmerge_base_2555154763767392416
@Override
    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {

      // Get the enum and start visiting terms.  If we
      // exhaust the enum before hitting either of the
      // cutoffs, we use ConstantBooleanQueryRewrite; else,
      // ConstantFilterRewrite:
      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());
      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);

      final CutOffTermCollector col = new CutOffTermCollector(reader, docCountCutoff, termCountLimit);
      collectTerms(reader, query, col);
      
      if (col.hasCutOff) {
        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);
      } else {
        final Query result;
        if (col.pendingTerms.isEmpty()) {
          result = new BooleanQuery(true);
        } else {
          BooleanQuery bq = new BooleanQuery(true);
          for(Term term : col.pendingTerms) {
            TermQuery tq = new TermQuery(term);
            bq.add(tq, BooleanClause.Occur.SHOULD);
          }
          // Strip scores
          result = new ConstantScoreQuery(new QueryWrapperFilter(bq));
          result.setBoost(query.getBoost());
        }
        query.incTotalNumberOfTerms(col.pendingTerms.size());
        return result;
      }
    }
=======
@Override
    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {

      // Get the enum and start visiting terms.  If we
      // exhaust the enum before hitting either of the
      // cutoffs, we use ConstantBooleanQueryRewrite; else,
      // ConstantFilterRewrite:
      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());
      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);

      final CutOffTermCollector col = new CutOffTermCollector(reader, query.field, docCountCutoff, termCountLimit);
      collectTerms(reader, query, col);
      
      if (col.hasCutOff) {
        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);
      } else if (col.termCount == 0) {
        return new BooleanQuery(true);
      } else {
        final PagedBytes.Reader bytesReader = col.pendingTerms.freeze(false);
        try {
          final BooleanQuery bq = new BooleanQuery(true);
          final Term placeholderTerm = new Term(query.field);
          long start = col.startOffset;
          for(int i = 0; i < col.termCount; i++) {
            final BytesRef bytes = new BytesRef();
            start = bytesReader.fillUsingLengthPrefix3(bytes, start);
            bq.add(new TermQuery(placeholderTerm.createTerm(bytes)), BooleanClause.Occur.SHOULD);
          }
          // Strip scores
          final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));
          result.setBoost(query.getBoost());
          query.incTotalNumberOfTerms(col.termCount);
          return result;
        } finally {
          bytesReader.close();
        }
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960606/fstmerge_var2_4181450066673843768

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/MultiTermQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## final ArrayList<Term> pendingTerms = new ArrayList<Term>(); ##FSTMerge## final PagedBytes pendingTerms = new PagedBytes(15);
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/MultiTermQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960626/fstmerge_var1_5788513113081939399
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960626/fstmerge_base_7988823746195702305
protected TermsEnum getTermsEnum(IndexReader reader) throws IOException {
    throw new UnsupportedOperationException();
  }
=======
protected abstract TermsEnum getTermsEnum(IndexReader reader) throws IOException;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960626/fstmerge_var2_1110720571294021901

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/MultiTermQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public DocIdSet getDocIdSet(IndexReader reader) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_base_3590855293768243131
    if (query.hasNewAPI) {
      if (query.field == null) {
        throw new NullPointerException("If you implement getTermsEnum(), you must specify a non-null field in the constructor of MultiTermQuery.");
      }
=======
    final Fields fields = MultiFields.getFields(reader);
    if (fields == null) {
      // reader has no fields
      return DocIdSet.EMPTY_DOCIDSET;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_var2_6677677745286902459

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_base_3590855293768243131
      final Fields fields = MultiFields.getFields(reader);
      if (fields == null) {
        // reader has no fields
        return DocIdSet.EMPTY_DOCIDSET;
      }
=======
    final Terms terms = fields.terms(query.field);
    if (terms == null) {
      // field does not exist
      return DocIdSet.EMPTY_DOCIDSET;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_var2_6677677745286902459

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_var1_569091919307258258
    final TermsEnum termsEnum = query.getTermsEnum(terms);
    assert termsEnum != null;
    if (termsEnum.next() != null) {
      // fill into a OpenBitSet
      final OpenBitSet bitSet = new OpenBitSet(reader.maxDoc());
      int termCount = 0;
      final Bits delDocs = MultiFields.getDeletedDocs(reader);
      DocsEnum docsEnum = null;
      do {
        termCount++;
        // System.out.println("  iter termCount=" + termCount + " term=" +
        // enumerator.term().toBytesString());
        docsEnum = termsEnum.docs(delDocs, docsEnum);
        final DocsEnum.BulkReadResult result = docsEnum.getBulkResult();
        while (true) {
          final int count = docsEnum.read();
          if (count != 0) {
            final int[] docs = result.docs.ints;
            for (int i = 0; i < count; i++) {
              bitSet.set(docs[i]);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_base_3590855293768243131
      final Terms terms = fields.terms(query.field);
      if (terms == null) {
        // field does not exist
        return DocIdSet.EMPTY_DOCIDSET;
      }

      final TermsEnum termsEnum = query.getTermsEnum(reader);
      assert termsEnum != null;
      if (termsEnum.next() != null) {
        // fill into a OpenBitSet
        final OpenBitSet bitSet = new OpenBitSet(reader.maxDoc());
        int termCount = 0;
        final Bits delDocs = MultiFields.getDeletedDocs(reader);
        DocsEnum docsEnum = null;
        do {
          termCount++;
          // System.out.println("  iter termCount=" + termCount + " term=" +
          // enumerator.term().toBytesString());
          docsEnum = termsEnum.docs(delDocs, docsEnum);
          final DocsEnum.BulkReadResult result = docsEnum.getBulkResult();
          while (true) {
            final int count = docsEnum.read();
            if (count != 0) {
              final int[] docs = result.docs.ints;
              for (int i = 0; i < count; i++) {
                bitSet.set(docs[i]);
              }
            } else {
              break;
=======
    final TermsEnum termsEnum = query.getTermsEnum(reader);
    assert termsEnum != null;
    if (termsEnum.next() != null) {
      // fill into a OpenBitSet
      final OpenBitSet bitSet = new OpenBitSet(reader.maxDoc());
      int termCount = 0;
      final Bits delDocs = MultiFields.getDeletedDocs(reader);
      DocsEnum docsEnum = null;
      do {
        termCount++;
        // System.out.println("  iter termCount=" + termCount + " term=" +
        // enumerator.term().toBytesString());
        docsEnum = termsEnum.docs(delDocs, docsEnum);
        final DocsEnum.BulkReadResult result = docsEnum.getBulkResult();
        while (true) {
          final int count = docsEnum.read();
          if (count != 0) {
            final int[] docs = result.docs.ints;
            for (int i = 0; i < count; i++) {
              bitSet.set(docs[i]);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_var2_6677677745286902459
            }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_base_3590855293768243131
=======
          } else {
            break;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_var2_6677677745286902459
          }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_base_3590855293768243131
        } while (termsEnum.next() != null);
        // System.out.println("  done termCount=" + termCount);
=======
        }
      } while (termsEnum.next() != null);
      // System.out.println("  done termCount=" + termCount);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_var2_6677677745286902459

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_base_3590855293768243131
        query.incTotalNumberOfTerms(termCount);
        return bitSet;
      } else {
        return DocIdSet.EMPTY_DOCIDSET;
      }
=======
      query.incTotalNumberOfTerms(termCount);
      return bitSet;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_var2_6677677745286902459
    } else {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_base_3590855293768243131
      final TermEnum enumerator = query.getEnum(reader);
      try {
        // if current term in enum is null, the enum is empty -> shortcut
        if (enumerator.term() == null)
          return DocIdSet.EMPTY_DOCIDSET;
        // else fill into a OpenBitSet
        final OpenBitSet bitSet = new OpenBitSet(reader.maxDoc());
        final int[] docs = new int[32];
        final int[] freqs = new int[32];
        TermDocs termDocs = reader.termDocs();
        try {
          int termCount = 0;
          do {
            Term term = enumerator.term();
            if (term == null)
              break;
            termCount++;
            termDocs.seek(term);
            while (true) {
              final int count = termDocs.read(docs, freqs);
              if (count != 0) {
                for (int i = 0; i < count; i++) {
                  bitSet.set(docs[i]);
                }
              } else {
                break;
              }
            }
          } while (enumerator.next());

          query.incTotalNumberOfTerms(termCount);

        } finally {
          termDocs.close();
        }
        return bitSet;
      } finally {
        enumerator.close();
      }
=======
      return DocIdSet.EMPTY_DOCIDSET;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627960781/fstmerge_var2_6677677745286902459
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter.java
Conflict type: ModifierList
Conflict body: 
~~FSTMerge~~ ##FSTMerge## private static ##FSTMerge## public static
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/FieldCacheImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627961166/fstmerge_var1_7531540067593427721
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627961166/fstmerge_base_5663673932543527524
@Override
    protected Object createValue(IndexReader reader, Entry entryKey)
        throws IOException {

      String field = StringHelper.intern(entryKey.field);
      Terms terms = MultiFields.getTerms(reader, field);

      final boolean fasterButMoreRAM = ((Boolean) entryKey.custom).booleanValue();

      final PagedBytes bytes = new PagedBytes(15);

      int startBytesBPV;
      int startTermsBPV;
      int startNumUniqueTerms;

      if (terms != null) {
        // Try for coarse estimate for number of bits; this
        // should be an underestimate most of the time, which
        // is fine -- GrowableWriter will reallocate as needed
        long numUniqueTerms = 0;
        try {
          numUniqueTerms = terms.getUniqueTermCount();
        } catch (UnsupportedOperationException uoe) {
          numUniqueTerms = -1;
        }
        if (numUniqueTerms != -1) {
          startBytesBPV = PackedInts.bitsRequired(numUniqueTerms*4);
          startTermsBPV = PackedInts.bitsRequired(numUniqueTerms);
          if (numUniqueTerms > Integer.MAX_VALUE-1) {
            throw new IllegalStateException("this field has too many (" + numUniqueTerms + ") unique terms");
          }
          startNumUniqueTerms = (int) numUniqueTerms;
        } else {
          startBytesBPV = 1;
          startTermsBPV = 1;
          startNumUniqueTerms = 1;
        }
      } else {
        startBytesBPV = 1;
        startTermsBPV = 1;
        startNumUniqueTerms = 1;
      }

      GrowableWriter termOrdToBytesOffset = new GrowableWriter(startBytesBPV, 1+startNumUniqueTerms, fasterButMoreRAM);
      final GrowableWriter docToTermOrd = new GrowableWriter(startTermsBPV, reader.maxDoc(), fasterButMoreRAM);

      // 0 is reserved for "unset"
      bytes.copyUsingLengthPrefix(new BytesRef());
      int termOrd = 1;

      if (terms != null) {
        final TermsEnum termsEnum = terms.iterator();
        final Bits delDocs = MultiFields.getDeletedDocs(reader);
        DocsEnum docs = null;

        while(true) {
          final BytesRef term = termsEnum.next();
          if (term == null) {
            break;
          }
          if (termOrd == termOrdToBytesOffset.size()) {
            // NOTE: this code only runs if the incoming
            // reader impl doesn't implement
            // getUniqueTermCount (which should be uncommon)
            termOrdToBytesOffset = termOrdToBytesOffset.resize(ArrayUtil.oversize(1+termOrd, 1));
          }
          termOrdToBytesOffset.set(termOrd, bytes.copyUsingLengthPrefix(term));
          docs = termsEnum.docs(delDocs, docs);
          while (true) {
            final int docID = docs.nextDoc();
            if (docID == DocsEnum.NO_MORE_DOCS) {
              break;
            }
            docToTermOrd.set(docID, termOrd);
          }
          termOrd++;
        }

        if (termOrdToBytesOffset.size() > termOrd) {
          termOrdToBytesOffset = termOrdToBytesOffset.resize(termOrd);
        }
      }

      // maybe an int-only impl?
      return new DocTermsIndexImpl(bytes.freeze(), termOrdToBytesOffset.getMutable(), docToTermOrd.getMutable(), termOrd);
    }
=======
@Override
    protected Object createValue(IndexReader reader, Entry entryKey)
        throws IOException {

      String field = StringHelper.intern(entryKey.field);
      Terms terms = MultiFields.getTerms(reader, field);

      final boolean fasterButMoreRAM = ((Boolean) entryKey.custom).booleanValue();

      final PagedBytes bytes = new PagedBytes(15);

      int startBytesBPV;
      int startTermsBPV;
      int startNumUniqueTerms;

      int maxDoc = reader.maxDoc();
      final int termCountHardLimit;
      if (maxDoc == Integer.MAX_VALUE) {
        termCountHardLimit = Integer.MAX_VALUE;
      } else {
        termCountHardLimit = maxDoc+1;
      }

      if (terms != null) {
        // Try for coarse estimate for number of bits; this
        // should be an underestimate most of the time, which
        // is fine -- GrowableWriter will reallocate as needed
        long numUniqueTerms = 0;
        try {
          numUniqueTerms = terms.getUniqueTermCount();
        } catch (UnsupportedOperationException uoe) {
          numUniqueTerms = -1;
        }
        if (numUniqueTerms != -1) {

          if (numUniqueTerms > termCountHardLimit) {
            // app is misusing the API (there is more than
            // one term per doc); in this case we make best
            // effort to load what we can (see LUCENE-2142)
            numUniqueTerms = termCountHardLimit;
          }

          startBytesBPV = PackedInts.bitsRequired(numUniqueTerms*4);
          startTermsBPV = PackedInts.bitsRequired(numUniqueTerms);

          startNumUniqueTerms = (int) numUniqueTerms;
        } else {
          startBytesBPV = 1;
          startTermsBPV = 1;
          startNumUniqueTerms = 1;
        }
      } else {
        startBytesBPV = 1;
        startTermsBPV = 1;
        startNumUniqueTerms = 1;
      }

      GrowableWriter termOrdToBytesOffset = new GrowableWriter(startBytesBPV, 1+startNumUniqueTerms, fasterButMoreRAM);
      final GrowableWriter docToTermOrd = new GrowableWriter(startTermsBPV, reader.maxDoc(), fasterButMoreRAM);

      // 0 is reserved for "unset"
      bytes.copyUsingLengthPrefix(new BytesRef());
      int termOrd = 1;

      if (terms != null) {
        final TermsEnum termsEnum = terms.iterator();
        final Bits delDocs = MultiFields.getDeletedDocs(reader);
        DocsEnum docs = null;

        while(true) {
          final BytesRef term = termsEnum.next();
          if (term == null) {
            break;
          }
          if (termOrd >= termCountHardLimit) {
            break;
          }

          if (termOrd == termOrdToBytesOffset.size()) {
            // NOTE: this code only runs if the incoming
            // reader impl doesn't implement
            // getUniqueTermCount (which should be uncommon)
            termOrdToBytesOffset = termOrdToBytesOffset.resize(ArrayUtil.oversize(1+termOrd, 1));
          }
          termOrdToBytesOffset.set(termOrd, bytes.copyUsingLengthPrefix(term));
          docs = termsEnum.docs(delDocs, docs);
          while (true) {
            final int docID = docs.nextDoc();
            if (docID == DocsEnum.NO_MORE_DOCS) {
              break;
            }
            docToTermOrd.set(docID, termOrd);
          }
          termOrd++;
        }

        if (termOrdToBytesOffset.size() > termOrd) {
          termOrdToBytesOffset = termOrdToBytesOffset.resize(termOrd);
        }
      }

      // maybe an int-only impl?
      return new DocTermsIndexImpl(bytes.freeze(true), termOrdToBytesOffset.getMutable(), docToTermOrd.getMutable(), termOrd);
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627961166/fstmerge_var2_900592574291957698

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/FieldCacheImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627961213/fstmerge_var1_2522511353583896757
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627961213/fstmerge_base_3219428915724772906
@Override
    protected Object createValue(IndexReader reader, Entry entryKey)
        throws IOException {

      String field = StringHelper.intern(entryKey.field);
      Terms terms = MultiFields.getTerms(reader, field);

      final boolean fasterButMoreRAM = ((Boolean) entryKey.custom).booleanValue();

      // Holds the actual term data, expanded.
      final PagedBytes bytes = new PagedBytes(15);

      int startBPV;

      if (terms != null) {
        // Try for coarse estimate for number of bits; this
        // should be an underestimate most of the time, which
        // is fine -- GrowableWriter will reallocate as needed
        long numUniqueTerms = 0;
        try {
          numUniqueTerms = terms.getUniqueTermCount();
        } catch (UnsupportedOperationException uoe) {
          numUniqueTerms = -1;
        }
        if (numUniqueTerms != -1) {
          startBPV = PackedInts.bitsRequired(numUniqueTerms*4);
        } else {
          startBPV = 1;
        }
      } else {
        startBPV = 1;
      }

      final GrowableWriter docToOffset = new GrowableWriter(startBPV, reader.maxDoc(), fasterButMoreRAM);
      
      // pointer==0 means not set
      bytes.copyUsingLengthPrefix(new BytesRef());

      if (terms != null) {
        final TermsEnum termsEnum = terms.iterator();
        final Bits delDocs = MultiFields.getDeletedDocs(reader);
        DocsEnum docs = null;
        while(true) {
          final BytesRef term = termsEnum.next();
          if (term == null) {
            break;
          }
          final long pointer = bytes.copyUsingLengthPrefix(term);
          docs = termsEnum.docs(delDocs, docs);
          while (true) {
            final int docID = docs.nextDoc();
            if (docID == DocsEnum.NO_MORE_DOCS) {
              break;
            }
            docToOffset.set(docID, pointer);
          }
        }
      }

      // maybe an int-only impl?
      return new DocTermsImpl(bytes.freeze(), docToOffset.getMutable());
    }
=======
@Override
    protected Object createValue(IndexReader reader, Entry entryKey)
        throws IOException {

      String field = StringHelper.intern(entryKey.field);
      Terms terms = MultiFields.getTerms(reader, field);

      final boolean fasterButMoreRAM = ((Boolean) entryKey.custom).booleanValue();

      final int termCountHardLimit = reader.maxDoc();

      // Holds the actual term data, expanded.
      final PagedBytes bytes = new PagedBytes(15);

      int startBPV;

      if (terms != null) {
        // Try for coarse estimate for number of bits; this
        // should be an underestimate most of the time, which
        // is fine -- GrowableWriter will reallocate as needed
        long numUniqueTerms = 0;
        try {
          numUniqueTerms = terms.getUniqueTermCount();
        } catch (UnsupportedOperationException uoe) {
          numUniqueTerms = -1;
        }
        if (numUniqueTerms != -1) {
          if (numUniqueTerms > termCountHardLimit) {
            numUniqueTerms = termCountHardLimit;
          }
          startBPV = PackedInts.bitsRequired(numUniqueTerms*4);
        } else {
          startBPV = 1;
        }
      } else {
        startBPV = 1;
      }

      final GrowableWriter docToOffset = new GrowableWriter(startBPV, reader.maxDoc(), fasterButMoreRAM);
      
      // pointer==0 means not set
      bytes.copyUsingLengthPrefix(new BytesRef());

      if (terms != null) {
        int termCount = 0;
        final TermsEnum termsEnum = terms.iterator();
        final Bits delDocs = MultiFields.getDeletedDocs(reader);
        DocsEnum docs = null;
        while(true) {
          if (termCount++ == termCountHardLimit) {
            // app is misusing the API (there is more than
            // one term per doc); in this case we make best
            // effort to load what we can (see LUCENE-2142)
            break;
          }

          final BytesRef term = termsEnum.next();
          if (term == null) {
            break;
          }
          final long pointer = bytes.copyUsingLengthPrefix(term);
          docs = termsEnum.docs(delDocs, docs);
          while (true) {
            final int docID = docs.nextDoc();
            if (docID == DocsEnum.NO_MORE_DOCS) {
              break;
            }
            docToOffset.set(docID, pointer);
          }
        }
      }

      // maybe an int-only impl?
      return new DocTermsImpl(bytes.freeze(true), docToOffset.getMutable());
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627961213/fstmerge_var2_2702208143745643345

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/FieldCacheImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public Spans getSpans(final IndexReader reader) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627962327/fstmerge_var1_7610583257055837854
    final DocsAndPositionsEnum postings = reader.termPositionsEnum(reader.getDeletedDocs(),
                                                                   term.field(),
                                                                   term.bytes());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627962327/fstmerge_base_1743173681212880498
    // NOTE: debateably, the caller should never pass in a
    // multi reader...
    final BytesRef textBytes = new BytesRef(term.text());
    final DocsAndPositionsEnum postings = MultiFields.getTermPositionsEnum(reader,
                                                                           MultiFields.getDeletedDocs(reader),
                                                                           term.field(),
                                                                           textBytes);
=======
    // NOTE: debateably, the caller should never pass in a
    // multi reader...
    final DocsAndPositionsEnum postings = MultiFields.getTermPositionsEnum(reader,
                                                                           MultiFields.getDeletedDocs(reader),
                                                                           term.field(),
                                                                           term.bytes());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627962327/fstmerge_var2_584284596543333637

    if (postings != null) {
      return new TermSpans(postings, term);
    } else {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627962327/fstmerge_var1_7610583257055837854
      if (reader.termDocsEnum(reader.getDeletedDocs(), term.field(), term.bytes()) != null) {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627962327/fstmerge_base_1743173681212880498
      if (MultiFields.getTermDocsEnum(reader, MultiFields.getDeletedDocs(reader), term.field(), textBytes) != null) {
=======
      if (MultiFields.getTermDocsEnum(reader, MultiFields.getDeletedDocs(reader), term.field(), term.bytes()) != null) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627962327/fstmerge_var2_584284596543333637
        // term does exist, but has no positions
        throw new IllegalStateException("field \"" + term.field() + "\" was indexed with Field.omitTermFreqAndPositions=true; cannot run SpanTermQuery (term=" + term.text() + ")");
      } else {
        // term does not exist
        return TermSpans.EMPTY_TERM_SPANS;
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/search/spans/SpanTermQuery.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627963967/fstmerge_var1_4966762798925874726
public void copy(BytesRef bytes, BytesRef out) throws IOException {
    int left = blockSize - upto;
    if (bytes.length > left || currentBlock==null) {
      if (currentBlock != null) {
        blocks.add(currentBlock);
        blockEnd.add(upto);
      }
      currentBlock = new byte[blockSize];
      upto = 0;
      left = blockSize;
      assert bytes.length <= blockSize;
      // TODO: we could also support variable block sizes
    }

    out.bytes = currentBlock;
    out.offset = upto;
    out.length = bytes.length;

    System.arraycopy(bytes.bytes, bytes.offset, currentBlock, upto, bytes.length);
    upto += bytes.length;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627963967/fstmerge_base_9123271535409414674
=======
public void copy(BytesRef bytes, BytesRef out) throws IOException {
    int left = blockSize - upto;
    if (bytes.length > left) {
      if (currentBlock != null) {
        blocks.add(currentBlock);
        blockEnd.add(upto);
      }
      currentBlock = new byte[blockSize];
      upto = 0;
      left = blockSize;
      assert bytes.length <= blockSize;
      // TODO: we could also support variable block sizes
    }

    out.bytes = currentBlock;
    out.offset = upto;
    out.length = bytes.length;

    System.arraycopy(bytes.bytes, bytes.offset, currentBlock, upto, bytes.length);
    upto += bytes.length;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627963967/fstmerge_var2_2179297608254829090

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/util/PagedBytes.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627968274/fstmerge_var1_1711959135704890400
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627968274/fstmerge_base_7237545122788812737
@Override
  public void copy(Directory to, String src, String dest) throws IOException {
    if (to instanceof FSDirectory) {
      FSDirectory target = (FSDirectory) to;
      target.ensureCanWrite(dest);
      FileChannel input = null;
      FileChannel output = null;
      IOException priorException = null;
      try {
        input = new FileInputStream(new File(directory, src)).getChannel();
        output = new FileOutputStream(new File(target.directory, dest)).getChannel();
        output.transferFrom(input, 0, input.size());
      } catch (IOException ioe) {
        priorException = ioe;
      } finally {
        IOUtils.closeSafely(priorException, input, output);
      }
    } else {
      super.copy(to, src, dest);
    }
  }
=======
@Override
  public void copy(Directory to, String src, String dest) throws IOException {
    if (to instanceof FSDirectory) {
      FSDirectory target = (FSDirectory) to;
      target.ensureCanWrite(dest);
      FileChannel input = null;
      FileChannel output = null;
      IOException priorException = null;
      try {
        input = new FileInputStream(new File(directory, src)).getChannel();
        output = new FileOutputStream(new File(target.directory, dest)).getChannel();
        copy(input, output, input.size());
      } catch (IOException ioe) {
        priorException = ioe;
      } finally {
        IOUtils.closeSafely(priorException, input, output);
      }
    } else {
      super.copy(to, src, dest);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627968274/fstmerge_var2_6192971686854366997

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/store/FSDirectory.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969091/fstmerge_var1_8695836369897713651
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969091/fstmerge_base_435975898415028759
private synchronized void acquireTestLock() {
    if (tested) return;
    tested = true;
    
    // Ensure that lockDir exists and is a directory.
    if (!lockDir.exists()) {
      if (!lockDir.mkdirs())
        throw new RuntimeException("Cannot create directory: " +
                              lockDir.getAbsolutePath());
    } else if (!lockDir.isDirectory()) {
      throw new RuntimeException("Found regular file where directory expected: " + 
                            lockDir.getAbsolutePath());
    }

    // add the RuntimeMXBean's name to the lock file, to reduce the chance for
    // name collisions when this code is invoked by multiple JVMs (such as in
    // our tests). On most systems, the name includes the process Id.
    // Also, remove any non-alphanumeric characters, so that the lock file will
    // be created for sure on all systems.
    String randomLockName = "lucene-"
        + ManagementFactory.getRuntimeMXBean().getName().replaceAll("[^a..zA..Z0..9]+","") + "-"
        + Long.toString(new Random().nextInt(), Character.MAX_RADIX)
        + "-test.lock";
    
    Lock l = makeLock(randomLockName);
    try {
      l.obtain();
      l.release();
      // If the test lock failed to delete after all the attempts, attempt a
      // delete when the JVM exits.
      File lockFile = new File(lockDir, randomLockName);
      if (lockFile.exists()) {
        lockFile.deleteOnExit();
      }
    } catch (IOException e) {
      RuntimeException e2 = new RuntimeException("Failed to acquire random test lock; please verify filesystem for lock directory '" + lockDir + "' supports locking");
      e2.initCause(e);
      throw e2;
    }    
  }
=======
private synchronized void acquireTestLock() {
    if (tested) return;
    tested = true;
    
    // Ensure that lockDir exists and is a directory.
    if (!lockDir.exists()) {
      if (!lockDir.mkdirs())
        throw new RuntimeException("Cannot create directory: " +
                              lockDir.getAbsolutePath());
    } else if (!lockDir.isDirectory()) {
      throw new RuntimeException("Found regular file where directory expected: " + 
                            lockDir.getAbsolutePath());
    }

    // add the RuntimeMXBean's name to the lock file, to reduce the chance for
    // name collisions when this code is invoked by multiple JVMs (such as in
    // our tests). On most systems, the name includes the process Id.
    // Also, remove any non-alphanumeric characters, so that the lock file will
    // be created for sure on all systems.
    String randomLockName = "lucene-"
        + ManagementFactory.getRuntimeMXBean().getName().replaceAll("[^a-zA-Z0-9]+","") + "-"
        + Long.toString(new Random().nextInt(), Character.MAX_RADIX)
        + "-test.lock";
    
    Lock l = makeLock(randomLockName);
    try {
      l.obtain();
      l.release();
      // If the test lock failed to delete after all the attempts, attempt a
      // delete when the JVM exits.
      File lockFile = new File(lockDir, randomLockName);
      if (lockFile.exists()) {
        lockFile.deleteOnExit();
      }
    } catch (IOException e) {
      RuntimeException e2 = new RuntimeException("Failed to acquire random test lock; please verify filesystem for lock directory '" + lockDir + "' supports locking");
      e2.initCause(e);
      throw e2;
    }    
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969091/fstmerge_var2_499517476980233526

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/store/NativeFSLockFactory.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969448/fstmerge_var1_2636196552479644331
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969448/fstmerge_base_2167412258405923667
public SegmentInfo(String name, int docCount, Directory dir, boolean isCompoundFile, int docStoreOffset, 
                     String docStoreSegment, boolean docStoreIsCompoundFile, boolean hasProx, Codec codec) { 
    this.name = name;
    this.docCount = docCount;
    this.dir = dir;
    delGen = NO;
    this.isCompoundFile = isCompoundFile;
    this.docStoreOffset = docStoreOffset;
    this.docStoreSegment = docStoreSegment;
    this.docStoreIsCompoundFile = docStoreIsCompoundFile;
    this.hasProx = hasProx;
    this.codec = codec;
    delCount = 0;
    assert docStoreOffset == -1 || docStoreSegment != null: "dso=" + docStoreOffset + " dss=" + docStoreSegment + " docCount=" + docCount;
  }
=======
private SegmentInfo(String name, int docCount, Directory dir, boolean isCompoundFile, int docStoreOffset, 
                            String docStoreSegment, boolean docStoreIsCompoundFile, boolean hasProx, Codec codec) {
    this.name = name;
    this.docCount = docCount;
    this.dir = dir;
    delGen = NO;
    this.isCompoundFile = isCompoundFile;
    this.hasProx = hasProx;
    this.codec = codec;
    delCount = 0;
    this.docStoreOffset = docStoreOffset;
    this.docStoreIsCompoundFile = docStoreIsCompoundFile;
    this.docStoreSegment = docStoreSegment;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969448/fstmerge_var2_5637385916252109575

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/SegmentInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
void reset(SegmentInfo src) {
    clearFiles();
    name = src.name;
    docCount = src.docCount;
    dir = src.dir;
    delGen = src.delGen;
    docStoreOffset = src.docStoreOffset;
    docStoreIsCompoundFile = src.docStoreIsCompoundFile;
    hasVectors = src.hasVectors;
    hasProx = src.hasProx;
    if (src.normGen == null) {
      normGen = null;
    } else {
      normGen = new long[src.normGen.length];
      System.arraycopy(src.normGen, 0, normGen, 0, src.normGen.length);
    }
    isCompoundFile = src.isCompoundFile;
    delCount = src.delCount;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969453/fstmerge_var1_4621656493743811144
    segmentCodecs = src.segmentCodecs;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969453/fstmerge_base_8956388629125914806
    codec = src.codec;
=======
    codec = src.codec;
    minSequenceID = src.minSequenceID;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969453/fstmerge_var2_7218205936752518795
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/SegmentInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969465/fstmerge_base_3195256093911274926
SegmentInfo(Directory dir, int format, IndexInput input, CodecProvider codecs) throws IOException {
=======
public SegmentInfo(Directory dir, int format, IndexInput input, CodecProvider codecs) throws IOException {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969465/fstmerge_var2_1281899029827218498
    this.dir = dir;
    name = input.readString();
    docCount = input.readInt();
    delGen = input.readLong();
    docStoreOffset = input.readInt();
    if (docStoreOffset != -1) {
      docStoreSegment = input.readString();
      docStoreIsCompoundFile = input.readByte() == YES;
    } else {
      docStoreSegment = name;
      docStoreIsCompoundFile = false;
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969465/fstmerge_var1_949063392723788920
    if (format > DefaultSegmentInfosWriter.FORMAT_4_0) {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969465/fstmerge_base_3195256093911274926
    if (format > SegmentInfos.FORMAT_4_0) {
=======

    if (format > DefaultSegmentInfosWriter.FORMAT_4_0) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969465/fstmerge_var2_1281899029827218498
      // pre-4.0 indexes write a byte if there is a single norms file
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969465/fstmerge_base_3195256093911274926
      assert 1 == input.readByte();
=======
      byte b = input.readByte();
      assert 1 == b;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969465/fstmerge_var2_1281899029827218498
    }

    int numNormGen = input.readInt();
    if (numNormGen == NO) {
      normGen = null;
    } else {
      normGen = new long[numNormGen];
      for(int j=0;j<numNormGen;j++) {
        normGen[j] = input.readLong();
      }
    }
    isCompoundFile = input.readByte() == YES;

    delCount = input.readInt();
    assert delCount <= docCount;

    hasProx = input.readByte() == YES;
    
    // System.out.println(Thread.currentThread().getName() + ": si.read hasProx=" + hasProx + " seg=" + name);
    segmentCodecs = new SegmentCodecs(codecs);
    if (format <= DefaultSegmentInfosWriter.FORMAT_4_0) {
      segmentCodecs.read(input);
    } else {
      // codec ID on FieldInfo is 0 so it will simply use the first codec available
      // TODO what todo if preflex is not available in the provider? register it or fail?
      segmentCodecs.codecs = new Codec[] { codecs.lookup("PreFlex")};
    }
    diagnostics = input.readStringStringMap();
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969465/fstmerge_var1_949063392723788920
    if (format <= DefaultSegmentInfosWriter.FORMAT_HAS_VECTORS) {
      hasVectors = input.readByte() == 1;
    } else {
      final String storesSegment;
      final String ext;
      final boolean isCompoundFile;
      if (docStoreOffset != -1) {
        storesSegment = docStoreSegment;
        isCompoundFile = docStoreIsCompoundFile;
        ext = IndexFileNames.COMPOUND_FILE_STORE_EXTENSION;
      } else {
        storesSegment = name;
        isCompoundFile = getUseCompoundFile();
        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;
      }
      final Directory dirToTest;
      if (isCompoundFile) {
        dirToTest = new CompoundFileReader(dir, IndexFileNames.segmentFileName(storesSegment, "", ext));
      } else {
        dirToTest = dir;
      }
      try {
        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, "", IndexFileNames.VECTORS_INDEX_EXTENSION));
      } finally {
        if (isCompoundFile) {
          dirToTest.close();
        }
      }
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969465/fstmerge_base_3195256093911274926
    if (format <= SegmentInfos.FORMAT_4_0)
      codecName = input.readString();
    else
      codecName = "PreFlex";
    
    diagnostics = input.readStringStringMap();
    codec = codecs.lookup(codecName);
=======
    if (format <= DefaultSegmentInfosWriter.FORMAT_4_0)
      codecName = input.readString();
    else
      codecName = "PreFlex";
    
    diagnostics = input.readStringStringMap();
    codec = codecs.lookup(codecName);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969465/fstmerge_var2_1281899029827218498
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/SegmentInfo.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969545/fstmerge_var1_3951985520766088226
public void setDocStoreSegment(String segment) {
    docStoreSegment = segment;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969545/fstmerge_base_3818514808394829908
=======
@Deprecated
  public void setDocStoreSegment(String docStoreSegment) {
    this.docStoreSegment = docStoreSegment;
    clearFiles();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969545/fstmerge_var2_890324539484980785

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/SegmentInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  boolean start(Fieldable[] fields, int count) {
    doVectors = false;
    doVectorPositions = false;
    doVectorOffsets = false;

    for(int i=0;i<count;i++) {
      Fieldable field = fields[i];
      if (field.isIndexed() && field.isTermVectorStored()) {
        doVectors = true;
        doVectorPositions |= field.isStorePositionWithTermVector();
        doVectorOffsets |= field.isStoreOffsetWithTermVector();
      }
    }

    if (doVectors) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969662/fstmerge_var1_5551634489899622747
      if (perThread.doc == null) {
        perThread.doc = termsWriter.getPerDoc();
        perThread.doc.docID = docState.docID;
        assert perThread.doc.numVectorFields == 0;
        assert 0 == perThread.doc.perDocTvf.length();
        assert 0 == perThread.doc.perDocTvf.getFilePointer();
      }

      assert perThread.doc.docID == docState.docID;

      if (termsHashPerField.bytesHash.size() != 0) {
        // Only necessary if previous doc hit a
        // non-aborting exception while writing vectors in
        // this field:
        termsHashPerField.reset();
        perThread.termsHashPerThread.reset(false);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969662/fstmerge_base_7126734762752698917
      if (perThread.doc == null) {
        perThread.doc = termsWriter.getPerDoc();
        perThread.doc.docID = docState.docID;
        assert perThread.doc.numVectorFields == 0;
        assert 0 == perThread.doc.perDocTvf.length();
        assert 0 == perThread.doc.perDocTvf.getFilePointer();
      } else {
        assert perThread.doc.docID == docState.docID;

        if (termsHashPerField.numPostings != 0)
          // Only necessary if previous doc hit a
          // non-aborting exception while writing vectors in
          // this field:
          termsHashPerField.reset();
=======
      if (termsWriter.tvx != null) {
        if (termsHashPerField.numPostings != 0)
          // Only necessary if previous doc hit a
          // non-aborting exception while writing vectors in
          // this field:
          termsHashPerField.reset();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969662/fstmerge_var2_4580430176750734391
      }
    }

    // TODO: only if needed for performance
    //perThread.postingsCount = 0;

    return doVectors;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  void finish() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969671/fstmerge_var1_5753795286653549541

    assert docState.testPoint("TermVectorsTermsWriterPerField.finish start");

    final int numPostings = termsHashPerField.bytesHash.size();

    final BytesRef flushTerm = perThread.flushTerm;

    assert numPostings >= 0;

    if (!doVectors || numPostings == 0)
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969671/fstmerge_base_4756311183136044830

    assert docState.testPoint("TermVectorsTermsWriterPerField.finish start");

    final int numPostings = termsHashPerField.numPostings;

    final BytesRef flushTerm = perThread.flushTerm;

    assert numPostings >= 0;

    if (!doVectors || numPostings == 0)
=======
    if (!doVectors || termsHashPerField.numPostings == 0)
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969671/fstmerge_var2_9019336806338803364
      return;

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969671/fstmerge_var1_5753795286653549541
    if (numPostings > maxNumPostings)
      maxNumPostings = numPostings;

    final IndexOutput tvf = perThread.doc.perDocTvf;

    // This is called once, after inverting all occurrences
    // of a given field in the doc.  At this point we flush
    // our hash into the DocWriter.

    assert fieldInfo.storeTermVector;
    assert perThread.vectorFieldsInOrder(fieldInfo);

    perThread.doc.addField(termsHashPerField.fieldInfo.number);
    TermVectorsPostingsArray postings = (TermVectorsPostingsArray) termsHashPerField.postingsArray;

    // TODO: we may want to make this sort in same order
    // as Codec's terms dict?
    final int[] termIDs = termsHashPerField.sortPostings(BytesRef.getUTF8SortedAsUnicodeComparator());

    tvf.writeVInt(numPostings);
    byte bits = 0x0;
    if (doVectorPositions)
      bits |= TermVectorsReader.STORE_POSITIONS_WITH_TERMVECTOR;
    if (doVectorOffsets) 
      bits |= TermVectorsReader.STORE_OFFSET_WITH_TERMVECTOR;
    tvf.writeByte(bits);

    int lastLen = 0;
    byte[] lastBytes = null;
    int lastStart = 0;
      
    final ByteSliceReader reader = perThread.vectorSliceReader;
    final ByteBlockPool termBytePool = perThread.termsHashPerThread.termBytePool;

    for(int j=0;j<numPostings;j++) {
      final int termID = termIDs[j];
      final int freq = postings.freqs[termID];
          
      // Get BytesRef
      termBytePool.setBytesRef(flushTerm, postings.textStarts[termID]);

      // Compute common byte prefix between last term and
      // this term
      int prefix = 0;
      if (j > 0) {
        while(prefix < lastLen && prefix < flushTerm.length) {
          if (lastBytes[lastStart+prefix] != flushTerm.bytes[flushTerm.offset+prefix]) {
            break;
          }
          prefix++;
        }
      }

      lastLen = flushTerm.length;
      lastBytes = flushTerm.bytes;
      lastStart = flushTerm.offset;

      final int suffix = flushTerm.length - prefix;
      tvf.writeVInt(prefix);
      tvf.writeVInt(suffix);
      tvf.writeBytes(flushTerm.bytes, lastStart+prefix, suffix);
      tvf.writeVInt(freq);

      if (doVectorPositions) {
        termsHashPerField.initReader(reader, termID, 0);
        reader.writeTo(tvf);
      }

      if (doVectorOffsets) {
        termsHashPerField.initReader(reader, termID, 1);
        reader.writeTo(tvf);
      }
    }

    termsHashPerField.reset();

    // NOTE: we clear, per-field, at the thread level,
    // because term vectors fully write themselves on each
    // field; this saves RAM (eg if large doc has two large
    // fields w/ term vectors on) because we recycle/reuse
    // all RAM after each field:
    perThread.termsHashPerThread.reset(false);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969671/fstmerge_base_4756311183136044830
    if (numPostings > maxNumPostings)
      maxNumPostings = numPostings;

    final IndexOutput tvf = perThread.doc.perDocTvf;

    // This is called once, after inverting all occurrences
    // of a given field in the doc.  At this point we flush
    // our hash into the DocWriter.

    assert fieldInfo.storeTermVector;
    assert perThread.vectorFieldsInOrder(fieldInfo);

    perThread.doc.addField(termsHashPerField.fieldInfo.number);
    TermVectorsPostingsArray postings = (TermVectorsPostingsArray) termsHashPerField.postingsArray;

    // TODO: we may want to make this sort in same order
    // as Codec's terms dict?
    final int[] termIDs = termsHashPerField.sortPostings(BytesRef.getUTF8SortedAsUTF16Comparator());

    tvf.writeVInt(numPostings);
    byte bits = 0x0;
    if (doVectorPositions)
      bits |= TermVectorsReader.STORE_POSITIONS_WITH_TERMVECTOR;
    if (doVectorOffsets) 
      bits |= TermVectorsReader.STORE_OFFSET_WITH_TERMVECTOR;
    tvf.writeByte(bits);

    int lastLen = 0;
    byte[] lastBytes = null;
    int lastStart = 0;
      
    final ByteSliceReader reader = perThread.vectorSliceReader;
    final ByteBlockPool termBytePool = perThread.termsHashPerThread.termBytePool;

    for(int j=0;j<numPostings;j++) {
      final int termID = termIDs[j];
      final int freq = postings.freqs[termID];
          
      // Get BytesRef
      termBytePool.setBytesRef(flushTerm, postings.textStarts[termID]);

      // Compute common byte prefix between last term and
      // this term
      int prefix = 0;
      if (j > 0) {
        while(prefix < lastLen && prefix < flushTerm.length) {
          if (lastBytes[lastStart+prefix] != flushTerm.bytes[flushTerm.offset+prefix]) {
            break;
          }
          prefix++;
        }
      }

      lastLen = flushTerm.length;
      lastBytes = flushTerm.bytes;
      lastStart = flushTerm.offset;

      final int suffix = flushTerm.length - prefix;
      tvf.writeVInt(prefix);
      tvf.writeVInt(suffix);
      tvf.writeBytes(flushTerm.bytes, lastStart+prefix, suffix);
      tvf.writeVInt(freq);

      if (doVectorPositions) {
        termsHashPerField.initReader(reader, termID, 0);
        reader.writeTo(tvf);
      }

      if (doVectorOffsets) {
        termsHashPerField.initReader(reader, termID, 1);
        reader.writeTo(tvf);
      }
    }

    termsHashPerField.reset();
    perThread.termsHashPerThread.reset(false);
=======
    termsWriter.addFieldToFlush(this);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969671/fstmerge_var2_9019336806338803364
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    int bytesPerPosting() {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969718/fstmerge_var1_92735639874229754
      return super.bytesPerPosting() + 3 * RamUsageEstimator.NUM_BYTES_INT;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969718/fstmerge_base_5398654050735778610
      return super.bytesPerPosting() + 3 * DocumentsWriter.INT_NUM_BYTE;
=======
      return super.bytesPerPosting() + 3 * DocumentsWriterRAMAllocator.INT_NUM_BYTE;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969718/fstmerge_var2_9211239746616002094
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
final void addDocument(Document doc) throws IOException {
    indexStream.writeLong(fieldsStream.getFilePointer());

    int storedCount = 0;
    List<Fieldable> fields = doc.getFields();
    for (Fieldable field : fields) {
      if (field.isStored())
          storedCount++;
    }
    fieldsStream.writeVInt(storedCount);



<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969796/fstmerge_var1_7199036268060331633
    for (Fieldable field : fields) {
      if (field.isStored())
        writeField(fieldInfos.fieldInfo(field.name()), field);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969796/fstmerge_base_7245223853468539124
        for (Fieldable field : fields) {
            if (field.isStored())
              writeField(fieldInfos.fieldInfo(field.name()), field);
        }
=======
        for (Fieldable field : fields) {
            if (field.isStored())
              writeField(fieldInfos.fieldInfo(field.name()).number, field);
        }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969796/fstmerge_var2_2996775492681190297
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/FieldsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969801/fstmerge_var1_3912078847179684618
void flushDocument(int numStoredFields, RAMOutputStream buffer) throws IOException {
    indexStream.writeLong(fieldsStream.getFilePointer());
    fieldsStream.writeVInt(numStoredFields);
    buffer.writeTo(fieldsStream);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969801/fstmerge_base_6287975194948466838
void flushDocument(int numStoredFields, RAMOutputStream buffer) throws IOException {
      indexStream.writeLong(fieldsStream.getFilePointer());
      fieldsStream.writeVInt(numStoredFields);
      buffer.writeTo(fieldsStream);
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969801/fstmerge_var2_4776759609120855604

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/FieldsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969806/fstmerge_var1_1842689714786889386
final void writeField(FieldInfo fi, Fieldable field) throws IOException {
    fieldsStream.writeVInt(fi.number);
    byte bits = 0;
    if (field.isTokenized())
      bits |= FieldsWriter.FIELD_IS_TOKENIZED;
    if (field.isBinary())
      bits |= FieldsWriter.FIELD_IS_BINARY;

    fieldsStream.writeByte(bits);

    if (field.isBinary()) {
      final byte[] data;
      final int len;
      final int offset;
      data = field.getBinaryValue();
      len = field.getBinaryLength();
      offset =  field.getBinaryOffset();

      fieldsStream.writeVInt(len);
      fieldsStream.writeBytes(data, offset, len);
    }
    else {
      fieldsStream.writeString(field.stringValue());
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969806/fstmerge_base_3195820048538155347
final void writeField(FieldInfo fi, Fieldable field) throws IOException {
      fieldsStream.writeVInt(fi.number);
      byte bits = 0;
      if (field.isTokenized())
        bits |= FieldsWriter.FIELD_IS_TOKENIZED;
      if (field.isBinary())
        bits |= FieldsWriter.FIELD_IS_BINARY;
                
      fieldsStream.writeByte(bits);
                
      if (field.isBinary()) {
        final byte[] data;
        final int len;
        final int offset;
        data = field.getBinaryValue();
        len = field.getBinaryLength();
        offset =  field.getBinaryOffset();

        fieldsStream.writeVInt(len);
        fieldsStream.writeBytes(data, offset, len);
      }
      else {
        fieldsStream.writeString(field.stringValue());
      }
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969806/fstmerge_var2_3293243263179442935

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/FieldsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void init(ByteBlockPool pool, int startIndex, int endIndex) {

    assert endIndex-startIndex >= 0;
    assert startIndex >= 0;
    assert endIndex >= 0;

    this.pool = pool;
    this.endIndex = endIndex;

    level = 0;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969838/fstmerge_var1_3581058074187348608
    bufferUpto = startIndex / ByteBlockPool.BYTE_BLOCK_SIZE;
    bufferOffset = bufferUpto * ByteBlockPool.BYTE_BLOCK_SIZE;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969838/fstmerge_base_1221456806014269265
    bufferUpto = startIndex / DocumentsWriter.BYTE_BLOCK_SIZE;
    bufferOffset = bufferUpto * DocumentsWriter.BYTE_BLOCK_SIZE;
=======
    bufferUpto = startIndex / DocumentsWriterRAMAllocator.BYTE_BLOCK_SIZE;
    bufferOffset = bufferUpto * DocumentsWriterRAMAllocator.BYTE_BLOCK_SIZE;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969838/fstmerge_var2_4668163148178398856
    buffer = pool.buffers[bufferUpto];
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969838/fstmerge_var1_3581058074187348608
    upto = startIndex & ByteBlockPool.BYTE_BLOCK_MASK;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969838/fstmerge_base_1221456806014269265
    upto = startIndex & DocumentsWriter.BYTE_BLOCK_MASK;
=======
    upto = startIndex & DocumentsWriterRAMAllocator.BYTE_BLOCK_MASK;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969838/fstmerge_var2_4668163148178398856

    final int firstSize = ByteBlockPool.levelSizeArray[0];

    if (startIndex+firstSize >= endIndex) {
      // There is only this one slice to read
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969838/fstmerge_var1_3581058074187348608
      limit = endIndex & ByteBlockPool.BYTE_BLOCK_MASK;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969838/fstmerge_base_1221456806014269265
      limit = endIndex & DocumentsWriter.BYTE_BLOCK_MASK;
=======
      limit = endIndex & DocumentsWriterRAMAllocator.BYTE_BLOCK_MASK;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969838/fstmerge_var2_4668163148178398856
    } else
      limit = upto+firstSize-4;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/ByteSliceReader.java
Conflict type: LineBasedMCFd
Conflict body: 
public void nextSlice() {

    // Skip to our next slice
    final int nextIndex = ((buffer[limit]&0xff)<<24) + ((buffer[1+limit]&0xff)<<16) + ((buffer[2+limit]&0xff)<<8) + (buffer[3+limit]&0xff);

    level = ByteBlockPool.nextLevelArray[level];
    final int newSize = ByteBlockPool.levelSizeArray[level];

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969856/fstmerge_var1_3752449355228969129
    bufferUpto = nextIndex / ByteBlockPool.BYTE_BLOCK_SIZE;
    bufferOffset = bufferUpto * ByteBlockPool.BYTE_BLOCK_SIZE;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969856/fstmerge_base_8409001595854835870
    bufferUpto = nextIndex / DocumentsWriter.BYTE_BLOCK_SIZE;
    bufferOffset = bufferUpto * DocumentsWriter.BYTE_BLOCK_SIZE;
=======
    bufferUpto = nextIndex / DocumentsWriterRAMAllocator.BYTE_BLOCK_SIZE;
    bufferOffset = bufferUpto * DocumentsWriterRAMAllocator.BYTE_BLOCK_SIZE;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969856/fstmerge_var2_2388833811968396956

    buffer = pool.buffers[bufferUpto];
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969856/fstmerge_var1_3752449355228969129
    upto = nextIndex & ByteBlockPool.BYTE_BLOCK_MASK;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969856/fstmerge_base_8409001595854835870
    upto = nextIndex & DocumentsWriter.BYTE_BLOCK_MASK;
=======
    upto = nextIndex & DocumentsWriterRAMAllocator.BYTE_BLOCK_MASK;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969856/fstmerge_var2_2388833811968396956

    if (nextIndex + newSize >= endIndex) {
      // We are advancing to the final slice
      assert endIndex - nextIndex > 0;
      limit = endIndex - bufferOffset;
    } else {
      // This is not the final slice (subtract 4 for the
      // forwarding address at the end of this new slice)
      limit = upto+newSize-4;
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/ByteSliceReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969880/fstmerge_var1_3384394028030876497
@Override
  public void flush(Map<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> threadsAndFields, final SegmentWriteState state) throws IOException {

    // Gather all FieldData's that have postings, across all
    // ThreadStates
    List<FreqProxTermsWriterPerField> allFields = new ArrayList<FreqProxTermsWriterPerField>();
    
    flushedDocCount = state.numDocs;

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {

      Collection<TermsHashConsumerPerField> fields = entry.getValue();


      for (final TermsHashConsumerPerField i : fields) {
        final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) i;
        if (perField.termsHashPerField.bytesHash.size() > 0)
          allFields.add(perField);
      }
    }

    final int numAllFields = allFields.size();

    // Sort by field name
    CollectionUtil.quickSort(allFields);

    final FieldsConsumer consumer = state.segmentCodecs.codec().fieldsConsumer(state);

    /*
    Current writer chain:
      FieldsConsumer
        -> IMPL: FormatPostingsTermsDictWriter
          -> TermsConsumer
            -> IMPL: FormatPostingsTermsDictWriter.TermsWriter
              -> DocsConsumer
                -> IMPL: FormatPostingsDocsWriter
                  -> PositionsConsumer
                    -> IMPL: FormatPostingsPositionsWriter
    */

    int start = 0;
    while(start < numAllFields) {
      final FieldInfo fieldInfo = allFields.get(start).fieldInfo;
      final String fieldName = fieldInfo.name;

      int end = start+1;
      while(end < numAllFields && allFields.get(end).fieldInfo.name.equals(fieldName))
        end++;
      
      FreqProxTermsWriterPerField[] fields = new FreqProxTermsWriterPerField[end-start];
      for(int i=start;i<end;i++) {
        fields[i-start] = allFields.get(i);

        // Aggregate the storePayload as seen by the same
        // field across multiple threads
        fieldInfo.storePayloads |= fields[i-start].hasPayloads;
      }

      // If this field has postings then add them to the
      // segment
      appendPostings(fields, consumer);

      for(int i=0;i<fields.length;i++) {
        TermsHashPerField perField = fields[i].termsHashPerField;
        int numPostings = perField.bytesHash.size();
        perField.reset();
        perField.shrinkHash(numPostings);
        fields[i].reset();
      }

      start = end;
    }

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {
      FreqProxTermsWriterPerThread perThread = (FreqProxTermsWriterPerThread) entry.getKey();
      perThread.termsHashPerThread.reset(true);
    }
    consumer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969880/fstmerge_base_6473628710971095211
@Override
  public void flush(Map<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> threadsAndFields, final SegmentWriteState state) throws IOException {

    // Gather all FieldData's that have postings, across all
    // ThreadStates
    List<FreqProxTermsWriterPerField> allFields = new ArrayList<FreqProxTermsWriterPerField>();
    
    flushedDocCount = state.numDocs;

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {

      Collection<TermsHashConsumerPerField> fields = entry.getValue();


      for (final TermsHashConsumerPerField i : fields) {
        final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) i;
        if (perField.termsHashPerField.numPostings > 0)
          allFields.add(perField);
      }
    }

    final int numAllFields = allFields.size();

    // Sort by field name
    Collections.sort(allFields);

    // TODO: allow Lucene user to customize this codec:
    final FieldsConsumer consumer = state.codec.fieldsConsumer(state);

    /*
    Current writer chain:
      FieldsConsumer
        -> IMPL: FormatPostingsTermsDictWriter
          -> TermsConsumer
            -> IMPL: FormatPostingsTermsDictWriter.TermsWriter
              -> DocsConsumer
                -> IMPL: FormatPostingsDocsWriter
                  -> PositionsConsumer
                    -> IMPL: FormatPostingsPositionsWriter
    */

    int start = 0;
    while(start < numAllFields) {
      final FieldInfo fieldInfo = allFields.get(start).fieldInfo;
      final String fieldName = fieldInfo.name;

      int end = start+1;
      while(end < numAllFields && allFields.get(end).fieldInfo.name.equals(fieldName))
        end++;
      
      FreqProxTermsWriterPerField[] fields = new FreqProxTermsWriterPerField[end-start];
      for(int i=start;i<end;i++) {
        fields[i-start] = allFields.get(i);

        // Aggregate the storePayload as seen by the same
        // field across multiple threads
        fieldInfo.storePayloads |= fields[i-start].hasPayloads;
      }

      // If this field has postings then add them to the
      // segment
      appendPostings(fields, consumer);

      for(int i=0;i<fields.length;i++) {
        TermsHashPerField perField = fields[i].termsHashPerField;
        int numPostings = perField.numPostings;
        perField.reset();
        perField.shrinkHash(numPostings);
        fields[i].reset();
      }

      start = end;
    }

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {
      FreqProxTermsWriterPerThread perThread = (FreqProxTermsWriterPerThread) entry.getKey();
      perThread.termsHashPerThread.reset(true);
    }
    consumer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627969880/fstmerge_var2_683406069033431944

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ public static final TermsEnum EMPTY = new TermsEnum() {    
    @Override
    public SeekStatus seek(BytesRef term, boolean useCache) { return SeekStatus.END; }
    
    @Override
    public SeekStatus seek(long ord) { return SeekStatus.END; }
    
    @Override
    public void cacheCurrentTerm() {}
    
    @Override
    public BytesRef term() {
      throw new IllegalStateException("this method should never be called");
    }

    @Override
    public Comparator<BytesRef> getComparator() {
      return null;
    }
      
    @Override
    public int docFreq() {
      throw new IllegalStateException("this method should never be called");
    }
      
    @Override
    public long ord() {
      throw new IllegalStateException("this method should never be called");
    }

    @Override
    public DocsEnum docs(Bits bits, DocsEnum reuse) {
      throw new IllegalStateException("this method should never be called");
    }
      
    @Override
    public DocsAndPositionsEnum docsAndPositions(Bits bits, DocsAndPositionsEnum reuse) {
      throw new IllegalStateException("this method should never be called");
    }
      
    @Override
    public BytesRef next() {
      return null;
    }
    
    @Override // make it synchronized here, to prevent double lazy init
    public synchronized AttributeSource attributes() {
      return super.attributes();
    }
  }; ##FSTMerge## public static final TermsEnum EMPTY = new TermsEnum() {    
    @Override
    public SeekStatus seek(BytesRef term, boolean useCache) { return SeekStatus.END; }
    
    @Override
    public SeekStatus seek(long ord) { return SeekStatus.END; }
    
    @Override
    public BytesRef term() {
      throw new IllegalStateException("this method should never be called");
    }

    @Override
    public Comparator<BytesRef> getComparator() {
      // return an unused dummy to prevent NPE
      return BytesRef.getUTF8SortedAsUTF16Comparator();
    }
      
    @Override
    public int docFreq() {
      throw new IllegalStateException("this method should never be called");
    }
      
    @Override
    public long ord() {
      throw new IllegalStateException("this method should never be called");
    }

    @Override
    public DocsEnum docs(Bits bits, DocsEnum reuse) {
      throw new IllegalStateException("this method should never be called");
    }
      
    @Override
    public DocsAndPositionsEnum docsAndPositions(Bits bits, DocsAndPositionsEnum reuse) {
      throw new IllegalStateException("this method should never be called");
    }
      
    @Override
    public BytesRef next() {
      return null;
    }
    
    @Override // make it synchronized here, to prevent double lazy init
    public synchronized AttributeSource attributes() {
      return super.attributes();
    }
  }; ##FSTMerge## public static final TermsEnum EMPTY = new TermsEnum() {    
    @Override
    public SeekStatus seek(BytesRef term, boolean useCache) { return SeekStatus.END; }
    
    @Override
    public SeekStatus seek(long ord) { return SeekStatus.END; }
    
    @Override
    public BytesRef term() {
      throw new IllegalStateException("this method should never be called");
    }

    @Override
    public Comparator<BytesRef> getComparator() {
      return null;
    }
      
    @Override
    public int docFreq() {
      throw new IllegalStateException("this method should never be called");
    }
      
    @Override
    public long ord() {
      throw new IllegalStateException("this method should never be called");
    }

    @Override
    public DocsEnum docs(Bits bits, DocsEnum reuse) {
      throw new IllegalStateException("this method should never be called");
    }
      
    @Override
    public DocsAndPositionsEnum docsAndPositions(Bits bits, DocsAndPositionsEnum reuse) {
      throw new IllegalStateException("this method should never be called");
    }
      
    @Override
    public BytesRef next() {
      return null;
    }
    
    @Override // make it synchronized here, to prevent double lazy init
    public synchronized AttributeSource attributes() {
      return super.attributes();
    }
  };
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsEnum.java
Conflict type: LineBasedMCFd
Conflict body: 
public void init(int address) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971095/fstmerge_var1_1304177374460993994
    slice = pool.buffers[address >> ByteBlockPool.BYTE_BLOCK_SHIFT];
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971095/fstmerge_base_3584041397756697350
    slice = pool.buffers[address >> DocumentsWriter.BYTE_BLOCK_SHIFT];
=======
    slice = pool.buffers[address >> DocumentsWriterRAMAllocator.BYTE_BLOCK_SHIFT];
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971095/fstmerge_var2_865479493817646004
    assert slice != null;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971095/fstmerge_var1_1304177374460993994
    upto = address & ByteBlockPool.BYTE_BLOCK_MASK;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971095/fstmerge_base_3584041397756697350
    upto = address & DocumentsWriter.BYTE_BLOCK_MASK;
=======
    upto = address & DocumentsWriterRAMAllocator.BYTE_BLOCK_MASK;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971095/fstmerge_var2_865479493817646004
    offset0 = address;
    assert upto < slice.length;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/ByteSliceWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971245/fstmerge_var1_4287125814481142119
  public void abort() {
    consumer.abort();
    if (nextTermsHash != null)
      nextTermsHash.abort();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971245/fstmerge_base_7938993113245196627
  synchronized public void abort() {
    consumer.abort();
    if (nextTermsHash != null)
      nextTermsHash.abort();
=======
  public void abort() {
    reset();
    try {
      consumer.abort();
    } finally {
      if (nextTermsHash != null) {
        nextTermsHash.abort();
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971245/fstmerge_var2_7789497390445482843
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHash.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ final static int BYTES_PER_POSTING = 3 * RamUsageEstimator.NUM_BYTES_INT; ##FSTMerge## final static int BYTES_PER_POSTING = 3 * DocumentsWriter.INT_NUM_BYTE; ##FSTMerge## final static int BYTES_PER_POSTING = 3 * DocumentsWriterRAMAllocator.INT_NUM_BYTE;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/ParallelPostingsArray.java
Conflict type: LineBasedMCFd
Conflict body: 
TermVectorsReader(Directory d, String segment, FieldInfos fieldInfos, int readBufferSize, int docStoreOffset, int size)
    throws CorruptIndexException, IOException {
    boolean success = false;

    try {
      String idxName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.VECTORS_INDEX_EXTENSION);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971551/fstmerge_var1_5667191510359482571
      tvx = d.openInput(idxName, readBufferSize);
      format = checkValidFormat(tvx, idxName);
      String fn = IndexFileNames.segmentFileName(segment, "", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);
      tvd = d.openInput(fn, readBufferSize);
      final int tvdFormat = checkValidFormat(tvd, fn);
      fn = IndexFileNames.segmentFileName(segment, "", IndexFileNames.VECTORS_FIELDS_EXTENSION);
      tvf = d.openInput(fn, readBufferSize);
      final int tvfFormat = checkValidFormat(tvf, fn);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971551/fstmerge_base_6095725281484341059
      if (d.fileExists(idxName)) {
        tvx = d.openInput(idxName, readBufferSize);
        format = checkValidFormat(tvx);
        tvd = d.openInput(IndexFileNames.segmentFileName(segment, "", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION), readBufferSize);
        final int tvdFormat = checkValidFormat(tvd);
        tvf = d.openInput(IndexFileNames.segmentFileName(segment, "", IndexFileNames.VECTORS_FIELDS_EXTENSION), readBufferSize);
        final int tvfFormat = checkValidFormat(tvf);
=======
      if (d.fileExists(idxName)) {
        tvx = d.openInput(idxName, readBufferSize);
        format = checkValidFormat(tvx, idxName);
        String fn = IndexFileNames.segmentFileName(segment, "", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);
        tvd = d.openInput(fn, readBufferSize);
        final int tvdFormat = checkValidFormat(tvd, fn);
        fn = IndexFileNames.segmentFileName(segment, "", IndexFileNames.VECTORS_FIELDS_EXTENSION);
        tvf = d.openInput(fn, readBufferSize);
        final int tvfFormat = checkValidFormat(tvf, fn);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971551/fstmerge_var2_5331901653519024707

      assert format == tvdFormat;
      assert format == tvfFormat;

      numTotalDocs = (int) (tvx.length() >> 4);

      if (-1 == docStoreOffset) {
        this.docStoreOffset = 0;
        this.size = numTotalDocs;
        assert size == 0 || numTotalDocs == size;
      } else {
        this.docStoreOffset = docStoreOffset;
        this.size = size;
        // Verify the file is long enough to hold all of our
        // docs
        assert numTotalDocs >= size + docStoreOffset: "numTotalDocs=" + numTotalDocs + " size=" + size + " docStoreOffset=" + docStoreOffset;
      }

      this.fieldInfos = fieldInfos;
      success = true;
    } finally {
      // With lock-less commits, it's entirely possible (and
      // fine) to hit a FileNotFound exception above. In
      // this case, we want to explicitly close any subset
      // of things that were opened so that we don't have to
      // wait for a GC to do so.
      if (!success) {
        close();
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermVectorsReader.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## private BufferedDeletes deletesInRAM = new BufferedDeletes(false); ##FSTMerge## private final BufferedDeletesInRAM deletesInRAM = new BufferedDeletesInRAM();
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## private int maxBufferedDeleteTerms = IndexWriterConfig.DEFAULT_MAX_BUFFERED_DELETE_TERMS; ##FSTMerge## private int maxBufferedDeleteTerms;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## private int numDocsInRAM; ##FSTMerge## private AtomicInteger numDocsInRAM = new AtomicInteger(0);
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971768/fstmerge_var1_8801373226069752853
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971768/fstmerge_base_1237611529029987951
int getMaxBufferedDeleteTerms() {
    return maxBufferedDeleteTerms;
  }
=======
public int getMaxBufferedDeleteTerms() {
    return maxBufferedDeleteTerms;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971768/fstmerge_var2_4529900352113249415

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971773/fstmerge_var1_2241738629908000887
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971773/fstmerge_base_3607964977937418442
void setMaxBufferedDeleteTerms(int maxBufferedDeleteTerms) {
    this.maxBufferedDeleteTerms = maxBufferedDeleteTerms;
  }
=======
public void setMaxBufferedDeleteTerms(int max) {
    this.maxBufferedDeleteTerms = max;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971773/fstmerge_var2_5224157963276525846

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971777/fstmerge_var1_4393227290946527617
synchronized boolean anyChanges() {
    return numDocs != 0 || pendingDeletes.any();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971777/fstmerge_base_1371465790519237633
synchronized boolean anyChanges() {
    return numDocsInRAM != 0 ||
      deletesInRAM.numTerms != 0 ||
      deletesInRAM.docIDs.size() != 0 ||
      deletesInRAM.queries.size() != 0;
=======
boolean anyChanges() {
    return numDocsInRAM.get() != 0 ||
      deletesInRAM.hasDeletes();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971777/fstmerge_var2_4866322784048190098
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971781/fstmerge_var1_4104886608429883949
boolean addDocument(Document doc, Analyzer analyzer) throws CorruptIndexException, IOException {
    return updateDocument(doc, analyzer, null);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971781/fstmerge_base_626661069031594699
boolean addDocument(Document doc, Analyzer analyzer)
    throws CorruptIndexException, IOException {
    return updateDocument(doc, analyzer, null);
=======
long addDocument(final Document doc, final Analyzer analyzer)
      throws CorruptIndexException, IOException {
    return updateDocument(null, doc, analyzer);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971781/fstmerge_var2_8645546115597170775
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971786/fstmerge_var1_1828276224956350695
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971786/fstmerge_base_5388238876889409800
boolean updateDocument(Term t, Document doc, Analyzer analyzer)
    throws CorruptIndexException, IOException {
    return updateDocument(doc, analyzer, t);
  }
=======
long updateDocument(final Term delTerm, final Document doc, final Analyzer analyzer)
      throws CorruptIndexException, IOException {

    UpdateResult result = threadPool.executePerThread(this, doc,
        new DocumentsWriterThreadPool.PerThreadTask<UpdateResult>() {
          @Override
          public UpdateResult process(final DocumentsWriterPerThread perThread) throws IOException {
            long perThreadRAMUsedBeforeAdd = perThread.numBytesUsed;
            perThread.addDocument(doc, analyzer);

            final long sequenceID;
            sequenceIDLock.lock();
            try {
              ensureOpen();
              sequenceID = nextSequenceID();
              if (delTerm != null) {
                deletesInRAM.addDeleteTerm(delTerm, sequenceID, numDocumentsWriterPerThreads);
              }
              perThread.commitDocument(sequenceID);
              if (!minSequenceIDsPerThread.containsKey(perThread)) {
                minSequenceIDsPerThread.put(perThread, sequenceID);
              }
              numDocsInRAM.incrementAndGet();
            } finally {
              sequenceIDLock.unlock();
            }

            UpdateResult result = new UpdateResult(sequenceID);
            if (finishAddDocument(perThread, perThreadRAMUsedBeforeAdd)) {
              result.flushed = true;
              super.clearThreadBindings();
            }
            return result;
          }
        });
        
    if (result == null) {
      return -1;
    }
    
    if (result.flushed) {
      indexWriter.maybeMerge();
    }
    return result.sequenceID;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971786/fstmerge_var2_3332577128806101647

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971790/fstmerge_var1_3152653904212443261
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971790/fstmerge_base_6060265005072025657
boolean bufferDeleteTerms(Term[] terms) throws IOException {
    synchronized(this) {
      waitReady(null);
      for (int i = 0; i < terms.length; i++)
        addDeleteTerm(terms[i], numDocsInRAM);
    }
    return timeToFlushDeletes();
  }
=======
long bufferDeleteTerms(final Term[] terms) throws IOException {
    sequenceIDLock.lock();
    try {
      ensureOpen();
      final long sequenceID = nextSequenceID();
      deletesInRAM.addDeleteTerms(terms, sequenceID, numDocumentsWriterPerThreads);
      return sequenceID;
    } finally {
      sequenceIDLock.unlock();
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971790/fstmerge_var2_1607199722015825370

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971795/fstmerge_var1_2069564829429995102
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971795/fstmerge_base_6654956638936204816
boolean bufferDeleteTerm(Term term) throws IOException {
    synchronized(this) {
      waitReady(null);
      addDeleteTerm(term, numDocsInRAM);
    }
    return timeToFlushDeletes();
  }
=======
long bufferDeleteTerm(final Term term) throws IOException {
    sequenceIDLock.lock();
    try {
      ensureOpen();
      final long sequenceID = nextSequenceID();
      deletesInRAM.addDeleteTerm(term, sequenceID, numDocumentsWriterPerThreads);
      return sequenceID;
    } finally {
      sequenceIDLock.unlock();
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971795/fstmerge_var2_2141830517515789409

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971800/fstmerge_var1_1027926322587731393
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971800/fstmerge_base_4581693887792377330
boolean bufferDeleteQueries(Query[] queries) throws IOException {
    synchronized(this) {
      waitReady(null);
      for (int i = 0; i < queries.length; i++)
        addDeleteQuery(queries[i], numDocsInRAM);
    }
    return timeToFlushDeletes();
  }
=======
long bufferDeleteQueries(final Query[] queries) throws IOException {
    sequenceIDLock.lock();
    try {
      ensureOpen();
      final long sequenceID = nextSequenceID();
      for (Query q : queries) {
        deletesInRAM.addDeleteQuery(q, sequenceID, numDocumentsWriterPerThreads);
      }
      return sequenceID;
    } finally {
      sequenceIDLock.unlock();
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971800/fstmerge_var2_3262391578667339727

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971804/fstmerge_var1_7124706310597929733
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971804/fstmerge_base_1025601250722263308
boolean bufferDeleteQuery(Query query) throws IOException {
    synchronized(this) {
      waitReady(null);
      addDeleteQuery(query, numDocsInRAM);
    }
    return timeToFlushDeletes();
  }
=======
long bufferDeleteQuery(final Query query) throws IOException {
    sequenceIDLock.lock();
    try {
      ensureOpen();
      final long sequenceID = nextSequenceID();
      deletesInRAM.addDeleteQuery(query, sequenceID, numDocumentsWriterPerThreads);
      return sequenceID;
    } finally {
      sequenceIDLock.unlock();
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971804/fstmerge_var2_9065265333195991759

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971809/fstmerge_var1_7913155808933817324
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971809/fstmerge_base_3767242465411947457
synchronized boolean pauseAllThreads() {
    pauseThreads++;
    while(!allThreadsIdle()) {
      try {
        wait();
      } catch (InterruptedException ie) {
        throw new ThreadInterruptedException(ie);
      }
    }

    return aborting;
  }
=======
void pauseAllThreads() {
    threadPool.pauseAllThreads();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971809/fstmerge_var2_3056972035791461920

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971813/fstmerge_var1_2623271945807223045
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971813/fstmerge_base_5547153623502682667
synchronized void resumeAllThreads() {
    pauseThreads--;
    assert pauseThreads >= 0;
    if (0 == pauseThreads)
      notifyAll();
  }
=======
void resumeAllThreads() {
    threadPool.resumeAllThreads();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971813/fstmerge_var2_3717095061567316396

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971823/fstmerge_var1_6860186777873659909
synchronized void abort() throws IOException {
    if (infoStream != null) {
      message("docWriter: abort");
    }

    boolean success = false;

    try {

      // Forcefully remove waiting ThreadStates from line
      waitQueue.abort();

      // Wait for all other threads to finish with
      // DocumentsWriter:
      waitIdle();

      if (infoStream != null) {
        message("docWriter: abort waitIdle done");
      }

      assert 0 == waitQueue.numWaiting: "waitQueue.numWaiting=" + waitQueue.numWaiting;

      waitQueue.waitingBytes = 0;

      pendingDeletes.clear();

      for (DocumentsWriterThreadState threadState : threadStates)
        try {
          threadState.consumer.abort();
        } catch (Throwable t) {
        }

      try {
        consumer.abort();
      } catch (Throwable t) {
      }

      // Reset all postings data
      doAfterFlush();
      success = true;
    } finally {
      aborting = false;
      notifyAll();
      if (infoStream != null) {
        message("docWriter: done abort; success=" + success);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971823/fstmerge_base_2255400090843353977
synchronized void abort() throws IOException {

    try {
      if (infoStream != null) {
        message("docWriter: now abort");
      }

      // Forcefully remove waiting ThreadStates from line
      waitQueue.abort();

      // Wait for all other threads to finish with
      // DocumentsWriter:
      pauseAllThreads();

      try {

        assert 0 == waitQueue.numWaiting;

        waitQueue.waitingBytes = 0;

        try {
          abortedFiles = openFiles();
        } catch (Throwable t) {
          abortedFiles = null;
        }

        deletesInRAM.clear();

        openFiles.clear();

        for(int i=0;i<threadStates.length;i++)
          try {
            threadStates[i].consumer.abort();
          } catch (Throwable t) {
          }

        try {
          consumer.abort();
        } catch (Throwable t) {
        }

        docStoreSegment = null;
        numDocsInStore = 0;
        docStoreOffset = 0;

        // Reset all postings data
        doAfterFlush();

      } finally {
        resumeAllThreads();
      }
    } finally {
      aborting = false;
      notifyAll();
      if (infoStream != null) {
        message("docWriter: done abort");
=======
void abort() throws IOException {
    threadPool.abort(new DocumentsWriterThreadPool.AbortTask() {
      
      @Override
      void abort() throws IOException {
        try {
          abortedFiles = openFiles();
        } catch (Throwable t) {
          abortedFiles = null;
        }
    
        deletesInRAM.clear();
        // nocommit
    //        deletesFlushed.clear();
    
        openFiles.clear();
        deletesInRAM.clear();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971823/fstmerge_var2_411521473453932267
      }
    });
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## final List<String> openFiles = new ArrayList<String>(); ##FSTMerge## final Set<String> openFiles = new HashSet<String>();
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971828/fstmerge_var1_4454459021629020879
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971828/fstmerge_base_4728677443891109673
@SuppressWarnings("unchecked")
  synchronized List<String> openFiles() {
    return (List<String>) ((ArrayList<String>) openFiles).clone();
  }
=======
@SuppressWarnings("unchecked")
  private Collection<String> openFiles() {
    synchronized(openFiles) {
      return (Set<String>) ((HashSet<String>) openFiles).clone();
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971828/fstmerge_var2_8260345398177691277

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971832/fstmerge_var1_4540494283653440972
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971832/fstmerge_base_3825596360795416662
synchronized void addOpenFile(String name) {
    assert !openFiles.contains(name);
    openFiles.add(name);
  }
=======
void addOpenFile(String file) {
    synchronized(openFiles) {
      openFiles.add(file);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971832/fstmerge_var2_4637217409839202250

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971837/fstmerge_var1_2184215432615831592
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971837/fstmerge_base_7356797718867624316
synchronized void removeOpenFile(String name) {
    assert openFiles.contains(name);
    openFiles.remove(name);
    closedFiles.add(name);
  }
=======
void removeOpenFile(String file) {
    synchronized(openFiles) {
      openFiles.remove(file);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971837/fstmerge_var2_4877111136389344112

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971847/fstmerge_var1_7987134250847648327
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971847/fstmerge_base_9218519390246812469
synchronized boolean hasDeletes() {
    return deletesFlushed.any();
  }
=======
boolean hasDeletes() {
    return deletesInRAM.hasDeletes();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971847/fstmerge_var2_5307809512401005262

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971852/fstmerge_var1_7862304764614113347
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971852/fstmerge_base_1128554528326812707
int getNumDocsInRAM() {
    return numDocsInRAM;
  }
=======
int getNumDocsInRAM() {
    return numDocsInRAM.get();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971852/fstmerge_var2_3806637482409310322

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971857/fstmerge_var1_4728244454553092094
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971857/fstmerge_base_3219300146737755024
long getRAMUsed() {
    return numBytesUsed + deletesInRAM.bytesUsed + deletesFlushed.bytesUsed;
  }
=======
long getRAMUsed() {
    return ramUsed.get();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971857/fstmerge_var2_8191297828806083044

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971862/fstmerge_var1_3755696770987961920
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971862/fstmerge_base_5884176446898946400
synchronized boolean applyDeletes(SegmentInfos infos) throws IOException {

    if (!hasDeletes())
      return false;

    final long t0 = System.currentTimeMillis();

    if (infoStream != null)
      message("apply " + deletesFlushed.numTerms + " buffered deleted terms and " +
              deletesFlushed.docIDs.size() + " deleted docIDs and " +
              deletesFlushed.queries.size() + " deleted queries on " +
              + infos.size() + " segments.");

    final int infosEnd = infos.size();

    int docStart = 0;
    boolean any = false;
    for (int i = 0; i < infosEnd; i++) {

      // Make sure we never attempt to apply deletes to
      // segment in external dir
      assert infos.info(i).dir == directory;

      SegmentReader reader = writer.readerPool.get(infos.info(i), false);
      try {
        any |= applyDeletes(reader, docStart);
        docStart += reader.maxDoc();
      } finally {
        writer.readerPool.release(reader);
      }
    }

    deletesFlushed.clear();
    if (infoStream != null) {
      message("apply deletes took " + (System.currentTimeMillis()-t0) + " msec");
    }

    return any;
  }
=======
boolean applyDeletes(SegmentInfos infos) throws IOException {
    if (!hasDeletes())
      return false;

    final long t0 = System.currentTimeMillis();

    if (infoStream != null) {
      message("apply " + deletesInRAM.getNumDeletes() + " buffered deletes on " +
              +infos.size() + " segments.");
    }

    final int infosEnd = infos.size();

    boolean any = false;
    for (int i = 0; i < infosEnd; i++) {

      // Make sure we never attempt to apply deletes to
      // segment in external dir
      assert infos.info(i).dir == indexWriter.getDirectory();

      SegmentInfo si = infos.info(i);
      // we have to synchronize here, because we need a write lock on
      // the segment in order to apply deletes
      synchronized (indexWriter) {
        SegmentReader reader = indexWriter.readerPool.get(si, false);
        try {
          any |= applyDeletes(reader, si.getMinSequenceID(), si.getMaxSequenceID(), null);
        } finally {
          indexWriter.readerPool.release(reader);
        }
      }
    }

    if (infoStream != null) {
      message("apply deletes took " + (System.currentTimeMillis() - t0) + " msec");
    }

    return any;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971862/fstmerge_var2_6544618890834744312

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
void message(String message) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971867/fstmerge_var1_5570270216989790057
    if (infoStream != null) {
      writer.message("DW: " + message);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971867/fstmerge_base_4041788386376334211
    if (infoStream != null)
      writer.message("DW: " + message);
=======
    indexWriter.message("DW: " + message);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971867/fstmerge_var2_6048057116556896229
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ static final IndexingChain defaultIndexingChain = new IndexingChain() {

    @Override
    DocConsumer getChain(DocumentsWriter documentsWriter) {
      /*
      This is the current indexing chain:

      DocConsumer / DocConsumerPerThread
        --> code: DocFieldProcessor / DocFieldProcessorPerThread
          --> DocFieldConsumer / DocFieldConsumerPerThread / DocFieldConsumerPerField
            --> code: DocFieldConsumers / DocFieldConsumersPerThread / DocFieldConsumersPerField
              --> code: DocInverter / DocInverterPerThread / DocInverterPerField
                --> InvertedDocConsumer / InvertedDocConsumerPerThread / InvertedDocConsumerPerField
                  --> code: TermsHash / TermsHashPerThread / TermsHashPerField
                    --> TermsHashConsumer / TermsHashConsumerPerThread / TermsHashConsumerPerField
                      --> code: FreqProxTermsWriter / FreqProxTermsWriterPerThread / FreqProxTermsWriterPerField
                      --> code: TermVectorsTermsWriter / TermVectorsTermsWriterPerThread / TermVectorsTermsWriterPerField
                --> InvertedDocEndConsumer / InvertedDocConsumerPerThread / InvertedDocConsumerPerField
                  --> code: NormsWriter / NormsWriterPerThread / NormsWriterPerField
              --> code: StoredFieldsWriter / StoredFieldsWriterPerThread / StoredFieldsWriterPerField
    */

    // Build up indexing chain:

      final TermsHashConsumer termVectorsWriter = new TermVectorsTermsWriter(documentsWriter);
      final TermsHashConsumer freqProxWriter = new FreqProxTermsWriter();
      /*
       * nesting TermsHash instances here to allow the secondary (TermVectors) share the interned postings
       * via a shared ByteBlockPool. See TermsHashPerField for details. 
       */
      final TermsHash termVectorsTermHash = new TermsHash(documentsWriter, false, termVectorsWriter, null);
      final InvertedDocConsumer  termsHash = new TermsHash(documentsWriter, true, freqProxWriter, termVectorsTermHash);
      final NormsWriter normsWriter = new NormsWriter();
      final DocInverter docInverter = new DocInverter(termsHash, normsWriter);
      return new DocFieldProcessor(documentsWriter, docInverter);
    }
  }; ##FSTMerge## static final IndexingChain defaultIndexingChain = new IndexingChain() {

    @Override
    DocConsumer getChain(DocumentsWriter documentsWriter) {
      /*
      This is the current indexing chain:

      DocConsumer / DocConsumerPerThread
        --> code: DocFieldProcessor / DocFieldProcessorPerThread
          --> DocFieldConsumer / DocFieldConsumerPerThread / DocFieldConsumerPerField
            --> code: DocFieldConsumers / DocFieldConsumersPerThread / DocFieldConsumersPerField
              --> code: DocInverter / DocInverterPerThread / DocInverterPerField
                --> InvertedDocConsumer / InvertedDocConsumerPerThread / InvertedDocConsumerPerField
                  --> code: TermsHash / TermsHashPerThread / TermsHashPerField
                    --> TermsHashConsumer / TermsHashConsumerPerThread / TermsHashConsumerPerField
                      --> code: FreqProxTermsWriter / FreqProxTermsWriterPerThread / FreqProxTermsWriterPerField
                      --> code: TermVectorsTermsWriter / TermVectorsTermsWriterPerThread / TermVectorsTermsWriterPerField
                --> InvertedDocEndConsumer / InvertedDocConsumerPerThread / InvertedDocConsumerPerField
                  --> code: NormsWriter / NormsWriterPerThread / NormsWriterPerField
              --> code: StoredFieldsWriter / StoredFieldsWriterPerThread / StoredFieldsWriterPerField
    */

    // Build up indexing chain:

      final TermsHashConsumer termVectorsWriter = new TermVectorsTermsWriter(documentsWriter);
      final TermsHashConsumer freqProxWriter = new FreqProxTermsWriter();

      final InvertedDocConsumer  termsHash = new TermsHash(documentsWriter, true, freqProxWriter,
                                                           new TermsHash(documentsWriter, false, termVectorsWriter, null));
      final NormsWriter normsWriter = new NormsWriter();
      final DocInverter docInverter = new DocInverter(termsHash, normsWriter);
      return new DocFieldProcessor(documentsWriter, docInverter);
    }
  }; ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971916/fstmerge_var1_9179322984759605523
synchronized void setInfoStream(PrintStream infoStream) {
    this.infoStream = infoStream;
    for(int i=0;i<threadStates.length;i++) {
      threadStates[i].docState.infoStream = infoStream;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971916/fstmerge_base_469526217339101839
synchronized void setInfoStream(PrintStream infoStream) {
    this.infoStream = infoStream;
    for(int i=0;i<threadStates.length;i++)
      threadStates[i].docState.infoStream = infoStream;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971916/fstmerge_var2_3032947383184724407

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971920/fstmerge_var1_734675121532113681
synchronized void setMaxFieldLength(int maxFieldLength) {
    this.maxFieldLength = maxFieldLength;
    for(int i=0;i<threadStates.length;i++) {
      threadStates[i].docState.maxFieldLength = maxFieldLength;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971920/fstmerge_base_4172287561326260317
synchronized void setMaxFieldLength(int maxFieldLength) {
    this.maxFieldLength = maxFieldLength;
    for(int i=0;i<threadStates.length;i++)
      threadStates[i].docState.maxFieldLength = maxFieldLength;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971920/fstmerge_var2_7692045833648673888

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971925/fstmerge_var1_2270233507240809135
synchronized void setSimilarity(Similarity similarity) {
    this.similarity = similarity;
    for(int i=0;i<threadStates.length;i++) {
      threadStates[i].docState.similarity = similarity;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971925/fstmerge_base_4584954303900508581
synchronized void setSimilarity(Similarity similarity) {
    this.similarity = similarity;
    for(int i=0;i<threadStates.length;i++)
      threadStates[i].docState.similarity = similarity;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971925/fstmerge_var2_6860566917622581502

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971929/fstmerge_var1_3600983631148173206
synchronized String getSegment() {
    return segment;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971929/fstmerge_base_7149866169847724238
String getSegment() {
    return segment;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971929/fstmerge_var2_5799307395772244462

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971934/fstmerge_var1_681997729615614465
synchronized void setAborting() {
    if (infoStream != null) {
      message("setAborting");
    }
    aborting = true;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971934/fstmerge_base_7724755265331084564
synchronized void setAborting() {
    aborting = true;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971934/fstmerge_var2_781854498534957203

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971938/fstmerge_var1_8190792049654622171
private void doAfterFlush() throws IOException {
    // All ThreadStates should be idle when we are called
    assert allThreadsIdle();
    threadBindings.clear();
    waitQueue.reset();
    segment = null;
    numDocs = 0;
    nextDocID = 0;
    bufferIsFull = false;
    for(int i=0;i<threadStates.length;i++) {
      threadStates[i].doAfterFlush();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971938/fstmerge_base_471854893092116730
private void doAfterFlush() throws IOException {
    // All ThreadStates should be idle when we are called
    assert allThreadsIdle();
    threadBindings.clear();
    waitQueue.reset();
    segment = null;
    numDocsInRAM = 0;
    nextDocID = 0;
    bufferIsFull = false;
    flushPending = false;
    for(int i=0;i<threadStates.length;i++)
      threadStates[i].doAfterFlush();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971938/fstmerge_var2_6508918086229705237

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971943/fstmerge_var1_4560201119756098873
private synchronized boolean allThreadsIdle() {
    for(int i=0;i<threadStates.length;i++) {
      if (!threadStates[i].isIdle) {
        return false;
      }
    }
    return true;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971943/fstmerge_base_3978303307323017615
private synchronized boolean allThreadsIdle() {
    for(int i=0;i<threadStates.length;i++)
      if (!threadStates[i].isIdle)
        return false;
    return true;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971943/fstmerge_var2_4740306254718043327

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971947/fstmerge_var1_6954893362109025957
synchronized DocumentsWriterThreadState getThreadState(Document doc, Term delTerm) throws IOException {

    final Thread currentThread = Thread.currentThread();
    assert !Thread.holdsLock(writer);

    // First, find a thread state.  If this thread already
    // has affinity to a specific ThreadState, use that one
    // again.
    DocumentsWriterThreadState state = threadBindings.get(currentThread);
    if (state == null) {

      // First time this thread has called us since last
      // flush.  Find the least loaded thread state:
      DocumentsWriterThreadState minThreadState = null;
      for(int i=0;i<threadStates.length;i++) {
        DocumentsWriterThreadState ts = threadStates[i];
        if (minThreadState == null || ts.numThreads < minThreadState.numThreads) {
          minThreadState = ts;
        }
      }
      if (minThreadState != null && (minThreadState.numThreads == 0 || threadStates.length >= maxThreadStates)) {
        state = minThreadState;
        state.numThreads++;
      } else {
        // Just create a new "private" thread state
        DocumentsWriterThreadState[] newArray = new DocumentsWriterThreadState[1+threadStates.length];
        if (threadStates.length > 0) {
          System.arraycopy(threadStates, 0, newArray, 0, threadStates.length);
        }
        state = newArray[threadStates.length] = new DocumentsWriterThreadState(this);
        threadStates = newArray;
      }
      threadBindings.put(currentThread, state);
    }

    // Next, wait until my thread state is idle (in case
    // it's shared with other threads), and no flush/abort
    // pending 
    waitReady(state);

    // Allocate segment name if this is the first doc since
    // last flush:
    if (segment == null) {
      segment = writer.newSegmentName();
      assert numDocs == 0;
    }

    state.docState.docID = nextDocID++;

    if (delTerm != null) {
      pendingDeletes.addTerm(delTerm, state.docState.docID);
    }

    numDocs++;
    state.isIdle = false;
    return state;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971947/fstmerge_base_3200775102332526927
synchronized DocumentsWriterThreadState getThreadState(Document doc, Term delTerm) throws IOException {

    // First, find a thread state.  If this thread already
    // has affinity to a specific ThreadState, use that one
    // again.
    DocumentsWriterThreadState state = threadBindings.get(Thread.currentThread());
    if (state == null) {

      // First time this thread has called us since last
      // flush.  Find the least loaded thread state:
      DocumentsWriterThreadState minThreadState = null;
      for(int i=0;i<threadStates.length;i++) {
        DocumentsWriterThreadState ts = threadStates[i];
        if (minThreadState == null || ts.numThreads < minThreadState.numThreads)
          minThreadState = ts;
      }
      if (minThreadState != null && (minThreadState.numThreads == 0 || threadStates.length >= maxThreadStates)) {
        state = minThreadState;
        state.numThreads++;
      } else {
        // Just create a new "private" thread state
        DocumentsWriterThreadState[] newArray = new DocumentsWriterThreadState[1+threadStates.length];
        if (threadStates.length > 0)
          System.arraycopy(threadStates, 0, newArray, 0, threadStates.length);
        state = newArray[threadStates.length] = new DocumentsWriterThreadState(this);
        threadStates = newArray;
      }
      threadBindings.put(Thread.currentThread(), state);
    }

    // Next, wait until my thread state is idle (in case
    // it's shared with other threads) and for threads to
    // not be paused nor a flush pending:
    waitReady(state);

    // Allocate segment name if this is the first doc since
    // last flush:
    initSegmentName(false);

    state.isIdle = false;

    boolean success = false;
    try {
      state.docState.docID = nextDocID;

      assert writer.testPoint("DocumentsWriter.ThreadState.init start");

      if (delTerm != null) {
        addDeleteTerm(delTerm, state.docState.docID);
        state.doFlushAfter = timeToFlushDeletes();
      }

      assert writer.testPoint("DocumentsWriter.ThreadState.init after delTerm");

      nextDocID++;
      numDocsInRAM++;

      // We must at this point commit to flushing to ensure we
      // always get N docs when we flush by doc count, even if
      // > 1 thread is adding documents:
      if (!flushPending &&
          maxBufferedDocs != IndexWriterConfig.DISABLE_AUTO_FLUSH
          && numDocsInRAM >= maxBufferedDocs) {
        flushPending = true;
        state.doFlushAfter = true;
      }

      success = true;
    } finally {
      if (!success) {
        // Forcefully idle this ThreadState:
        state.isIdle = true;
        notifyAll();
        if (state.doFlushAfter) {
          state.doFlushAfter = false;
          flushPending = false;
        }
      }
    }

    return state;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971947/fstmerge_var2_3590378004298152510

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971953/fstmerge_var1_2466091725126365578
boolean updateDocument(Document doc, Analyzer analyzer, Term delTerm)
    throws CorruptIndexException, IOException {

    // Possibly trigger a flush, or wait until any running flush completes:
    boolean doFlush = flushControl.waitUpdate(1, delTerm != null ? 1 : 0);

    // This call is synchronized but fast
    final DocumentsWriterThreadState state = getThreadState(doc, delTerm);

    final DocState docState = state.docState;
    docState.doc = doc;
    docState.analyzer = analyzer;

    boolean success = false;
    try {
      // This call is not synchronized and does all the
      // work
      final DocWriter perDoc;
      try {
        perDoc = state.consumer.processDocument();
      } finally {
        docState.clear();
      }

      // This call is synchronized but fast
      finishDocument(state, perDoc);

      success = true;
    } finally {
      if (!success) {

        // If this thread state had decided to flush, we
        // must clear it so another thread can flush
        if (doFlush) {
          flushControl.clearFlushPending();
        }

        if (infoStream != null) {
          message("exception in updateDocument aborting=" + aborting);
        }

        synchronized(this) {

          state.isIdle = true;
          notifyAll();
            
          if (aborting) {
            abort();
          } else {
            skipDocWriter.docID = docState.docID;
            boolean success2 = false;
            try {
              waitQueue.add(skipDocWriter);
              success2 = true;
            } finally {
              if (!success2) {
                abort();
                return false;
              }
            }

            // Immediately mark this document as deleted
            // since likely it was partially added.  This
            // keeps indexing as "all or none" (atomic) when
            // adding a document:
            deleteDocID(state.docState.docID);
          }
        }
      }
    }

    doFlush |= flushControl.flushByRAMUsage("new document");

    return doFlush;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971953/fstmerge_base_7102065633247260372
boolean updateDocument(Document doc, Analyzer analyzer, Term delTerm)
    throws CorruptIndexException, IOException {
    
    // This call is synchronized but fast
    final DocumentsWriterThreadState state = getThreadState(doc, delTerm);

    final DocState docState = state.docState;
    docState.doc = doc;
    docState.analyzer = analyzer;

    boolean success = false;
    try {
      // This call is not synchronized and does all the
      // work
      final DocWriter perDoc;
      try {
        perDoc = state.consumer.processDocument();
      } finally {
        docState.clear();
      }

      // This call is synchronized but fast
      finishDocument(state, perDoc);

      success = true;
    } finally {
      if (!success) {
        synchronized(this) {

          if (aborting) {
            state.isIdle = true;
            notifyAll();
            abort();
          } else {
            skipDocWriter.docID = docState.docID;
            boolean success2 = false;
            try {
              waitQueue.add(skipDocWriter);
              success2 = true;
            } finally {
              if (!success2) {
                state.isIdle = true;
                notifyAll();
                abort();
                return false;
              }
            }

            state.isIdle = true;
            notifyAll();

            // If this thread state had decided to flush, we
            // must clear it so another thread can flush
            if (state.doFlushAfter) {
              state.doFlushAfter = false;
              flushPending = false;
              notifyAll();
            }

            // Immediately mark this document as deleted
            // since likely it was partially added.  This
            // keeps indexing as "all or none" (atomic) when
            // adding a document:
            addDeleteDocID(state.docState.docID);
          }
        }
      }
    }

    return state.doFlushAfter || timeToFlushDeletes();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971953/fstmerge_var2_5112196818404541523

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971958/fstmerge_var1_9081180695310376033
synchronized void waitReady(DocumentsWriterThreadState state) {
    while (!closed && (!state.isIdle || aborting)) {
      try {
        wait();
      } catch (InterruptedException ie) {
        throw new ThreadInterruptedException(ie);
      }
    }

    if (closed) {
      throw new AlreadyClosedException("this IndexWriter is closed");
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971958/fstmerge_base_6522406999865816084
synchronized private void waitReady(DocumentsWriterThreadState state) {

    while (!closed && ((state != null && !state.isIdle) || pauseThreads != 0 || flushPending || aborting)) {
      try {
        wait();
      } catch (InterruptedException ie) {
        throw new ThreadInterruptedException(ie);
      }
    }

    if (closed)
      throw new AlreadyClosedException("this IndexWriter is closed");
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971958/fstmerge_var2_3588764276228629283

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971963/fstmerge_var1_7180447056362585624
private void finishDocument(DocumentsWriterThreadState perThread, DocWriter docWriter) throws IOException {

    // Must call this w/o holding synchronized(this) else
    // we'll hit deadlock:
    balanceRAM();

    synchronized(this) {

      assert docWriter == null || docWriter.docID == perThread.docState.docID;

      if (aborting) {

        // We are currently aborting, and another thread is
        // waiting for me to become idle.  We just forcefully
        // idle this threadState; it will be fully reset by
        // abort()
        if (docWriter != null) {
          try {
            docWriter.abort();
          } catch (Throwable t) {
          }
        }

        perThread.isIdle = true;

        // wakes up any threads waiting on the wait queue
        notifyAll();

        return;
      }

      final boolean doPause;

      if (docWriter != null) {
        doPause = waitQueue.add(docWriter);
      } else {
        skipDocWriter.docID = perThread.docState.docID;
        doPause = waitQueue.add(skipDocWriter);
      }

      if (doPause) {
        waitForWaitQueue();
      }

      perThread.isIdle = true;

      // wakes up any threads waiting on the wait queue
      notifyAll();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971963/fstmerge_base_1135061284983768835
private void finishDocument(DocumentsWriterThreadState perThread, DocWriter docWriter) throws IOException {

    // Must call this w/o holding synchronized(this) else
    // we'll hit deadlock:
    balanceRAM();

    synchronized(this) {

      assert docWriter == null || docWriter.docID == perThread.docState.docID;

      if (aborting) {

        // We are currently aborting, and another thread is
        // waiting for me to become idle.  We just forcefully
        // idle this threadState; it will be fully reset by
        // abort()
        if (docWriter != null)
          try {
            docWriter.abort();
          } catch (Throwable t) {
          }

        perThread.isIdle = true;
        notifyAll();
        return;
      }

      final boolean doPause;

      if (docWriter != null)
        doPause = waitQueue.add(docWriter);
      else {
        skipDocWriter.docID = perThread.docState.docID;
        doPause = waitQueue.add(skipDocWriter);
      }

      if (doPause)
        waitForWaitQueue();

      if (bufferIsFull && !flushPending) {
        flushPending = true;
        perThread.doFlushAfter = true;
      }

      perThread.isIdle = true;
      notifyAll();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971963/fstmerge_var2_7518523719557210063

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ private List<int[]> freeIntBlocks = new ArrayList<int[]>(); ##FSTMerge## private ArrayList<int[]> freeIntBlocks = new ArrayList<int[]>(); ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971985/fstmerge_var1_8079394812166180798
synchronized int[] getIntBlock() {
    final int size = freeIntBlocks.size();
    final int[] b;
    if (0 == size) {
      b = new int[INT_BLOCK_SIZE];
      bytesUsed.addAndGet(INT_BLOCK_SIZE*RamUsageEstimator.NUM_BYTES_INT);
    } else {
      b = freeIntBlocks.remove(size-1);
    }
    return b;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971985/fstmerge_base_769322338269664895
synchronized int[] getIntBlock() {
    final int size = freeIntBlocks.size();
    final int[] b;
    if (0 == size) {
      b = new int[INT_BLOCK_SIZE];
      numBytesUsed += INT_BLOCK_SIZE*INT_NUM_BYTE;
    } else
      b = freeIntBlocks.remove(size-1);
    return b;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971985/fstmerge_var2_3012719788361224388

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ final RecyclingByteBlockAllocator byteBlockAllocator = new RecyclingByteBlockAllocator(BYTE_BLOCK_SIZE, Integer.MAX_VALUE, bytesUsed); ##FSTMerge## ByteBlockAllocator byteBlockAllocator = new ByteBlockAllocator(BYTE_BLOCK_SIZE); ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ final RecyclingByteBlockAllocator perDocAllocator = new RecyclingByteBlockAllocator(PER_DOC_BLOCK_SIZE, Integer.MAX_VALUE, bytesUsed); ##FSTMerge## final ByteBlockAllocator perDocAllocator = new ByteBlockAllocator(PER_DOC_BLOCK_SIZE); ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971999/fstmerge_var1_7785515874268382766
void balanceRAM() {

    final boolean doBalance;
    final long deletesRAMUsed;

    deletesRAMUsed = bufferedDeletes.bytesUsed();

    synchronized(this) {
      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {
        return;
      }
    
      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;
    }

    if (doBalance) {

      if (infoStream != null) {
        message("  RAM: balance allocations: usedMB=" + toMB(bytesUsed()) +
                " vs trigger=" + toMB(ramBufferSize) +
                " deletesMB=" + toMB(deletesRAMUsed) +
                " byteBlockFree=" + toMB(byteBlockAllocator.bytesUsed()) +
                " perDocFree=" + toMB(perDocAllocator.bytesUsed()));
      }

      final long startBytesUsed = bytesUsed() + deletesRAMUsed;

      int iter = 0;

      // We free equally from each pool in 32 KB
      // chunks until we are below our threshold
      // (freeLevel)

      boolean any = true;

      while(bytesUsed()+deletesRAMUsed > freeLevel) {
      
        synchronized(this) {
          if (0 == perDocAllocator.numBufferedBlocks() &&
              0 == byteBlockAllocator.numBufferedBlocks() &&
              0 == freeIntBlocks.size() && !any) {
            // Nothing else to free -- must flush now.
            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;
            if (infoStream != null) {
              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {
                message("    nothing to free; set bufferIsFull");
              } else {
                message("    nothing to free");
              }
            }
            break;
          }

          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {
            byteBlockAllocator.freeBlocks(1);
          }
          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {
            freeIntBlocks.remove(freeIntBlocks.size()-1);
            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);
          }
          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {
            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)
          }
        }

        if ((3 == iter % 4) && any) {
          // Ask consumer to free any recycled state
          any = consumer.freeRAM();
        }

        iter++;
      }

      if (infoStream != null) {
        message("    after free: freedMB=" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + " usedMB=" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971999/fstmerge_base_2862104626166512023
void balanceRAM() {

    final boolean doBalance;
    final long deletesRAMUsed;

    synchronized(this) {
      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {
        return;
      }
    
      deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;
      doBalance = numBytesUsed+deletesRAMUsed >= ramBufferSize;
    }

    if (doBalance) {

      if (infoStream != null)
        message("  RAM: now balance allocations: usedMB=" + toMB(numBytesUsed) +
                " vs trigger=" + toMB(ramBufferSize) +
                " deletesMB=" + toMB(deletesRAMUsed) +
                " byteBlockFree=" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +
                " perDocFree=" + toMB(perDocAllocator.freeByteBlocks.size()*PER_DOC_BLOCK_SIZE));

      final long startBytesUsed = numBytesUsed + deletesRAMUsed;

      int iter = 0;

      // We free equally from each pool in 32 KB
      // chunks until we are below our threshold
      // (freeLevel)

      boolean any = true;

      while(numBytesUsed+deletesRAMUsed > freeLevel) {
      
        synchronized(this) {
          if (0 == perDocAllocator.freeByteBlocks.size() &&
              0 == byteBlockAllocator.freeByteBlocks.size() &&
              0 == freeIntBlocks.size() && !any) {
            // Nothing else to free -- must flush now.
            bufferIsFull = numBytesUsed+deletesRAMUsed > ramBufferSize;
            if (infoStream != null) {
              if (numBytesUsed+deletesRAMUsed > ramBufferSize)
                message("    nothing to free; now set bufferIsFull");
              else
                message("    nothing to free");
            }
            break;
          }

          if ((0 == iter % 4) && byteBlockAllocator.freeByteBlocks.size() > 0) {
            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);
            numBytesUsed -= BYTE_BLOCK_SIZE;
          }

          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {
            freeIntBlocks.remove(freeIntBlocks.size()-1);
            numBytesUsed -= INT_BLOCK_SIZE * INT_NUM_BYTE;
          }

          if ((2 == iter % 4) && perDocAllocator.freeByteBlocks.size() > 0) {
            // Remove upwards of 32 blocks (each block is 1K)
            for (int i = 0; i < 32; ++i) {
              perDocAllocator.freeByteBlocks.remove(perDocAllocator.freeByteBlocks.size() - 1);
              numBytesUsed -= PER_DOC_BLOCK_SIZE;
              if (perDocAllocator.freeByteBlocks.size() == 0) {
                break;
              }
            }
          }
        }

        if ((3 == iter % 4) && any)
          // Ask consumer to free any recycled state
          any = consumer.freeRAM();

        iter++;
      }

      if (infoStream != null)
        message("    after free: freedMB=" + nf.format((startBytesUsed-numBytesUsed-deletesRAMUsed)/1024./1024.) + " usedMB=" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.));
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627971999/fstmerge_var2_795110645421246407

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972026/fstmerge_var1_6295181148447486502
private void writeDocument(DocWriter doc) throws IOException {
      assert doc == skipDocWriter || nextWriteDocID == doc.docID;
      boolean success = false;
      try {
        doc.finish();
        nextWriteDocID++;
        nextWriteLoc++;
        assert nextWriteLoc <= waiting.length;
        if (nextWriteLoc == waiting.length) {
          nextWriteLoc = 0;
        }
        success = true;
      } finally {
        if (!success) {
          setAborting();
        }
      }
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972026/fstmerge_base_3795676308799419094
private void writeDocument(DocWriter doc) throws IOException {
      assert doc == skipDocWriter || nextWriteDocID == doc.docID;
      boolean success = false;
      try {
        doc.finish();
        nextWriteDocID++;
        numDocsInStore++;
        nextWriteLoc++;
        assert nextWriteLoc <= waiting.length;
        if (nextWriteLoc == waiting.length)
          nextWriteLoc = 0;
        success = true;
      } finally {
        if (!success)
          setAborting();
      }
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972026/fstmerge_var2_8636946106259664756

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972030/fstmerge_var1_2494688535233775345
synchronized public boolean add(DocWriter doc) throws IOException {

      assert doc.docID >= nextWriteDocID;

      if (doc.docID == nextWriteDocID) {
        writeDocument(doc);
        while(true) {
          doc = waiting[nextWriteLoc];
          if (doc != null) {
            numWaiting--;
            waiting[nextWriteLoc] = null;
            waitingBytes -= doc.sizeInBytes();
            writeDocument(doc);
          } else {
            break;
          }
        }
      } else {

        // I finished before documents that were added
        // before me.  This can easily happen when I am a
        // small doc and the docs before me were large, or,
        // just due to luck in the thread scheduling.  Just
        // add myself to the queue and when that large doc
        // finishes, it will flush me:
        int gap = doc.docID - nextWriteDocID;
        if (gap >= waiting.length) {
          // Grow queue
          DocWriter[] newArray = new DocWriter[ArrayUtil.oversize(gap, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
          assert nextWriteLoc >= 0;
          System.arraycopy(waiting, nextWriteLoc, newArray, 0, waiting.length-nextWriteLoc);
          System.arraycopy(waiting, 0, newArray, waiting.length-nextWriteLoc, nextWriteLoc);
          nextWriteLoc = 0;
          waiting = newArray;
          gap = doc.docID - nextWriteDocID;
        }

        int loc = nextWriteLoc + gap;
        if (loc >= waiting.length) {
          loc -= waiting.length;
        }

        // We should only wrap one time
        assert loc < waiting.length;

        // Nobody should be in my spot!
        assert waiting[loc] == null;
        waiting[loc] = doc;
        numWaiting++;
        waitingBytes += doc.sizeInBytes();
      }
      
      return doPause();
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972030/fstmerge_base_8001631373806670836
synchronized public boolean add(DocWriter doc) throws IOException {

      assert doc.docID >= nextWriteDocID;

      if (doc.docID == nextWriteDocID) {
        writeDocument(doc);
        while(true) {
          doc = waiting[nextWriteLoc];
          if (doc != null) {
            numWaiting--;
            waiting[nextWriteLoc] = null;
            waitingBytes -= doc.sizeInBytes();
            writeDocument(doc);
          } else
            break;
        }
      } else {

        // I finished before documents that were added
        // before me.  This can easily happen when I am a
        // small doc and the docs before me were large, or,
        // just due to luck in the thread scheduling.  Just
        // add myself to the queue and when that large doc
        // finishes, it will flush me:
        int gap = doc.docID - nextWriteDocID;
        if (gap >= waiting.length) {
          // Grow queue
          DocWriter[] newArray = new DocWriter[ArrayUtil.oversize(gap, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
          assert nextWriteLoc >= 0;
          System.arraycopy(waiting, nextWriteLoc, newArray, 0, waiting.length-nextWriteLoc);
          System.arraycopy(waiting, 0, newArray, waiting.length-nextWriteLoc, nextWriteLoc);
          nextWriteLoc = 0;
          waiting = newArray;
          gap = doc.docID - nextWriteDocID;
        }

        int loc = nextWriteLoc + gap;
        if (loc >= waiting.length)
          loc -= waiting.length;

        // We should only wrap one time
        assert loc < waiting.length;

        // Nobody should be in my spot!
        assert waiting[loc] == null;
        waiting[loc] = doc;
        numWaiting++;
        waitingBytes += doc.sizeInBytes();
      }
      
      return doPause();
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972030/fstmerge_var2_8972456158821060068

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  protected void doCommit(Map<String,String> commitUserData) throws IOException {
    // poll subreaders for changes
    for (int i = 0; !hasChanges && i < subReaders.length; i++) {
      hasChanges |= subReaders[i].hasChanges;
    }
    
    if (hasChanges) {
      segmentInfos.setUserData(commitUserData);
      // Default deleter (for backwards compatibility) is
      // KeepOnlyLastCommitDeleter:
      IndexFileDeleter deleter = new IndexFileDeleter(directory,
                                                      deletionPolicy == null ? new KeepOnlyLastCommitDeletionPolicy() : deletionPolicy,
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972328/fstmerge_var1_7758957008899120404
                                                      segmentInfos, null, codecs);
      segmentInfos.updateGeneration(deleter.getLastSegmentInfos());
      segmentInfos.changed();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972328/fstmerge_base_2667684856980978127
                                                      segmentInfos, null, null, codecs);
=======
                                                      segmentInfos, null, null, codecs);
      segmentInfos.updateGeneration(deleter.getLastSegmentInfos());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972328/fstmerge_var2_1597355675982581077

      // Checkpoint the state we are about to change, in
      // case we have to roll back:
      startCommit();

      boolean success = false;
      try {
        for (int i = 0; i < subReaders.length; i++)
          subReaders[i].commit();

        // Sync all files we just wrote
        directory.sync(segmentInfos.files(directory, false));
        segmentInfos.commit(directory);
        success = true;
      } finally {

        if (!success) {

          // Rollback changes that were made to
          // SegmentInfos but failed to get [fully]
          // committed.  This way this reader instance
          // remains consistent (matched to what's
          // actually in the index):
          rollbackCommit();

          // Recompute deletable files & remove them (so
          // partially written .del files, etc, are
          // removed):
          deleter.refresh();
        }
      }

      // Have the deleter remove any now unreferenced
      // files due to this commit:
      deleter.checkpoint(segmentInfos, true);
      deleter.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972328/fstmerge_base_2667684856980978127
=======
      maxIndexVersion = segmentInfos.getVersion();

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972328/fstmerge_var2_1597355675982581077
      if (writeLock != null) {
        writeLock.release();  // release write lock
        writeLock = null;
      }
    }
    hasChanges = false;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DirectoryReader.java
Conflict type: LineBasedMCFd
Conflict body: 
final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)
          throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972523/fstmerge_var1_4509137288524721004
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972523/fstmerge_base_4709821584587443065
    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);

    Set<String> fileSet = new HashSet<String>();

    // Basic files
    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {
      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&
                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
    }

    codec.files(directory, info, fileSet);
    
    // Fieldable norm files
    int numFIs = fieldInfos.size();
    for (int i = 0; i < numFIs; i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed && !fi.omitNorms) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", IndexFileNames.NORMS_EXTENSION));
        break;
      }
    }

    // Vector files
    if (fieldInfos.hasVectors() && mergeDocStores) {
      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
      }
    }
=======
    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);

    Set<String> fileSet = new HashSet<String>();

    // Basic files
    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {
      fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
    }

    codec.files(directory, info, fileSet);
    
    // Fieldable norm files
    int numFIs = fieldInfos.size();
    for (int i = 0; i < numFIs; i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed && !fi.omitNorms) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", IndexFileNames.NORMS_EXTENSION));
        break;
      }
    }

    // Vector files
    if (fieldInfos.hasVectors()) {
      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972523/fstmerge_var2_6224381127089110906

    // Now merge all added files
    Collection<String> files = getMergedFiles(info);
    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);
    for (String file : files) {
      cfsWriter.addFile(file);
    }
    
    // Perform the merge
    cfsWriter.close();
   
    return files;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_var1_728288502535569771
private int mergeFields() throws CorruptIndexException, IOException {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_base_4415400304088177082
private final int mergeFields() throws CorruptIndexException, IOException {

    if (!mergeDocStores) {
      // When we are not merging by doc stores, their field
      // name -> number mapping are the same.  So, we start
      // with the fieldInfos of the last segment in this
      // case, to keep that numbering.
      final SegmentReader sr = (SegmentReader) readers.get(readers.size()-1);
      fieldInfos = (FieldInfos) sr.core.fieldInfos.clone();
    } else {
      fieldInfos = new FieldInfos();		  // merge field names
    }
=======
private final int mergeFields() throws CorruptIndexException, IOException {

    //nocommit
//    if (!mergeDocStores) {
//      // When we are not merging by doc stores, their field
//      // name -> number mapping are the same.  So, we start
//      // with the fieldInfos of the last segment in this
//      // case, to keep that numbering.
//      final SegmentReader sr = (SegmentReader) readers.get(readers.size()-1);
//      fieldInfos = (FieldInfos) sr.core.fieldInfos.clone();
//    } else {
//      fieldInfos = new FieldInfos();		  // merge field names
//    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_var2_1100233429735224734

    fieldInfos = new FieldInfos();      // merge field names
    
    for (IndexReader reader : readers) {
      if (reader instanceof SegmentReader) {
        SegmentReader segmentReader = (SegmentReader) reader;
        FieldInfos readerFieldInfos = segmentReader.fieldInfos();
        int numReaderFieldInfos = readerFieldInfos.size();
        for (int j = 0; j < numReaderFieldInfos; j++) {
          fieldInfos.add(readerFieldInfos.fieldInfo(j));
        }
      } else {
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION_OFFSET), true, true, true, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION), true, true, false, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_OFFSET), true, false, true, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR), true, false, false, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.OMIT_TERM_FREQ_AND_POSITIONS), false, false, false, false, true);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.STORES_PAYLOADS), false, false, false, true, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.INDEXED), false, false, false, false, false);
        fieldInfos.add(reader.getFieldNames(FieldOption.UNINDEXED), false);
      }
    }
    final SegmentCodecs codecInfo = SegmentCodecs.build(fieldInfos, this.codecs);
    fieldInfos.write(directory, segment + ".fnm");

    int docCount = 0;

    setMatchingSegmentReaders();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_var1_728288502535569771
    final FieldsWriter fieldsWriter = new FieldsWriter(directory, segment, fieldInfos);

    try {
      int idx = 0;
      for (IndexReader reader : readers) {
        final SegmentReader matchingSegmentReader = matchingSegmentReaders[idx++];
        FieldsReader matchingFieldsReader = null;
        if (matchingSegmentReader != null) {
          final FieldsReader fieldsReader = matchingSegmentReader.getFieldsReader();
          if (fieldsReader != null) {
            matchingFieldsReader = fieldsReader;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_base_4415400304088177082
    if (mergeDocStores) {
      // merge field values
      final FieldsWriter fieldsWriter = new FieldsWriter(directory, segment, fieldInfos);

      try {
        int idx = 0;
        for (IndexReader reader : readers) {
          final SegmentReader matchingSegmentReader = matchingSegmentReaders[idx++];
          FieldsReader matchingFieldsReader = null;
          if (matchingSegmentReader != null) {
            final FieldsReader fieldsReader = matchingSegmentReader.getFieldsReader();
            if (fieldsReader != null && fieldsReader.canReadRawDocs()) {            
              matchingFieldsReader = fieldsReader;
            }
=======
    // merge field values
    final FieldsWriter fieldsWriter = new FieldsWriter(directory, segment, fieldInfos);

    try {
      int idx = 0;
      for (IndexReader reader : readers) {
        final SegmentReader matchingSegmentReader = matchingSegmentReaders[idx++];
        FieldsReader matchingFieldsReader = null;
        if (matchingSegmentReader != null) {
          final FieldsReader fieldsReader = matchingSegmentReader.getFieldsReader();
          if (fieldsReader != null && fieldsReader.canReadRawDocs()) {            
            matchingFieldsReader = fieldsReader;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_var2_1100233429735224734
          }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_base_4415400304088177082
          if (reader.hasDeletions()) {
            docCount += copyFieldsWithDeletions(fieldsWriter,
                                                reader, matchingFieldsReader);
          } else {
            docCount += copyFieldsNoDeletions(fieldsWriter,
=======
        }
        if (reader.hasDeletions()) {
          docCount += copyFieldsWithDeletions(fieldsWriter,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_var2_1100233429735224734
                                              reader, matchingFieldsReader);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_base_4415400304088177082
          }
=======
        } else {
          docCount += copyFieldsNoDeletions(fieldsWriter,
                                            reader, matchingFieldsReader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_var2_1100233429735224734
        }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_base_4415400304088177082
      } finally {
        fieldsWriter.close();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_var2_1100233429735224734
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_base_4415400304088177082
=======
    } finally {
      fieldsWriter.close();
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_var2_1100233429735224734

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_var1_728288502535569771
    final String fileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.FIELDS_INDEX_EXTENSION);
    final long fdxFileLength = directory.fileLength(fileName);

    if (4+((long) docCount)*8 != fdxFileLength)
      // This is most likely a bug in Sun JRE 1.6.0_04/_05;
      // we detect that the bug has struck, here, and
      // throw an exception to prevent the corruption from
      // entering the index.  See LUCENE-1282 for
      // details.
      throw new RuntimeException("mergeFields produced an invalid result: docCount is " + docCount + " but fdx file size is " + fdxFileLength + " file=" + fileName + " file exists?=" + directory.fileExists(fileName) + "; now aborting this merge to prevent index corruption");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_base_4415400304088177082
      final String fileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.FIELDS_INDEX_EXTENSION);
      final long fdxFileLength = directory.fileLength(fileName);

      if (4+((long) docCount)*8 != fdxFileLength)
        // This is most likely a bug in Sun JRE 1.6.0_04/_05;
        // we detect that the bug has struck, here, and
        // throw an exception to prevent the corruption from
        // entering the index.  See LUCENE-1282 for
        // details.
        throw new RuntimeException("mergeFields produced an invalid result: docCount is " + docCount + " but fdx file size is " + fdxFileLength + " file=" + fileName + " file exists?=" + directory.fileExists(fileName) + "; now aborting this merge to prevent index corruption");

    } else {
      // If we are skipping the doc stores, that means there
      // are no deletions in any of these segments, so we
      // just sum numDocs() of each segment to get total docCount
      for (final IndexReader reader : readers) {
        docCount += reader.numDocs();
      }
    }

    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, null, docCount, 0, termIndexInterval, codecs);
=======
    final String fileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.FIELDS_INDEX_EXTENSION);
    final long fdxFileLength = directory.fileLength(fileName);

    if (4+((long) docCount)*8 != fdxFileLength) {
      // This is most likely a bug in Sun JRE 1.6.0_04/_05;
      // we detect that the bug has struck, here, and
      // throw an exception to prevent the corruption from
      // entering the index.  See LUCENE-1282 for
      // details.
      throw new RuntimeException("mergeFields produced an invalid result: docCount is " + docCount + " but fdx file size is " + fdxFileLength + " file=" + fileName + " file exists?=" + directory.fileExists(fileName) + "; now aborting this merge to prevent index corruption");
    }
      
    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, docCount, termIndexInterval, codecs);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972536/fstmerge_var2_1100233429735224734

    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, docCount, termIndexInterval, codecInfo);
    
    return docCount;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972736/fstmerge_var1_6842912441535480738
synchronized public void flush(SegmentWriteState state) throws IOException {
    if (state.numDocs > lastDocID) {
      initFieldsWriter();
      fill(state.numDocs);
    }

    if (fieldsWriter != null) {
      fieldsWriter.close();
      fieldsWriter = null;
      lastDocID = 0;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972736/fstmerge_base_4634672980276479801
synchronized public void flush(SegmentWriteState state) throws IOException {
=======
public void flush(SegmentWriteState state) throws IOException {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972736/fstmerge_var2_6597442917162321559

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972736/fstmerge_var1_6842912441535480738
      String fieldsName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.FIELDS_EXTENSION);
      String fieldsIdxName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.FIELDS_INDEX_EXTENSION);
      state.flushedFiles.add(fieldsName);
      state.flushedFiles.add(fieldsIdxName);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972736/fstmerge_base_4634672980276479801
    if (state.numDocsInStore > 0) {
      // It's possible that all documents seen in this segment
      // hit non-aborting exceptions, in which case we will
      // not have yet init'd the FieldsWriter:
      initFieldsWriter();
=======
    if (state.numDocs > 0) {
      // It's possible that all documents seen in this segment
      // hit non-aborting exceptions, in which case we will
      // not have yet init'd the FieldsWriter:
      initFieldsWriter();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972736/fstmerge_var2_6597442917162321559

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972736/fstmerge_var1_6842912441535480738
      if (4 + ((long) state.numDocs) * 8 != state.directory.fileLength(fieldsIdxName)) {
        throw new RuntimeException("after flush: fdx size mismatch: " + state.numDocs + " docs vs " + state.directory.fileLength(fieldsIdxName) + " length in bytes of " + fieldsIdxName + " file exists?=" + state.directory.fileExists(fieldsIdxName));
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972736/fstmerge_base_4634672980276479801
      // Fill fdx file to include any final docs that we
      // skipped because they hit non-aborting exceptions
      fill(state.numDocsInStore - docWriter.getDocStoreOffset());
=======
      // Fill fdx file to include any final docs that we
      // skipped because they hit non-aborting exceptions
      fill(state.numDocs);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972736/fstmerge_var2_6597442917162321559
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972736/fstmerge_var1_6842912441535480738
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972736/fstmerge_base_4634672980276479801

    if (fieldsWriter != null)
      fieldsWriter.flush();
=======

    if (fieldsWriter != null) {
      fieldsWriter.flush();
      fieldsWriter.close();
      fieldsWriter = null;
      lastDocID = 0;
      String fieldsName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.FIELDS_EXTENSION);
      String fieldsIdxName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.FIELDS_INDEX_EXTENSION);
      state.flushedFiles.add(fieldsName);
      state.flushedFiles.add(fieldsIdxName);

      if (4+((long) state.numDocs)*8 != state.directory.fileLength(fieldsIdxName)) {
        throw new RuntimeException("after flush: fdx size mismatch: " + state.numDocs + " docs vs " + state.directory.fileLength(fieldsIdxName) + " length in bytes of " + fieldsIdxName + " file exists?=" + state.directory.fileExists(fieldsIdxName));
      }
    }

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972736/fstmerge_var2_6597442917162321559
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/StoredFieldsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private void initFieldsWriter() throws IOException {
    if (fieldsWriter == null) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972741/fstmerge_var1_6060857476774542498
      fieldsWriter = new FieldsWriter(docWriter.directory, docWriter.getSegment(), fieldInfos);
      lastDocID = 0;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972741/fstmerge_base_2271584614168993907
      docStoreSegment = docWriter.getDocStoreSegment();
      if (docStoreSegment != null) {
        fieldsWriter = new FieldsWriter(docWriter.directory,
                                        docStoreSegment,
                                        fieldInfos);
        docWriter.addOpenFile(IndexFileNames.segmentFileName(docStoreSegment, "", IndexFileNames.FIELDS_EXTENSION));
        docWriter.addOpenFile(IndexFileNames.segmentFileName(docStoreSegment, "", IndexFileNames.FIELDS_INDEX_EXTENSION));
        lastDocID = 0;
      }
=======
      segment = docWriter.getSegment();
      if (segment != null) {
        fieldsWriter = new FieldsWriter(docWriter.directory,
                                        segment,
                                        fieldInfos);
        lastDocID = 0;
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972741/fstmerge_var2_6971480586098033862
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/StoredFieldsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
void fill(int docID) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972751/fstmerge_base_3132297015032713491
    final int docStoreOffset = docWriter.getDocStoreOffset();

=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972751/fstmerge_var2_6306494820737666126
    // We must "catch up" for all docs before us
    // that had no stored fields:
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972751/fstmerge_var1_6955485185542568916
    while(lastDocID < docID) {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972751/fstmerge_base_3132297015032713491
    final int end = docID+docStoreOffset;
    while(lastDocID < end) {
=======
    final int end = docID;
    while(lastDocID < end) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972751/fstmerge_var2_6306494820737666126
      fieldsWriter.skipDocument();
      lastDocID++;
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/StoredFieldsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972765/fstmerge_var1_5011883295754775295
synchronized PerDoc getPerDoc() {
    if (freeCount == 0) {
      allocCount++;
      if (allocCount > docFreeList.length) {
        // Grow our free list up front to make sure we have
        // enough space to recycle all outstanding PerDoc
        // instances
        assert allocCount == 1+docFreeList.length;
        docFreeList = new PerDoc[ArrayUtil.oversize(allocCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
      }
      return new PerDoc();
    } else {
      return docFreeList[--freeCount];
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972765/fstmerge_base_3398448665374160560
synchronized PerDoc getPerDoc() {
    if (freeCount == 0) {
      allocCount++;
      if (allocCount > docFreeList.length) {
        // Grow our free list up front to make sure we have
        // enough space to recycle all outstanding PerDoc
        // instances
        assert allocCount == 1+docFreeList.length;
        docFreeList = new PerDoc[ArrayUtil.oversize(allocCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
      }
      return new PerDoc();
    } else
      return docFreeList[--freeCount];
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972765/fstmerge_var2_1237017140723577262

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/StoredFieldsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972995/fstmerge_var1_8939198493727424037
public DocFieldProcessor(DocumentsWriter docWriter, DocFieldConsumer consumer) {
    this.docWriter = docWriter;
    this.consumer = consumer;
    fieldInfos = docWriter.getFieldInfos();
    consumer.setFieldInfos(fieldInfos);
    fieldsWriter = new StoredFieldsWriter(docWriter, fieldInfos);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972995/fstmerge_base_889630493826524408
public DocFieldProcessor(DocumentsWriter docWriter, DocFieldConsumer consumer) {
    this.docWriter = docWriter;
    this.consumer = consumer;
    consumer.setFieldInfos(fieldInfos);
    fieldsWriter = new StoredFieldsWriter(docWriter, fieldInfos);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627972995/fstmerge_var2_5094733744202252856

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## public int byteUpto = DocumentsWriter.BYTE_BLOCK_SIZE; ##FSTMerge## public int byteUpto = DocumentsWriterRAMAllocator.BYTE_BLOCK_SIZE;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/ByteBlockPool.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## public int byteOffset = -DocumentsWriter.BYTE_BLOCK_SIZE; ##FSTMerge## public int byteOffset = -DocumentsWriterRAMAllocator.BYTE_BLOCK_SIZE;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/ByteBlockPool.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973031/fstmerge_var1_8152336520319765703
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973031/fstmerge_base_3767021968684003915
public void nextBuffer() {
    if (1+bufferUpto == buffers.length) {
      byte[][] newBuffers = new byte[ArrayUtil.oversize(buffers.length+1,
                                                        NUM_BYTES_OBJECT_REF)][];
      System.arraycopy(buffers, 0, newBuffers, 0, buffers.length);
      buffers = newBuffers;
    }
    buffer = buffers[1+bufferUpto] = allocator.getByteBlock();
    bufferUpto++;

    byteUpto = 0;
    byteOffset += DocumentsWriter.BYTE_BLOCK_SIZE;
  }
=======
public void nextBuffer() {
    if (1+bufferUpto == buffers.length) {
      byte[][] newBuffers = new byte[ArrayUtil.oversize(buffers.length+1,
                                                        NUM_BYTES_OBJECT_REF)][];
      System.arraycopy(buffers, 0, newBuffers, 0, buffers.length);
      buffers = newBuffers;
    }
    buffer = buffers[1+bufferUpto] = allocator.getByteBlock();
    bufferUpto++;

    byteUpto = 0;
    byteOffset += DocumentsWriterRAMAllocator.BYTE_BLOCK_SIZE;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973031/fstmerge_var2_1645268365166321338

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/ByteBlockPool.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973036/fstmerge_var1_5506803129950303899
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973036/fstmerge_base_667937830206493961
public int newSlice(final int size) {
    if (byteUpto > DocumentsWriter.BYTE_BLOCK_SIZE-size)
      nextBuffer();
    final int upto = byteUpto;
    byteUpto += size;
    buffer[byteUpto-1] = 16;
    return upto;
  }
=======
public int newSlice(final int size) {
    if (byteUpto > DocumentsWriterRAMAllocator.BYTE_BLOCK_SIZE-size)
      nextBuffer();
    final int upto = byteUpto;
    byteUpto += size;
    buffer[byteUpto-1] = 16;
    return upto;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973036/fstmerge_var2_5863802209340767765

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/ByteBlockPool.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973040/fstmerge_var1_4608430396578860776
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973040/fstmerge_base_10781738872065595
public int allocSlice(final byte[] slice, final int upto) {

    final int level = slice[upto] & 15;
    final int newLevel = nextLevelArray[level];
    final int newSize = levelSizeArray[newLevel];

    // Maybe allocate another block
    if (byteUpto > DocumentsWriter.BYTE_BLOCK_SIZE-newSize)
      nextBuffer();

    final int newUpto = byteUpto;
    final int offset = newUpto + byteOffset;
    byteUpto += newSize;

    // Copy forward the past 3 bytes (which we are about
    // to overwrite with the forwarding address):
    buffer[newUpto] = slice[upto-3];
    buffer[newUpto+1] = slice[upto-2];
    buffer[newUpto+2] = slice[upto-1];

    // Write forwarding address at end of last slice:
    slice[upto-3] = (byte) (offset >>> 24);
    slice[upto-2] = (byte) (offset >>> 16);
    slice[upto-1] = (byte) (offset >>> 8);
    slice[upto] = (byte) offset;
        
    // Write new level:
    buffer[byteUpto-1] = (byte) (16|newLevel);

    return newUpto+3;
  }
=======
public int allocSlice(final byte[] slice, final int upto) {

    final int level = slice[upto] & 15;
    final int newLevel = nextLevelArray[level];
    final int newSize = levelSizeArray[newLevel];

    // Maybe allocate another block
    if (byteUpto > DocumentsWriterRAMAllocator.BYTE_BLOCK_SIZE-newSize)
      nextBuffer();

    final int newUpto = byteUpto;
    final int offset = newUpto + byteOffset;
    byteUpto += newSize;

    // Copy forward the past 3 bytes (which we are about
    // to overwrite with the forwarding address):
    buffer[newUpto] = slice[upto-3];
    buffer[newUpto+1] = slice[upto-2];
    buffer[newUpto+2] = slice[upto-1];

    // Write forwarding address at end of last slice:
    slice[upto-3] = (byte) (offset >>> 24);
    slice[upto-2] = (byte) (offset >>> 16);
    slice[upto-1] = (byte) (offset >>> 8);
    slice[upto] = (byte) offset;
        
    // Write new level:
    buffer[byteUpto-1] = (byte) (16|newLevel);

    return newUpto+3;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973040/fstmerge_var2_5169323331608885838

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/ByteBlockPool.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973045/fstmerge_var1_6609027617345641064
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973045/fstmerge_base_4823343527058945395
final BytesRef setBytesRef(BytesRef term, int textStart) {
    final byte[] bytes = term.bytes = buffers[textStart >> DocumentsWriter.BYTE_BLOCK_SHIFT];
    int pos = textStart & DocumentsWriter.BYTE_BLOCK_MASK;
    if ((bytes[pos] & 0x80) == 0) {
      // length is 1 byte
      term.length = bytes[pos];
      term.offset = pos+1;
    } else {
      // length is 2 bytes
      term.length = (bytes[pos]&0x7f) + ((bytes[pos+1]&0xff)<<7);
      term.offset = pos+2;
    }
    assert term.length >= 0;
    return term;
  }
=======
final BytesRef setBytesRef(BytesRef term, int textStart) {
    final byte[] bytes = term.bytes = buffers[textStart >> DocumentsWriterRAMAllocator.BYTE_BLOCK_SHIFT];
    int pos = textStart & DocumentsWriterRAMAllocator.BYTE_BLOCK_MASK;
    if ((bytes[pos] & 0x80) == 0) {
      // length is 1 byte
      term.length = bytes[pos];
      term.offset = pos+1;
    } else {
      // length is 2 bytes
      term.length = (bytes[pos]&0x7f) + ((bytes[pos+1]&0xff)<<7);
      term.offset = pos+2;
    }
    assert term.length >= 0;
    return term;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973045/fstmerge_var2_3784833729513901093

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/ByteBlockPool.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    int bytesPerPosting() {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973181/fstmerge_var1_625739980365352172
      return ParallelPostingsArray.BYTES_PER_POSTING + 4 * RamUsageEstimator.NUM_BYTES_INT;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973181/fstmerge_base_7621502583448965018
      return ParallelPostingsArray.BYTES_PER_POSTING + 4 * DocumentsWriter.INT_NUM_BYTE;
=======
      return ParallelPostingsArray.BYTES_PER_POSTING + 4 * DocumentsWriterRAMAllocator.INT_NUM_BYTE;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973181/fstmerge_var2_1706893555299416149
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973304/fstmerge_var1_2305209174132974565
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973304/fstmerge_base_4897622206360795557
public IndexFileDeleter(Directory directory, IndexDeletionPolicy policy, SegmentInfos segmentInfos, PrintStream infoStream, DocumentsWriter docWriter,
                          CodecProvider codecs)
    throws CorruptIndexException, IOException {

    this.docWriter = docWriter;
    this.infoStream = infoStream;

    if (infoStream != null)
      message("init: current segments file is \"" + segmentInfos.getCurrentSegmentFileName() + "\"; deletionPolicy=" + policy);

    this.policy = policy;
    this.directory = directory;

    // First pass: walk the files and initialize our ref
    // counts:
    long currentGen = segmentInfos.getGeneration();
    indexFilenameFilter = new IndexFileNameFilter(codecs);
    
    CommitPoint currentCommitPoint = null;
    boolean seenIndexFiles = false;
    String[] files = null;
    try {
      files = directory.listAll();
    } catch (NoSuchDirectoryException e) {  
      // it means the directory is empty, so ignore it.
      files = new String[0];
    }

    for (String fileName : files) {

      if ((indexFilenameFilter.accept(null, fileName)) && !fileName.endsWith("write.lock") && !fileName.equals(IndexFileNames.SEGMENTS_GEN)) {
        seenIndexFiles = true;
        
        // Add this file to refCounts with initial count 0:
        getRefCount(fileName);

        if (fileName.startsWith(IndexFileNames.SEGMENTS)) {

          // This is a commit (segments or segments_N), and
          // it's valid (<= the max gen).  Load it, then
          // incref all files it refers to:
          if (SegmentInfos.generationFromSegmentsFileName(fileName) <= currentGen) {
            if (infoStream != null) {
              message("init: load commit \"" + fileName + "\"");
            }
            SegmentInfos sis = new SegmentInfos();
            try {
              sis.read(directory, fileName, codecs);
            } catch (FileNotFoundException e) {
              // LUCENE-948: on NFS (and maybe others), if
              // you have writers switching back and forth
              // between machines, it's very likely that the
              // dir listing will be stale and will claim a
              // file segments_X exists when in fact it
              // doesn't.  So, we catch this and handle it
              // as if the file does not exist
              if (infoStream != null) {
                message("init: hit FileNotFoundException when loading commit \"" + fileName + "\"; skipping this commit point");
              }
              sis = null;
            }
            if (sis != null) {
              CommitPoint commitPoint = new CommitPoint(commitsToDelete, directory, sis);
              if (sis.getGeneration() == segmentInfos.getGeneration()) {
                currentCommitPoint = commitPoint;
              }
              commits.add(commitPoint);
              incRef(sis, true);
            }
          }
        }
      }
    }

    // If we haven't seen any Lucene files, then currentCommitPoint is expected
    // to be null, because it means it's a fresh Directory. Therefore it cannot
    // be any NFS cache issues - so just ignore.
    if (currentCommitPoint == null && seenIndexFiles) {
      // We did not in fact see the segments_N file
      // corresponding to the segmentInfos that was passed
      // in.  Yet, it must exist, because our caller holds
      // the write lock.  This can happen when the directory
      // listing was stale (eg when index accessed via NFS
      // client with stale directory listing cache).  So we
      // try now to explicitly open this commit point:
      SegmentInfos sis = new SegmentInfos();
      try {
        sis.read(directory, segmentInfos.getCurrentSegmentFileName(), codecs);
      } catch (IOException e) {
        throw new CorruptIndexException("failed to locate current segments_N file");
      }
      if (infoStream != null)
        message("forced open of current segments file " + segmentInfos.getCurrentSegmentFileName());
      currentCommitPoint = new CommitPoint(commitsToDelete, directory, sis);
      commits.add(currentCommitPoint);
      incRef(sis, true);
    }

    // We keep commits list in sorted order (oldest to newest):
    Collections.sort(commits);

    // Now delete anything with ref count at 0.  These are
    // presumably abandoned files eg due to crash of
    // IndexWriter.
    for(Map.Entry<String, RefCount> entry : refCounts.entrySet() ) {  
      RefCount rc = entry.getValue();
      final String fileName = entry.getKey();
      if (0 == rc.count) {
        if (infoStream != null) {
          message("init: removing unreferenced file \"" + fileName + "\"");
        }
        deleteFile(fileName);
      }
    }

    // Finally, give policy a chance to remove things on
    // startup:
    if (seenIndexFiles) {
      policy.onInit(commits);
    }

    // Always protect the incoming segmentInfos since
    // sometime it may not be the most recent commit
    checkpoint(segmentInfos, false);
    
    startingCommitDeleted = currentCommitPoint == null ? false : currentCommitPoint.isDeleted();

    deleteCommits();
  }
=======
public IndexFileDeleter(Directory directory, IndexDeletionPolicy policy, SegmentInfos segmentInfos, PrintStream infoStream, DocumentsWriter docWriter,
                          CodecProvider codecs)
    throws CorruptIndexException, IOException {

    this.docWriter = docWriter;
    this.infoStream = infoStream;

    final String currentSegmentsFile = segmentInfos.getCurrentSegmentFileName();

    if (infoStream != null)
      message("init: current segments file is \"" + currentSegmentsFile + "\"; deletionPolicy=" + policy);

    this.policy = policy;
    this.directory = directory;

    // First pass: walk the files and initialize our ref
    // counts:
    long currentGen = segmentInfos.getGeneration();
    indexFilenameFilter = new IndexFileNameFilter(codecs);
    
    CommitPoint currentCommitPoint = null;
    String[] files = null;
    try {
      files = directory.listAll();
    } catch (NoSuchDirectoryException e) {  
      // it means the directory is empty, so ignore it.
      files = new String[0];
    }

    for (String fileName : files) {

      if ((indexFilenameFilter.accept(null, fileName)) && !fileName.endsWith("write.lock") && !fileName.equals(IndexFileNames.SEGMENTS_GEN)) {
        
        // Add this file to refCounts with initial count 0:
        getRefCount(fileName);

        if (fileName.startsWith(IndexFileNames.SEGMENTS)) {

          // This is a commit (segments or segments_N), and
          // it's valid (<= the max gen).  Load it, then
          // incref all files it refers to:
          if (infoStream != null) {
            message("init: load commit \"" + fileName + "\"");
          }
          SegmentInfos sis = new SegmentInfos();
          try {
            sis.read(directory, fileName, codecs);
          } catch (FileNotFoundException e) {
            // LUCENE-948: on NFS (and maybe others), if
            // you have writers switching back and forth
            // between machines, it's very likely that the
            // dir listing will be stale and will claim a
            // file segments_X exists when in fact it
            // doesn't.  So, we catch this and handle it
            // as if the file does not exist
            if (infoStream != null) {
              message("init: hit FileNotFoundException when loading commit \"" + fileName + "\"; skipping this commit point");
            }
            sis = null;
          } catch (IOException e) {
            if (SegmentInfos.generationFromSegmentsFileName(fileName) <= currentGen) {
              throw e;
            } else {
              // Most likely we are opening an index that
              // has an aborted "future" commit, so suppress
              // exc in this case
              sis = null;
            }
          }
          if (sis != null) {
            CommitPoint commitPoint = new CommitPoint(commitsToDelete, directory, sis);
            if (sis.getGeneration() == segmentInfos.getGeneration()) {
              currentCommitPoint = commitPoint;
            }
            commits.add(commitPoint);
            incRef(sis, true);

            if (lastSegmentInfos == null || sis.getGeneration() > lastSegmentInfos.getGeneration()) {
              lastSegmentInfos = sis;
            }
          }
        }
      }
    }

    if (currentCommitPoint == null && currentSegmentsFile != null) {
      // We did not in fact see the segments_N file
      // corresponding to the segmentInfos that was passed
      // in.  Yet, it must exist, because our caller holds
      // the write lock.  This can happen when the directory
      // listing was stale (eg when index accessed via NFS
      // client with stale directory listing cache).  So we
      // try now to explicitly open this commit point:
      SegmentInfos sis = new SegmentInfos();
      try {
        sis.read(directory, currentSegmentsFile, codecs);
      } catch (IOException e) {
        throw new CorruptIndexException("failed to locate current segments_N file");
      }
      if (infoStream != null)
        message("forced open of current segments file " + segmentInfos.getCurrentSegmentFileName());
      currentCommitPoint = new CommitPoint(commitsToDelete, directory, sis);
      commits.add(currentCommitPoint);
      incRef(sis, true);
    }

    // We keep commits list in sorted order (oldest to newest):
    Collections.sort(commits);

    // Now delete anything with ref count at 0.  These are
    // presumably abandoned files eg due to crash of
    // IndexWriter.
    for(Map.Entry<String, RefCount> entry : refCounts.entrySet() ) {  
      RefCount rc = entry.getValue();
      final String fileName = entry.getKey();
      if (0 == rc.count) {
        if (infoStream != null) {
          message("init: removing unreferenced file \"" + fileName + "\"");
        }
        deleteFile(fileName);
      }
    }

    // Finally, give policy a chance to remove things on
    // startup:
    if (currentSegmentsFile != null) {
      policy.onInit(commits);
    }

    // Always protect the incoming segmentInfos since
    // sometime it may not be the most recent commit
    checkpoint(segmentInfos, false);
    
    startingCommitDeleted = currentCommitPoint == null ? false : currentCommitPoint.isDeleted();

    deleteCommits();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973304/fstmerge_var2_772261033817730648

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexFileDeleter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void checkpoint(SegmentInfos segmentInfos, boolean isCommit) throws IOException {

    if (infoStream != null) {
      message("now checkpoint \"" + segmentInfos + "\" [" + segmentInfos.size() + " segments " + "; isCommit = " + isCommit + "]");
    }

    // Try again now to delete any previously un-deletable
    // files (because they were in use, on Windows):
    deletePendingFiles();

    // Incref the files:
    incRef(segmentInfos, isCommit);

    if (isCommit) {
      // Append to our commits list:
      commits.add(new CommitPoint(commitsToDelete, directory, segmentInfos));

      // Tell policy so it can remove commits:
      policy.onCommit(commits);

      // Decref files for commits that were deleted by the policy:
      deleteCommits();
    } else {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973344/fstmerge_base_6975461081491487197

      final List<String> docWriterFiles;
      if (docWriter != null) {
        docWriterFiles = docWriter.openFiles();
        if (docWriterFiles != null)
          // We must incRef these files before decRef'ing
          // last files to make sure we don't accidentally
          // delete them:
          incRef(docWriterFiles);
      } else
        docWriterFiles = null;

=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973344/fstmerge_var2_3865060859502300071
      // DecRef old files from the last checkpoint, if any:
      for (Collection<String> lastFile : lastFiles) {
        decRef(lastFile);
      }
      lastFiles.clear();

      // Save files so we can decr on next checkpoint/commit:
      lastFiles.add(segmentInfos.files(directory, false));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973344/fstmerge_var1_4816052159176061451
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973344/fstmerge_base_6975461081491487197

      if (docWriterFiles != null)
        lastFiles.add(docWriterFiles);
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973344/fstmerge_var2_3865060859502300071
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexFileDeleter.java
Conflict type: LineBasedMCFd
Conflict body: 
public String segString(Directory dir) {
      StringBuilder b = new StringBuilder();
      final int numSegments = segments.size();
      for(int i=0;i<numSegments;i++) {
        if (i > 0) b.append(' ');
        b.append(segments.info(i).toString(dir, 0));
      }
      if (info != null)
        b.append(" into ").append(info.name);
      if (optimize)
        b.append(" [optimize]");
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973489/fstmerge_var1_6636019870910205695
      if (aborted) {
        b.append(" [ABORTED]");
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973489/fstmerge_base_35676833338862261
      if (mergeDocStores) {
        b.append(" [mergeDocStores]");
      }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973489/fstmerge_var2_1581317097027863594
      return b.toString();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/MergePolicy.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973635/fstmerge_var1_7235308570967995462
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973635/fstmerge_base_3547424734619645800
private void bytesUsed(long size) {
    if (perThread.termsHash.trackAllocations) {
      perThread.termsHash.docWriter.bytesUsed(size);
    }
  }
=======
private void bytesUsed(long size) {
    if (termsHash.trackAllocations) {
      termsHash.docWriter.bytesUsed(size);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973635/fstmerge_var2_8432933524895933238

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHashPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973663/fstmerge_var1_4660658952783158419
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973663/fstmerge_base_1852069638687210300
private synchronized void compactPostings() {
    int upto = 0;
    for(int i=0;i<postingsHashSize;i++) {
      if (postingsHash[i] != -1) {
        if (upto < i) {
          postingsHash[upto] = postingsHash[i];
          postingsHash[i] = -1;
        }
        upto++;
      }
    }

    assert upto == numPostings;
    postingsCompacted = true;
  }
=======
private void compactPostings() {
    int upto = 0;
    for(int i=0;i<postingsHashSize;i++) {
      if (postingsHash[i] != -1) {
        if (upto < i) {
          postingsHash[upto] = postingsHash[i];
          postingsHash[i] = -1;
        }
        upto++;
      }
    }

    assert upto == numPostings;
    postingsCompacted = true;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973663/fstmerge_var2_4123518379041736973

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHashPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973675/fstmerge_var1_3659508325091283812
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973675/fstmerge_base_5476461336145409216
int comparePostings(int term1, int term2) {

    if (term1 == term2) {
      // Our quicksort does this, eg during partition
      return 0;
    }

    termBytePool.setBytesRef(perThread.tr1, postingsArray.textStarts[term1]);
    termBytePool.setBytesRef(perThread.tr2, postingsArray.textStarts[term2]);

    return termComp.compare(perThread.tr1, perThread.tr2);
  }
=======
int comparePostings(int term1, int term2) {

    if (term1 == term2) {
      // Our quicksort does this, eg during partition
      return 0;
    }

    termBytePool.setBytesRef(termsHash.tr1, postingsArray.textStarts[term1]);
    termBytePool.setBytesRef(termsHash.tr2, postingsArray.textStarts[term2]);

    return termComp.compare(termsHash.tr1, termsHash.tr2);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973675/fstmerge_var2_6487090355784316056

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHashPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973680/fstmerge_var1_8728097737143578171
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973680/fstmerge_base_3277095521414530285
private boolean postingEquals(final int termID) {
    final int textStart = postingsArray.textStarts[termID];
    final byte[] text = termBytePool.buffers[textStart >> DocumentsWriter.BYTE_BLOCK_SHIFT];
    assert text != null;

    int pos = textStart & DocumentsWriter.BYTE_BLOCK_MASK;
    
    final int len;
    if ((text[pos] & 0x80) == 0) {
      // length is 1 byte
      len = text[pos];
      pos += 1;
    } else {
      // length is 2 bytes
      len = (text[pos]&0x7f) + ((text[pos+1]&0xff)<<7);
      pos += 2;
    }

    if (len == utf8.length) {
      final byte[] utf8Bytes = utf8.bytes;
      for(int tokenPos=0;tokenPos<utf8.length;pos++,tokenPos++) {
        if (utf8Bytes[tokenPos] != text[pos]) {
          return false;
        }
      }
      return true;
    } else {
      return false;
    }
  }
=======
private boolean postingEquals(final int termID) {
    final int textStart = postingsArray.textStarts[termID];
    final byte[] text = termBytePool.buffers[textStart >> DocumentsWriterRAMAllocator.BYTE_BLOCK_SHIFT];
    assert text != null;

    int pos = textStart & DocumentsWriterRAMAllocator.BYTE_BLOCK_MASK;
    
    final int len;
    if ((text[pos] & 0x80) == 0) {
      // length is 1 byte
      len = text[pos];
      pos += 1;
    } else {
      // length is 2 bytes
      len = (text[pos]&0x7f) + ((text[pos+1]&0xff)<<7);
      pos += 2;
    }

    if (len == utf8.length) {
      final byte[] utf8Bytes = utf8.bytes;
      for(int tokenPos=0;tokenPos<utf8.length;pos++,tokenPos++) {
        if (utf8Bytes[tokenPos] != text[pos]) {
          return false;
        }
      }
      return true;
    } else {
      return false;
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973680/fstmerge_var2_6822399920487123488

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHashPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
public void add(int textStart) throws IOException {
    int termID = bytesHash.addByPoolOffset(textStart);
    if (termID >= 0) {      // New posting
      // First time we are seeing this token since we last
      // flushed the hash.
      // Init stream slices
      if (numPostingInt + intPool.intUpto > DocumentsWriterRAMAllocator.INT_BLOCK_SIZE)
        intPool.nextBuffer();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973693/fstmerge_var1_6187465973256163431
      if (ByteBlockPool.BYTE_BLOCK_SIZE - bytePool.byteUpto < numPostingInt*ByteBlockPool.FIRST_LEVEL_SIZE)
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973693/fstmerge_base_6431949608537173623
      if (DocumentsWriter.BYTE_BLOCK_SIZE - bytePool.byteUpto < numPostingInt*ByteBlockPool.FIRST_LEVEL_SIZE)
=======
      if (DocumentsWriterRAMAllocator.BYTE_BLOCK_SIZE - bytePool.byteUpto < numPostingInt*ByteBlockPool.FIRST_LEVEL_SIZE)
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973693/fstmerge_var2_5272984040846336005
        bytePool.nextBuffer();

      intUptos = intPool.buffer;
      intUptoStart = intPool.intUpto;
      intPool.intUpto += streamCount;

      postingsArray.intStarts[termID] = intUptoStart + intPool.intOffset;

      for(int i=0;i<streamCount;i++) {
        final int upto = bytePool.newSlice(ByteBlockPool.FIRST_LEVEL_SIZE);
        intUptos[intUptoStart+i] = upto + bytePool.byteOffset;
      }
      postingsArray.byteStarts[termID] = intUptos[intUptoStart];

      consumer.newTerm(termID);

    } else {
      termID = (-termID)-1;
      int intStart = postingsArray.intStarts[termID];
      intUptos = intPool.buffers[intStart >> DocumentsWriterRAMAllocator.INT_BLOCK_SHIFT];
      intUptoStart = intStart & DocumentsWriterRAMAllocator.INT_BLOCK_MASK;
      consumer.addTerm(termID);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHashPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  void add() throws IOException {

    // We are first in the chain so we must "intern" the
    // term text into textStart address
    // Get the text & hash of this term.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973698/fstmerge_var1_7731185526231047129
    int termID;
    try{
       termID = bytesHash.add(termBytesRef, termAtt.toBytesRef(termBytesRef));
    }catch (MaxBytesLengthExceededException e) {
      // Not enough room in current block
      // Just skip this term, to remain as robust as
      // possible during indexing.  A TokenFilter
      // can be inserted into the analyzer chain if
      // other behavior is wanted (pruning the term
      // to a prefix, throwing an exception, etc).
      if (docState.maxTermPrefix == null) {
        final int saved = termBytesRef.length;
        try {
          termBytesRef.length = Math.min(30, DocumentsWriter.MAX_TERM_LENGTH_UTF8);
          docState.maxTermPrefix = termBytesRef.toString();
        } finally {
          termBytesRef.length = saved;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973698/fstmerge_base_8297016164380198409
    int code = termAtt.toBytesRef(utf8);

    int hashPos = code & postingsHashMask;

    // Locate RawPostingList in hash
    int termID = postingsHash[hashPos];

    if (termID != -1 && !postingEquals(termID)) {
      // Conflict: keep searching different locations in
      // the hash table.
      final int inc = ((code>>8)+code)|1;
      do {
        code += inc;
        hashPos = code & postingsHashMask;
        termID = postingsHash[hashPos];
      } while (termID != -1 && !postingEquals(termID));
    }

    if (termID == -1) {

      // First time we are seeing this token since we last
      // flushed the hash.
      final int textLen2 = 2+utf8.length;
      if (textLen2 + bytePool.byteUpto > DocumentsWriter.BYTE_BLOCK_SIZE) {
        // Not enough room in current block

        if (utf8.length > DocumentsWriter.MAX_TERM_LENGTH_UTF8) {
          // Just skip this term, to remain as robust as
          // possible during indexing.  A TokenFilter
          // can be inserted into the analyzer chain if
          // other behavior is wanted (pruning the term
          // to a prefix, throwing an exception, etc).
          if (docState.maxTermPrefix == null) {
            final int saved = utf8.length;
            try {
              utf8.length = Math.min(30, DocumentsWriter.MAX_TERM_LENGTH_UTF8);
              docState.maxTermPrefix = utf8.toString();
            } finally {
              utf8.length = saved;
            }
          }

          consumer.skippingLongTerm();
          return;
=======
    int code = termAtt.toBytesRef(utf8);

    int hashPos = code & postingsHashMask;

    // Locate RawPostingList in hash
    int termID = postingsHash[hashPos];

    if (termID != -1 && !postingEquals(termID)) {
      // Conflict: keep searching different locations in
      // the hash table.
      final int inc = ((code>>8)+code)|1;
      do {
        code += inc;
        hashPos = code & postingsHashMask;
        termID = postingsHash[hashPos];
      } while (termID != -1 && !postingEquals(termID));
    }

    if (termID == -1) {

      // First time we are seeing this token since we last
      // flushed the hash.
      final int textLen2 = 2+utf8.length;
      if (textLen2 + bytePool.byteUpto > DocumentsWriterRAMAllocator.BYTE_BLOCK_SIZE) {
        // Not enough room in current block

        if (utf8.length > DocumentsWriterRAMAllocator.MAX_TERM_LENGTH_UTF8) {
          // Just skip this term, to remain as robust as
          // possible during indexing.  A TokenFilter
          // can be inserted into the analyzer chain if
          // other behavior is wanted (pruning the term
          // to a prefix, throwing an exception, etc).
          if (docState.maxTermPrefix == null) {
            final int saved = utf8.length;
            try {
              utf8.length = Math.min(30, DocumentsWriterRAMAllocator.MAX_TERM_LENGTH_UTF8);
              docState.maxTermPrefix = utf8.toString();
            } finally {
              utf8.length = saved;
            }
          }

          consumer.skippingLongTerm();
          return;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973698/fstmerge_var2_3849070814762344571
        }
      }
      consumer.skippingLongTerm();
      return;
    }
    if (termID >= 0) {// New posting
      bytesHash.byteStart(termID);
      // Init stream slices
      if (numPostingInt + intPool.intUpto > DocumentsWriterRAMAllocator.INT_BLOCK_SIZE) {
        intPool.nextBuffer();
      }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973698/fstmerge_var1_7731185526231047129
      if (ByteBlockPool.BYTE_BLOCK_SIZE - bytePool.byteUpto < numPostingInt*ByteBlockPool.FIRST_LEVEL_SIZE) {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973698/fstmerge_base_8297016164380198409
      if (DocumentsWriter.BYTE_BLOCK_SIZE - bytePool.byteUpto < numPostingInt*ByteBlockPool.FIRST_LEVEL_SIZE) {
=======
      if (DocumentsWriterRAMAllocator.BYTE_BLOCK_SIZE - bytePool.byteUpto < numPostingInt*ByteBlockPool.FIRST_LEVEL_SIZE) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973698/fstmerge_var2_3849070814762344571
        bytePool.nextBuffer();
      }

      intUptos = intPool.buffer;
      intUptoStart = intPool.intUpto;
      intPool.intUpto += streamCount;

      postingsArray.intStarts[termID] = intUptoStart + intPool.intOffset;

      for(int i=0;i<streamCount;i++) {
        final int upto = bytePool.newSlice(ByteBlockPool.FIRST_LEVEL_SIZE);
        intUptos[intUptoStart+i] = upto + bytePool.byteOffset;
      }
      postingsArray.byteStarts[termID] = intUptos[intUptoStart];

      consumer.newTerm(termID);

    } else {
      termID = (-termID)-1;
      final int intStart = postingsArray.intStarts[termID];
      intUptos = intPool.buffers[intStart >> DocumentsWriterRAMAllocator.INT_BLOCK_SHIFT];
      intUptoStart = intStart & DocumentsWriterRAMAllocator.INT_BLOCK_MASK;
      consumer.addTerm(termID);
    }

    if (doNextCall)
      nextPerField.add(postingsArray.textStarts[termID]);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHashPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
void writeByte(int stream, byte b) {
    int upto = intUptos[intUptoStart+stream];
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973703/fstmerge_var1_4253344582682444982
    byte[] bytes = bytePool.buffers[upto >> ByteBlockPool.BYTE_BLOCK_SHIFT];
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973703/fstmerge_base_1397630121666983738
    byte[] bytes = bytePool.buffers[upto >> DocumentsWriter.BYTE_BLOCK_SHIFT];
=======
    byte[] bytes = bytePool.buffers[upto >> DocumentsWriterRAMAllocator.BYTE_BLOCK_SHIFT];
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973703/fstmerge_var2_2306282066518131559
    assert bytes != null;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973703/fstmerge_var1_4253344582682444982
    int offset = upto & ByteBlockPool.BYTE_BLOCK_MASK;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973703/fstmerge_base_1397630121666983738
    int offset = upto & DocumentsWriter.BYTE_BLOCK_MASK;
=======
    int offset = upto & DocumentsWriterRAMAllocator.BYTE_BLOCK_MASK;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973703/fstmerge_var2_2306282066518131559
    if (bytes[offset] != 0) {
      // End of slice; allocate a new one
      offset = bytePool.allocSlice(bytes, offset);
      bytes = bytePool.buffer;
      intUptos[intUptoStart+stream] = offset + bytePool.byteOffset;
    }
    bytes[offset] = b;
    (intUptos[intUptoStart+stream])++;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHashPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973722/fstmerge_var1_8712246302530601640
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973722/fstmerge_base_5316194697087294978
void rehashPostings(final int newSize) {

    final int newMask = newSize-1;

    int[] newHash = new int[newSize];
    Arrays.fill(newHash, -1);
    for(int i=0;i<postingsHashSize;i++) {
      int termID = postingsHash[i];
      if (termID != -1) {
        int code;
        if (perThread.primary) {
          final int textStart = postingsArray.textStarts[termID];
          final int start = textStart & DocumentsWriter.BYTE_BLOCK_MASK;
          final byte[] text = bytePool.buffers[textStart >> DocumentsWriter.BYTE_BLOCK_SHIFT];
          code = 0;

          final int len;
          int pos;
          if ((text[start] & 0x80) == 0) {
            // length is 1 byte
            len = text[start];
            pos = start+1;
          } else {
            len = (text[start]&0x7f) + ((text[start+1]&0xff)<<7);
            pos = start+2;
          }

          final int endPos = pos+len;
          while(pos < endPos) {
            code = (code*31) + text[pos++];
          }
        } else {
          code = postingsArray.textStarts[termID];
        }

        int hashPos = code & newMask;
        assert hashPos >= 0;
        if (newHash[hashPos] != -1) {
          final int inc = ((code>>8)+code)|1;
          do {
            code += inc;
            hashPos = code & newMask;
          } while (newHash[hashPos] != -1);
        }
        newHash[hashPos] = termID;
      }
    }

    postingsHashMask = newMask;
    postingsHash = newHash;

    postingsHashSize = newSize;
    postingsHashHalfSize = newSize >> 1;
  }
=======
void rehashPostings(final int newSize) {

    final int newMask = newSize-1;

    int[] newHash = new int[newSize];
    Arrays.fill(newHash, -1);
    for(int i=0;i<postingsHashSize;i++) {
      int termID = postingsHash[i];
      if (termID != -1) {
        int code;
        if (termsHash.primary) {
          final int textStart = postingsArray.textStarts[termID];
          final int start = textStart & DocumentsWriterRAMAllocator.BYTE_BLOCK_MASK;
          final byte[] text = bytePool.buffers[textStart >> DocumentsWriterRAMAllocator.BYTE_BLOCK_SHIFT];
          code = 0;

          final int len;
          int pos;
          if ((text[start] & 0x80) == 0) {
            // length is 1 byte
            len = text[start];
            pos = start+1;
          } else {
            len = (text[start]&0x7f) + ((text[start+1]&0xff)<<7);
            pos = start+2;
          }

          final int endPos = pos+len;
          while(pos < endPos) {
            code = (code*31) + text[pos++];
          }
        } else {
          code = postingsArray.textStarts[termID];
        }

        int hashPos = code & newMask;
        assert hashPos >= 0;
        if (newHash[hashPos] != -1) {
          final int inc = ((code>>8)+code)|1;
          do {
            code += inc;
            hashPos = code & newMask;
          } while (newHash[hashPos] != -1);
        }
        newHash[hashPos] = termID;
      }
    }

    postingsHashMask = newMask;
    postingsHash = newHash;

    postingsHashSize = newSize;
    postingsHashHalfSize = newSize >> 1;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973722/fstmerge_var2_2700399929599956556

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHashPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973728/fstmerge_var1_9220283352385605034
public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {
    this.perThread = perThread;
    intPool = perThread.intPool;
    bytePool = perThread.bytePool;
    termBytePool = perThread.termBytePool;
    docState = perThread.docState;
    bytesUsed =  perThread.termsHash.trackAllocations?perThread.termsHash.docWriter.bytesUsed:new AtomicLong();

    fieldState = docInverterPerField.fieldState;
    this.consumer = perThread.consumer.addField(this, fieldInfo);
    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);
    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts); 
    streamCount = consumer.getStreamCount();
    numPostingInt = 2*streamCount;
    termBytesRef = perThread.termBytesRef;
    this.fieldInfo = fieldInfo;
    if (nextPerThread != null)
      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);
    else
      nextPerField = null;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973728/fstmerge_base_4952953589219751383
public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {
    this.perThread = perThread;
    intPool = perThread.intPool;
    bytePool = perThread.bytePool;
    termBytePool = perThread.termBytePool;
    docState = perThread.docState;

    postingsHash = new int[postingsHashSize];
    Arrays.fill(postingsHash, -1);
    bytesUsed(postingsHashSize * RamUsageEstimator.NUM_BYTES_INT);

    fieldState = docInverterPerField.fieldState;
    this.consumer = perThread.consumer.addField(this, fieldInfo);
    initPostingsArray();

    streamCount = consumer.getStreamCount();
    numPostingInt = 2*streamCount;
    utf8 = perThread.utf8;
    this.fieldInfo = fieldInfo;
    if (nextPerThread != null)
      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);
    else
      nextPerField = null;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973728/fstmerge_var2_1868510965018128302

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHashPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973842/fstmerge_var1_6436711284454120611
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973842/fstmerge_base_9192847213749962092
boolean canReadRawDocs() {
    // Disable reading raw docs in 2.x format, because of the removal of compressed
    // fields in 3.0. We don't want rawDocs() to decode field bits to figure out
    // if a field was compressed, hence we enforce ordinary (non-raw) stored field merges
    // for <3.0 indexes.
    return format >= FieldsWriter.FORMAT_LUCENE_3_0_NO_COMPRESSED_FIELDS;
  }
=======
boolean canReadRawDocs() {
    // Since we currently only support >3.0 format anymore, always return true!
    // I leave this method in because it may help for later format changes.
    return true;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627973842/fstmerge_var2_5574488975863297804

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/FieldsReader.java
Conflict type: SameIdFd
Conflict body: 
~~FSTMerge~~ static final int FORMAT_CURRENT = FORMAT_PER_FIELD_CODEC; ##FSTMerge## ##FSTMerge## static final int FORMAT_CURRENT = FORMAT_START;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/FieldInfos.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974254/fstmerge_var1_4804728601913903908
public FieldInfos() {
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974254/fstmerge_base_2671541527599905739
FieldInfos() { }
=======
public FieldInfos() { }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974254/fstmerge_var2_549093267358886253

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/FieldInfos.java
Conflict type: LineBasedMCFd
Conflict body: 
void fill(int docID) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974924/fstmerge_var1_8171226438840965919
    if (lastDocID < docID) {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974924/fstmerge_base_3524170747342623419
    final int docStoreOffset = docWriter.getDocStoreOffset();
    final int end = docID+docStoreOffset;
    if (lastDocID < end) {
=======
    final int end = docID;
    if (lastDocID < end) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974924/fstmerge_var2_3497554679358568868
      final long tvfPosition = tvf.getFilePointer();
      while(lastDocID < docID) {
        tvx.writeLong(tvd.getFilePointer());
        tvd.writeVInt(0);
        tvx.writeLong(tvfPosition);
        lastDocID++;
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private final void initTermVectorsWriter() throws IOException {        
    if (tvx == null) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974929/fstmerge_var1_1163627178918774944
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974929/fstmerge_base_9222375140636942338
      
      final String docStoreSegment = docWriter.getDocStoreSegment();

      if (docStoreSegment == null)
        return;
=======
      
      final String segment = docWriter.getSegment();

      if (segment == null)
        return;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974929/fstmerge_var2_5339259614391241688

      // If we hit an exception while init'ing the term
      // vector output files, we must abort this segment
      // because those files will be in an unknown
      // state:
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974929/fstmerge_var1_1163627178918774944
      hasVectors = true;
      tvx = docWriter.directory.createOutput(IndexFileNames.segmentFileName(docWriter.getSegment(), "", IndexFileNames.VECTORS_INDEX_EXTENSION));
      tvd = docWriter.directory.createOutput(IndexFileNames.segmentFileName(docWriter.getSegment(), "", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));
      tvf = docWriter.directory.createOutput(IndexFileNames.segmentFileName(docWriter.getSegment(), "", IndexFileNames.VECTORS_FIELDS_EXTENSION));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974929/fstmerge_base_9222375140636942338
      String idxName = IndexFileNames.segmentFileName(docStoreSegment, "", IndexFileNames.VECTORS_INDEX_EXTENSION);
      String docName = IndexFileNames.segmentFileName(docStoreSegment, "", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);
      String fldName = IndexFileNames.segmentFileName(docStoreSegment, "", IndexFileNames.VECTORS_FIELDS_EXTENSION);
      tvx = docWriter.directory.createOutput(idxName);
      tvd = docWriter.directory.createOutput(docName);
      tvf = docWriter.directory.createOutput(fldName);
=======
      String idxName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.VECTORS_INDEX_EXTENSION);
      String docName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);
      String fldName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.VECTORS_FIELDS_EXTENSION);
      tvx = docWriter.directory.createOutput(idxName);
      tvd = docWriter.directory.createOutput(docName);
      tvf = docWriter.directory.createOutput(fldName);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974929/fstmerge_var2_5339259614391241688
      
      tvx.writeInt(TermVectorsReader.FORMAT_CURRENT);
      tvd.writeInt(TermVectorsReader.FORMAT_CURRENT);
      tvf.writeInt(TermVectorsReader.FORMAT_CURRENT);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974929/fstmerge_base_9222375140636942338
      docWriter.addOpenFile(idxName);
      docWriter.addOpenFile(fldName);
      docWriter.addOpenFile(docName);

=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974929/fstmerge_var2_5339259614391241688
      lastDocID = 0;
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void abort() {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974934/fstmerge_var1_4672926160541885235
    hasVectors = false;
    try {
      IOUtils.closeSafely(tvx, tvd, tvf);
    } catch (IOException ignored) {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974934/fstmerge_base_361601675005343472
    if (tvx != null) {
      try {
        tvx.close();
      } catch (Throwable t) {
      }
      tvx = null;
=======

    if (tvx != null) {
      try {
        tvx.close();
      } catch (Throwable t) {
      }
      tvx = null;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974934/fstmerge_var2_8184996307567338976
    }
    try {
      docWriter.directory.deleteFile(IndexFileNames.segmentFileName(docWriter.getSegment(), "", IndexFileNames.VECTORS_INDEX_EXTENSION));
    } catch (IOException ignored) {
    }
    try {
      docWriter.directory.deleteFile(IndexFileNames.segmentFileName(docWriter.getSegment(), "", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));
    } catch (IOException ignored) {
    }
    try {
      docWriter.directory.deleteFile(IndexFileNames.segmentFileName(docWriter.getSegment(), "", IndexFileNames.VECTORS_FIELDS_EXTENSION));
    } catch (IOException ignored) {
    }
    tvx = tvd = tvf = null;
    lastDocID = 0;
    
    reset();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974946/fstmerge_var1_8338111846955011313
@Override
  synchronized void flush(Map<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> threadsAndFields, final SegmentWriteState state) throws IOException {
    if (tvx != null) {
      // At least one doc in this run had term vectors enabled
      fill(state.numDocs);
      tvx.close();
      tvf.close();
      tvd.close();
      tvx = tvd = tvf = null;
      assert state.segmentName != null;
      String idxName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.VECTORS_INDEX_EXTENSION);
      String fldName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.VECTORS_FIELDS_EXTENSION);
      String docName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);

      if (4 + ((long) state.numDocs) * 16 != state.directory.fileLength(idxName)) {
        throw new RuntimeException("after flush: tvx size mismatch: " + state.numDocs + " docs vs " + state.directory.fileLength(idxName) + " length in bytes of " + idxName + " file exists?=" + state.directory.fileExists(idxName));
      }

      state.flushedFiles.add(idxName);
      state.flushedFiles.add(fldName);
      state.flushedFiles.add(docName);

      lastDocID = 0;
      state.hasVectors = hasVectors;
      hasVectors = false;
    }

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {
      for (final TermsHashConsumerPerField field : entry.getValue() ) {
        TermVectorsTermsWriterPerField perField = (TermVectorsTermsWriterPerField) field;
        perField.termsHashPerField.reset();
        perField.shrinkHash();
      }

      TermVectorsTermsWriterPerThread perThread = (TermVectorsTermsWriterPerThread) entry.getKey();
      perThread.termsHashPerThread.reset(true);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974946/fstmerge_base_1544951291801442615
@Override
  synchronized void flush(Map<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> threadsAndFields, final SegmentWriteState state) throws IOException {

    if (tvx != null) {

      if (state.numDocsInStore > 0)
        // In case there are some final documents that we
        // didn't see (because they hit a non-aborting exception):
        fill(state.numDocsInStore - docWriter.getDocStoreOffset());

      tvx.flush();
      tvd.flush();
      tvf.flush();
    }

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {
      for (final TermsHashConsumerPerField field : entry.getValue() ) {
        TermVectorsTermsWriterPerField perField = (TermVectorsTermsWriterPerField) field;
        perField.termsHashPerField.reset();
        perField.shrinkHash();
      }

      TermVectorsTermsWriterPerThread perThread = (TermVectorsTermsWriterPerThread) entry.getKey();
      perThread.termsHashPerThread.reset(true);
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974946/fstmerge_var2_5743279021810094641

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974951/fstmerge_var1_2807461028254900802
synchronized PerDoc getPerDoc() {
    if (freeCount == 0) {
      allocCount++;
      if (allocCount > docFreeList.length) {
        // Grow our free list up front to make sure we have
        // enough space to recycle all outstanding PerDoc
        // instances
        assert allocCount == 1+docFreeList.length;
        docFreeList = new PerDoc[ArrayUtil.oversize(allocCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
      }
      return new PerDoc();
    } else {
      return docFreeList[--freeCount];
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974951/fstmerge_base_1289157801831103271
synchronized PerDoc getPerDoc() {
    if (freeCount == 0) {
      allocCount++;
      if (allocCount > docFreeList.length) {
        // Grow our free list up front to make sure we have
        // enough space to recycle all outstanding PerDoc
        // instances
        assert allocCount == 1+docFreeList.length;
        docFreeList = new PerDoc[ArrayUtil.oversize(allocCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
      }
      return new PerDoc();
    } else
      return docFreeList[--freeCount];
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974951/fstmerge_var2_5385884608048791423

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974955/fstmerge_var1_1925817125629059568
synchronized void finishDocument(PerDoc perDoc) throws IOException {

    assert docWriter.writer.testPoint("TermVectorsTermsWriter.finishDocument start");

    initTermVectorsWriter();

    fill(perDoc.docID);

    // Append term vectors to the real outputs:
    tvx.writeLong(tvd.getFilePointer());
    tvx.writeLong(tvf.getFilePointer());
    tvd.writeVInt(perDoc.numVectorFields);
    if (perDoc.numVectorFields > 0) {
      for(int i=0;i<perDoc.numVectorFields;i++) {
        tvd.writeVInt(perDoc.fieldNumbers[i]);
      }
      assert 0 == perDoc.fieldPointers[0];
      long lastPos = perDoc.fieldPointers[0];
      for(int i=1;i<perDoc.numVectorFields;i++) {
        long pos = perDoc.fieldPointers[i];
        tvd.writeVLong(pos-lastPos);
        lastPos = pos;
      }
      perDoc.perDocTvf.writeTo(tvf);
      perDoc.numVectorFields = 0;
    }

    assert lastDocID == perDoc.docID;

    lastDocID++;

    perDoc.reset();
    free(perDoc);
    assert docWriter.writer.testPoint("TermVectorsTermsWriter.finishDocument end");
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974955/fstmerge_base_7517113534657576452
synchronized void finishDocument(PerDoc perDoc) throws IOException {

    assert docWriter.writer.testPoint("TermVectorsTermsWriter.finishDocument start");

    initTermVectorsWriter();

    fill(perDoc.docID);

    // Append term vectors to the real outputs:
    tvx.writeLong(tvd.getFilePointer());
    tvx.writeLong(tvf.getFilePointer());
    tvd.writeVInt(perDoc.numVectorFields);
    if (perDoc.numVectorFields > 0) {
      for(int i=0;i<perDoc.numVectorFields;i++)
        tvd.writeVInt(perDoc.fieldNumbers[i]);
      assert 0 == perDoc.fieldPointers[0];
      long lastPos = perDoc.fieldPointers[0];
      for(int i=1;i<perDoc.numVectorFields;i++) {
        long pos = perDoc.fieldPointers[i];
        tvd.writeVLong(pos-lastPos);
        lastPos = pos;
      }
      perDoc.perDocTvf.writeTo(tvf);
      perDoc.numVectorFields = 0;
    }

    assert lastDocID == perDoc.docID + docWriter.getDocStoreOffset();

    lastDocID++;

    perDoc.reset();
    free(perDoc);
    assert docWriter.writer.testPoint("TermVectorsTermsWriter.finishDocument end");
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627974955/fstmerge_var2_2717659287944659948

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ final SegmentInfos segmentInfos; ##FSTMerge## private SegmentInfos segmentInfos = new SegmentInfos(); ##FSTMerge## private final SegmentInfos segmentInfos = new SegmentInfos();
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975001/fstmerge_var1_5010629951050927506
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975001/fstmerge_base_4640818246666399668
public IndexReader getReader(int termInfosIndexDivisor) throws IOException {

    ensureOpen();

    if (infoStream != null) {
      message("flush at getReader");
    }

    // Do this up front before flushing so that the readers
    // obtained during this flush are pooled, the first time
    // this method is called:
    poolReaders = true;

    flush(true, true, false);
    
    // Prevent segmentInfos from changing while opening the
    // reader; in theory we could do similar retry logic,
    // just like we do when loading segments_N
    synchronized(this) {
      applyDeletes();
      final IndexReader r = new ReadOnlyDirectoryReader(this, segmentInfos, termInfosIndexDivisor, codecs);
      if (infoStream != null) {
        message("return reader version=" + r.getVersion() + " reader=" + r);
      }
      return r;
    }
  }
=======
public IndexReader getReader(int termInfosIndexDivisor) throws IOException {

    ensureOpen();

    if (infoStream != null) {
      message("flush at getReader");
    }

    // Do this up front before flushing so that the readers
    // obtained during this flush are pooled, the first time
    // this method is called:
    poolReaders = true;

    flush(true, false);
    
    // Prevent segmentInfos from changing while opening the
    // reader; in theory we could do similar retry logic,
    // just like we do when loading segments_N
    synchronized(this) {
      applyDeletes();
      final IndexReader r = new ReadOnlyDirectoryReader(this, segmentInfos, termInfosIndexDivisor, codecs);
      if (infoStream != null) {
        message("return reader version=" + r.getVersion() + " reader=" + r);
      }
      return r;
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975001/fstmerge_var2_4493020484321326848

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public IndexWriter(Directory d, IndexWriterConfig conf)
      throws CorruptIndexException, LockObtainFailedException, IOException {
    config = (IndexWriterConfig) conf.clone();
    directory = d;
    analyzer = conf.getAnalyzer();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975054/fstmerge_var1_8144313284016806071
    infoStream = defaultInfoStream;
    maxFieldLength = conf.getMaxFieldLength();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975054/fstmerge_base_8475277920030973068
    setMessageID(defaultInfoStream);
    maxFieldLength = conf.getMaxFieldLength();
=======
    setMessageID(defaultInfoStream);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975054/fstmerge_var2_7451551195729817342
    termIndexInterval = conf.getTermIndexInterval();
    mergePolicy = conf.getMergePolicy();
    mergePolicy.setIndexWriter(this);
    mergeScheduler = conf.getMergeScheduler();
    mergedSegmentWarmer = conf.getMergedSegmentWarmer();
    codecs = conf.getCodecProvider();
    
    bufferedDeletes = new BufferedDeletes(messageID);
    bufferedDeletes.setInfoStream(infoStream);
    poolReaders = conf.getReaderPooling();

    this.readerPool = new IndexReaderPool(this, directory, config);
    
    OpenMode mode = conf.getOpenMode();
    boolean create;
    if (mode == OpenMode.CREATE) {
      create = true;
    } else if (mode == OpenMode.APPEND) {
      create = false;
    } else {
      // CREATE_OR_APPEND - create only if an index does not exist
      create = !IndexReader.indexExists(directory);
    }

    writeLock = directory.makeLock(WRITE_LOCK_NAME);

    if (!writeLock.obtain(conf.getWriteLockTimeout())) // obtain write lock
      throw new LockObtainFailedException("Index locked for write: " + writeLock);

    boolean success = false;

    // TODO: we should check whether this index is too old,
    // and throw an IndexFormatTooOldExc up front, here,
    // instead of later when merge, applyDeletes, getReader
    // is attempted.  I think to do this we should store the
    // oldest segment's version in segments_N.
    segmentInfos = new SegmentInfos(codecs);
    try {
      if (create) {
        // Try to read first.  This is to allow create
        // against an index that's currently open for
        // searching.  In this case we write the next
        // segments_N file with no segments:
        try {
          segmentInfos.read(directory, codecs);
          segmentInfos.clear();
        } catch (IOException e) {
          // Likely this means it's a fresh directory
        }

        // Record that we have a change (zero out all
        // segments) pending:
        changeCount++;
        segmentInfos.changed();
      } else {
        segmentInfos.read(directory, codecs);

        IndexCommit commit = conf.getIndexCommit();
        if (commit != null) {
          // Swap out all segments, but, keep metadata in
          // SegmentInfos, like version & generation, to
          // preserve write-once.  This is important if
          // readers are open against the future commit
          // points.
          if (commit.getDirectory() != directory)
            throw new IllegalArgumentException("IndexCommit's directory doesn't match my directory");
          SegmentInfos oldInfos = new SegmentInfos(codecs);
          oldInfos.read(directory, commit.getSegmentsFileName(), codecs);
          segmentInfos.replace(oldInfos);
          changeCount++;
          segmentInfos.changed();
          if (infoStream != null)
            message("init: loaded commit \"" + commit.getSegmentsFileName() + "\"");
        }
      }

      setRollbackSegmentInfos(segmentInfos);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975054/fstmerge_var1_8144313284016806071
      docWriter = new DocumentsWriter(directory, this, conf.getIndexingChain(), conf.getMaxThreadStates(), getCurrentFieldInfos(), bufferedDeletes);
      docWriter.setInfoStream(infoStream);
      docWriter.setMaxFieldLength(maxFieldLength);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975054/fstmerge_base_8475277920030973068
      docWriter = new DocumentsWriter(directory, this, conf.getIndexingChain(), conf.getMaxThreadStates());
      docWriter.setInfoStream(infoStream);
      docWriter.setMaxFieldLength(maxFieldLength);
=======
      docWriter = new DocumentsWriter(directory, this, conf);
      // nocommit
      //docWriter.setInfoStream(infoStream);
      //docWriter.setMaxFieldLength(maxFieldLength);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975054/fstmerge_var2_7451551195729817342

      // Default deleter (for backwards compatibility) is
      // KeepOnlyLastCommitDeleter:
      deleter = new IndexFileDeleter(directory,
                                     conf.getIndexDeletionPolicy(),
                                     segmentInfos, infoStream, codecs);

      if (deleter.startingCommitDeleted) {
        // Deletion policy deleted the "head" commit point.
        // We have to mark ourself as changed so that if we
        // are closed w/o any further changes we write a new
        // segments_N file.
        changeCount++;
        segmentInfos.changed();
      }

      docWriter.setRAMBufferSizeMB(conf.getRAMBufferSizeMB());
      docWriter.setMaxBufferedDocs(conf.getMaxBufferedDocs());
      pushMaxBufferedDocs();

      if (infoStream != null) {
        message("init: create=" + create);
        messageState();
      }

      success = true;

    } finally {
      if (!success) {
        if (infoStream != null) {
          message("init: hit exception on init; releasing write lock");
        }
        try {
          writeLock.release();
        } catch (Throwable t) {
          // don't mask the original exception
        }
        writeLock = null;
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void setInfoStream(PrintStream infoStream) {
    ensureOpen();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975116/fstmerge_var1_9196644863973859691
    this.infoStream = infoStream;
    docWriter.setInfoStream(infoStream);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975116/fstmerge_base_8651063223270051558
    setMessageID(infoStream);
    docWriter.setInfoStream(infoStream);
=======
    setMessageID(infoStream);
    // nocommit
    //docWriter.setInfoStream(infoStream);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975116/fstmerge_var2_2388457265008631985
    deleter.setInfoStream(infoStream);
    bufferedDeletes.setInfoStream(infoStream);
    if (infoStream != null)
      messageState();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private void closeInternal(boolean waitForMerges) throws CorruptIndexException, IOException {

    try {
      if (infoStream != null)
        message("now flush at close");

      docWriter.close();

      // Only allow a new merge to be triggered if we are
      // going to wait for merges:
      if (!hitOOM) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975147/fstmerge_base_2721677796861759972
        flush(waitForMerges, true, true);
=======
        flush(waitForMerges, true);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975147/fstmerge_var2_2516504452894306461
      }

      if (waitForMerges)
        // Give merge scheduler last chance to run, in case
        // any pending merges are waiting:
        mergeScheduler.merge(this);

      mergePolicy.close();

      synchronized(this) {
        finishMerges(waitForMerges);
        stopMerges = true;
      }

      mergeScheduler.close();

      if (infoStream != null)
        message("now call final commit()");
      
      if (!hitOOM) {
        commitInternal(null);
      }

      if (infoStream != null)
        message("at close: " + segString());

      synchronized(this) {
        readerPool.close();
        docWriter = null;
        deleter.close();
      }
      
      if (writeLock != null) {
        writeLock.release();                          // release write lock
        writeLock = null;
      }
      synchronized(this) {
        closed = true;
      }
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "closeInternal");
    } finally {
      synchronized(this) {
        closing = false;
        notifyAll();
        if (!closed) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975147/fstmerge_var1_2262169033487160981
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975147/fstmerge_base_2721677796861759972
          if (docWriter != null)
            docWriter.resumeAllThreads();
=======
          if (docWriter != null) {
            docWriter.resumeAllThreads();
          }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975147/fstmerge_var2_2516504452894306461
          if (infoStream != null)
            message("hit exception while closing");
        }
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public long addDocument(Document doc, Analyzer analyzer) throws CorruptIndexException, IOException {
    ensureOpen();
    boolean success = false;
    try {
      try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975180/fstmerge_var1_3655788558745876732
        doFlush = docWriter.updateDocument(doc, analyzer, null);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975180/fstmerge_base_8919494318359833864
        doFlush = docWriter.addDocument(doc, analyzer);
=======
        long sequenceID = docWriter.addDocument(doc, analyzer);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975180/fstmerge_var2_8712976060022215687
        success = true;
        return sequenceID;
      } finally {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975180/fstmerge_var1_3655788558745876732
        if (!success && infoStream != null)
          message("hit exception adding document");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975180/fstmerge_base_8919494318359833864
        if (!success) {

          if (infoStream != null)
            message("hit exception adding document");

          synchronized (this) {
            // If docWriter has some aborted files that were
            // never incref'd, then we clean them up here
            if (docWriter != null) {
              final Collection<String> files = docWriter.abortedFiles();
              if (files != null)
                deleter.deleteNewFiles(files);
            }
          }
        }
=======
        if (!success) {
          if (infoStream != null) {
            message("hit exception adding document");
          }
          synchronized (this) {
            // If docWriter has some aborted files that were
            // never incref'd, then we clean them up here
            if (docWriter != null) {
              final Collection<String> files = docWriter.abortedFiles();
              if (files != null) {
                deleter.deleteNewFiles(files);
              }
            }
          }
        }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975180/fstmerge_var2_8712976060022215687
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975180/fstmerge_var1_3655788558745876732
      if (doFlush)
        flush(true, false);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975180/fstmerge_base_8919494318359833864
      if (doFlush)
        flush(true, false, false);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975180/fstmerge_var2_8712976060022215687
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "addDocument");
    }
    
    return -1;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public long deleteDocuments(Term term) throws CorruptIndexException, IOException {
    ensureOpen();
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975184/fstmerge_var1_7713934162148923532
      if (docWriter.deleteTerm(term, false)) {
        flush(true, false);
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975184/fstmerge_base_1396769202894252265
      boolean doFlush = docWriter.bufferDeleteTerm(term);
      if (doFlush)
        flush(true, false, false);
=======
      return docWriter.bufferDeleteTerm(term);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975184/fstmerge_var2_1687766165002925972
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Term)");
    }
    return -1;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public long deleteDocuments(Term... terms) throws CorruptIndexException, IOException {
    ensureOpen();
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975189/fstmerge_var1_281445343175466225
      if (docWriter.deleteTerm(term, false)) {
        flush(true, false);
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975189/fstmerge_base_8752584814620872349
      boolean doFlush = docWriter.bufferDeleteTerm(term);
      if (doFlush)
        flush(true, false, false);
=======
      return docWriter.bufferDeleteTerms(terms);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975189/fstmerge_var2_3006753884609433045
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Term..)");
    }
    return -1;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public long deleteDocuments(Query query) throws CorruptIndexException, IOException {
    ensureOpen();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975194/fstmerge_var1_1894173470021512730
    try {
      if (docWriter.deleteQuery(query)) {
        flush(true, false);
      }
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Query)");
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975194/fstmerge_base_1983350286830351618
    boolean doFlush = docWriter.bufferDeleteQuery(query);
    if (doFlush)
      flush(true, false, false);
=======
    return docWriter.bufferDeleteQuery(query);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975194/fstmerge_var2_138023525394605082
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public long deleteDocuments(Query... queries) throws CorruptIndexException, IOException {
    ensureOpen();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975199/fstmerge_var1_7981978098803024260
    try {
      if (docWriter.deleteQuery(query)) {
        flush(true, false);
      }
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Query)");
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975199/fstmerge_base_8569535705782409697
    boolean doFlush = docWriter.bufferDeleteQuery(query);
    if (doFlush)
      flush(true, false, false);
=======
    return docWriter.bufferDeleteQueries(queries);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975199/fstmerge_var2_7328010744963885632
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public long updateDocument(Term term, Document doc, Analyzer analyzer)
      throws CorruptIndexException, IOException {
    ensureOpen();
    try {
      boolean success = false;
      try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975208/fstmerge_var1_5267152671077255457
        doFlush = docWriter.updateDocument(doc, analyzer, term);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975208/fstmerge_base_3963536199095399532
        doFlush = docWriter.updateDocument(term, doc, analyzer);
=======
        long sequenceID = docWriter.updateDocument(term, doc, analyzer);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975208/fstmerge_var2_9127179842777265801
        success = true;
        return sequenceID;
      } finally {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975208/fstmerge_var1_5267152671077255457
        if (!success && infoStream != null)
          message("hit exception updating document");
      }
      if (doFlush) {
        flush(true, false);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975208/fstmerge_base_3963536199095399532
        if (!success) {

          if (infoStream != null)
            message("hit exception updating document");

          synchronized (this) {
            // If docWriter has some aborted files that were
            // never incref'd, then we clean them up here
            final Collection<String> files = docWriter.abortedFiles();
            if (files != null)
              deleter.deleteNewFiles(files);
          }
        }
=======
        if (!success) {

          if (infoStream != null) {
            message("hit exception updating document");
          }
          
          synchronized (this) {
            // If docWriter has some aborted files that were
            // never incref'd, then we clean them up here
            final Collection<String> files = docWriter.abortedFiles();
            if (files != null) {
              deleter.deleteNewFiles(files);
            }
          }
        }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975208/fstmerge_var2_9127179842777265801
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975208/fstmerge_base_3963536199095399532
      if (doFlush)
        flush(true, false, false);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975208/fstmerge_var2_9127179842777265801
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "updateDocument");
    }
    
    return -1;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public synchronized void deleteAll() throws IOException {
    try {

      // Abort any running merges
      finishMerges(false);

      // Remove any buffered docs
      docWriter.abort();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975304/fstmerge_var1_1930431635963552406
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975304/fstmerge_base_107059567508324825
      docWriter.setFlushedDocCount(0);
=======
      // nocommit
      //docWriter.setFlushedDocCount(0);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975304/fstmerge_var2_1343050799789626629

      // Remove all segments
      segmentInfos.clear();

      // Ask deleter to locate unreferenced files & remove them:
      deleter.checkpoint(segmentInfos, false);
      deleter.refresh();

      // Don't bother saving any changes in our segmentInfos
      readerPool.clear(null);      

      // Mark that the index has changed
      ++changeCount;
      segmentInfos.changed();
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteAll");
    } finally {
      if (infoStream != null) {
        message("hit exception during deleteAll");
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void addIndexes(Directory... dirs) throws CorruptIndexException, IOException {
    ensureOpen();

    noDupDirs(dirs);

    try {
      if (infoStream != null)
        message("flush at addIndexes(Directory...)");
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975331/fstmerge_var1_522165589087533993
      flush(false, true);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975331/fstmerge_base_8051980215666046248
      flush(true, false, true);
=======
      flush(true, true);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975331/fstmerge_var2_1852631816035225218

      int docCount = 0;
      List<SegmentInfo> infos = new ArrayList<SegmentInfo>();
      for (Directory dir : dirs) {
        if (infoStream != null) {
          message("addIndexes: process directory " + dir);
        }
        SegmentInfos sis = new SegmentInfos(codecs); // read infos from dir
        sis.read(dir, codecs);
        final Set<String> dsFilesCopied = new HashSet<String>();
        final Map<String, String> dsNames = new HashMap<String, String>();
        for (SegmentInfo info : sis) {
          assert !infos.contains(info): "dup info dir=" + info.dir + " name=" + info.name;

          docCount += info.docCount;
          String newSegName = newSegmentName();
          String dsName = info.getDocStoreSegment();

          if (infoStream != null) {
            message("addIndexes: process segment origName=" + info.name + " newName=" + newSegName + " dsName=" + dsName + " info=" + info);
          }

          // Determine if the doc store of this segment needs to be copied. It's
          // only relevant for segments who share doc store with others, because
          // the DS might have been copied already, in which case we just want
          // to update the DS name of this SegmentInfo.
          // NOTE: pre-3x segments include a null DSName if they don't share doc
          // store. So the following code ensures we don't accidentally insert
          // 'null' to the map.
          final String newDsName;
          if (dsName != null) {
            if (dsNames.containsKey(dsName)) {
              newDsName = dsNames.get(dsName);
            } else {
              dsNames.put(dsName, newSegName);
              newDsName = newSegName;
            }
          } else {
            newDsName = newSegName;
          }

          // Copy the segment files
          for (String file: info.files()) {
            final String newFileName;
            if (IndexFileNames.isDocStoreFile(file)) {
              newFileName = newDsName + IndexFileNames.stripSegmentName(file);
              if (dsFilesCopied.contains(newFileName)) {
                continue;
              }
              dsFilesCopied.add(newFileName);
            } else {
              newFileName = newSegName + IndexFileNames.stripSegmentName(file);
            }
            assert !directory.fileExists(newFileName): "file \"" + newFileName + "\" already exists";
            dir.copy(directory, file, newFileName);
          }

          // Update SI appropriately
          info.setDocStoreSegment(newDsName);
          info.dir = directory;
          info.name = newSegName;

          infos.add(info);
        }
      }      

      synchronized (this) {
        ensureOpen();
        segmentInfos.addAll(infos);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975331/fstmerge_var1_522165589087533993
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975331/fstmerge_base_8051980215666046248
        // Notify DocumentsWriter that the flushed count just increased
        docWriter.updateFlushedDocCount(docCount);

=======
        // Notify DocumentsWriter that the flushed count just increased
        // nocommit
        //docWriter.updateFlushedDocCount(docCount);

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975331/fstmerge_var2_1852631816035225218
        checkpoint();
      }

    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "addIndexes(Directory...)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void addIndexes(IndexReader... readers) throws CorruptIndexException, IOException {
    ensureOpen();

    try {
      String mergedName = newSegmentName();
      SegmentMerger merger = new SegmentMerger(directory, termIndexInterval,
                                               mergedName, null, codecs, payloadProcessorProvider,
                                               ((FieldInfos) docWriter.getFieldInfos().clone()));
      
      for (IndexReader reader : readers)      // add new indexes
        merger.add(reader);
      
      int docCount = merger.merge();                // merge 'em
      
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975337/fstmerge_var1_3836332589478527003
      SegmentInfo info = new SegmentInfo(mergedName, docCount, directory,
                                         false, merger.fieldInfos().hasProx(), merger.getSegmentCodecs(),
                                         merger.fieldInfos().hasVectors());
      setDiagnostics(info, "addIndexes(IndexReader...)");

      boolean useCompoundFile;
      synchronized(this) { // Guard segmentInfos
        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, info);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975337/fstmerge_base_5788087484418482231
      SegmentInfo info = null;
      synchronized(this) {
        info = new SegmentInfo(mergedName, docCount, directory, false, -1,
            null, false, merger.hasProx(), merger.getCodec());
        setDiagnostics(info, "addIndexes(IndexReader...)");
        segmentInfos.add(info);
        checkpoint();
        
        // Notify DocumentsWriter that the flushed count just increased
        docWriter.updateFlushedDocCount(docCount);
=======
      SegmentInfo info = null;
      synchronized(this) {
        info = new SegmentInfo(mergedName, docCount, directory, false, merger.hasProx(), merger.getCodec());
        setDiagnostics(info, "addIndexes(IndexReader...)");
        segmentInfos.add(info);
        checkpoint();
        
        // Notify DocumentsWriter that the flushed count just increased
        // nocommit
        //docWriter.updateFlushedDocCount(docCount);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975337/fstmerge_var2_9132979651098389037
      }
      
      // Now create the compound file if needed
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975337/fstmerge_var1_3836332589478527003
      if (useCompoundFile) {
        merger.createCompoundFile(mergedName + ".cfs", info);
        info.setUseCompoundFile(true);
        
        // delete new non cfs files directly: they were never
        // registered with IFD
        deleter.deleteNewFiles(merger.getMergedFiles(info));
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975337/fstmerge_base_5788087484418482231
      if (mergePolicy instanceof LogMergePolicy && getUseCompoundFile()) {
=======
      if (mergePolicy instanceof LogMergePolicy && getLogMergePolicy().getUseCompoundFile()) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975337/fstmerge_var2_9132979651098389037

      // Register the new segment
      synchronized(this) {
        segmentInfos.add(info);
        checkpoint();
      }
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "addIndexes(IndexReader...)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975390/fstmerge_var1_2455114631332550036
protected final void flush(boolean triggerMerge, boolean flushDeletes) throws CorruptIndexException, IOException {

    // NOTE: this method cannot be sync'd because
    // maybeMerge() in turn calls mergeScheduler.merge which
    // in turn can take a long time to run and we don't want
    // to hold the lock for that.  In the case of
    // ConcurrentMergeScheduler this can lead to deadlock
    // when it stalls due to too many running merges.

    // We can be called during close, when closing==true, so we must pass false to ensureOpen:
    ensureOpen(false);
    if (doFlush(flushDeletes) && triggerMerge) {
      maybeMerge();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975390/fstmerge_base_2467040144635451784
=======
protected final void flush(boolean triggerMerge, boolean flushDeletes) throws CorruptIndexException, IOException {
    // We can be called during close, when closing==true, so we must pass false to ensureOpen:
    ensureOpen(false);
    
    doBeforeFlush();
    
    if (flushDeletes) {
      if (applyDeletes()) {
        checkpoint();
      }
    }
    boolean maybeMerge = false;
    boolean success = false;
    try {
      maybeMerge = docWriter.flushAllThreads(flushDeletes) && triggerMerge;
      success = true;
    } finally {
      if (!success) {
        synchronized (this) {
          // If docWriter has some aborted files that were
          // never incref'd, then we clean them up here
          final Collection<String> files = docWriter.abortedFiles();
          if (files != null) {
            deleter.deleteNewFiles(files);
          }
        }
      }
    }
    
    doAfterFlush();
    
    if (maybeMerge) {
      maybeMerge();
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975390/fstmerge_var2_8487304671799870438

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975413/fstmerge_var1_1142818813593925851
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975413/fstmerge_base_9197931404924012894
synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentMerger merger, int mergedDocCount, SegmentReader mergedReader) throws IOException {

    assert testPoint("startCommitMerge");

    if (hitOOM) {
      throw new IllegalStateException("this writer hit an OutOfMemoryError; cannot complete merge");
    }

    if (infoStream != null)
      message("commitMerge: " + merge.segString(directory) + " index=" + segString());

    assert merge.registerDone;

    // If merge was explicitly aborted, or, if rollback() or
    // rollbackTransaction() had been called since our merge
    // started (which results in an unqualified
    // deleter.refresh() call that will remove any index
    // file that current segments does not reference), we
    // abort this merge
    if (merge.isAborted()) {
      if (infoStream != null)
        message("commitMerge: skipping merge " + merge.segString(directory) + ": it was aborted");

      deleter.refresh(merge.info.name);
      return false;
    }

    final int start = ensureContiguousMerge(merge);

    commitMergedDeletes(merge, mergedReader);
    docWriter.remapDeletes(segmentInfos, merger.getDocMaps(), merger.getDelCounts(), merge, mergedDocCount);
      
    setMergeDocStoreIsCompoundFile(merge);
    merge.info.setHasProx(merger.hasProx());

    segmentInfos.subList(start, start + merge.segments.size()).clear();
    assert !segmentInfos.contains(merge.info);
    segmentInfos.add(start, merge.info);

    // Must note the change to segmentInfos so any commits
    // in-flight don't lose it:
    checkpoint();

    // If the merged segments had pending changes, clear
    // them so that they don't bother writing them to
    // disk, updating SegmentInfo, etc.:
    readerPool.clear(merge.segments);

    if (merge.optimize)
      segmentsToOptimize.add(merge.info);
    return true;
  }
=======
synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentMerger merger, int mergedDocCount, SegmentReader mergedReader) throws IOException {

    assert testPoint("startCommitMerge");

    if (hitOOM) {
      throw new IllegalStateException("this writer hit an OutOfMemoryError; cannot complete merge");
    }

    if (infoStream != null)
      message("commitMerge: " + merge.segString(directory) + " index=" + segString());

    assert merge.registerDone;

    // If merge was explicitly aborted, or, if rollback() or
    // rollbackTransaction() had been called since our merge
    // started (which results in an unqualified
    // deleter.refresh() call that will remove any index
    // file that current segments does not reference), we
    // abort this merge
    if (merge.isAborted()) {
      if (infoStream != null)
        message("commitMerge: skipping merge " + merge.segString(directory) + ": it was aborted");

      deleter.refresh(merge.info.name);
      return false;
    }

    final int start = ensureContiguousMerge(merge);

    commitMergedDeletes(merge, mergedReader);
    // nocommit
    //docWriter.remapDeletes(segmentInfos, merger.getDocMaps(), merger.getDelCounts(), merge, mergedDocCount);
      
    merge.info.setHasProx(merger.hasProx());

    segmentInfos.subList(start, start + merge.segments.size()).clear();
    assert !segmentInfos.contains(merge.info);
    segmentInfos.add(start, merge.info);

    // Must note the change to segmentInfos so any commits
    // in-flight don't lose it:
    checkpoint();

    // If the merged segments had pending changes, clear
    // them so that they don't bother writing them to
    // disk, updating SegmentInfo, etc.:
    readerPool.clear(merge.segments);

    if (merge.optimize)
      segmentsToOptimize.add(merge.info);
    return true;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975413/fstmerge_var2_3552226433206664395

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
synchronized private void _mergeInit(MergePolicy.OneMerge merge) throws IOException {

    assert testPoint("startMergeInit");

    assert merge.registerDone;
    assert !merge.optimize || merge.maxNumSegmentsOptimize > 0;

    if (hitOOM) {
      throw new IllegalStateException("this writer hit an OutOfMemoryError; cannot merge");
    }

    if (merge.info != null)
      // mergeInit already done
      return;

    if (merge.isAborted())
      return;

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975469/fstmerge_var1_8846371344221126288
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975469/fstmerge_base_7855561197696546657
    applyDeletes();

    final SegmentInfos sourceSegments = merge.segments;
    final int end = sourceSegments.size();

    // Check whether this merge will allow us to skip
    // merging the doc stores (stored field & vectors).
    // This is a very substantial optimization (saves tons
    // of IO).

    Directory lastDir = directory;
    String lastDocStoreSegment = null;
    int next = -1;

    boolean mergeDocStores = false;
    boolean doFlushDocStore = false;
    final String currentDocStoreSegment = docWriter.getDocStoreSegment();

    // Test each segment to be merged: check if we need to
    // flush/merge doc stores
    for (int i = 0; i < end; i++) {
      SegmentInfo si = sourceSegments.info(i);

      // If it has deletions we must merge the doc stores
      if (si.hasDeletions())
        mergeDocStores = true;

      // If it has its own (private) doc stores we must
      // merge the doc stores
      if (-1 == si.getDocStoreOffset())
        mergeDocStores = true;

      // If it has a different doc store segment than
      // previous segments, we must merge the doc stores
      String docStoreSegment = si.getDocStoreSegment();
      if (docStoreSegment == null)
        mergeDocStores = true;
      else if (lastDocStoreSegment == null)
        lastDocStoreSegment = docStoreSegment;
      else if (!lastDocStoreSegment.equals(docStoreSegment))
        mergeDocStores = true;

      // Segments' docScoreOffsets must be in-order,
      // contiguous.  For the default merge policy now
      // this will always be the case but for an arbitrary
      // merge policy this may not be the case
      if (-1 == next)
        next = si.getDocStoreOffset() + si.docCount;
      else if (next != si.getDocStoreOffset())
        mergeDocStores = true;
      else
        next = si.getDocStoreOffset() + si.docCount;
      
      // If the segment comes from a different directory
      // we must merge
      if (lastDir != si.dir)
        mergeDocStores = true;

      // If the segment is referencing the current "live"
      // doc store outputs then we must merge
      if (si.getDocStoreOffset() != -1 && currentDocStoreSegment != null && si.getDocStoreSegment().equals(currentDocStoreSegment)) {
        doFlushDocStore = true;
      }
    }

    final int docStoreOffset;
    final String docStoreSegment;
    final boolean docStoreIsCompoundFile;

    if (mergeDocStores) {
      docStoreOffset = -1;
      docStoreSegment = null;
      docStoreIsCompoundFile = false;
    } else {
      SegmentInfo si = sourceSegments.info(0);        
      docStoreOffset = si.getDocStoreOffset();
      docStoreSegment = si.getDocStoreSegment();
      docStoreIsCompoundFile = si.getDocStoreIsCompoundFile();
    }

    if (mergeDocStores && doFlushDocStore) {
      // SegmentMerger intends to merge the doc stores
      // (stored fields, vectors), and at least one of the
      // segments to be merged refers to the currently
      // live doc stores.

      // TODO: if we know we are about to merge away these
      // newly flushed doc store files then we should not
      // make compound file out of them...
      if (infoStream != null)
        message("now flush at merge");
      doFlush(true, false);
    }

    merge.increfDone = true;

    merge.mergeDocStores = mergeDocStores;

=======
    applyDeletes();

    final SegmentInfos sourceSegments = merge.segments;
    final int end = sourceSegments.size();

    merge.increfDone = true;

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975469/fstmerge_var2_6261997002953568962
    // Bind a new segment name here so even with
    // ConcurrentMergePolicy we keep deterministic segment
    // names.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975469/fstmerge_var1_8846371344221126288
    merge.info = new SegmentInfo(newSegmentName(), 0, directory, false, false, null, false);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975469/fstmerge_base_7855561197696546657
    merge.info = new SegmentInfo(newSegmentName(), 0,
                                 directory, false, docStoreOffset,
                                 docStoreSegment,
                                 docStoreIsCompoundFile,
                                 false,
                                 null);

=======
    merge.info = new SegmentInfo(newSegmentName(), 0,
                                 directory, false,
                                 false,
                                 null);

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975469/fstmerge_var2_6261997002953568962

    Map<String,String> details = new HashMap<String,String>();
    details.put("optimize", Boolean.toString(merge.optimize));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975469/fstmerge_var1_8846371344221126288
    details.put("mergeFactor", Integer.toString(merge.segments.size()));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975469/fstmerge_base_7855561197696546657
    details.put("mergeFactor", Integer.toString(end));
    details.put("mergeDocStores", Boolean.toString(mergeDocStores));
=======
    details.put("mergeFactor", Integer.toString(end));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975469/fstmerge_var2_6261997002953568962
    setDiagnostics(merge.info, "merge", details);

    if (infoStream != null) {
      message("merge seg=" + merge.info.name);
    }

    // Also enroll the merged segment into mergingSegments;
    // this prevents it from getting selected for a merge
    // after our merge is done but while we are building the
    // CFS:
    mergingSegments.add(merge.info);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private int mergeMiddle(MergePolicy.OneMerge merge)
    throws CorruptIndexException, IOException {
    
    merge.checkAborted(directory);

    final String mergedName = merge.info.name;
    
    int mergedDocCount = 0;

    SegmentInfos sourceSegments = merge.segments;
    final int numSegments = sourceSegments.size();

    SegmentMerger merger = new SegmentMerger(directory, termIndexInterval, mergedName, merge,
                                             codecs, payloadProcessorProvider,
                                             ((FieldInfos) docWriter.getFieldInfos().clone()));

    if (infoStream != null) {
      message("merging " + merge.segString(directory) + " mergeVectors=" + merger.fieldInfos().hasVectors());
    }

    merge.info.setHasVectors(merger.fieldInfos().hasVectors());
    merge.readers = new SegmentReader[numSegments];
    merge.readersClone = new SegmentReader[numSegments];

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_base_1223688137743340530
    boolean mergeDocStores = false;

    final Set<String> dss = new HashSet<String>();
    
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_var2_7049099224298536167
    // This is try/finally to make sure merger's readers are
    // closed:
    boolean success = false;
    try {
      int totDocCount = 0;

      for (int i = 0; i < numSegments; i++) {
        final SegmentInfo info = sourceSegments.info(i);

        // Hold onto the "live" reader; we will use this to
        // commit merged deletes
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_base_1223688137743340530
        SegmentReader reader = merge.readers[i] = readerPool.get(info, merge.mergeDocStores,
=======
        SegmentReader reader = merge.readers[i] = readerPool.get(info, true,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_var2_7049099224298536167
                                                                 MERGE_READ_BUFFER_SIZE,
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_base_1223688137743340530
                                                                 -1);
=======
                                                                 -config.getReaderTermsIndexDivisor());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_var2_7049099224298536167

        // We clone the segment readers because other
        // deletes may come in while we're merging so we
        // need readers that will not change
        SegmentReader clone = merge.readersClone[i] = (SegmentReader) reader.clone(true);
        merger.add(clone);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_base_1223688137743340530
        if (clone.hasDeletions()) {
          mergeDocStores = true;
        }
        
        if (info.getDocStoreOffset() != -1) {
          dss.add(info.getDocStoreSegment());
        }

=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_var2_7049099224298536167
        totDocCount += clone.numDocs();
      }

      if (infoStream != null) {
        message("merge: total "+totDocCount+" docs");
      }

      merge.checkAborted(directory);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_var1_3120312768965219666
      // This is where all the work happens:
      mergedDocCount = merge.info.docCount = merger.merge();

      // Record which codec was used to write the segment
      merge.info.setSegmentCodecs(merger.getSegmentCodecs());

      if (infoStream != null) {
        message("merge segmentCodecs=" + merger.getSegmentCodecs());
        message("merge store matchedCount=" + merger.getMatchedSubReaderCount() + " vs " + numSegments);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_base_1223688137743340530
      // If deletions have arrived and it has now become
      // necessary to merge doc stores, go and open them:
      if (mergeDocStores && !merge.mergeDocStores) {
        merge.mergeDocStores = true;
        synchronized(this) {

          // If 1) we must now merge doc stores, and 2) at
          // least one of the segments we are merging uses
          // the doc store we are now writing to, we must at
          // this point force this doc store closed (by
          // calling flush).  If we didn't do this then the
          // readers will attempt to open an IndexInput
          // on files that have still-open IndexOutputs
          // against them:
          if (dss.contains(docWriter.getDocStoreSegment())) {
            if (infoStream != null)
              message("now flush at mergeMiddle");
            doFlush(true, false);
          }
        }

        for(int i=0;i<numSegments;i++) {
          merge.readersClone[i].openDocStores();
        }

        // Clear DSS
        synchronized(this) {
          merge.info.setDocStore(-1, null, false);
        }
=======
      for(int i=0;i<numSegments;i++) {
        merge.readersClone[i].openDocStores();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_var2_7049099224298536167
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_var1_3120312768965219666
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_base_1223688137743340530

      // This is where all the work happens:
      mergedDocCount = merge.info.docCount = merger.merge(merge.mergeDocStores);

      // Record which codec was used to write the segment
      merge.info.setCodec(merger.getCodec());
=======

      // This is where all the work happens:
      mergedDocCount = merge.info.docCount = merger.merge();

      // Record which codec was used to write the segment
      merge.info.setCodec(merger.getCodec());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_var2_7049099224298536167
      
      assert mergedDocCount == totDocCount;

      // Very important to do this before opening the reader
      // because codec must know if prox was written for
      // this segment:
      //System.out.println("merger set hasProx=" + merger.hasProx() + " seg=" + merge.info.name);
      merge.info.setHasProx(merger.fieldInfos().hasProx());

      boolean useCompoundFile;
      synchronized (this) { // Guard segmentInfos
        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);
      }

      if (useCompoundFile) {
        success = false;
        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        try {
          if (infoStream != null) {
            message("create compound file " + compoundFileName);
          }
          merger.createCompoundFile(compoundFileName, merge.info);
          success = true;
        } catch (IOException ioe) {
          synchronized(this) {
            if (merge.isAborted()) {
              // This can happen if rollback or close(false)
              // is called -- fall through to logic below to
              // remove the partially created CFS:
            } else {
              handleMergeException(ioe, merge);
            }
          }
        } catch (Throwable t) {
          handleMergeException(t, merge);
        } finally {
          if (!success) {
            if (infoStream != null) {
              message("hit exception creating compound file during merge");
            }

            synchronized(this) {
              deleter.deleteFile(compoundFileName);
              deleter.deleteNewFiles(merger.getMergedFiles(merge.info));
            }
          }
        }

        success = false;

        synchronized(this) {

          // delete new non cfs files directly: they were never
          // registered with IFD
          deleter.deleteNewFiles(merger.getMergedFiles(merge.info));

          if (merge.isAborted()) {
            if (infoStream != null) {
              message("abort merge after building CFS");
            }
            deleter.deleteFile(compoundFileName);
            return 0;
          }
        }

        merge.info.setUseCompoundFile(true);
      }

      final int termsIndexDivisor;
      final boolean loadDocStores;

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_var1_3120312768965219666
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_base_1223688137743340530
      synchronized(this) {
        // If the doc store we are using has been closed and
        // is in now compound format (but wasn't when we
        // started), then we will switch to the compound
        // format as well:
        setMergeDocStoreIsCompoundFile(merge);
        assert merge.mergeFiles == null;
        merge.mergeFiles = merge.info.files();
        deleter.incRef(merge.mergeFiles);
      }

=======
      synchronized(this) {
        assert merge.mergeFiles == null;
        merge.mergeFiles = merge.info.files();
        deleter.incRef(merge.mergeFiles);
      }

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975490/fstmerge_var2_7049099224298536167
      if (poolReaders && mergedSegmentWarmer != null) {
        // Load terms index & doc stores so the segment
        // warmer can run searches, load documents/term
        // vectors
        termsIndexDivisor = config.getReaderTermsIndexDivisor();
        loadDocStores = true;
      } else {
        termsIndexDivisor = -1;
        loadDocStores = false;
      }

      // TODO: in the non-realtime case, we may want to only
      // keep deletes (it's costly to open entire reader
      // when we just need deletes)

      final SegmentReader mergedReader = readerPool.get(merge.info, loadDocStores, BufferedIndexInput.BUFFER_SIZE, termsIndexDivisor);
      try {
        if (poolReaders && mergedSegmentWarmer != null) {
          mergedSegmentWarmer.warm(mergedReader);
        }

        if (!commitMerge(merge, mergedReader)) {
          // commitMerge will return false if this merge was aborted
          return 0;
        }
      } finally {
        synchronized(this) {
          if (readerPool.release(mergedReader)) {
            // Must checkpoint after releasing the
            // mergedReader since it may have written a new
            // deletes file:
            checkpoint();
          }
        }
      }

      success = true;

    } finally {
      // Readers are already closed in commitMerge if we didn't hit
      // an exc:
      if (!success) {
        closeMergeReaders(merge, true);
      }
    }

    return mergedDocCount;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975507/fstmerge_var1_2700164006442017833
final int getBufferedDeleteTermsSize() {
    return docWriter.getPendingDeletes().terms.size();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975507/fstmerge_base_5540065406271905076
final synchronized int getBufferedDeleteTermsSize() {
    return docWriter.getBufferedDeleteTerms().size();
=======
final synchronized int getBufferedDeleteTermsSize() {
    // nocommit
    return 0;
    //return docWriter.getBufferedDeleteTerms().size();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975507/fstmerge_var2_5148709215257185054
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975511/fstmerge_var1_4981741144350798061
final int getNumBufferedDeleteTerms() {
    return docWriter.getPendingDeletes().numTermDeletes.get();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975511/fstmerge_base_3564273771364801
final synchronized int getNumBufferedDeleteTerms() {
    return docWriter.getNumBufferedDeleteTerms();
=======
final synchronized int getNumBufferedDeleteTerms() {
    // nocommit
    return 0;
    //return docWriter.getNumBufferedDeleteTerms();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975511/fstmerge_var2_1843399751741603309
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975619/fstmerge_var1_6490728396969742323
public synchronized boolean release(SegmentReader sr) throws IOException {
      return release(sr, false);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975619/fstmerge_base_4990505694908668175
public synchronized void release(SegmentReader sr) throws IOException {
      release(sr, false);
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975619/fstmerge_var2_6612003606772701609

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975624/fstmerge_var1_4445299661173171758
public synchronized boolean release(SegmentReader sr, boolean drop) throws IOException {

      final boolean pooled = readerMap.containsKey(sr.getSegmentInfo());

      assert !pooled || readerMap.get(sr.getSegmentInfo()) == sr;

      // Drop caller's ref; for an external reader (not
      // pooled), this decRef will close it
      sr.decRef();

      if (pooled && (drop || (!poolReaders && sr.getRefCount() == 1))) {

        // We invoke deleter.checkpoint below, so we must be
        // sync'd on IW if there are changes:
        assert !sr.hasChanges || Thread.holdsLock(IndexWriter.this);

        // Discard (don't save) changes when we are dropping
        // the reader; this is used only on the sub-readers
        // after a successful merge.
        sr.hasChanges &= !drop;

        final boolean hasChanges = sr.hasChanges;

        // Drop our ref -- this will commit any pending
        // changes to the dir
        sr.close();

        // We are the last ref to this reader; since we're
        // not pooling readers, we release it:
        readerMap.remove(sr.getSegmentInfo());

        return hasChanges;
      }

      return false;
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975624/fstmerge_base_7090157909467351941
public synchronized void release(SegmentReader sr, boolean drop) throws IOException {

      final boolean pooled = readerMap.containsKey(sr.getSegmentInfo());

      assert !pooled | readerMap.get(sr.getSegmentInfo()) == sr;

      // Drop caller's ref; for an external reader (not
      // pooled), this decRef will close it
      sr.decRef();

      if (pooled && (drop || (!poolReaders && sr.getRefCount() == 1))) {

        // We are the last ref to this reader; since we're
        // not pooling readers, we release it:
        readerMap.remove(sr.getSegmentInfo());

        assert !sr.hasChanges || Thread.holdsLock(IndexWriter.this);

        // Drop our ref -- this will commit any pending
        // changes to the dir
        boolean success = false;
        try {
          sr.close();
          success = true;
        } finally {
          if (!success && sr.hasChanges) {
            // Abandon the changes & retry closing:
            sr.hasChanges = false;
            try {
              sr.close();
            } catch (Throwable ignore) {
              // Keep throwing original exception
            }
          }
        }
      }
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975624/fstmerge_var2_4874051202965523594

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975629/fstmerge_var1_7905418286295035236
synchronized void close() throws IOException {
      // We invoke deleter.checkpoint below, so we must be
      // sync'd on IW:
      assert Thread.holdsLock(IndexWriter.this);

      Iterator<Map.Entry<SegmentInfo,SegmentReader>> iter = readerMap.entrySet().iterator();
      while (iter.hasNext()) {
        
        Map.Entry<SegmentInfo,SegmentReader> ent = iter.next();

        SegmentReader sr = ent.getValue();
        if (sr.hasChanges) {
          assert infoIsLive(sr.getSegmentInfo());
          sr.doCommit(null);

          // Must checkpoint w/ deleter, because this
          // segment reader will have created new _X_N.del
          // file.
          deleter.checkpoint(segmentInfos, false);
        }

        iter.remove();

        // NOTE: it is allowed that this decRef does not
        // actually close the SR; this can happen when a
        // near real-time reader is kept open after the
        // IndexWriter instance is closed
        sr.decRef();
      }
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975629/fstmerge_base_8001936700483295757
synchronized void close() throws IOException {
      Iterator<Map.Entry<SegmentInfo,SegmentReader>> iter = readerMap.entrySet().iterator();
      while (iter.hasNext()) {
        
        Map.Entry<SegmentInfo,SegmentReader> ent = iter.next();

        SegmentReader sr = ent.getValue();
        if (sr.hasChanges) {
          assert infoIsLive(sr.getSegmentInfo());
          sr.startCommit();
          boolean success = false;
          try {
            sr.doCommit(null);
            success = true;
          } finally {
            if (!success) {
              sr.rollbackCommit();
            }
          }
        }

        iter.remove();

        // NOTE: it is allowed that this decRef does not
        // actually close the SR; this can happen when a
        // near real-time reader is kept open after the
        // IndexWriter instance is closed
        sr.decRef();
      }
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975629/fstmerge_var2_4850655223907524710

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975634/fstmerge_var1_457716082632744449
synchronized void commit() throws IOException {

      // We invoke deleter.checkpoint below, so we must be
      // sync'd on IW:
      assert Thread.holdsLock(IndexWriter.this);

      for (Map.Entry<SegmentInfo,SegmentReader> ent : readerMap.entrySet()) {

        SegmentReader sr = ent.getValue();
        if (sr.hasChanges) {
          assert infoIsLive(sr.getSegmentInfo());
          sr.doCommit(null);

          // Must checkpoint w/ deleter, because this
          // segment reader will have created new _X_N.del
          // file.
          deleter.checkpoint(segmentInfos, false);
        }
      }
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975634/fstmerge_base_1290508724001687349
synchronized void commit() throws IOException {
      for (Map.Entry<SegmentInfo,SegmentReader> ent : readerMap.entrySet()) {

        SegmentReader sr = ent.getValue();
        if (sr.hasChanges) {
          assert infoIsLive(sr.getSegmentInfo());
          sr.startCommit();
          boolean success = false;
          try {
            sr.doCommit(null);
            success = true;
          } finally {
            if (!success) {
              sr.rollbackCommit();
            }
          }
        }
      }
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975634/fstmerge_var2_2023483654903923081

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975646/fstmerge_var1_724662362509863764
public synchronized SegmentReader get(SegmentInfo info, boolean doOpenStores, int readBufferSize, int termsIndexDivisor) throws IOException {

      if (poolReaders) {
        readBufferSize = BufferedIndexInput.BUFFER_SIZE;
      }

      SegmentReader sr = readerMap.get(info);
      if (sr == null) {
        // TODO: we may want to avoid doing this while
        // synchronized
        // Returns a ref, which we xfer to readerMap:
        sr = SegmentReader.get(false, info.dir, info, readBufferSize, doOpenStores, termsIndexDivisor);

        if (info.dir == directory) {
          // Only pool if reader is not external
          readerMap.put(info, sr);
        }
      } else {
        if (doOpenStores) {
          sr.openDocStores();
        }
        if (termsIndexDivisor != -1) {
          // If this reader was originally opened because we
          // needed to merge it, we didn't load the terms
          // index.  But now, if the caller wants the terms
          // index (eg because it's doing deletes, or an NRT
          // reader is being opened) we ask the reader to
          // load its terms index.
          sr.loadTermsIndex(termsIndexDivisor);
        }
      }

      // Return a ref to our caller
      if (info.dir == directory) {
        // Only incRef if we pooled (reader is not external)
        sr.incRef();
      }
      return sr;
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975646/fstmerge_base_6753098901626531445
public synchronized SegmentReader get(SegmentInfo info, boolean doOpenStores, int readBufferSize, int termsIndexDivisor) throws IOException {

      if (poolReaders) {
        readBufferSize = BufferedIndexInput.BUFFER_SIZE;
      }

      SegmentReader sr = readerMap.get(info);
      if (sr == null) {
        // TODO: we may want to avoid doing this while
        // synchronized
        // Returns a ref, which we xfer to readerMap:
        sr = SegmentReader.get(false, info.dir, info, readBufferSize, doOpenStores, termsIndexDivisor, codecs);

        if (info.dir == directory) {
          // Only pool if reader is not external
          readerMap.put(info, sr);
        }
      } else {
        if (doOpenStores) {
          sr.openDocStores();
        }
        if (termsIndexDivisor != -1) {
          // If this reader was originally opened because we
          // needed to merge it, we didn't load the terms
          // index.  But now, if the caller wants the terms
          // index (eg because it's doing deletes, or an NRT
          // reader is being opened) we ask the reader to
          // load its terms index.
          sr.loadTermsIndex(termsIndexDivisor);
        }
      }

      // Return a ref to our caller
      if (info.dir == directory) {
        // Only incRef if we pooled (reader is not external)
        sr.incRef();
      }
      return sr;
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975646/fstmerge_var2_4993127690216460053

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975709/fstmerge_var1_8973690605020309208
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975709/fstmerge_base_5439960719504140000
CoreReaders(SegmentReader origInstance, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor, CodecProvider codecs) throws IOException {

      if (termsIndexDivisor < 1 && termsIndexDivisor != -1) {
        throw new IllegalArgumentException("indexDivisor must be -1 (don't load terms index) or greater than 0: got " + termsIndexDivisor);
      }

      segment = si.name;
      if (codecs == null) {
        codecs = CodecProvider.getDefault();
      }
      this.codecs = codecs;      
      this.readBufferSize = readBufferSize;
      this.dir = dir;

      boolean success = false;

      try {
        Directory dir0 = dir;
        if (si.getUseCompoundFile()) {
          cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);
          dir0 = cfsReader;
        }
        cfsDir = dir0;

        fieldInfos = new FieldInfos(cfsDir, IndexFileNames.segmentFileName(segment, "", IndexFileNames.FIELD_INFOS_EXTENSION));

        this.termsIndexDivisor = termsIndexDivisor;

        // Ask codec for its Fields
        fields = si.getCodec().fieldsProducer(new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor));
        assert fields != null;

        isPreFlex = fields instanceof PreFlexFields;
        success = true;
      } finally {
        if (!success) {
          decRef();
        }
      }

      // Must assign this at the end -- if we hit an
      // exception above core, we don't want to attempt to
      // purge the FieldCache (will hit NPE because core is
      // not assigned yet).
      this.origInstance = origInstance;
    }
=======
CoreReaders(SegmentReader origInstance, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor, CodecProvider codecs) throws IOException {

      if (termsIndexDivisor < 1 && termsIndexDivisor != -1) {
        throw new IllegalArgumentException("indexDivisor must be -1 (don't load terms index) or greater than 0: got " + termsIndexDivisor);
      }

      segment = si.name;
      if (codecs == null) {
        codecs = CodecProvider.getDefault();
      }
      this.codecs = codecs;      
      this.readBufferSize = readBufferSize;
      this.dir = dir;

      boolean success = false;

      try {
        Directory dir0 = dir;
        if (si.getUseCompoundFile()) {
          cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);
          dir0 = cfsReader;
        }
        cfsDir = dir0;

        fieldInfos = new FieldInfos(cfsDir, IndexFileNames.segmentFileName(segment, "", IndexFileNames.FIELD_INFOS_EXTENSION));

        this.termsIndexDivisor = termsIndexDivisor;

        // Ask codec for its Fields
        fields = si.getCodec().fieldsProducer(new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor));
        assert fields != null;

        success = true;
      } finally {
        if (!success) {
          decRef();
        }
      }

      // Must assign this at the end -- if we hit an
      // exception above core, we don't want to attempt to
      // purge the FieldCache (will hit NPE because core is
      // not assigned yet).
      this.origInstance = origInstance;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627975709/fstmerge_var2_3550632454683388428

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/SegmentReader.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976334/fstmerge_var1_2363575100975986775
@Override
  public void read(Directory directory, String segmentsFileName, CodecProvider codecs,
          SegmentInfos infos) throws IOException {
    IndexInput input = null;
    try {
      input = openInput(directory, segmentsFileName);
      final int format = input.readInt();
      infos.setFormat(format);
  
      // check that it is a format we can understand
      if (format > DefaultSegmentInfosWriter.FORMAT_MINIMUM)
        throw new IndexFormatTooOldException(segmentsFileName, format,
          DefaultSegmentInfosWriter.FORMAT_MINIMUM, DefaultSegmentInfosWriter.FORMAT_CURRENT);
      if (format < DefaultSegmentInfosWriter.FORMAT_CURRENT)
        throw new IndexFormatTooNewException(segmentsFileName, format,
          DefaultSegmentInfosWriter.FORMAT_MINIMUM, DefaultSegmentInfosWriter.FORMAT_CURRENT);
  
      infos.version = input.readLong(); // read version
      infos.counter = input.readInt(); // read counter
  
      for (int i = input.readInt(); i > 0; i--) { // read segmentInfos
        infos.add(new SegmentInfo(directory, format, input, codecs));
      }
      
      infos.userData = input.readStringStringMap();
      finalizeInput(input);
      
    } finally {
      if (input != null) {
        input.close();
      }
    }

  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976334/fstmerge_base_5596569477076296231
=======
@Override
  public void read(Directory directory, String segmentsFileName, CodecProvider codecs,
          SegmentInfos infos) throws IOException {
    IndexInput input = null;
    try {
      input = openInput(directory, segmentsFileName);
      int format = input.readInt();
  
      // check that it is a format we can understand
      if (format > DefaultSegmentInfosWriter.FORMAT_MINIMUM)
        throw new IndexFormatTooOldException(segmentsFileName, format,
          DefaultSegmentInfosWriter.FORMAT_MINIMUM, DefaultSegmentInfosWriter.FORMAT_CURRENT);
      if (format < DefaultSegmentInfosWriter.FORMAT_CURRENT)
        throw new IndexFormatTooNewException(segmentsFileName, format,
          DefaultSegmentInfosWriter.FORMAT_MINIMUM, DefaultSegmentInfosWriter.FORMAT_CURRENT);
  
      infos.version = input.readLong(); // read version
      infos.counter = input.readInt(); // read counter
  
      for (int i = input.readInt(); i > 0; i--) { // read segmentInfos
        infos.add(new SegmentInfo(directory, format, input, codecs));
      }
      
      infos.userData = input.readStringStringMap();
      finalizeInput(input);
      
    } finally {
      if (input != null) {
        input.close();
      }
    }

  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976334/fstmerge_var2_4351466477846854719

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/DefaultSegmentInfosReader.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ public final static String[] CORE_CODECS = new String[] {"Standard", "Pulsing", "PreFlex", "SimpleText"}; ##FSTMerge## public final static String[] CORE_CODECS = new String[] {"Standard", "Sep", "Pulsing", "IntBlock"}; ##FSTMerge## public final static String[] CORE_CODECS = new String[] {"Standard", "Sep", "Pulsing", "IntBlock", "PreFlex"};
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/CodecProvider.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976499/fstmerge_var1_3413326683819477567
public synchronized void unregister(Codec codec) {
    if (codec.name == null) {
      throw new IllegalArgumentException("code.name is null");
    }
    if (codecs.containsKey(codec.name)) {
      Codec c = codecs.get(codec.name);
      if (codec == c) {
        codecs.remove(codec.name);
      } else {
        throw new IllegalArgumentException("codec '" + codec.name + "' is being impersonated by a different codec instance!!!");
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976499/fstmerge_base_6379843699211771298
=======
public void unregister(Codec codec) {
    if (codec.name == null) {
      throw new IllegalArgumentException("code.name is null");
    }
    if (codecs.containsKey(codec.name)) {
      Codec c = codecs.get(codec.name);
      if (codec == c) {
        codecs.remove(codec.name);
      } else {
        throw new IllegalArgumentException("codec '" + codec.name + "' is being impersonated by a different codec instance!!!");
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976499/fstmerge_var2_7891625824266420354

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/CodecProvider.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976539/fstmerge_var1_6190386406773491698
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976539/fstmerge_base_8191802270667249111
@Override
  public Codec getWriter(SegmentWriteState state) {
    return lookup(CodecProvider.getDefaultCodec());
    //return lookup("Pulsing");
    //return lookup("Sep");
    //return lookup("IntBlock");
  }
=======
@Override
  public Codec getWriter(SegmentWriteState state) {
    return lookup(CodecProvider.getDefaultCodec());
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976539/fstmerge_var2_5209692041587540819

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/CodecProvider.java
Conflict type: SameIdFd
Conflict body: 
~~FSTMerge~~ public static final int FORMAT_4_0 = -11; ##FSTMerge## ##FSTMerge## public static final int FORMAT_4_0 = -10;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/DefaultSegmentInfosWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976570/fstmerge_var1_1945181810873606589
@Override
  public IndexOutput writeInfos(Directory dir, String segmentFileName, SegmentInfos infos)
          throws IOException {
    IndexOutput out = createOutput(dir, segmentFileName);
    out.writeInt(FORMAT_CURRENT); // write FORMAT
    out.writeLong(infos.version);
    out.writeInt(infos.counter); // write counter
    out.writeInt(infos.size()); // write infos
    for (SegmentInfo si : infos) {
      si.write(out);
    }
    out.writeStringStringMap(infos.getUserData());
    return out;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976570/fstmerge_base_1530585296064111895
=======
@Override
  public IndexOutput writeInfos(Directory dir, String segmentFileName, SegmentInfos infos)
          throws IOException {
    IndexOutput out = createOutput(dir, segmentFileName);
    out.writeInt(FORMAT_CURRENT); // write FORMAT
    out.writeLong(++infos.version); // every write changes
                                 // the index
    out.writeInt(infos.counter); // write counter
    out.writeInt(infos.size()); // write infos
    for (SegmentInfo si : infos) {
      si.write(out);
    }
    out.writeStringStringMap(infos.getUserData());
    return out;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976570/fstmerge_var2_3505671978384143348

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/DefaultSegmentInfosWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976767/fstmerge_var1_3746125918103943624
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976767/fstmerge_base_4408071253816108004
public SingleIntIndexInput(Directory dir, String fileName, int readBufferSize)
    throws IOException {
    in = dir.openInput(fileName, readBufferSize);
    CodecUtil.checkHeader(in, SingleIntIndexOutput.CODEC, SingleIntIndexOutput.VERSION_START);
  }
=======
public SingleIntIndexInput(Directory dir, String fileName, int readBufferSize)
    throws IOException {
    in = dir.openInput(fileName, readBufferSize);
    CodecUtil.checkHeader(in, SingleIntIndexOutput.CODEC,
      SingleIntIndexOutput.VERSION_START, SingleIntIndexOutput.VERSION_START);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976767/fstmerge_var2_4594414968492111088

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/sep/SingleIntIndexInput.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976815/fstmerge_var1_1219499294157201282
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976815/fstmerge_base_5612824423391891074
@Override
  public FieldsConsumer fieldsConsumer(SegmentWriteState state) throws IOException {

    StandardPostingsWriter postingsWriter = new SepPostingsWriterImpl(state, new SingleIntFactory());

    boolean success = false;
    StandardTermsIndexWriter indexWriter;
    try {
      indexWriter = new SimpleStandardTermsIndexWriter(state);
      success = true;
    } finally {
      if (!success) {
        postingsWriter.close();
      }
    }

    success = false;
    try {
      FieldsConsumer ret = new StandardTermsDictWriter(indexWriter, state, postingsWriter, BytesRef.getUTF8SortedAsUTF16Comparator());
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          postingsWriter.close();
        } finally {
          indexWriter.close();
        }
      }
    }
  }
=======
@Override
  public FieldsConsumer fieldsConsumer(SegmentWriteState state) throws IOException {

    StandardPostingsWriter postingsWriter = new SepPostingsWriterImpl(state, new SingleIntFactory());

    boolean success = false;
    StandardTermsIndexWriter indexWriter;
    try {
      indexWriter = new SimpleStandardTermsIndexWriter(state);
      success = true;
    } finally {
      if (!success) {
        postingsWriter.close();
      }
    }

    success = false;
    try {
      FieldsConsumer ret = new StandardTermsDictWriter(indexWriter, state, postingsWriter, BytesRef.getUTF8SortedAsUnicodeComparator());
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          postingsWriter.close();
        } finally {
          indexWriter.close();
        }
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976815/fstmerge_var2_7006054781670431528

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/sep/SepCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976820/fstmerge_var1_6939609146573987091
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976820/fstmerge_base_7158571192986715562
@Override
  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {

    StandardPostingsReader postingsReader = new SepPostingsReaderImpl(state.dir, state.segmentInfo, state.readBufferSize, new SingleIntFactory());

    StandardTermsIndexReader indexReader;
    boolean success = false;
    try {
      indexReader = new SimpleStandardTermsIndexReader(state.dir,
                                                       state.fieldInfos,
                                                       state.segmentInfo.name,
                                                       state.termsIndexDivisor,
                                                       BytesRef.getUTF8SortedAsUTF16Comparator());
      success = true;
    } finally {
      if (!success) {
        postingsReader.close();
      }
    }

    success = false;
    try {
      FieldsProducer ret = new StandardTermsDictReader(indexReader,
                                                       state.dir,
                                                       state.fieldInfos,
                                                       state.segmentInfo.name,
                                                       postingsReader,
                                                       state.readBufferSize,
                                                       BytesRef.getUTF8SortedAsUTF16Comparator(),
                                                       StandardCodec.TERMS_CACHE_SIZE);
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          postingsReader.close();
        } finally {
          indexReader.close();
        }
      }
    }
  }
=======
@Override
  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {

    StandardPostingsReader postingsReader = new SepPostingsReaderImpl(state.dir, state.segmentInfo, state.readBufferSize, new SingleIntFactory());

    StandardTermsIndexReader indexReader;
    boolean success = false;
    try {
      indexReader = new SimpleStandardTermsIndexReader(state.dir,
                                                       state.fieldInfos,
                                                       state.segmentInfo.name,
                                                       state.termsIndexDivisor,
                                                       BytesRef.getUTF8SortedAsUnicodeComparator());
      success = true;
    } finally {
      if (!success) {
        postingsReader.close();
      }
    }

    success = false;
    try {
      FieldsProducer ret = new StandardTermsDictReader(indexReader,
                                                       state.dir,
                                                       state.fieldInfos,
                                                       state.segmentInfo.name,
                                                       postingsReader,
                                                       state.readBufferSize,
                                                       BytesRef.getUTF8SortedAsUnicodeComparator(),
                                                       StandardCodec.TERMS_CACHE_SIZE);
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          postingsReader.close();
        } finally {
          indexReader.close();
        }
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627976820/fstmerge_var2_5391698360828558940

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/sep/SepCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977156/fstmerge_var1_2480492354127191303
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977156/fstmerge_base_3314703466669620535
public SimpleStandardTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, int indexDivisor, Comparator<BytesRef> termComp)
    throws IOException {

    this.termComp = termComp;

    IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, "", StandardCodec.TERMS_INDEX_EXTENSION));
    
    boolean success = false;

    try {
      CodecUtil.checkHeader(in, SimpleStandardTermsIndexWriter.CODEC_NAME, SimpleStandardTermsIndexWriter.VERSION_START);

      final long dirOffset = in.readLong();

      indexInterval = in.readInt();
      this.indexDivisor = indexDivisor;

      if (indexDivisor == -1) {
        totalIndexInterval = indexInterval;
      } else {
        // In case terms index gets loaded, later, on demand
        totalIndexInterval = indexInterval * indexDivisor;
      }

      // Read directory
      in.seek(dirOffset);

      final int numFields = in.readInt();

      for(int i=0;i<numFields;i++) {
        final int field = in.readInt();
        final int numIndexTerms = in.readInt();
        final long termsStart = in.readLong();
        final long indexStart = in.readLong();
        final long packedIndexStart = in.readLong();
        final long packedOffsetsStart = in.readLong();
        assert packedIndexStart >= indexStart: "packedStart=" + packedIndexStart + " indexStart=" + indexStart + " numIndexTerms=" + numIndexTerms + " seg=" + segment;
        if (numIndexTerms > 0) {
          final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
          fields.put(fieldInfo, new FieldIndexReader(in, fieldInfo, numIndexTerms, indexStart, termsStart, packedIndexStart, packedOffsetsStart));
        }
      }
      success = true;
    } finally {
      if (indexDivisor != -1) {
        in.close();
        this.in = null;
        if (success) {
          indexLoaded = true;
        }
        termBytesReader = termBytes.freeze();
      } else {
        this.in = in;
      }
    }
  }
=======
public SimpleStandardTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, int indexDivisor, Comparator<BytesRef> termComp)
    throws IOException {

    this.termComp = termComp;

    IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, "", StandardCodec.TERMS_INDEX_EXTENSION));
    
    boolean success = false;

    try {
      
      readHeader(in);
      indexInterval = in.readInt();
      this.indexDivisor = indexDivisor;

      if (indexDivisor < 0) {
        totalIndexInterval = indexInterval;
      } else {
        // In case terms index gets loaded, later, on demand
        totalIndexInterval = indexInterval * indexDivisor;
      }
      
      seekDir(in, dirOffset);

      // Read directory
      final int numFields = in.readInt();

      for(int i=0;i<numFields;i++) {
        final int field = in.readInt();
        final int numIndexTerms = in.readInt();
        final long termsStart = in.readLong();
        final long indexStart = in.readLong();
        final long packedIndexStart = in.readLong();
        final long packedOffsetsStart = in.readLong();
        assert packedIndexStart >= indexStart: "packedStart=" + packedIndexStart + " indexStart=" + indexStart + " numIndexTerms=" + numIndexTerms + " seg=" + segment;
        if (numIndexTerms > 0) {
          final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
          fields.put(fieldInfo, new FieldIndexReader(in, fieldInfo, numIndexTerms, indexStart, termsStart, packedIndexStart, packedOffsetsStart));
        }
      }
      success = true;
    } finally {
      if (indexDivisor > 0) {
        in.close();
        this.in = null;
        if (success) {
          indexLoaded = true;
        }
        termBytesReader = termBytes.freeze(true);
      } else {
        this.in = in;
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977156/fstmerge_var2_6073450769823241581

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/SimpleStandardTermsIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977161/fstmerge_var1_3845013938376634416
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977161/fstmerge_base_5196729464759446493
public FieldIndexReader(IndexInput in, FieldInfo fieldInfo, int numIndexTerms, long indexStart, long termsStart, long packedIndexStart,
                            long packedOffsetsStart) throws IOException {

      this.fieldInfo = fieldInfo;
      this.in = in;
      this.termsStart = termsStart;
      this.indexStart = indexStart;
      this.packedIndexStart = packedIndexStart;
      this.packedOffsetsStart = packedOffsetsStart;
      this.numIndexTerms = numIndexTerms;

      // We still create the indexReader when indexDivisor
      // is -1, so that StandardTermsDictReader can call
      // isIndexTerm for each field:
      if (indexDivisor != -1) {
        coreIndex = new CoreFieldIndex(indexStart,
                                       termsStart,
                                       packedIndexStart,
                                       packedOffsetsStart,
                                       numIndexTerms);
      
      }
    }
=======
public FieldIndexReader(IndexInput in, FieldInfo fieldInfo, int numIndexTerms, long indexStart, long termsStart, long packedIndexStart,
                            long packedOffsetsStart) throws IOException {

      this.fieldInfo = fieldInfo;
      this.in = in;
      this.termsStart = termsStart;
      this.indexStart = indexStart;
      this.packedIndexStart = packedIndexStart;
      this.packedOffsetsStart = packedOffsetsStart;
      this.numIndexTerms = numIndexTerms;

      // We still create the indexReader when indexDivisor
      // is -1, so that StandardTermsDictReader can call
      // isIndexTerm for each field:
      if (indexDivisor > 0) {
        coreIndex = new CoreFieldIndex(indexStart,
                                       termsStart,
                                       packedIndexStart,
                                       packedOffsetsStart,
                                       numIndexTerms);
      
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977161/fstmerge_var2_5157157265896376686

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/SimpleStandardTermsIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977184/fstmerge_var1_5087266423430169247
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977184/fstmerge_base_475367748243984979
@Override
    public void getIndexOffset(long ord, TermsIndexResult result) throws IOException {
      // You must call loadTermsIndex if you had specified -1 for indexDivisor
      if (coreIndex == null) {
        throw new IllegalStateException("terms index was not loaded");
      }
      coreIndex.getIndexOffset(ord, result);
    }
=======
@Override
    public void getIndexOffset(long ord, TermsIndexResult result) throws IOException {
      // You must call loadTermsIndex if you had specified
      // indexDivisor < 0 to ctor
      if (coreIndex == null) {
        throw new IllegalStateException("terms index was not loaded");
      }
      coreIndex.getIndexOffset(ord, result);
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977184/fstmerge_var2_5405857447165768844

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/SimpleStandardTermsIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977223/fstmerge_var1_9088362741423793484
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977223/fstmerge_base_6287546772980547966
@Override
  public void loadTermsIndex(int indexDivisor) throws IOException {
    if (!indexLoaded) {

      this.indexDivisor = indexDivisor;
      this.totalIndexInterval = indexInterval * indexDivisor;

      Iterator<FieldIndexReader> it = fields.values().iterator();
      while(it.hasNext()) {
        it.next().loadTermsIndex();
      }

      indexLoaded = true;
      in.close();
      termBytesReader = termBytes.freeze();
    }
  }
=======
@Override
  public void loadTermsIndex(int indexDivisor) throws IOException {
    if (!indexLoaded) {

      this.indexDivisor = indexDivisor;
      this.totalIndexInterval = indexInterval * indexDivisor;

      Iterator<FieldIndexReader> it = fields.values().iterator();
      while(it.hasNext()) {
        it.next().loadTermsIndex();
      }

      indexLoaded = true;
      in.close();
      termBytesReader = termBytes.freeze(true);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977223/fstmerge_var2_5760189086953134295

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/SimpleStandardTermsIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## final IndexOutput out; ##FSTMerge## protected final IndexOutput out;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977259/fstmerge_var1_6410504898438807926
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977259/fstmerge_base_8693336502610401204
public StandardTermsDictWriter(StandardTermsIndexWriter indexWriter, SegmentWriteState state, StandardPostingsWriter postingsWriter, Comparator<BytesRef> termComp) throws IOException {
    final String termsFileName = IndexFileNames.segmentFileName(state.segmentName, "", StandardCodec.TERMS_EXTENSION);
    this.indexWriter = indexWriter;
    this.termComp = termComp;
    out = state.directory.createOutput(termsFileName);
    indexWriter.setTermsOutput(out);
    state.flushedFiles.add(termsFileName);

    fieldInfos = state.fieldInfos;

    // Count indexed fields up front
    CodecUtil.writeHeader(out, CODEC_NAME, VERSION_CURRENT); 

    out.writeLong(0);                             // leave space for end index pointer

    termWriter = new DeltaBytesWriter(out);
    currentField = null;
    this.postingsWriter = postingsWriter;

    postingsWriter.start(out);                          // have consumer write its format/header
  }
=======
public StandardTermsDictWriter(
      StandardTermsIndexWriter termsIndexWriter,
      SegmentWriteState state,
      StandardPostingsWriter postingsWriter,
      Comparator<BytesRef> termComp) throws IOException
  {
    final String termsFileName = IndexFileNames.segmentFileName(state.segmentName, "", StandardCodec.TERMS_EXTENSION);
    this.termsIndexWriter = termsIndexWriter;
    this.termComp = termComp;
    out = state.directory.createOutput(termsFileName);
    termsIndexWriter.setTermsOutput(out);
    state.flushedFiles.add(termsFileName);

    fieldInfos = state.fieldInfos;
    writeHeader(out);
    termWriter = new DeltaBytesWriter(out);
    currentField = null;
    this.postingsWriter = postingsWriter;

    postingsWriter.start(out);                          // have consumer write its format/header
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977259/fstmerge_var2_4095060453777421630

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977264/fstmerge_var1_6997223872958285618
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977264/fstmerge_base_7680482588932181969
@Override
  public TermsConsumer addField(FieldInfo field) {
    assert currentField == null || currentField.name.compareTo(field.name) < 0;
    currentField = field;
    StandardTermsIndexWriter.FieldWriter fieldIndexWriter = indexWriter.addField(field);
    TermsConsumer terms = new TermsWriter(fieldIndexWriter, field, postingsWriter);
    fields.add(terms);
    return terms;
  }
=======
@Override
  public TermsConsumer addField(FieldInfo field) {
    assert currentField == null || currentField.name.compareTo(field.name) < 0;
    currentField = field;
    StandardTermsIndexWriter.FieldWriter fieldIndexWriter = termsIndexWriter.addField(field);
    TermsConsumer terms = new TermsWriter(fieldIndexWriter, field, postingsWriter);
    fields.add(terms);
    return terms;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977264/fstmerge_var2_4241525535385258844

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977269/fstmerge_var1_3180031952369228494
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977269/fstmerge_base_7805412115851991930
@Override
  public void close() throws IOException {

    try {
      final int fieldCount = fields.size();

      final long dirStart = out.getFilePointer();

      out.writeInt(fieldCount);
      for(int i=0;i<fieldCount;i++) {
        TermsWriter field = (TermsWriter) fields.get(i);
        out.writeInt(field.fieldInfo.number);
        out.writeLong(field.numTerms);
        out.writeLong(field.termsStartPointer);
      }
      out.seek(CodecUtil.headerLength(CODEC_NAME));
      out.writeLong(dirStart);
    } finally {
      try {
        out.close();
      } finally {
        try {
          postingsWriter.close();
        } finally {
          indexWriter.close();
        }
      }
    }
  }
=======
@Override
  public void close() throws IOException {

    try {
      final int fieldCount = fields.size();

      final long dirStart = out.getFilePointer();

      out.writeInt(fieldCount);
      for(int i=0;i<fieldCount;i++) {
        TermsWriter field = (TermsWriter) fields.get(i);
        out.writeInt(field.fieldInfo.number);
        out.writeLong(field.numTerms);
        out.writeLong(field.termsStartPointer);
      }
      writeTrailer(dirStart);
    } finally {
      try {
        out.close();
      } finally {
        try {
          postingsWriter.close();
        } finally {
          termsIndexWriter.close();
        }
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977269/fstmerge_var2_2155962668909820634

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977274/fstmerge_var1_495747393524946710
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977274/fstmerge_base_3387318407426087386
TermsWriter(StandardTermsIndexWriter.FieldWriter fieldIndexWriter, FieldInfo fieldInfo, StandardPostingsWriter postingsWriter) {
      this.fieldInfo = fieldInfo;
      this.fieldIndexWriter = fieldIndexWriter;

      termWriter.reset();
      termsStartPointer = out.getFilePointer();
      postingsWriter.setField(fieldInfo);
      this.postingsWriter = postingsWriter;
    }
=======
TermsWriter(
        StandardTermsIndexWriter.FieldWriter fieldIndexWriter,
        FieldInfo fieldInfo,
        StandardPostingsWriter postingsWriter) 
    {
      this.fieldInfo = fieldInfo;
      this.fieldIndexWriter = fieldIndexWriter;

      termWriter.reset();
      termsStartPointer = out.getFilePointer();
      postingsWriter.setField(fieldInfo);
      this.postingsWriter = postingsWriter;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977274/fstmerge_var2_7222088398229257877

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977303/fstmerge_var1_3120421038931616900
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977303/fstmerge_base_682230307521342136
@Override
  public void init(IndexInput termsIn) throws IOException {

    // Make sure we are talking to the matching past writer
    CodecUtil.checkHeader(termsIn, StandardPostingsWriterImpl.CODEC, StandardPostingsWriterImpl.VERSION_START);

    skipInterval = termsIn.readInt();
    maxSkipLevels = termsIn.readInt();
  }
=======
@Override
  public void init(IndexInput termsIn) throws IOException {

    // Make sure we are talking to the matching past writer
    CodecUtil.checkHeader(termsIn, StandardPostingsWriterImpl.CODEC,
      StandardPostingsWriterImpl.VERSION_START, StandardPostingsWriterImpl.VERSION_START);

    skipInterval = termsIn.readInt();
    maxSkipLevels = termsIn.readInt();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977303/fstmerge_var2_6768286124881663951

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardPostingsReaderImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977330/fstmerge_var1_3149075438444730760
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977330/fstmerge_base_417958439852872241
@Override
  public DocsEnum docs(FieldInfo fieldInfo, TermState termState, Bits skipDocs, DocsEnum reuse) throws IOException {
    final SegmentDocsEnum docsEnum;
    if (reuse == null) {
      docsEnum = new SegmentDocsEnum(freqIn);
    } else {
      docsEnum = (SegmentDocsEnum) reuse;
    }
    return docsEnum.reset(fieldInfo, (DocTermState) termState, skipDocs);
  }
=======
@Override
  public DocsEnum docs(FieldInfo fieldInfo, TermState termState, Bits skipDocs, DocsEnum reuse) throws IOException {
    SegmentDocsEnum docsEnum;
    if (reuse == null || !(reuse instanceof SegmentDocsEnum)) {
      docsEnum = new SegmentDocsEnum(freqIn);
    } else {
      docsEnum = (SegmentDocsEnum) reuse;
      if (docsEnum.startFreqIn != freqIn) {
        // If you are using ParellelReader, and pass in a
        // reused DocsEnum, it could have come from another
        // reader also using standard codec
        docsEnum = new SegmentDocsEnum(freqIn);
      }
    }
    return docsEnum.reset(fieldInfo, (DocTermState) termState, skipDocs);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977330/fstmerge_var2_8427995633636063690

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardPostingsReaderImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977335/fstmerge_var1_1418953948261271798
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977335/fstmerge_base_2806641420645689541
@Override
  public DocsAndPositionsEnum docsAndPositions(FieldInfo fieldInfo, TermState termState, Bits skipDocs, DocsAndPositionsEnum reuse) throws IOException {
    if (fieldInfo.omitTermFreqAndPositions) {
      return null;
    }
    final SegmentDocsAndPositionsEnum docsEnum;
    if (reuse == null) {
      docsEnum = new SegmentDocsAndPositionsEnum(freqIn, proxIn);
    } else {
      docsEnum = (SegmentDocsAndPositionsEnum) reuse;
    }
    return docsEnum.reset(fieldInfo, (DocTermState) termState, skipDocs);
  }
=======
@Override
  public DocsAndPositionsEnum docsAndPositions(FieldInfo fieldInfo, TermState termState, Bits skipDocs, DocsAndPositionsEnum reuse) throws IOException {
    if (fieldInfo.omitTermFreqAndPositions) {
      return null;
    }
    SegmentDocsAndPositionsEnum docsEnum;
    if (reuse == null || !(reuse instanceof SegmentDocsAndPositionsEnum)) {
      docsEnum = new SegmentDocsAndPositionsEnum(freqIn, proxIn);
    } else {
      docsEnum = (SegmentDocsAndPositionsEnum) reuse;
      if (docsEnum.startFreqIn != freqIn) {
        // If you are using ParellelReader, and pass in a
        // reused DocsEnum, it could have come from another
        // reader also using standard codec
        docsEnum = new SegmentDocsAndPositionsEnum(freqIn, proxIn);
      }
    }
    return docsEnum.reset(fieldInfo, (DocTermState) termState, skipDocs);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977335/fstmerge_var2_7720097215749028688

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardPostingsReaderImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977339/fstmerge_var1_3711377438688826879
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977339/fstmerge_base_3270836436351062379
public SegmentDocsEnum(IndexInput freqIn) throws IOException {
      this.freqIn = (IndexInput) freqIn.clone();
    }
=======
public SegmentDocsEnum(IndexInput freqIn) throws IOException {
      startFreqIn = freqIn;
      this.freqIn = (IndexInput) freqIn.clone();
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977339/fstmerge_var2_1595412655805473240

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardPostingsReaderImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977367/fstmerge_var1_7146045168205842070
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977367/fstmerge_base_6698556801308786747
public SegmentDocsAndPositionsEnum(IndexInput freqIn, IndexInput proxIn) throws IOException {
      this.freqIn = (IndexInput) freqIn.clone();
      this.proxIn = (IndexInput) proxIn.clone();
    }
=======
public SegmentDocsAndPositionsEnum(IndexInput freqIn, IndexInput proxIn) throws IOException {
      startFreqIn = freqIn;
      this.freqIn = (IndexInput) freqIn.clone();
      this.proxIn = (IndexInput) proxIn.clone();
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977367/fstmerge_var2_5845231225311441945

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardPostingsReaderImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977430/fstmerge_var1_7946749226452978525
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977430/fstmerge_base_161120575338387269
public StandardTermsDictReader(StandardTermsIndexReader indexReader, Directory dir, FieldInfos fieldInfos, String segment, StandardPostingsReader postingsReader, int readBufferSize,
                                 Comparator<BytesRef> termComp, int termsCacheSize)
    throws IOException {
    
    this.postingsReader = postingsReader;
    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);

    this.termComp = termComp;
    
    in = dir.openInput(IndexFileNames.segmentFileName(segment, "", StandardCodec.TERMS_EXTENSION),
                       readBufferSize);

    boolean success = false;
    try {
      CodecUtil.checkHeader(in, StandardTermsDictWriter.CODEC_NAME, StandardTermsDictWriter.VERSION_CURRENT);

      final long dirOffset = in.readLong();

      // Have PostingsReader init itself
      postingsReader.init(in);

      // Read per-field details
      in.seek(dirOffset);

      final int numFields = in.readInt();

      for(int i=0;i<numFields;i++) {
        final int field = in.readInt();
        final long numTerms = in.readLong();
        assert numTerms >= 0;
        final long termsStartPointer = in.readLong();
        final StandardTermsIndexReader.FieldReader fieldIndexReader;
        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
        fieldIndexReader = indexReader.getField(fieldInfo);
        if (numTerms > 0) {
          assert !fields.containsKey(fieldInfo.name);
          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));
        }
      }
      success = true;
    } finally {
      if (!success) {
        in.close();
      }
    }

    this.indexReader = indexReader;
  }
=======
public StandardTermsDictReader(StandardTermsIndexReader indexReader, Directory dir, FieldInfos fieldInfos, String segment, StandardPostingsReader postingsReader, int readBufferSize,
                                 Comparator<BytesRef> termComp, int termsCacheSize)
    throws IOException {
    
    this.postingsReader = postingsReader;
    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);

    this.termComp = termComp;
    
    in = dir.openInput(IndexFileNames.segmentFileName(segment, "", StandardCodec.TERMS_EXTENSION),
                       readBufferSize);

    boolean success = false;
    try {
      readHeader(in);

      // Have PostingsReader init itself
      postingsReader.init(in);

      // Read per-field details
      seekDir(in, dirOffset);

      final int numFields = in.readInt();

      for(int i=0;i<numFields;i++) {
        final int field = in.readInt();
        final long numTerms = in.readLong();
        assert numTerms >= 0;
        final long termsStartPointer = in.readLong();
        final StandardTermsIndexReader.FieldReader fieldIndexReader;
        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
        fieldIndexReader = indexReader.getField(fieldInfo);
        if (numTerms > 0) {
          assert !fields.containsKey(fieldInfo.name);
          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));
        }
      }
      success = true;
    } finally {
      if (!success) {
        in.close();
      }
    }

    this.indexReader = indexReader;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977430/fstmerge_var2_6209806750656966722

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## final private IndexOutput out; ##FSTMerge## protected final IndexOutput out;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/SimpleStandardTermsIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977580/fstmerge_var1_7027368036083763278
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977580/fstmerge_base_1745471084858232401
public SimpleStandardTermsIndexWriter(SegmentWriteState state) throws IOException {
    final String indexFileName = IndexFileNames.segmentFileName(state.segmentName, "", StandardCodec.TERMS_INDEX_EXTENSION);
    state.flushedFiles.add(indexFileName);
    termIndexInterval = state.termIndexInterval;
    out = state.directory.createOutput(indexFileName);
    CodecUtil.writeHeader(out, CODEC_NAME, VERSION_CURRENT);
    fieldInfos = state.fieldInfos;

    // Placeholder for dir offset
    out.writeLong(0);
    out.writeInt(termIndexInterval);
  }
=======
public SimpleStandardTermsIndexWriter(SegmentWriteState state) throws IOException {
    final String indexFileName = IndexFileNames.segmentFileName(state.segmentName, "", StandardCodec.TERMS_INDEX_EXTENSION);
    state.flushedFiles.add(indexFileName);
    termIndexInterval = state.termIndexInterval;
    out = state.directory.createOutput(indexFileName);
    fieldInfos = state.fieldInfos;
    writeHeader(out);
    out.writeInt(termIndexInterval);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977580/fstmerge_var2_544737880722077378

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/SimpleStandardTermsIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977606/fstmerge_var1_4334581538909198414
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977606/fstmerge_base_950091576933679782
@Override
  public void close() throws IOException {
    final long dirStart = out.getFilePointer();
    final int fieldCount = fields.size();

    out.writeInt(fieldCount);
    for(int i=0;i<fieldCount;i++) {
      SimpleFieldWriter field = fields.get(i);
      out.writeInt(field.fieldInfo.number);
      out.writeInt(field.numIndexTerms);
      out.writeLong(field.termsStart);
      out.writeLong(field.indexStart);
      out.writeLong(field.packedIndexStart);
      out.writeLong(field.packedOffsetsStart);
    }
    out.seek(CodecUtil.headerLength(CODEC_NAME));
    out.writeLong(dirStart);
    out.close();
  }
=======
@Override
  public void close() throws IOException {
    final long dirStart = out.getFilePointer();
    final int fieldCount = fields.size();

    out.writeInt(fieldCount);
    for(int i=0;i<fieldCount;i++) {
      SimpleFieldWriter field = fields.get(i);
      out.writeInt(field.fieldInfo.number);
      out.writeInt(field.numIndexTerms);
      out.writeLong(field.termsStart);
      out.writeLong(field.indexStart);
      out.writeLong(field.packedIndexStart);
      out.writeLong(field.packedOffsetsStart);
    }
    writeTrailer(dirStart);
    out.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977606/fstmerge_var2_4919325679748746530

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/SimpleStandardTermsIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public FieldsConsumer fieldsConsumer(SegmentWriteState state) throws IOException {
    PostingsWriterBase docs = new StandardPostingsWriter(state);

    // TODO: should we make the terms index more easily
    // pluggable?  Ie so that this codec would record which
    // index impl was used, and switch on loading?
    // Or... you must make a new Codec for this?
    TermsIndexWriterBase indexWriter;
    boolean success = false;
    try {
      indexWriter = new FixedGapTermsIndexWriter(state);
      success = true;
    } finally {
      if (!success) {
        docs.close();
      }
    }

    success = false;
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977616/fstmerge_var1_3978902449467709674
      FieldsConsumer ret = new PrefixCodedTermsWriter(indexWriter, state, docs, BytesRef.getUTF8SortedAsUnicodeComparator());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977616/fstmerge_base_639236192012154291
      FieldsConsumer ret = new StandardTermsDictWriter(indexWriter, state, docs, BytesRef.getUTF8SortedAsUTF16Comparator());
=======
      FieldsConsumer ret = new StandardTermsDictWriter(indexWriter, state, docs, BytesRef.getUTF8SortedAsUnicodeComparator());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977616/fstmerge_var2_7746334859366892477
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          docs.close();
        } finally {
          indexWriter.close();
        }
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {
    PostingsReaderBase postings = new StandardPostingsReader(state.dir, state.segmentInfo, state.readBufferSize, state.codecId);
    TermsIndexReaderBase indexReader;

    boolean success = false;
    try {
      indexReader = new FixedGapTermsIndexReader(state.dir,
                                                       state.fieldInfos,
                                                       state.segmentInfo.name,
                                                       state.termsIndexDivisor,
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977621/fstmerge_var1_5495191393593260262
                                                       BytesRef.getUTF8SortedAsUnicodeComparator(),
                                                       state.codecId);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977621/fstmerge_base_6651882925466762461
                                                       BytesRef.getUTF8SortedAsUTF16Comparator());
=======
                                                       BytesRef.getUTF8SortedAsUnicodeComparator());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977621/fstmerge_var2_7497298327271340448
      success = true;
    } finally {
      if (!success) {
        postings.close();
      }
    }

    success = false;
    try {
      FieldsProducer ret = new PrefixCodedTermsReader(indexReader,
                                                       state.dir,
                                                       state.fieldInfos,
                                                       state.segmentInfo.name,
                                                       postings,
                                                       state.readBufferSize,
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977621/fstmerge_var1_5495191393593260262
                                                       BytesRef.getUTF8SortedAsUnicodeComparator(),
                                                       TERMS_CACHE_SIZE,
                                                       state.codecId);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977621/fstmerge_base_6651882925466762461
                                                       BytesRef.getUTF8SortedAsUTF16Comparator(),
                                                       TERMS_CACHE_SIZE);
=======
                                                       BytesRef.getUTF8SortedAsUnicodeComparator(),
                                                       TERMS_CACHE_SIZE);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977621/fstmerge_var2_7497298327271340448
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          postings.close();
        } finally {
          indexReader.close();
        }
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977728/fstmerge_var1_6770649588805832839
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977728/fstmerge_base_3999839601483122006
public SimpleIntBlockIndexInput(Directory dir, String fileName, int readBufferSize) throws IOException {
    IndexInput in = dir.openInput(fileName, readBufferSize);
    CodecUtil.checkHeader(in, SimpleIntBlockIndexOutput.CODEC, SimpleIntBlockIndexOutput.VERSION_START);
    init(in);
  }
=======
public SimpleIntBlockIndexInput(Directory dir, String fileName, int readBufferSize) throws IOException {
    IndexInput in = dir.openInput(fileName, readBufferSize);
    CodecUtil.checkHeader(in, SimpleIntBlockIndexOutput.CODEC,
      SimpleIntBlockIndexOutput.VERSION_START, SimpleIntBlockIndexOutput.VERSION_START);
    init(in);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977728/fstmerge_var2_3864053222418899040

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/intblock/SimpleIntBlockIndexInput.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977828/fstmerge_var1_5673879112142367084
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977828/fstmerge_base_8525444408351044983
@Override
  public FieldsConsumer fieldsConsumer(SegmentWriteState state) throws IOException {
    StandardPostingsWriter postingsWriter = new SepPostingsWriterImpl(state, new SimpleIntBlockFactory(1024));

    boolean success = false;
    StandardTermsIndexWriter indexWriter;
    try {
      indexWriter = new SimpleStandardTermsIndexWriter(state);
      success = true;
    } finally {
      if (!success) {
        postingsWriter.close();
      }
    }

    success = false;
    try {
      FieldsConsumer ret = new StandardTermsDictWriter(indexWriter, state, postingsWriter, BytesRef.getUTF8SortedAsUTF16Comparator());
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          postingsWriter.close();
        } finally {
          indexWriter.close();
        }
      }
    }
  }
=======
@Override
  public FieldsConsumer fieldsConsumer(SegmentWriteState state) throws IOException {
    StandardPostingsWriter postingsWriter = new SepPostingsWriterImpl(state, new SimpleIntBlockFactory(1024));

    boolean success = false;
    StandardTermsIndexWriter indexWriter;
    try {
      indexWriter = new SimpleStandardTermsIndexWriter(state);
      success = true;
    } finally {
      if (!success) {
        postingsWriter.close();
      }
    }

    success = false;
    try {
      FieldsConsumer ret = new StandardTermsDictWriter(indexWriter, state, postingsWriter, BytesRef.getUTF8SortedAsUnicodeComparator());
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          postingsWriter.close();
        } finally {
          indexWriter.close();
        }
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977828/fstmerge_var2_289922717531067290

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/intblock/IntBlockCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977833/fstmerge_var1_5467583540668930759
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977833/fstmerge_base_5345768788079489107
@Override
  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {
    StandardPostingsReader postingsReader = new SepPostingsReaderImpl(state.dir,
                                                                      state.segmentInfo,
                                                                      state.readBufferSize,
                                                                      new SimpleIntBlockFactory(1024));

    StandardTermsIndexReader indexReader;
    boolean success = false;
    try {
      indexReader = new SimpleStandardTermsIndexReader(state.dir,
                                                       state.fieldInfos,
                                                       state.segmentInfo.name,
                                                       state.termsIndexDivisor,
                                                       BytesRef.getUTF8SortedAsUTF16Comparator());
      success = true;
    } finally {
      if (!success) {
        postingsReader.close();
      }
    }

    success = false;
    try {
      FieldsProducer ret = new StandardTermsDictReader(indexReader,
                                                       state.dir,
                                                       state.fieldInfos,
                                                       state.segmentInfo.name,
                                                       postingsReader,
                                                       state.readBufferSize,
                                                       BytesRef.getUTF8SortedAsUTF16Comparator(),
                                                       StandardCodec.TERMS_CACHE_SIZE);
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          postingsReader.close();
        } finally {
          indexReader.close();
        }
      }
    }
  }
=======
@Override
  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {
    StandardPostingsReader postingsReader = new SepPostingsReaderImpl(state.dir,
                                                                      state.segmentInfo,
                                                                      state.readBufferSize,
                                                                      new SimpleIntBlockFactory(1024));

    StandardTermsIndexReader indexReader;
    boolean success = false;
    try {
      indexReader = new SimpleStandardTermsIndexReader(state.dir,
                                                       state.fieldInfos,
                                                       state.segmentInfo.name,
                                                       state.termsIndexDivisor,
                                                       BytesRef.getUTF8SortedAsUnicodeComparator());
      success = true;
    } finally {
      if (!success) {
        postingsReader.close();
      }
    }

    success = false;
    try {
      FieldsProducer ret = new StandardTermsDictReader(indexReader,
                                                       state.dir,
                                                       state.fieldInfos,
                                                       state.segmentInfo.name,
                                                       postingsReader,
                                                       state.readBufferSize,
                                                       BytesRef.getUTF8SortedAsUnicodeComparator(),
                                                       StandardCodec.TERMS_CACHE_SIZE);
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          postingsReader.close();
        } finally {
          indexReader.close();
        }
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977833/fstmerge_var2_8669398610046951706

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/intblock/IntBlockCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public FieldsConsumer fieldsConsumer(SegmentWriteState state) throws IOException {
    // We wrap StandardPostingsWriter, but any StandardPostingsWriter
    // will work:
    PostingsWriterBase docsWriter = new StandardPostingsWriter(state);

    // Terms that have <= freqCutoff number of docs are
    // "pulsed" (inlined):
    PostingsWriterBase pulsingWriter = new PulsingPostingsWriterImpl(freqCutoff, docsWriter);

    // Terms dict index
    TermsIndexWriterBase indexWriter;
    boolean success = false;
    try {
      indexWriter = new FixedGapTermsIndexWriter(state);
      success = true;
    } finally {
      if (!success) {
        pulsingWriter.close();
      }
    }

    // Terms dict
    success = false;
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977859/fstmerge_var1_8223132987618375368
      FieldsConsumer ret = new PrefixCodedTermsWriter(indexWriter, state, pulsingWriter, BytesRef.getUTF8SortedAsUnicodeComparator());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977859/fstmerge_base_8705892363550861314
      FieldsConsumer ret = new StandardTermsDictWriter(indexWriter, state, pulsingWriter, BytesRef.getUTF8SortedAsUTF16Comparator());
=======
      FieldsConsumer ret = new StandardTermsDictWriter(indexWriter, state, pulsingWriter, BytesRef.getUTF8SortedAsUnicodeComparator());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977859/fstmerge_var2_2604118540980923374
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          pulsingWriter.close();
        } finally {
          indexWriter.close();
        }
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/pulsing/PulsingCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {

    // We wrap StandardPostingsReader, but any StandardPostingsReader
    // will work:
    PostingsReaderBase docsReader = new StandardPostingsReader(state.dir, state.segmentInfo, state.readBufferSize, state.codecId);
    PostingsReaderBase pulsingReader = new PulsingPostingsReaderImpl(docsReader);

    // Terms dict index reader
    TermsIndexReaderBase indexReader;

    boolean success = false;
    try {
      indexReader = new FixedGapTermsIndexReader(state.dir,
                                                       state.fieldInfos,
                                                       state.segmentInfo.name,
                                                       state.termsIndexDivisor,
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977865/fstmerge_var1_9173967500416519885
                                                       BytesRef.getUTF8SortedAsUnicodeComparator(),
                                                       state.codecId);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977865/fstmerge_base_1395083501173170562
                                                       BytesRef.getUTF8SortedAsUTF16Comparator());
=======
                                                       BytesRef.getUTF8SortedAsUnicodeComparator());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977865/fstmerge_var2_2005588742301971136
      success = true;
    } finally {
      if (!success) {
        pulsingReader.close();
      }
    }

    // Terms dict reader
    success = false;
    try {
      FieldsProducer ret = new PrefixCodedTermsReader(indexReader,
                                                       state.dir, state.fieldInfos, state.segmentInfo.name,
                                                       pulsingReader,
                                                       state.readBufferSize,
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977865/fstmerge_var1_9173967500416519885
                                                       BytesRef.getUTF8SortedAsUnicodeComparator(),
                                                       StandardCodec.TERMS_CACHE_SIZE,
                                                       state.codecId);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977865/fstmerge_base_1395083501173170562
                                                       BytesRef.getUTF8SortedAsUTF16Comparator(),
                                                       StandardCodec.TERMS_CACHE_SIZE);
=======
                                                       BytesRef.getUTF8SortedAsUnicodeComparator(),
                                                       StandardCodec.TERMS_CACHE_SIZE);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627977865/fstmerge_var2_2005588742301971136
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          pulsingReader.close();
        } finally {
          indexReader.close();
        }
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/pulsing/PulsingCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978167/fstmerge_var1_3477916938803410453
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978167/fstmerge_base_4658474729868172474
TermInfo seekEnum(SegmentTermEnum enumerator, Term term, TermInfoAndOrd tiOrd) throws IOException {

    // optimize sequential access: first try scanning cached enum w/o seeking
    if (enumerator.term() != null                 // term is at or past current
	&& ((enumerator.prev() != null && term.compareTo(enumerator.prev())> 0)
	    || term.compareTo(enumerator.term()) >= 0)) {
      int enumOffset = (int)(enumerator.position/totalIndexInterval)+1;
      if (indexTerms.length == enumOffset	  // but before end of block
    || term.compareTo(indexTerms[enumOffset]) < 0) {
       // no need to seek

        final TermInfo ti;

        int numScans = enumerator.scanTo(term);
        if (enumerator.term() != null && term.compareTo(enumerator.term()) == 0) {
          ti = enumerator.termInfo();
          if (numScans > 1) {
            // we only  want to put this TermInfo into the cache if
            // scanEnum skipped more than one dictionary entry.
            // This prevents RangeQueries or WildcardQueries to 
            // wipe out the cache when they iterate over a large numbers
            // of terms in order
            if (tiOrd == null) {
              termsCache.put(new CloneableTerm(term), new TermInfoAndOrd(ti, (int) enumerator.position));
            } else {
              assert sameTermInfo(ti, tiOrd, enumerator);
              assert (int) enumerator.position == tiOrd.termOrd;
            }
          }
        } else {
          ti = null;
        }

        return ti;
      }  
    }

    // random-access: must seek
    final int indexPos;
    if (tiOrd != null) {
      indexPos = tiOrd.termOrd / totalIndexInterval;
    } else {
      // Must do binary search:
      indexPos = getIndexOffset(term);
    }

    seekEnum(enumerator, indexPos);
    enumerator.scanTo(term);
    final TermInfo ti;
    if (enumerator.term() != null && term.compareTo(enumerator.term()) == 0) {
      ti = enumerator.termInfo();
      if (tiOrd == null) {
        termsCache.put(new CloneableTerm(term), new TermInfoAndOrd(ti, (int) enumerator.position));
      } else {
        assert sameTermInfo(ti, tiOrd, enumerator);
        assert (int) enumerator.position == tiOrd.termOrd;
      }
    } else {
      ti = null;
    }
    return ti;
  }
=======
TermInfo seekEnum(SegmentTermEnum enumerator, Term term, TermInfoAndOrd tiOrd) throws IOException {
    if (size == 0) {
      return null;
    }

    // optimize sequential access: first try scanning cached enum w/o seeking
    if (enumerator.term() != null                 // term is at or past current
	&& ((enumerator.prev() != null && term.compareToUTF16(enumerator.prev())> 0)
	    || term.compareToUTF16(enumerator.term()) >= 0)) {
      int enumOffset = (int)(enumerator.position/totalIndexInterval)+1;
      if (indexTerms.length == enumOffset	  // but before end of block
    || term.compareToUTF16(indexTerms[enumOffset]) < 0) {
       // no need to seek

        final TermInfo ti;
        int numScans = enumerator.scanTo(term);
        if (enumerator.term() != null && term.compareToUTF16(enumerator.term()) == 0) {
          ti = enumerator.termInfo();
          if (numScans > 1) {
            // we only  want to put this TermInfo into the cache if
            // scanEnum skipped more than one dictionary entry.
            // This prevents RangeQueries or WildcardQueries to 
            // wipe out the cache when they iterate over a large numbers
            // of terms in order
            if (tiOrd == null) {
              termsCache.put(new CloneableTerm(term), new TermInfoAndOrd(ti, (int) enumerator.position));
            } else {
              assert sameTermInfo(ti, tiOrd, enumerator);
              assert (int) enumerator.position == tiOrd.termOrd;
            }
          }
        } else {
          ti = null;
        }

        return ti;
      }  
    }

    // random-access: must seek
    final int indexPos;
    if (tiOrd != null) {
      indexPos = tiOrd.termOrd / totalIndexInterval;
    } else {
      // Must do binary search:
      indexPos = getIndexOffset(term);
    }

    seekEnum(enumerator, indexPos);
    enumerator.scanTo(term);
    final TermInfo ti;

    if (enumerator.term() != null && term.compareToUTF16(enumerator.term()) == 0) {
      ti = enumerator.termInfo();
      if (tiOrd == null) {
        termsCache.put(new CloneableTerm(term), new TermInfoAndOrd(ti, (int) enumerator.position));
      } else {
        assert sameTermInfo(ti, tiOrd, enumerator);
        assert (int) enumerator.position == tiOrd.termOrd;
      }
    } else {
      ti = null;
    }
    return ti;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978167/fstmerge_var2_3753799461633544251

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfosReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978388/fstmerge_base_7820064400828155658
PreFlexFields(Directory dir, FieldInfos fieldInfos, SegmentInfo info, int readBufferSize, int indexDivisor)
=======
public PreFlexFields(Directory dir, FieldInfos fieldInfos, SegmentInfo info, int readBufferSize, int indexDivisor)
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978388/fstmerge_var2_5524458250149480144
    throws IOException {

    si = info;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978388/fstmerge_var1_3438313529906950918

    // NOTE: we must always load terms index, even for
    // "sequential" scan during merging, because what is
    // sequential to merger may not be to TermInfosReader
    // since we do the surrogates dance:
    if (indexDivisor < 0) {
      indexDivisor = -indexDivisor;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978388/fstmerge_base_7820064400828155658
    TermInfosReader r = new TermInfosReader(dir, info.name, fieldInfos, readBufferSize, indexDivisor);    
    if (indexDivisor == -1) {
      tisNoIndex = r;
    } else {
      tisNoIndex = null;
      tis = r;
=======

    // NOTE: we must always load terms index, even for
    // "sequential" scan during merging, because what is
    // sequential to merger may not be to TermInfosReader
    // since we do the surrogates dance:
    if (indexDivisor < 0) {
      indexDivisor = -indexDivisor;
    }

    TermInfosReader r = new TermInfosReader(dir, info.name, fieldInfos, readBufferSize, indexDivisor);    
    if (indexDivisor == -1) {
      tisNoIndex = r;
    } else {
      tisNoIndex = null;
      tis = r;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978388/fstmerge_var2_5524458250149480144
    }
    
    boolean success = false;
    try {
      TermInfosReader r = new TermInfosReader(dir, info.name, fieldInfos, readBufferSize, indexDivisor);    
      if (indexDivisor == -1) {
        tisNoIndex = r;
      } else {
        tisNoIndex = null;
        tis = r;
      }
      this.readBufferSize = readBufferSize;
      this.fieldInfos = fieldInfos;

      // make sure that all index files have been read or are kept open
      // so that if an index update removes them we'll still have them
      freqStream = dir.openInput(info.name + ".frq", readBufferSize);
      boolean anyProx = false;
      final int numFields = fieldInfos.size();
      for(int i=0;i<numFields;i++) {
        final FieldInfo fieldInfo = fieldInfos.fieldInfo(i);
        if (fieldInfo.isIndexed) {
          fields.put(fieldInfo.name, fieldInfo);
          preTerms.put(fieldInfo.name, new PreTerms(fieldInfo));
          if (!fieldInfo.omitTermFreqAndPositions) {
            anyProx = true;
          }
        }
      }

      if (anyProx) {
        proxStream = dir.openInput(info.name + ".prx", readBufferSize);
      } else {
        proxStream = null;
      }
      success = true;
    } finally {
      // With lock-less commits, it's entirely possible (and
      // fine) to hit a FileNotFound exception above. In
      // this case, we want to explicitly close any subset
      // of things that were opened so that we don't have to
      // wait for a GC to do so.
      if (!success) {
        close();
      }
    }
    this.dir = dir;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978483/fstmerge_var1_2966444614948976397
private boolean seekToNonBMP(SegmentTermEnum te, BytesRef term, int pos) throws IOException {
      final int savLength = term.length;

      assert term.offset == 0;

      // The 3 bytes starting at downTo make up 1
      // unicode character:
      assert isHighBMPChar(term.bytes, pos);

      // NOTE: we cannot make this assert, because
      // AutomatonQuery legitimately sends us malformed UTF8
      // (eg the UTF8 bytes with just 0xee)
      // assert term.length >= pos + 3: "term.length=" + term.length + " pos+3=" + (pos+3) + " byte=" + Integer.toHexString(term.bytes[pos]) + " term=" + term.toString();

      // Save the bytes && length, since we need to
      // restore this if seek "back" finds no matching
      // terms
      if (term.bytes.length < 4+pos) {
        term.grow(4+pos);
      }

      scratch[0] = term.bytes[pos];
      scratch[1] = term.bytes[pos+1];
      scratch[2] = term.bytes[pos+2];

      term.bytes[pos] = (byte) 0xf0;
      term.bytes[pos+1] = (byte) 0x90;
      term.bytes[pos+2] = (byte) 0x80;
      term.bytes[pos+3] = (byte) 0x80;
      term.length = 4+pos;

      if (DEBUG_SURROGATES) {
        System.out.println("      try seek term=" + UnicodeUtil.toHexString(term.utf8ToString()));
      }

      // Seek "back":
      getTermsDict().seekEnum(te, protoTerm.createTerm(term), true);

      // Test if the term we seek'd to in fact found a
      // surrogate pair at the same position as the E:
      Term t2 = te.term();

      // Cannot be null (or move to next field) because at
      // "worst" it'd seek to the same term we are on now,
      // unless we are being called from seek
      if (t2 == null || t2.field() != fieldInfo.name) {
        return false;
      }

      if (DEBUG_SURROGATES) {
        System.out.println("      got term=" + UnicodeUtil.toHexString(t2.text()));
      }

      // Now test if prefix is identical and we found
      // a non-BMP char at the same position:
      BytesRef b2 = t2.bytes();
      assert b2.offset == 0;

      boolean matches;
      if (b2.length >= term.length && isNonBMPChar(b2.bytes, pos)) {
        matches = true;
        for(int i=0;i<pos;i++) {
          if (term.bytes[i] != b2.bytes[i]) {
            matches = false;
            break;
          }
        }              
      } else {
        matches = false;
      }

      // Restore term:
      term.length = savLength;
      term.bytes[pos] = scratch[0];
      term.bytes[pos+1] = scratch[1];
      term.bytes[pos+2] = scratch[2];

      return matches;
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978483/fstmerge_base_344417516165896926
=======
private boolean seekToNonBMP(SegmentTermEnum te, BytesRef term, int pos) throws IOException {
      final int savLength = term.length;

      assert term.offset == 0;

      // The 3 bytes starting at downTo make up 1
      // unicode character:
      assert isHighBMPChar(term.bytes, pos);

      // NOTE: we cannot make this assert, because
      // AutomatonQuery legitimately sends us malformed UTF8
      // (eg the UTF8 bytes with just 0xee)
      // assert term.length >= pos + 3: "term.length=" + term.length + " pos+3=" + (pos+3) + " byte=" + Integer.toHexString(term.bytes[pos]) + " term=" + term.toString();

      // Save the bytes && length, since we need to
      // restore this if seek "back" finds no matching
      // terms
      if (term.bytes.length < 4+pos) {
        term.grow(4+pos);
      }

      scratch[0] = term.bytes[pos];
      scratch[1] = term.bytes[pos+1];
      scratch[2] = term.bytes[pos+2];

      term.bytes[pos] = (byte) 0xf0;
      term.bytes[pos+1] = (byte) 0x90;
      term.bytes[pos+2] = (byte) 0x80;
      term.bytes[pos+3] = (byte) 0x80;
      term.length = 4+pos;

      if (DEBUG_SURROGATES) {
        System.out.println("      try seek term=" + UnicodeUtil.toHexString(term.utf8ToString()));
      }

      // Seek "back":
      getTermsDict().seekEnum(te, protoTerm.createTerm(term));

      // Test if the term we seek'd to in fact found a
      // surrogate pair at the same position as the E:
      Term t2 = te.term();

      // Cannot be null (or move to next field) because at
      // "worst" it'd seek to the same term we are on now,
      // unless we are being called from seek
      if (t2 == null || t2.field() != fieldInfo.name) {
        return false;
      }

      if (DEBUG_SURROGATES) {
        System.out.println("      got term=" + UnicodeUtil.toHexString(t2.text()));
      }

      // Now test if prefix is identical and we found
      // a non-BMP char at the same position:
      BytesRef b2 = t2.bytes();
      assert b2.offset == 0;

      boolean matches;
      if (b2.length >= term.length && isNonBMPChar(b2.bytes, pos)) {
        matches = true;
        for(int i=0;i<pos;i++) {
          if (term.bytes[i] != b2.bytes[i]) {
            matches = false;
            break;
          }
        }              
      } else {
        matches = false;
      }

      // Restore term:
      term.length = savLength;
      term.bytes[pos] = scratch[0];
      term.bytes[pos+1] = scratch[1];
      term.bytes[pos+2] = scratch[2];

      return matches;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978483/fstmerge_var2_4452672908600835587

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978489/fstmerge_var1_2114210463775705845
private boolean doContinue() throws IOException {

      if (DEBUG_SURROGATES) {
        System.out.println("  try cont");
      }

      int downTo = prevTerm.length-1;

      boolean didSeek = false;
      
      final int limit = Math.min(newSuffixStart, scratchTerm.length-1);

      while(downTo > limit) {

        if (isHighBMPChar(prevTerm.bytes, downTo)) {

          if (DEBUG_SURROGATES) {
            System.out.println("    found E pos=" + downTo + " vs len=" + prevTerm.length);
          }

          if (seekToNonBMP(seekTermEnum, prevTerm, downTo)) {
            // TODO: more efficient seek?
            getTermsDict().seekEnum(termEnum, seekTermEnum.term(), true);
            //newSuffixStart = downTo+4;
            newSuffixStart = downTo;
            scratchTerm.copy(termEnum.term().bytes());
            didSeek = true;
            if (DEBUG_SURROGATES) {
              System.out.println("      seek!");
            }
            break;
          } else {
            if (DEBUG_SURROGATES) {
              System.out.println("      no seek");
            }
          }
        }

        // Shorten prevTerm in place so that we don't redo
        // this loop if we come back here:
        if ((prevTerm.bytes[downTo] & 0xc0) == 0xc0 || (prevTerm.bytes[downTo] & 0x80) == 0) {
          prevTerm.length = downTo;
        }
        
        downTo--;
      }

      return didSeek;
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978489/fstmerge_base_9133173263611990030
=======
private boolean doContinue() throws IOException {

      if (DEBUG_SURROGATES) {
        System.out.println("  try cont");
      }

      int downTo = prevTerm.length-1;

      boolean didSeek = false;
      
      final int limit = Math.min(newSuffixStart, scratchTerm.length-1);

      while(downTo > limit) {

        if (isHighBMPChar(prevTerm.bytes, downTo)) {

          if (DEBUG_SURROGATES) {
            System.out.println("    found E pos=" + downTo + " vs len=" + prevTerm.length);
          }

          if (seekToNonBMP(seekTermEnum, prevTerm, downTo)) {
            // TODO: more efficient seek?
            getTermsDict().seekEnum(termEnum, seekTermEnum.term());
            //newSuffixStart = downTo+4;
            newSuffixStart = downTo;
            scratchTerm.copy(termEnum.term().bytes());
            didSeek = true;
            if (DEBUG_SURROGATES) {
              System.out.println("      seek!");
            }
            break;
          } else {
            if (DEBUG_SURROGATES) {
              System.out.println("      no seek");
            }
          }
        }

        // Shorten prevTerm in place so that we don't redo
        // this loop if we come back here:
        if ((prevTerm.bytes[downTo] & 0xc0) == 0xc0 || (prevTerm.bytes[downTo] & 0x80) == 0) {
          prevTerm.length = downTo;
        }
        
        downTo--;
      }

      return didSeek;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978489/fstmerge_var2_5639402199428296114

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978494/fstmerge_var1_3518111104787692995
private boolean doPop() throws IOException {

      if (DEBUG_SURROGATES) {
        System.out.println("  try pop");
      }

      assert newSuffixStart <= prevTerm.length;
      assert newSuffixStart < scratchTerm.length || newSuffixStart == 0;

      if (prevTerm.length > newSuffixStart &&
          isNonBMPChar(prevTerm.bytes, newSuffixStart) &&
          isHighBMPChar(scratchTerm.bytes, newSuffixStart)) {

        // Seek type 2 -- put 0xFF at this position:
        scratchTerm.bytes[newSuffixStart] = (byte) 0xff;
        scratchTerm.length = newSuffixStart+1;

        if (DEBUG_SURROGATES) {
          System.out.println("    seek to term=" + UnicodeUtil.toHexString(scratchTerm.utf8ToString()) + " " + scratchTerm.toString());
        }
          
        // TODO: more efficient seek?  can we simply swap
        // the enums?
        getTermsDict().seekEnum(termEnum, protoTerm.createTerm(scratchTerm), true);

        final Term t2 = termEnum.term();

        // We could hit EOF or different field since this
        // was a seek "forward":
        if (t2 != null && t2.field() == fieldInfo.name) {

          if (DEBUG_SURROGATES) {
            System.out.println("      got term=" + UnicodeUtil.toHexString(t2.text()) + " " + t2.bytes());
          }

          final BytesRef b2 = t2.bytes();
          assert b2.offset == 0;


          // Set newSuffixStart -- we can't use
          // termEnum's since the above seek may have
          // done no scanning (eg, term was precisely
          // and index term, or, was in the term seek
          // cache):
          scratchTerm.copy(b2);
          setNewSuffixStart(prevTerm, scratchTerm);

          return true;
        } else if (newSuffixStart != 0 || scratchTerm.length != 0) {
          if (DEBUG_SURROGATES) {
            System.out.println("      got term=null (or next field)");
          }
          newSuffixStart = 0;
          scratchTerm.length = 0;
          return true;
        }
      }

      return false;
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978494/fstmerge_base_113722818273194431
=======
private boolean doPop() throws IOException {

      if (DEBUG_SURROGATES) {
        System.out.println("  try pop");
      }

      assert newSuffixStart <= prevTerm.length;
      assert newSuffixStart < scratchTerm.length || newSuffixStart == 0;

      if (prevTerm.length > newSuffixStart &&
          isNonBMPChar(prevTerm.bytes, newSuffixStart) &&
          isHighBMPChar(scratchTerm.bytes, newSuffixStart)) {

        // Seek type 2 -- put 0xFF at this position:
        scratchTerm.bytes[newSuffixStart] = (byte) 0xff;
        scratchTerm.length = newSuffixStart+1;

        if (DEBUG_SURROGATES) {
          System.out.println("    seek to term=" + UnicodeUtil.toHexString(scratchTerm.utf8ToString()) + " " + scratchTerm.toString());
        }
          
        // TODO: more efficient seek?  can we simply swap
        // the enums?
        getTermsDict().seekEnum(termEnum, protoTerm.createTerm(scratchTerm));

        final Term t2 = termEnum.term();

        // We could hit EOF or different field since this
        // was a seek "forward":
        if (t2 != null && t2.field() == fieldInfo.name) {

          if (DEBUG_SURROGATES) {
            System.out.println("      got term=" + UnicodeUtil.toHexString(t2.text()) + " " + t2.bytes());
          }

          final BytesRef b2 = t2.bytes();
          assert b2.offset == 0;


          // Set newSuffixStart -- we can't use
          // termEnum's since the above seek may have
          // done no scanning (eg, term was precisely
          // and index term, or, was in the term seek
          // cache):
          scratchTerm.copy(b2);
          setNewSuffixStart(prevTerm, scratchTerm);

          return true;
        } else if (newSuffixStart != 0 || scratchTerm.length != 0) {
          if (DEBUG_SURROGATES) {
            System.out.println("      got term=null (or next field)");
          }
          newSuffixStart = 0;
          scratchTerm.length = 0;
          return true;
        }
      }

      return false;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978494/fstmerge_var2_4119719349318913703

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978505/fstmerge_var1_1560411745486630597
private void doPushes() throws IOException {

      int upTo = newSuffixStart;
      if (DEBUG_SURROGATES) {
        System.out.println("  try push newSuffixStart=" + newSuffixStart + " scratchLen=" + scratchTerm.length);
      }

      while(upTo < scratchTerm.length) {
        if (isNonBMPChar(scratchTerm.bytes, upTo) &&
            (upTo > newSuffixStart ||
             (upTo >= prevTerm.length ||
              (!isNonBMPChar(prevTerm.bytes, upTo) &&
               !isHighBMPChar(prevTerm.bytes, upTo))))) {

          // A non-BMP char (4 bytes UTF8) starts here:
          assert scratchTerm.length >= upTo + 4;
          
          final int savLength = scratchTerm.length;
          scratch[0] = scratchTerm.bytes[upTo];
          scratch[1] = scratchTerm.bytes[upTo+1];
          scratch[2] = scratchTerm.bytes[upTo+2];

          scratchTerm.bytes[upTo] = UTF8_HIGH_BMP_LEAD;
          scratchTerm.bytes[upTo+1] = (byte) 0x80;
          scratchTerm.bytes[upTo+2] = (byte) 0x80;
          scratchTerm.length = upTo+3;

          if (DEBUG_SURROGATES) {
            System.out.println("    try seek 1 pos=" + upTo + " term=" + UnicodeUtil.toHexString(scratchTerm.utf8ToString()) + " " + scratchTerm.toString() + " len=" + scratchTerm.length);
          }

          // Seek "forward":
          // TODO: more efficient seek?
          getTermsDict().seekEnum(seekTermEnum, protoTerm.createTerm(scratchTerm), true);

          scratchTerm.bytes[upTo] = scratch[0];
          scratchTerm.bytes[upTo+1] = scratch[1];
          scratchTerm.bytes[upTo+2] = scratch[2];
          scratchTerm.length = savLength;

          // Did we find a match?
          final Term t2 = seekTermEnum.term();
            
          if (DEBUG_SURROGATES) {
            if (t2 == null) {
              System.out.println("      hit term=null");
            } else {
              System.out.println("      hit term=" + UnicodeUtil.toHexString(t2.text()) + " " + (t2==null? null:t2.bytes()));
            }
          }

          // Since this was a seek "forward", we could hit
          // EOF or a different field:
          boolean matches;

          if (t2 != null && t2.field() == fieldInfo.name) {
            final BytesRef b2 = t2.bytes();
            assert b2.offset == 0;
            if (b2.length >= upTo+3 && isHighBMPChar(b2.bytes, upTo)) {
              matches = true;
              for(int i=0;i<upTo;i++) {
                if (scratchTerm.bytes[i] != b2.bytes[i]) {
                  matches = false;
                  break;
                }
              }              
                
            } else {
              matches = false;
            }
          } else {
            matches = false;
          }

          if (matches) {

            if (DEBUG_SURROGATES) {
              System.out.println("      matches!");
            }

            // OK seek "back"
            // TODO: more efficient seek?
            getTermsDict().seekEnum(termEnum, seekTermEnum.term(), true);

            scratchTerm.copy(seekTermEnum.term().bytes());

            // +3 because we don't need to check the char
            // at upTo: we know it's > BMP
            upTo += 3;

            // NOTE: we keep iterating, now, since this
            // can easily "recurse".  Ie, after seeking
            // forward at a certain char position, we may
            // find another surrogate in our [new] suffix
            // and must then do another seek (recurse)
          } else {
            upTo++;
          }
        } else {
          upTo++;
        }
      }
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978505/fstmerge_base_5948545125276459697
=======
private void doPushes() throws IOException {

      int upTo = newSuffixStart;
      if (DEBUG_SURROGATES) {
        System.out.println("  try push newSuffixStart=" + newSuffixStart + " scratchLen=" + scratchTerm.length);
      }

      while(upTo < scratchTerm.length) {
        if (isNonBMPChar(scratchTerm.bytes, upTo) &&
            (upTo > newSuffixStart ||
             (upTo >= prevTerm.length ||
              (!isNonBMPChar(prevTerm.bytes, upTo) &&
               !isHighBMPChar(prevTerm.bytes, upTo))))) {

          // A non-BMP char (4 bytes UTF8) starts here:
          assert scratchTerm.length >= upTo + 4;
          
          final int savLength = scratchTerm.length;
          scratch[0] = scratchTerm.bytes[upTo];
          scratch[1] = scratchTerm.bytes[upTo+1];
          scratch[2] = scratchTerm.bytes[upTo+2];

          scratchTerm.bytes[upTo] = UTF8_HIGH_BMP_LEAD;
          scratchTerm.bytes[upTo+1] = (byte) 0x80;
          scratchTerm.bytes[upTo+2] = (byte) 0x80;
          scratchTerm.length = upTo+3;

          if (DEBUG_SURROGATES) {
            System.out.println("    try seek 1 pos=" + upTo + " term=" + UnicodeUtil.toHexString(scratchTerm.utf8ToString()) + " " + scratchTerm.toString() + " len=" + scratchTerm.length);
          }

          // Seek "forward":
          // TODO: more efficient seek?
          getTermsDict().seekEnum(seekTermEnum, protoTerm.createTerm(scratchTerm));

          scratchTerm.bytes[upTo] = scratch[0];
          scratchTerm.bytes[upTo+1] = scratch[1];
          scratchTerm.bytes[upTo+2] = scratch[2];
          scratchTerm.length = savLength;

          // Did we find a match?
          final Term t2 = seekTermEnum.term();
            
          if (DEBUG_SURROGATES) {
            if (t2 == null) {
              System.out.println("      hit term=null");
            } else {
              System.out.println("      hit term=" + UnicodeUtil.toHexString(t2.text()) + " " + (t2==null? null:t2.bytes()));
            }
          }

          // Since this was a seek "forward", we could hit
          // EOF or a different field:
          boolean matches;

          if (t2 != null && t2.field() == fieldInfo.name) {
            final BytesRef b2 = t2.bytes();
            assert b2.offset == 0;
            if (b2.length >= upTo+3 && isHighBMPChar(b2.bytes, upTo)) {
              matches = true;
              for(int i=0;i<upTo;i++) {
                if (scratchTerm.bytes[i] != b2.bytes[i]) {
                  matches = false;
                  break;
                }
              }              
                
            } else {
              matches = false;
            }
          } else {
            matches = false;
          }

          if (matches) {

            if (DEBUG_SURROGATES) {
              System.out.println("      matches!");
            }

            // OK seek "back"
            // TODO: more efficient seek?
            getTermsDict().seekEnum(termEnum, seekTermEnum.term());

            scratchTerm.copy(seekTermEnum.term().bytes());

            // +3 because we don't need to check the char
            // at upTo: we know it's > BMP
            upTo += 3;

            // NOTE: we keep iterating, now, since this
            // can easily "recurse".  Ie, after seeking
            // forward at a certain char position, we may
            // find another surrogate in our [new] suffix
            // and must then do another seek (recurse)
          } else {
            upTo++;
          }
        } else {
          upTo++;
        }
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978505/fstmerge_var2_3775246609913329120

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978511/fstmerge_var1_3911821626310219798
void reset(FieldInfo fieldInfo) throws IOException {
      //System.out.println("pff.reset te=" + termEnum);
      this.fieldInfo = fieldInfo;
      protoTerm = new Term(fieldInfo.name);
      if (termEnum == null) {
        termEnum = getTermsDict().terms(protoTerm);
        seekTermEnum = getTermsDict().terms(protoTerm);
        //System.out.println("  term=" + termEnum.term());
      } else {
        getTermsDict().seekEnum(termEnum, protoTerm, true);
      }
      skipNext = true;

      unicodeSortOrder = sortTermsByUnicode();

      final Term t = termEnum.term();
      if (t != null && t.field() == fieldInfo.name) {
        newSuffixStart = 0;
        prevTerm.length = 0;
        surrogateDance();
      }
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978511/fstmerge_base_52806956931655898
=======
void reset(FieldInfo fieldInfo) throws IOException {
      //System.out.println("pff.reset te=" + termEnum);
      this.fieldInfo = fieldInfo;
      protoTerm = new Term(fieldInfo.name);
      if (termEnum == null) {
        termEnum = getTermsDict().terms(protoTerm);
        seekTermEnum = getTermsDict().terms(protoTerm);
        //System.out.println("  term=" + termEnum.term());
      } else {
        getTermsDict().seekEnum(termEnum, protoTerm);
      }
      skipNext = true;

      unicodeSortOrder = sortTermsByUnicode();

      final Term t = termEnum.term();
      if (t != null && t.field() == fieldInfo.name) {
        newSuffixStart = 0;
        prevTerm.length = 0;
        surrogateDance();
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978511/fstmerge_var2_8095126287141601479

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public SeekStatus seek(BytesRef term, boolean useCache) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978529/fstmerge_base_5938512830072874735
=======
      if (DEBUG_SURROGATES) {
        System.out.println("TE.seek target=" + UnicodeUtil.toHexString(term.utf8ToString()));
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978529/fstmerge_var2_2982398915517002017
      skipNext = false;
      final TermInfosReader tis = getTermsDict();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978529/fstmerge_var1_8062651323438952662
      final Term t0 = protoTerm.createTerm(term);

      assert termEnum != null;

      tis.seekEnum(termEnum, t0, useCache);

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978529/fstmerge_base_5938512830072874735
      final Term t0 = new Term(fieldInfo.name, term.utf8ToString());
      if (termEnum == null) {
        termEnum = tis.terms(t0);
      } else {
        tis.seekEnum(termEnum, t0);
      }
=======
      final Term t0 = protoTerm.createTerm(term);

      assert termEnum != null;

      tis.seekEnum(termEnum, t0);

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978529/fstmerge_var2_2982398915517002017
      final Term t = termEnum.term();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978529/fstmerge_base_5938512830072874735
      final BytesRef tr;
      if (t != null) {
        tr = scratchBytesRef;
        scratchBytesRef.copy(t.text());
      } else {
        tr = null;
      }

      if (t != null && t.field() == fieldInfo.name && term.bytesEquals(tr)) {
        current = tr;
=======
      if (t != null && t.field() == fieldInfo.name && term.bytesEquals(t.bytes())) {
        // If we found an exact match, no need to do the
        // surrogate dance
        if (DEBUG_SURROGATES) {
          System.out.println("  seek exact match");
        }
        current = t.bytes();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978529/fstmerge_var2_2982398915517002017
        return SeekStatus.FOUND;
      } else if (t == null || t.field() != fieldInfo.name) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978529/fstmerge_var1_8062651323438952662

        // TODO: maybe we can handle this like the next()
        // into null?  set term as prevTerm then dance?

        if (DEBUG_SURROGATES) {
          System.out.println("  seek hit EOF");
        }

        // We hit EOF; try end-case surrogate dance: if we
        // find an E, try swapping in S, backwards:
        scratchTerm.copy(term);

        assert scratchTerm.offset == 0;

        for(int i=scratchTerm.length-1;i>=0;i--) {
          if (isHighBMPChar(scratchTerm.bytes, i)) {
            if (DEBUG_SURROGATES) {
              System.out.println("    found E pos=" + i + "; try seek");
            }

            if (seekToNonBMP(seekTermEnum, scratchTerm, i)) {

              scratchTerm.copy(seekTermEnum.term().bytes());
              getTermsDict().seekEnum(termEnum, seekTermEnum.term(), useCache);

              newSuffixStart = 1+i;

              doPushes();

              // Found a match
              // TODO: faster seek?
              current = termEnum.term().bytes();
              return SeekStatus.NOT_FOUND;
            }
          }
        }
        
        if (DEBUG_SURROGATES) {
          System.out.println("  seek END");
        }

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978529/fstmerge_base_5938512830072874735
=======

        // TODO: maybe we can handle this like the next()
        // into null?  set term as prevTerm then dance?

        if (DEBUG_SURROGATES) {
          System.out.println("  seek hit EOF");
        }

        // We hit EOF; try end-case surrogate dance: if we
        // find an E, try swapping in S, backwards:
        scratchTerm.copy(term);

        assert scratchTerm.offset == 0;

        for(int i=scratchTerm.length-1;i>=0;i--) {
          if (isHighBMPChar(scratchTerm.bytes, i)) {
            if (DEBUG_SURROGATES) {
              System.out.println("    found E pos=" + i + "; try seek");
            }

            if (seekToNonBMP(seekTermEnum, scratchTerm, i)) {

              scratchTerm.copy(seekTermEnum.term().bytes());
              getTermsDict().seekEnum(termEnum, seekTermEnum.term());

              newSuffixStart = 1+i;

              doPushes();

              // Found a match
              // TODO: faster seek?
              current = termEnum.term().bytes();
              return SeekStatus.NOT_FOUND;
            }
          }
        }
        
        if (DEBUG_SURROGATES) {
          System.out.println("  seek END");
        }

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978529/fstmerge_var2_2982398915517002017
        current = null;
        return SeekStatus.END;
      } else {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978529/fstmerge_base_5938512830072874735
        current = tr;
        return SeekStatus.NOT_FOUND;
=======

        // We found a non-exact but non-null term; this one
        // is fun -- just treat it like next, by pretending
        // requested term was prev:
        prevTerm.copy(term);

        if (DEBUG_SURROGATES) {
          System.out.println("  seek hit non-exact term=" + UnicodeUtil.toHexString(t.text()));
        }

        final BytesRef br = t.bytes();
        assert br.offset == 0;

        setNewSuffixStart(term, br);

        surrogateDance();

        final Term t2 = termEnum.term();
        if (t2 == null || t2.field() != fieldInfo.name) {
          assert t2 == null || !t2.field().equals(fieldInfo.name); // make sure fields are in fact interned
          current = null;
          return SeekStatus.END;
        } else {
          current = t2.bytes();
          assert !unicodeSortOrder || term.compareTo(current) < 0 : "term=" + UnicodeUtil.toHexString(term.utf8ToString()) + " vs current=" + UnicodeUtil.toHexString(current.utf8ToString());
          return SeekStatus.NOT_FOUND;
        }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978529/fstmerge_var2_2982398915517002017
      }
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978746/fstmerge_var1_5744278215298414643
@Override
  public DocumentsWriter.DocWriter processDocument() throws IOException {

    consumer.startDocument();
    fieldsWriter.startDocument();

    final Document doc = docState.doc;

    assert docFieldProcessor.docWriter.writer.testPoint("DocumentsWriter.ThreadState.init start");

    fieldCount = 0;
    
    final int thisFieldGen = fieldGen++;

    final List<Fieldable> docFields = doc.getFields();
    final int numDocFields = docFields.size();

    // Absorb any new fields first seen in this document.
    // Also absorb any changes to fields we had already
    // seen before (eg suddenly turning on norms or
    // vectors, etc.):

    for(int i=0;i<numDocFields;i++) {
      Fieldable field = docFields.get(i);
      final String fieldName = field.name();

      // Make sure we have a PerField allocated
      final int hashPos = fieldName.hashCode() & hashMask;
      DocFieldProcessorPerField fp = fieldHash[hashPos];
      while(fp != null && !fp.fieldInfo.name.equals(fieldName))
        fp = fp.next;

      if (fp == null) {

        // TODO FI: we need to genericize the "flags" that a
        // field holds, and, how these flags are merged; it
        // needs to be more "pluggable" such that if I want
        // to have a new "thing" my Fields can do, I can
        // easily add it
        FieldInfo fi = fieldInfos.add(fieldName, field.isIndexed(), field.isTermVectorStored(),
                                      field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                                      field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
        fp = new DocFieldProcessorPerField(this, fi);
        fp.next = fieldHash[hashPos];
        fieldHash[hashPos] = fp;
        totalFieldCount++;

        if (totalFieldCount >= fieldHash.length/2)
          rehash();
      } else
        fp.fieldInfo.update(field.isIndexed(), field.isTermVectorStored(),
                            field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                            field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());

      if (thisFieldGen != fp.lastGen) {

        // First time we're seeing this field for this doc
        fp.fieldCount = 0;

        if (fieldCount == fields.length) {
          final int newSize = fields.length*2;
          DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];
          System.arraycopy(fields, 0, newArray, 0, fieldCount);
          fields = newArray;
        }

        fields[fieldCount++] = fp;
        fp.lastGen = thisFieldGen;
      }

      if (fp.fieldCount == fp.fields.length) {
        Fieldable[] newArray = new Fieldable[fp.fields.length*2];
        System.arraycopy(fp.fields, 0, newArray, 0, fp.fieldCount);
        fp.fields = newArray;
      }

      fp.fields[fp.fieldCount++] = field;
      if (field.isStored()) {
        fieldsWriter.addField(field, fp.fieldInfo);
      }
    }

    // If we are writing vectors then we must visit
    // fields in sorted order so they are written in
    // sorted order.  TODO: we actually only need to
    // sort the subset of fields that have vectors
    // enabled; we could save [small amount of] CPU
    // here.
    ArrayUtil.quickSort(fields, 0, fieldCount, fieldsComp);

    for(int i=0;i<fieldCount;i++)
      fields[i].consumer.processFields(fields[i].fields, fields[i].fieldCount);

    if (docState.maxTermPrefix != null && docState.infoStream != null) {
      docState.infoStream.println("WARNING: document contains at least one immense term (whose UTF8 encoding is longer than the max length " + DocumentsWriter.MAX_TERM_LENGTH_UTF8 + "), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '" + docState.maxTermPrefix + "...'"); 
      docState.maxTermPrefix = null;
    }

    final DocumentsWriter.DocWriter one = fieldsWriter.finishDocument();
    final DocumentsWriter.DocWriter two = consumer.finishDocument();
    if (one == null) {
      return two;
    } else if (two == null) {
      return one;
    } else {
      PerDoc both = getPerDoc();
      both.docID = docState.docID;
      assert one.docID == docState.docID;
      assert two.docID == docState.docID;
      both.one = one;
      both.two = two;
      return both;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978746/fstmerge_base_8255052462107706971
@Override
  public DocumentsWriter.DocWriter processDocument() throws IOException {

    consumer.startDocument();
    fieldsWriter.startDocument();

    final Document doc = docState.doc;

    assert docFieldProcessor.docWriter.writer.testPoint("DocumentsWriter.ThreadState.init start");

    fieldCount = 0;
    
    final int thisFieldGen = fieldGen++;

    final List<Fieldable> docFields = doc.getFields();
    final int numDocFields = docFields.size();

    // Absorb any new fields first seen in this document.
    // Also absorb any changes to fields we had already
    // seen before (eg suddenly turning on norms or
    // vectors, etc.):

    for(int i=0;i<numDocFields;i++) {
      Fieldable field = docFields.get(i);
      final String fieldName = field.name();

      // Make sure we have a PerField allocated
      final int hashPos = fieldName.hashCode() & hashMask;
      DocFieldProcessorPerField fp = fieldHash[hashPos];
      while(fp != null && !fp.fieldInfo.name.equals(fieldName))
        fp = fp.next;

      if (fp == null) {

        // TODO FI: we need to genericize the "flags" that a
        // field holds, and, how these flags are merged; it
        // needs to be more "pluggable" such that if I want
        // to have a new "thing" my Fields can do, I can
        // easily add it
        FieldInfo fi = fieldInfos.add(fieldName, field.isIndexed(), field.isTermVectorStored(),
                                      field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                                      field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());

        fp = new DocFieldProcessorPerField(this, fi);
        fp.next = fieldHash[hashPos];
        fieldHash[hashPos] = fp;
        totalFieldCount++;

        if (totalFieldCount >= fieldHash.length/2)
          rehash();
      } else
        fp.fieldInfo.update(field.isIndexed(), field.isTermVectorStored(),
                            field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                            field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());

      if (thisFieldGen != fp.lastGen) {

        // First time we're seeing this field for this doc
        fp.fieldCount = 0;

        if (fieldCount == fields.length) {
          final int newSize = fields.length*2;
          DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];
          System.arraycopy(fields, 0, newArray, 0, fieldCount);
          fields = newArray;
        }

        fields[fieldCount++] = fp;
        fp.lastGen = thisFieldGen;
      }

      if (fp.fieldCount == fp.fields.length) {
        Fieldable[] newArray = new Fieldable[fp.fields.length*2];
        System.arraycopy(fp.fields, 0, newArray, 0, fp.fieldCount);
        fp.fields = newArray;
      }

      fp.fields[fp.fieldCount++] = field;
      if (field.isStored()) {
        fieldsWriter.addField(field, fp.fieldInfo);
      }
    }

    // If we are writing vectors then we must visit
    // fields in sorted order so they are written in
    // sorted order.  TODO: we actually only need to
    // sort the subset of fields that have vectors
    // enabled; we could save [small amount of] CPU
    // here.
    quickSort(fields, 0, fieldCount-1);

    for(int i=0;i<fieldCount;i++)
      fields[i].consumer.processFields(fields[i].fields, fields[i].fieldCount);

    if (docState.maxTermPrefix != null && docState.infoStream != null) {
      docState.infoStream.println("WARNING: document contains at least one immense term (whose UTF8 encoding is longer than the max length " + DocumentsWriter.MAX_TERM_LENGTH_UTF8 + "), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '" + docState.maxTermPrefix + "...'"); 
      docState.maxTermPrefix = null;
    }

    final DocumentsWriter.DocWriter one = fieldsWriter.finishDocument();
    final DocumentsWriter.DocWriter two = consumer.finishDocument();
    if (one == null) {
      return two;
    } else if (two == null) {
      return one;
    } else {
      PerDoc both = getPerDoc();
      both.docID = docState.docID;
      assert one.docID == docState.docID;
      assert two.docID == docState.docID;
      both.one = one;
      both.two = two;
      return both;
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978746/fstmerge_var2_4440498873507284859

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978829/fstmerge_var1_9172245548005205655
public TermsHashPerThread(DocInverterPerThread docInverterPerThread, final TermsHash termsHash, final TermsHash nextTermsHash, final TermsHashPerThread primaryPerThread) {
    docState = docInverterPerThread.docState;

    this.termsHash = termsHash;
    this.consumer = termsHash.consumer.addThread(this);

    intPool = new IntBlockPool(termsHash.docWriter);
    bytePool = new ByteBlockPool(termsHash.docWriter.byteBlockAllocator); // use the allocator from the docWriter which tracks the used bytes 
    primary = nextTermsHash != null;
    if (primary) {
      // We are primary
      termBytePool = bytePool;
      nextPerThread = nextTermsHash.addThread(docInverterPerThread, this); // this will be the primaryPerThread in the secondary
      assert nextPerThread != null;
    } else {
      assert primaryPerThread != null;
      termBytePool = primaryPerThread.bytePool; // we are secondary and share the byte pool with the primary 
      nextPerThread = null;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978829/fstmerge_base_4825707663479156511
public TermsHashPerThread(DocInverterPerThread docInverterPerThread, final TermsHash termsHash, final TermsHash nextTermsHash, final TermsHashPerThread primaryPerThread) {
    docState = docInverterPerThread.docState;

    this.termsHash = termsHash;
    this.consumer = termsHash.consumer.addThread(this);

    intPool = new IntBlockPool(termsHash.docWriter);
    bytePool = new ByteBlockPool(termsHash.docWriter.byteBlockAllocator);

    if (nextTermsHash != null) {
      // We are primary
      primary = true;
      termBytePool = bytePool;
    } else {
      primary = false;
      termBytePool = primaryPerThread.bytePool;
    }

    if (nextTermsHash != null)
      nextPerThread = nextTermsHash.addThread(docInverterPerThread, this);
    else
      nextPerThread = null;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978829/fstmerge_var2_1547274030218003859

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHashPerThread.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978838/fstmerge_var1_661149142069374482
@Override
  synchronized public void abort() {
    reset(true);
    consumer.abort();
    if (primary)
      nextPerThread.abort();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978838/fstmerge_base_356530827417568838
@Override
  synchronized public void abort() {
    reset(true);
    consumer.abort();
    if (nextPerThread != null)
      nextPerThread.abort();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978838/fstmerge_var2_2105852778403162192

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHashPerThread.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978843/fstmerge_var1_3542635636374622398
@Override
  public void startDocument() throws IOException {
    consumer.startDocument();
    if (primary)
      nextPerThread.consumer.startDocument();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978843/fstmerge_base_4986516781074037133
@Override
  public void startDocument() throws IOException {
    consumer.startDocument();
    if (nextPerThread != null)
      nextPerThread.consumer.startDocument();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978843/fstmerge_var2_1551660949613664340

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHashPerThread.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978847/fstmerge_var1_8411197669125013881
@Override
  public DocumentsWriter.DocWriter finishDocument() throws IOException {
    final DocumentsWriter.DocWriter doc = consumer.finishDocument();
    final DocumentsWriter.DocWriter docFromSecondary = primary? nextPerThread.consumer.finishDocument():null;
    if (doc == null)
      return docFromSecondary;
    else {
      doc.setNext(docFromSecondary);
      return doc;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978847/fstmerge_base_8942754546241735835
@Override
  public DocumentsWriter.DocWriter finishDocument() throws IOException {
    final DocumentsWriter.DocWriter doc = consumer.finishDocument();

    final DocumentsWriter.DocWriter doc2;
    if (nextPerThread != null)
      doc2 = nextPerThread.consumer.finishDocument();
    else
      doc2 = null;
    if (doc == null)
      return doc2;
    else {
      doc.setNext(doc2);
      return doc;
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978847/fstmerge_var2_5689082101305099969

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHashPerThread.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978851/fstmerge_var1_1576101181785080194
void reset(boolean recyclePostings) {
    intPool.reset();
    bytePool.reset();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978851/fstmerge_base_2742386347112953313
void reset(boolean recyclePostings) {
    intPool.reset();
    bytePool.reset();

    if (primary) {
      bytePool.reset();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978851/fstmerge_var2_3116215314925106755

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/TermsHashPerThread.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978860/fstmerge_var1_2428173905761434041
void doAfterFlush() {
    numThreads = 0;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978860/fstmerge_base_2987315799898667942
void doAfterFlush() {
    numThreads = 0;
    doFlushAfter = false;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978860/fstmerge_var2_8440479139278978664

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/DocumentsWriterThreadState.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ private final AtomicInteger numTerms = new AtomicInteger(); ##FSTMerge## int numTerms; ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/BufferedDeletes.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ private final AtomicLong bytesUsed = new AtomicLong(); ##FSTMerge## long bytesUsed; ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/BufferedDeletes.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978917/fstmerge_var1_3688922469328500787
public synchronized void clear() {
    deletesMap.clear();
    numTerms.set(0);
    bytesUsed.set(0);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978917/fstmerge_base_4810330229229994769
void clear() {
    terms.clear();
    queries.clear();
    docIDs.clear();
    numTerms = 0;
    bytesUsed = 0;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978917/fstmerge_var2_3730913905254521619

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/BufferedDeletes.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978922/fstmerge_var1_4433983766763655834
synchronized boolean any() {
    return bytesUsed.get() != 0;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978922/fstmerge_base_1576095698943643038
boolean any() {
    return terms.size() > 0 || docIDs.size() > 0 || queries.size() > 0;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627978922/fstmerge_var2_5201898356754800795

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/BufferedDeletes.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979003/fstmerge_var1_5747700728249337147
public FreqProxFieldMergeState(FreqProxTermsWriterPerField field, Comparator<BytesRef> termComp) {
    this.field = field;
    this.numPostings = field.termsHashPerField.bytesHash.size();
    this.bytePool = field.perThread.termsHashPerThread.bytePool;
    this.termIDs = field.termsHashPerField.sortPostings(termComp);
    this.postings = (FreqProxPostingsArray) field.termsHashPerField.postingsArray;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979003/fstmerge_base_1223506925775772810
public FreqProxFieldMergeState(FreqProxTermsWriterPerField field, Comparator<BytesRef> termComp) {
    this.field = field;
    this.numPostings = field.termsHashPerField.numPostings;
    this.bytePool = field.perThread.termsHashPerThread.bytePool;
    this.termIDs = field.termsHashPerField.sortPostings(termComp);
    this.postings = (FreqProxPostingsArray) field.termsHashPerField.postingsArray;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979003/fstmerge_var2_7349868337522884185

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/index/FreqProxFieldMergeState.java
Conflict type: LineBasedMCFd
Conflict body: 
public QueryParser(Version matchVersion, String f, Analyzer a) {
    this(new FastCharStream(new StringReader("")));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979331/fstmerge_var1_5734503962979581533
    init(matchVersion, f, a);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979331/fstmerge_base_7777133638380936164
    analyzer = a;
    field = f;
    if (matchVersion.onOrAfter(Version.LUCENE_29)) {
      enablePositionIncrements = true;
    } else {
      enablePositionIncrements = false;
    }
=======
    analyzer = a;
    field = f;
    if (matchVersion.onOrAfter(Version.LUCENE_29)) {
      enablePositionIncrements = true;
    } else {
      enablePositionIncrements = false;
    }
    if (matchVersion.onOrAfter(Version.LUCENE_31)) {
      setAutoGeneratePhraseQueries(false);
    } else {
      setAutoGeneratePhraseQueries(true);
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979331/fstmerge_var2_7390081287144387105
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/queryParser/QueryParser.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979456/fstmerge_var1_4482042966176348526
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979456/fstmerge_base_404652008477433551
protected Query getFieldQuery(String field, String queryText)  throws ParseException {
    // Use the analyzer to get all the tokens, and then build a TermQuery,
    // PhraseQuery, or nothing based on the term count

    TokenStream source;
    try {
      source = analyzer.reusableTokenStream(field, new StringReader(queryText));
      source.reset();
    } catch (IOException e) {
      source = analyzer.tokenStream(field, new StringReader(queryText));
    }
    CachingTokenFilter buffer = new CachingTokenFilter(source);
    CharTermAttribute termAtt = null;
    PositionIncrementAttribute posIncrAtt = null;
    int numTokens = 0;

    boolean success = false;
    try {
      buffer.reset();
      success = true;
    } catch (IOException e) {
      // success==false if we hit an exception
    }
    if (success) {
      if (buffer.hasAttribute(CharTermAttribute.class)) {
        termAtt = buffer.getAttribute(CharTermAttribute.class);
      }
      if (buffer.hasAttribute(PositionIncrementAttribute.class)) {
        posIncrAtt = buffer.getAttribute(PositionIncrementAttribute.class);
      }
    }

    int positionCount = 0;
    boolean severalTokensAtSamePosition = false;

    boolean hasMoreTokens = false;
    if (termAtt != null) {
      try {
        hasMoreTokens = buffer.incrementToken();
        while (hasMoreTokens) {
          numTokens++;
          int positionIncrement = (posIncrAtt != null) ? posIncrAtt.getPositionIncrement() : 1;
          if (positionIncrement != 0) {
            positionCount += positionIncrement;
          } else {
            severalTokensAtSamePosition = true;
          }
          hasMoreTokens = buffer.incrementToken();
        }
      } catch (IOException e) {
        // ignore
      }
    }
    try {
      // rewind the buffer stream
      buffer.reset();

      // close original stream - all tokens buffered
      source.close();
    }
    catch (IOException e) {
      // ignore
    }

    if (numTokens == 0)
      return null;
    else if (numTokens == 1) {
      String term = null;
      try {
        boolean hasNext = buffer.incrementToken();
        assert hasNext == true;
        term = termAtt.toString();
      } catch (IOException e) {
        // safe to ignore, because we know the number of tokens
      }
      return newTermQuery(new Term(field, term));
    } else {
      if (severalTokensAtSamePosition) {
        if (positionCount == 1) {
          // no phrase query:
          BooleanQuery q = newBooleanQuery(true);
          for (int i = 0; i < numTokens; i++) {
            String term = null;
            try {
              boolean hasNext = buffer.incrementToken();
              assert hasNext == true;
              term = termAtt.toString();
            } catch (IOException e) {
              // safe to ignore, because we know the number of tokens
            }

            Query currentQuery = newTermQuery(
                new Term(field, term));
            q.add(currentQuery, BooleanClause.Occur.SHOULD);
          }
          return q;
        }
        else {
          // phrase query:
          MultiPhraseQuery mpq = newMultiPhraseQuery();
          mpq.setSlop(phraseSlop);
          List<Term> multiTerms = new ArrayList<Term>();
          int position = -1;
          for (int i = 0; i < numTokens; i++) {
            String term = null;
            int positionIncrement = 1;
            try {
              boolean hasNext = buffer.incrementToken();
              assert hasNext == true;
              term = termAtt.toString();
              if (posIncrAtt != null) {
                positionIncrement = posIncrAtt.getPositionIncrement();
              }
            } catch (IOException e) {
              // safe to ignore, because we know the number of tokens
            }

            if (positionIncrement > 0 && multiTerms.size() > 0) {
              if (enablePositionIncrements) {
                mpq.add(multiTerms.toArray(new Term[0]),position);
              } else {
                mpq.add(multiTerms.toArray(new Term[0]));
              }
              multiTerms.clear();
            }
            position += positionIncrement;
            multiTerms.add(new Term(field, term));
          }
          if (enablePositionIncrements) {
            mpq.add(multiTerms.toArray(new Term[0]),position);
          } else {
            mpq.add(multiTerms.toArray(new Term[0]));
          }
          return mpq;
        }
      }
      else {
        PhraseQuery pq = newPhraseQuery();
        pq.setSlop(phraseSlop);
        int position = -1;


        for (int i = 0; i < numTokens; i++) {
          String term = null;
          int positionIncrement = 1;

          try {
            boolean hasNext = buffer.incrementToken();
            assert hasNext == true;
            term = termAtt.toString();
            if (posIncrAtt != null) {
              positionIncrement = posIncrAtt.getPositionIncrement();
            }
          } catch (IOException e) {
            // safe to ignore, because we know the number of tokens
          }

          if (enablePositionIncrements) {
            position += positionIncrement;
            pq.add(new Term(field, term),position);
          } else {
            pq.add(new Term(field, term));
          }
        }
        return pq;
      }
    }
  }
=======
@Deprecated
  protected Query getFieldQuery(String field, String queryText) throws ParseException {
    // treat the text as if it was quoted, to drive phrase logic with old versions.
    return getFieldQuery(field, queryText, true);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979456/fstmerge_var2_97633850232523783

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/queryParser/QueryParser.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979463/fstmerge_var1_1325157725735228637
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979463/fstmerge_base_6303324328564525627
protected Query getFieldQuery(String field, String queryText, int slop)
        throws ParseException {
    Query query = getFieldQuery(field, queryText);

    if (query instanceof PhraseQuery) {
      ((PhraseQuery) query).setSlop(slop);
    }
    if (query instanceof MultiPhraseQuery) {
      ((MultiPhraseQuery) query).setSlop(slop);
    }

    return query;
  }
=======
protected Query getFieldQuery(String field, String queryText, int slop)
        throws ParseException {
    Query query = hasNewAPI ? getFieldQuery(field, queryText, true) : getFieldQuery(field, queryText);

    if (query instanceof PhraseQuery) {
      ((PhraseQuery) query).setSlop(slop);
    }
    if (query instanceof MultiPhraseQuery) {
      ((MultiPhraseQuery) query).setSlop(slop);
    }

    return query;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979463/fstmerge_var2_3734514180856040971

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/queryParser/QueryParser.java
Conflict type: LineBasedMCFd
Conflict body: 
final public Query Term(String field) throws ParseException {
  Token term, boost=null, fuzzySlop=null, goop1, goop2;
  boolean prefix = false;
  boolean wildcard = false;
  boolean fuzzy = false;
  boolean regexp = false;
  boolean startInc=false;
  boolean endInc=false;
  Query q;
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case BAREOPER:
    case STAR:
    case TERM:
    case PREFIXTERM:
    case WILDTERM:
    case REGEXPTERM:
    case NUMBER:
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case TERM:
        term = jj_consume_token(TERM);
        break;
      case STAR:
        term = jj_consume_token(STAR);
                       wildcard=true;
        break;
      case PREFIXTERM:
        term = jj_consume_token(PREFIXTERM);
                             prefix=true;
        break;
      case WILDTERM:
        term = jj_consume_token(WILDTERM);
                           wildcard=true;
        break;
      case REGEXPTERM:
        term = jj_consume_token(REGEXPTERM);
                             regexp=true;
        break;
      case NUMBER:
        term = jj_consume_token(NUMBER);
        break;
      case BAREOPER:
        term = jj_consume_token(BAREOPER);
                           term.image = term.image.substring(0,1);
        break;
      default:
        jj_la1[8] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case FUZZY_SLOP:
        fuzzySlop = jj_consume_token(FUZZY_SLOP);
                                fuzzy=true;
        break;
      default:
        jj_la1[9] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
        case FUZZY_SLOP:
          fuzzySlop = jj_consume_token(FUZZY_SLOP);
                                                         fuzzy=true;
          break;
        default:
          jj_la1[10] = jj_gen;
          ;
        }
        break;
      default:
        jj_la1[11] = jj_gen;
        ;
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979576/fstmerge_var1_707118988548385900
       q = handleBareTokenQuery(field, term, fuzzySlop, prefix, wildcard, fuzzy, regexp);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979576/fstmerge_base_9064782516076153216
       String termImage=discardEscapeChar(term.image);
       if (wildcard) {
       q = getWildcardQuery(field, termImage);
       } else if (prefix) {
         q = getPrefixQuery(field,
           discardEscapeChar(term.image.substring
          (0, term.image.length()-1)));
       } else if (fuzzy) {
          float fms = fuzzyMinSim;
          try {
            fms = Float.valueOf(fuzzySlop.image.substring(1)).floatValue();
          } catch (Exception ignored) { }
         if(fms < 0.0f || fms > 1.0f){
           {if (true) throw new ParseException("Minimum similarity for a FuzzyQuery has to be between 0.0f and 1.0f !");}
         }
         q = getFuzzyQuery(field, termImage,fms);
       } else {
         q = getFieldQuery(field, termImage);
       }
=======
       String termImage=discardEscapeChar(term.image);
       if (wildcard) {
       q = getWildcardQuery(field, termImage);
       } else if (prefix) {
         q = getPrefixQuery(field,
           discardEscapeChar(term.image.substring
          (0, term.image.length()-1)));
       } else if (fuzzy) {
          float fms = fuzzyMinSim;
          try {
            fms = Float.valueOf(fuzzySlop.image.substring(1)).floatValue();
          } catch (Exception ignored) { }
         if(fms < 0.0f || fms > 1.0f){
           {if (true) throw new ParseException("Minimum similarity for a FuzzyQuery has to be between 0.0f and 1.0f !");}
         }
         q = getFuzzyQuery(field, termImage,fms);
       } else {
         q = hasNewAPI ? getFieldQuery(field, termImage, false) : getFieldQuery(field, termImage);
       }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627979576/fstmerge_var2_3754404483881684180
      break;
    case RANGEIN_START:
    case RANGEEX_START:
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEIN_START:
        jj_consume_token(RANGEIN_START);
                            startInc=true;
        break;
      case RANGEEX_START:
        jj_consume_token(RANGEEX_START);
        break;
      default:
        jj_la1[12] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGE_GOOP:
        goop1 = jj_consume_token(RANGE_GOOP);
        break;
      case RANGE_QUOTED:
        goop1 = jj_consume_token(RANGE_QUOTED);
        break;
      default:
        jj_la1[13] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGE_TO:
        jj_consume_token(RANGE_TO);
        break;
      default:
        jj_la1[14] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGE_GOOP:
        goop2 = jj_consume_token(RANGE_GOOP);
        break;
      case RANGE_QUOTED:
        goop2 = jj_consume_token(RANGE_QUOTED);
        break;
      default:
        jj_la1[15] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEIN_END:
        jj_consume_token(RANGEIN_END);
                          endInc=true;
        break;
      case RANGEEX_END:
        jj_consume_token(RANGEEX_END);
        break;
      default:
        jj_la1[16] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[17] = jj_gen;
        ;
      }
          boolean startOpen=false;
          boolean endOpen=false;
          if (goop1.kind == RANGE_QUOTED) {
            goop1.image = goop1.image.substring(1, goop1.image.length()-1);
          } else if ("*".equals(goop1.image)) {
            startOpen=true;
          }
          if (goop2.kind == RANGE_QUOTED) {
            goop2.image = goop2.image.substring(1, goop2.image.length()-1);
          } else if ("*".equals(goop2.image)) {
            endOpen=true;
          }
          q = getRangeQuery(field, startOpen ? null : discardEscapeChar(goop1.image), endOpen ? null : discardEscapeChar(goop2.image), startInc, endInc);
      break;
    case QUOTED:
      term = jj_consume_token(QUOTED);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case FUZZY_SLOP:
        fuzzySlop = jj_consume_token(FUZZY_SLOP);
        break;
      default:
        jj_la1[18] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[19] = jj_gen;
        ;
      }
         q = handleQuotedTerm(field, term, fuzzySlop);
      break;
    default:
      jj_la1[20] = jj_gen;
      jj_consume_token(-1);
      throw new ParseException();
    }
    {if (true) return handleBoost(q, boost);}
    throw new Error("Missing return statement in function");
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/src/java/org/apache/lucene/queryParser/QueryParser.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980443/fstmerge_var1_2299568744881390957
public void testLatLonCorner() throws Exception {
    double[] zero = new double[]{0, 0};
    double[] zero45 = new double[]{0, DistanceUtils.DEG_45_AS_RADS};
    double[] result;
    // 	00°38′09″N, 000°38′09″E
    //Verify at http://www.movable-type.co.uk/scripts/latlong.html
    result = DistanceUtils.latLonCorner(zero[0], zero[1], 100, null, true, DistanceUtils.EARTH_MEAN_RADIUS_KM);
    assertEquals(0.63583 * DistanceUtils.DEGREES_TO_RADIANS, result[0], 0.001);
    assertEquals(0.63583 * DistanceUtils.DEGREES_TO_RADIANS, result[1], 0.001);

    result = DistanceUtils.latLonCornerDegs(zero[0], zero[1], 100, null, true, DistanceUtils.EARTH_MEAN_RADIUS_KM);
    // 	00°38′09″N, 000°38′09″E
    assertEquals(0.63583, result[0], 0.001);
    assertEquals(0.63583, result[1], 0.001);

    result = DistanceUtils.latLonCornerDegs(zero[0], zero[1], 100, null, false, DistanceUtils.EARTH_MEAN_RADIUS_KM);
    // 	00°38′09″N, 000°38′09″E
    assertEquals(-0.63583, result[0], 0.001);
    assertEquals(-0.63583, result[1], 0.001);

    //test some edge cases
    //89°16′02″N, 060°12′35″E
    result = DistanceUtils.latLonCornerDegs(89.0, 0, 100, null, true, DistanceUtils.EARTH_MEAN_RADIUS_KM);
    assertEquals(89.26722, result[0], 0.001);
    assertEquals(60.20972, result[1], 0.001);

    result = DistanceUtils.latLonCornerDegs(0, -179.0, 100, null, true, DistanceUtils.EARTH_MEAN_RADIUS_KM);
    assertEquals(0.63583, result[0], 0.001);
    assertEquals(-178.36417, result[1], 0.001);

  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980443/fstmerge_base_6794396904544120078
=======
public void testLatLonCorner() throws Exception {
    double[] zero = new double[]{0, 0};
    double[] zero45 = new double[]{0, DistanceUtils.DEG_45};
    double[] result;
    // 	00°38′09″N, 000°38′09″E
    //Verify at http://www.movable-type.co.uk/scripts/latlong.html
    result = DistanceUtils.latLonCorner(zero[0], zero[1], 100, null, true, DistanceUtils.EARTH_MEAN_RADIUS_KM);
    assertEquals(0.63583 * DistanceUtils.DEGREES_TO_RADIANS, result[0], 0.001);
    assertEquals(0.63583 * DistanceUtils.DEGREES_TO_RADIANS, result[1], 0.001);

    result = DistanceUtils.latLonCornerDegs(zero[0], zero[1], 100, null, true, DistanceUtils.EARTH_MEAN_RADIUS_KM);
    // 	00°38′09″N, 000°38′09″E
    assertEquals(0.63583, result[0], 0.001);
    assertEquals(0.63583, result[1], 0.001);

    result = DistanceUtils.latLonCornerDegs(zero[0], zero[1], 100, null, false, DistanceUtils.EARTH_MEAN_RADIUS_KM);
    // 	00°38′09″N, 000°38′09″E
    assertEquals(-0.63583, result[0], 0.001);
    assertEquals(-0.63583, result[1], 0.001);

    //test some edge cases
    //89°16′02″N, 060°12′35″E
    result = DistanceUtils.latLonCornerDegs(89.0, 0, 100, null, true, DistanceUtils.EARTH_MEAN_RADIUS_KM);
    assertEquals(89.26722, result[0], 0.001);
    assertEquals(60.20972, result[1], 0.001);

    result = DistanceUtils.latLonCornerDegs(0, -179.0, 100, null, true, DistanceUtils.EARTH_MEAN_RADIUS_KM);
    assertEquals(0.63583, result[0], 0.001);
    assertEquals(-178.36417, result[1], 0.001);

  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980443/fstmerge_var2_3269523135608007634

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/spatial/src/test/org/apache/lucene/spatial/DistanceUtilsTest.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980447/fstmerge_var1_1508187048218171449
public void testVectorDistance() throws Exception {
    double[] zero = new double[]{0, 0};

    double[] zeroOne = new double[]{0, 1};
    double[] oneZero = new double[]{1, 0};
    double[] oneOne = new double[]{1, 1};
    double distance;
    distance = DistanceUtils.vectorDistance(zero, zeroOne, 2);
    assertEquals(1.0, distance);
    distance = DistanceUtils.vectorDistance(zero, oneZero, 2);
    assertEquals(1.0, distance);
    distance = DistanceUtils.vectorDistance(zero, oneOne, 2);
    assertEquals(Math.sqrt(2), distance, 0.001);

    distance = DistanceUtils.squaredEuclideanDistance(zero, oneOne);
    assertEquals(2, distance, 0.001);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980447/fstmerge_base_6264747932621025242
=======
public void testVectorDistance() throws Exception {
    double[] zero = new double[]{0, 0};
    double[] zeroOne = new double[]{0, 1};
    double[] oneZero = new double[]{1, 0};
    double[] oneOne = new double[]{1, 1};
    double distance;
    distance = DistanceUtils.vectorDistance(zero, zeroOne, 2);
    assertEquals(1.0, distance);
    distance = DistanceUtils.vectorDistance(zero, oneZero, 2);
    assertEquals(1.0, distance);
    distance = DistanceUtils.vectorDistance(zero, oneOne, 2);
    assertEquals(Math.sqrt(2), distance, 0.001);

    distance = DistanceUtils.squaredEuclideanDistance(zero, oneOne);
    assertEquals(2, distance, 0.001);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980447/fstmerge_var2_8374778585155224150

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/spatial/src/test/org/apache/lucene/spatial/DistanceUtilsTest.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980601/fstmerge_var1_723534720607238121
public static double[] vectorBoxCorner(double[] center, double[] result, double distance, boolean upperRight) {
    if (result == null || result.length != center.length) {
      result = new double[center.length];
    }
    if (upperRight == false) {
      distance = -distance;
    }
    //We don't care about the power here,
    // b/c we are always in a rectangular coordinate system, so any norm can be used by
    //using the definition of sine
    distance = SIN_45_AS_RADS * distance; // sin(Pi/4) == (2^0.5)/2 == opp/hyp == opp/distance, solve for opp, similarily for cosine
    for (int i = 0; i < center.length; i++) {
      result[i] = center[i] + distance;
    }
    return result;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980601/fstmerge_base_8099283185213173485
=======
public static double[] vectorBoxCorner(double[] center, double[] result, double distance, boolean upperRight) {
    if (result == null || result.length != center.length) {
      result = new double[center.length];
    }
    if (upperRight == false) {
      distance = -distance;
    }
    //We don't care about the power here,
    // b/c we are always in a rectangular coordinate system, so any norm can be used by
    //using the definition of sine
    distance = SIN_45 * distance; // sin(Pi/4) == (2^0.5)/2 == opp/hyp == opp/distance, solve for opp, similarily for cosine
    for (int i = 0; i < center.length; i++) {
      result[i] = center[i] + distance;
    }
    return result;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980601/fstmerge_var2_2365916654213748471

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/DistanceUtils.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980605/fstmerge_var1_3425909276161375359
public static double[] latLonCornerDegs(double latCenter, double lonCenter,
                                          double distance, double [] result,
                                          boolean upperRight, double sphereRadius) {
    result = latLonCorner(latCenter * DEGREES_TO_RADIANS,
            lonCenter * DEGREES_TO_RADIANS, distance, result, upperRight, sphereRadius);
    result[0] = result[0] * RADIANS_TO_DEGREES;
    result[1] = result[1] * RADIANS_TO_DEGREES;
    return result;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980605/fstmerge_base_6620774612054701383
=======
public static double[] latLonCornerDegs(double latCenter, double lonCenter,
                                          double distance, double [] result,
                                          boolean upperRight, double radius) {
    result = latLonCorner(latCenter * DEGREES_TO_RADIANS,
            lonCenter * DEGREES_TO_RADIANS, distance, result, upperRight, radius);
    result[0] = result[0] * RADIANS_TO_DEGREES;
    result[1] = result[1] * RADIANS_TO_DEGREES;
    return result;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980605/fstmerge_var2_7395431336597015710

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/DistanceUtils.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980610/fstmerge_var1_6497660577970388423
public static double[] latLonCorner(double latCenter, double lonCenter,
                                      double distance, double [] result, boolean upperRight, double sphereRadius) {
    // Haversine formula
    double brng = upperRight ? DEG_45_AS_RADS : DEG_225_AS_RADS;
    result = pointOnBearing(latCenter, lonCenter, distance, brng, result, sphereRadius);

    return result;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980610/fstmerge_base_1599683109492146058
=======
public static double[] latLonCorner(double latCenter, double lonCenter,
                                      double distance, double [] result, boolean upperRight, double radius) {
    // Haversine formula
    double brng = upperRight ? DEG_45 : DEG_225;
    double lat2 = Math.asin(Math.sin(latCenter) * Math.cos(distance / radius) +
            Math.cos(latCenter) * Math.sin(distance / radius) * Math.cos(brng));
    double lon2 = lonCenter + Math.atan2(Math.sin(brng) * Math.sin(distance / radius) * Math.cos(latCenter),
            Math.cos(distance / radius) - Math.sin(latCenter) * Math.sin(lat2));

    /*lat2 = (lat2*180)/Math.PI;
    lon2 = (lon2*180)/Math.PI;*/
    //From Lucene.  Move back to Lucene when synced
    // normalize long first
    if (result == null || result.length != 2){
      result = new double[2];
    }
    result[0] = lat2;
    result[1] = lon2;
    normLng(result);

    // normalize lat - could flip poles
    normLat(result);

    return result;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980610/fstmerge_var2_8650865808055481617

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/DistanceUtils.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980614/fstmerge_var1_6692744028068075342
public static void normLat(double[] latLng) {

    if (latLng[0] > DEG_90_AS_RADS) {
      latLng[0] = DEG_90_AS_RADS - (latLng[0] - DEG_90_AS_RADS);
      if (latLng[1] < 0) {
        latLng[1] = latLng[1] + DEG_180_AS_RADS;
      } else {
        latLng[1] = latLng[1] - DEG_180_AS_RADS;
      }
    } else if (latLng[0] < -DEG_90_AS_RADS) {
      latLng[0] = -DEG_90_AS_RADS - (latLng[0] + DEG_90_AS_RADS);
      if (latLng[1] < 0) {
        latLng[1] = latLng[1] + DEG_180_AS_RADS;
      } else {
        latLng[1] = latLng[1] - DEG_180_AS_RADS;
      }
    }

  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980614/fstmerge_base_2167970778192066929
=======
public static void normLat(double[] latLng) {

    if (latLng[0] > DEG_90) {
      latLng[0] = DEG_90 - (latLng[0] - DEG_90);
      if (latLng[1] < 0) {
        latLng[1] = latLng[1] + DEG_180;
      } else {
        latLng[1] = latLng[1] - DEG_180;
      }
    } else if (latLng[0] < -DEG_90) {
      latLng[0] = -DEG_90 - (latLng[0] + DEG_90);
      if (latLng[1] < 0) {
        latLng[1] = latLng[1] + DEG_180;
      } else {
        latLng[1] = latLng[1] - DEG_180;
      }
    }

  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980614/fstmerge_var2_6389439061719165241

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/DistanceUtils.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980619/fstmerge_var1_6997352289104346229
public static void normLng(double[] latLng) {
    if (latLng[1] > DEG_180_AS_RADS) {
      latLng[1] = -1.0 * (DEG_180_AS_RADS - (latLng[1] - DEG_180_AS_RADS));
    } else if (latLng[1] < -DEG_180_AS_RADS) {
      latLng[1] = (latLng[1] + DEG_180_AS_RADS) + DEG_180_AS_RADS;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980619/fstmerge_base_9014703104580737609
=======
public static void normLng(double[] latLng) {
    if (latLng[1] > DEG_180) {
      latLng[1] = -1.0 * (DEG_180 - (latLng[1] - DEG_180));
    } else if (latLng[1] < -DEG_180) {
      latLng[1] = (latLng[1] + DEG_180) + DEG_180;
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627980619/fstmerge_var2_7575375581049606306

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/DistanceUtils.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981688/fstmerge_var1_6500335391796355904
public void testTermsEnum() throws Exception {

    InstantiatedIndex ii = new InstantiatedIndex();
    IndexReader r = new InstantiatedIndexReader(ii);
    termsEnumTest(r);
    r.close();
    ii.close();

    // make sure a Directory acts the same
    Directory d = newDirectory();
    new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())).close();
    r = IndexReader.open(d, false);
    termsEnumTest(r);
    r.close();
    d.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981688/fstmerge_base_7092264718798486674
=======
public void testTermsEnum() throws Exception {

    InstantiatedIndex ii = new InstantiatedIndex();
    IndexReader r = new InstantiatedIndexReader(ii);
    termsEnumTest(r);
    r.close();
    ii.close();

    // make sure a Directory acts the same

    Directory d = new RAMDirectory();
    new IndexWriter(d, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())).close();
    r = IndexReader.open(d, false);
    termsEnumTest(r);
    r.close();
    d.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981688/fstmerge_var2_3271515702895272968

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestEmptyIndex.java
Conflict type: LineBasedMCFd
Conflict body: 
protected void testEquals(Directory aprioriIndex, InstantiatedIndex testIndex) throws Exception {

    testTermDocsSomeMore(aprioriIndex, testIndex);

    IndexReader aprioriReader = IndexReader.open(aprioriIndex, false);
    IndexReader testReader = testIndex.indexReaderFactory();

    assertEquals(aprioriReader.numDocs(), testReader.numDocs());

    // assert field options
    assertEquals(aprioriReader.getFieldNames(IndexReader.FieldOption.INDEXED), testReader.getFieldNames(IndexReader.FieldOption.INDEXED));
    assertEquals(aprioriReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR), testReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR));
    assertEquals(aprioriReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR), testReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR));
    assertEquals(aprioriReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS), testReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS));
    assertEquals(aprioriReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR), testReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR));
    assertEquals(aprioriReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET), testReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET));
    assertEquals(aprioriReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION), testReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION));
    assertEquals(aprioriReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET), testReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET));
    assertEquals(aprioriReader.getFieldNames(IndexReader.FieldOption.UNINDEXED), testReader.getFieldNames(IndexReader.FieldOption.UNINDEXED));

    for (Object field : aprioriReader.getFieldNames(IndexReader.FieldOption.ALL)) {

      // test norms as used by normal use

      byte[] aprioriNorms = aprioriReader.norms((String) field);
      byte[] testNorms = testReader.norms((String) field);

      if (aprioriNorms != null) {
        assertEquals(aprioriNorms.length, testNorms.length);

        for (int i = 0; i < aprioriNorms.length; i++) {
          assertEquals("norms does not equals for field " + field + " in document " + i, aprioriNorms[i], testNorms[i]);
        }

        // test norms as used by multireader

        aprioriNorms = new byte[aprioriReader.maxDoc()];
        aprioriReader.norms((String) field, aprioriNorms, 0);

        testNorms = new byte[testReader.maxDoc()];
        testReader.norms((String) field, testNorms, 0);

        assertEquals(aprioriNorms.length, testNorms.length);

        for (int i = 0; i < aprioriNorms.length; i++) {
          assertEquals("norms does not equals for field " + field + " in document " + i, aprioriNorms[i], testNorms[i]);
        }


        // test norms as used by multireader

        aprioriNorms = new byte[aprioriReader.maxDoc() + 10];
        aprioriReader.norms((String) field, aprioriNorms, 10);

        testNorms = new byte[testReader.maxDoc() + 10];
        testReader.norms((String) field, testNorms, 10);

        assertEquals(aprioriNorms.length, testNorms.length);
        
        for (int i = 0; i < aprioriNorms.length; i++) {
          assertEquals("norms does not equals for field " + field + " in document " + i, aprioriNorms[i], testNorms[i]);
        }
      }
    }

    final Bits apDelDocs = MultiFields.getDeletedDocs(aprioriReader);
    final Bits testDelDocs = MultiFields.getDeletedDocs(testReader);
    assertTrue((apDelDocs != null && testDelDocs != null) || 
               (apDelDocs == null && testDelDocs == null));
    if (apDelDocs != null) {
      for (int docIndex = 0; docIndex < aprioriReader.numDocs(); docIndex++) {
        assertEquals(apDelDocs.get(docIndex), testDelDocs.get(docIndex));
      }
    }

    // compare term enumeration stepping

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
    TermEnum aprioriTermEnum = aprioriReader.terms();
    TermEnum testTermEnum = testReader.terms();
=======
    FieldsEnum aprioriFieldsEnum = MultiFields.getFields(aprioriReader).iterator();
    FieldsEnum testFieldsEnum = MultiFields.getFields(testReader).iterator();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
=======
    String aprioriField;
    while((aprioriField = aprioriFieldsEnum.next()) != null) {
      String testField = testFieldsEnum.next();
      assertEquals(aprioriField, testField);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
    while (true) {
=======
      TermsEnum aprioriTermEnum = aprioriFieldsEnum.terms();
      TermsEnum testTermEnum = testFieldsEnum.terms();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
      if (!aprioriTermEnum.next()) {
        assertFalse(testTermEnum.next());
        break;
      }
      assertTrue(testTermEnum.next());
=======
      BytesRef aprioriText;
      while((aprioriText = aprioriTermEnum.next()) != null) {
        assertEquals(aprioriText, testTermEnum.next());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
      assertEquals(aprioriTermEnum.term(), testTermEnum.term());
      assertTrue(aprioriTermEnum.docFreq() == testTermEnum.docFreq());
=======
        assertTrue(aprioriTermEnum.docFreq() == testTermEnum.docFreq());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
      // compare termDocs seeking
=======
        // compare termDocs seeking
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
      TermDocs aprioriTermDocsSeeker = aprioriReader.termDocs(aprioriTermEnum.term());
      TermDocs testTermDocsSeeker = testReader.termDocs(testTermEnum.term());
=======
        DocsEnum aprioriTermDocs = aprioriTermEnum.docs(MultiFields.getDeletedDocs(aprioriReader), null);
        DocsEnum testTermDocs = testTermEnum.docs(MultiFields.getDeletedDocs(testReader), null);
        
        while (aprioriTermDocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {
          assertTrue(testTermDocs.advance(aprioriTermDocs.docID()) != DocsEnum.NO_MORE_DOCS);
          assertEquals(aprioriTermDocs.docID(), testTermDocs.docID());
        }
        
        // compare documents per term
        
        assertEquals(aprioriReader.docFreq(aprioriField, aprioriTermEnum.term()), testReader.docFreq(aprioriField, testTermEnum.term()));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
      while (aprioriTermDocsSeeker.next()) {
        assertTrue(testTermDocsSeeker.skipTo(aprioriTermDocsSeeker.doc()));
        assertEquals(aprioriTermDocsSeeker.doc(), testTermDocsSeeker.doc());
      }
=======
        aprioriTermDocs = aprioriTermEnum.docs(MultiFields.getDeletedDocs(aprioriReader), aprioriTermDocs);
        testTermDocs = testTermEnum.docs(MultiFields.getDeletedDocs(testReader), testTermDocs);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
      aprioriTermDocsSeeker.close();
      testTermDocsSeeker.close();

      // compare documents per term

      assertEquals(aprioriReader.docFreq(aprioriTermEnum.term()), testReader.docFreq(testTermEnum.term()));

      TermDocs aprioriTermDocs = aprioriReader.termDocs(aprioriTermEnum.term());
      TermDocs testTermDocs = testReader.termDocs(testTermEnum.term());

      while (true) {
        if (!aprioriTermDocs.next()) {
          assertFalse(testTermDocs.next());
          break;
=======
        while (true) {
          if (aprioriTermDocs.nextDoc() == DocsEnum.NO_MORE_DOCS) {
            assertEquals(DocsEnum.NO_MORE_DOCS, testTermDocs.nextDoc());
            break;
          }
          assertTrue(testTermDocs.nextDoc() != DocsEnum.NO_MORE_DOCS);

          assertEquals(aprioriTermDocs.docID(), testTermDocs.docID());
          assertEquals(aprioriTermDocs.freq(), testTermDocs.freq());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850
        }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var1_6508652377257356855

        // compare term positions
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
        assertTrue(testTermDocs.next());

        assertEquals(aprioriTermDocs.doc(), testTermDocs.doc());
        assertEquals(aprioriTermDocs.freq(), testTermDocs.freq());
      }

      aprioriTermDocs.close();
      testTermDocs.close();

      // compare term positions
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var1_6508652377257356855
        DocsAndPositionsEnum aprioriTermPositions = aprioriTermEnum.docsAndPositions(MultiFields.getDeletedDocs(aprioriReader), null);
        DocsAndPositionsEnum testTermPositions = testTermEnum.docsAndPositions(MultiFields.getDeletedDocs(testReader), null);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
      TermPositions testTermPositions = testReader.termPositions(testTermEnum.term());
      TermPositions aprioriTermPositions = aprioriReader.termPositions(aprioriTermEnum.term());
=======
        // compare term positions
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var1_6508652377257356855
        if (aprioriTermPositions != null) {
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
      if (aprioriTermPositions != null) {
=======
        DocsAndPositionsEnum aprioriTermPositions = aprioriTermEnum.docsAndPositions(MultiFields.getDeletedDocs(aprioriReader), null);
        DocsAndPositionsEnum testTermPositions = testTermEnum.docsAndPositions(MultiFields.getDeletedDocs(testReader), null);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var1_6508652377257356855
          for (int docIndex = 0; docIndex < aprioriReader.maxDoc(); docIndex++) {
            boolean hasNext = aprioriTermPositions.nextDoc() != DocsEnum.NO_MORE_DOCS;
            if (hasNext) {
              assertTrue(testTermPositions.nextDoc() != DocsEnum.NO_MORE_DOCS);
              
              assertEquals(aprioriTermPositions.freq(), testTermPositions.freq());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
        for (int docIndex = 0; docIndex < aprioriReader.maxDoc(); docIndex++) {
          boolean hasNext = aprioriTermPositions.next();
          if (hasNext) {
            assertTrue(testTermPositions.next());
=======
        if (aprioriTermPositions != null) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var1_6508652377257356855
              for (int termPositionIndex = 0; termPositionIndex < aprioriTermPositions.freq(); termPositionIndex++) {
                int aprioriPos = aprioriTermPositions.nextPosition();
                int testPos = testTermPositions.nextPosition();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
            assertEquals(aprioriTermPositions.freq(), testTermPositions.freq());
=======
          for (int docIndex = 0; docIndex < aprioriReader.maxDoc(); docIndex++) {
            boolean hasNext = aprioriTermPositions.nextDoc() != DocsEnum.NO_MORE_DOCS;
            if (hasNext) {
              assertTrue(testTermPositions.nextDoc() != DocsEnum.NO_MORE_DOCS);
              
              assertEquals(aprioriTermPositions.freq(), testTermPositions.freq());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var1_6508652377257356855
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776

            for (int termPositionIndex = 0; termPositionIndex < aprioriTermPositions.freq(); termPositionIndex++) {
              int aprioriPos = aprioriTermPositions.nextPosition();
              int testPos = testTermPositions.nextPosition();

              if (aprioriPos != testPos) {
=======
              for (int termPositionIndex = 0; termPositionIndex < aprioriTermPositions.freq(); termPositionIndex++) {
                int aprioriPos = aprioriTermPositions.nextPosition();
                int testPos = testTermPositions.nextPosition();

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850
                assertEquals(aprioriPos, testPos);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
              }


              assertEquals(aprioriTermPositions.isPayloadAvailable(), testTermPositions.isPayloadAvailable());
              if (aprioriTermPositions.isPayloadAvailable()) {
                assertEquals(aprioriTermPositions.getPayloadLength(), testTermPositions.getPayloadLength());
                byte[] aprioriPayloads = aprioriTermPositions.getPayload(new byte[aprioriTermPositions.getPayloadLength()], 0);
                byte[] testPayloads = testTermPositions.getPayload(new byte[testTermPositions.getPayloadLength()], 0);
                for (int i = 0; i < aprioriPayloads.length; i++) {
                  assertEquals(aprioriPayloads[i], testPayloads[i]);
=======

                assertEquals(aprioriTermPositions.hasPayload(), testTermPositions.hasPayload());
                if (aprioriTermPositions.hasPayload()) {
                  BytesRef apPayload = aprioriTermPositions.getPayload();
                  BytesRef testPayload = testTermPositions.getPayload();
                  assertEquals(apPayload, testPayload);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850
                }
              }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776

=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850
            }
          }
        }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776

        aprioriTermPositions.close();
        testTermPositions.close();

=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
=======
      assertNull(testTermEnum.next());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
=======
    assertNull(testFieldsEnum.next());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850

    // compare term vectors and position vectors

    for (int documentNumber = 0; documentNumber < aprioriReader.numDocs(); documentNumber++) {

      if (documentNumber > 0) {
        assertNotNull(aprioriReader.getTermFreqVector(documentNumber, "b0"));
        assertNull(aprioriReader.getTermFreqVector(documentNumber, "b1"));

        assertNotNull(testReader.getTermFreqVector(documentNumber, "b0"));
        assertNull(testReader.getTermFreqVector(documentNumber, "b1"));

      }

      TermFreqVector[] aprioriFreqVectors = aprioriReader.getTermFreqVectors(documentNumber);
      TermFreqVector[] testFreqVectors = testReader.getTermFreqVectors(documentNumber);

      if (aprioriFreqVectors != null && testFreqVectors != null) {

        Arrays.sort(aprioriFreqVectors, new Comparator<TermFreqVector>() {
          public int compare(TermFreqVector termFreqVector, TermFreqVector termFreqVector1) {
            return termFreqVector.getField().compareTo(termFreqVector1.getField());
          }
        });
        Arrays.sort(testFreqVectors, new Comparator<TermFreqVector>() {
          public int compare(TermFreqVector termFreqVector, TermFreqVector termFreqVector1) {
            return termFreqVector.getField().compareTo(termFreqVector1.getField());
          }
        });

        assertEquals("document " + documentNumber + " vectors does not match", aprioriFreqVectors.length, testFreqVectors.length);

        for (int freqVectorIndex = 0; freqVectorIndex < aprioriFreqVectors.length; freqVectorIndex++) {
          assertTrue(Arrays.equals(aprioriFreqVectors[freqVectorIndex].getTermFrequencies(), testFreqVectors[freqVectorIndex].getTermFrequencies()));
          assertTrue(Arrays.equals(aprioriFreqVectors[freqVectorIndex].getTerms(), testFreqVectors[freqVectorIndex].getTerms()));

          if (aprioriFreqVectors[freqVectorIndex] instanceof TermPositionVector) {
            TermPositionVector aprioriTermPositionVector = (TermPositionVector) aprioriFreqVectors[freqVectorIndex];
            TermPositionVector testTermPositionVector = (TermPositionVector) testFreqVectors[freqVectorIndex];

            for (int positionVectorIndex = 0; positionVectorIndex < aprioriFreqVectors[freqVectorIndex].getTerms().length; positionVectorIndex++)
            {
              if (aprioriTermPositionVector.getOffsets(positionVectorIndex) != null) {
                assertTrue(Arrays.equals(aprioriTermPositionVector.getOffsets(positionVectorIndex), testTermPositionVector.getOffsets(positionVectorIndex)));
              }

              if (aprioriTermPositionVector.getTermPositions(positionVectorIndex) != null) {
                assertTrue(Arrays.equals(aprioriTermPositionVector.getTermPositions(positionVectorIndex), testTermPositionVector.getTermPositions(positionVectorIndex)));
              }
            }
          }

        }
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776

=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850
    }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_base_7975023584741436776
    aprioriTermEnum.close();
    testTermEnum.close();

=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627981723/fstmerge_var2_5156510408293924850
    aprioriReader.close();
    testReader.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestIndicesEquals.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627985216/fstmerge_var1_8667563327391900021
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627985216/fstmerge_base_4599148423668886533
public void testQPA() throws Exception {
    assertQueryEquals("term term^3.0 term", qpAnalyzer, "term term^3.0 term");
    assertQueryEquals("term stop^3.0 term", qpAnalyzer, "term term");

    assertQueryEquals("term term term", qpAnalyzer, "term term term");
    assertQueryEquals("term +stop term", qpAnalyzer, "term term");
    assertQueryEquals("term -stop term", qpAnalyzer, "term term");

    assertQueryEquals("drop AND (stop) AND roll", qpAnalyzer, "+drop +roll");
    assertQueryEquals("term +(stop) term", qpAnalyzer, "term term");
    assertQueryEquals("term -(stop) term", qpAnalyzer, "term term");

    assertQueryEquals("drop AND stop AND roll", qpAnalyzer, "+drop +roll");
    assertQueryEquals("term phrase term", qpAnalyzer,
        "term \"phrase1 phrase2\" term");

    assertQueryEquals("term AND NOT phrase term", qpAnalyzer,
        "+term -\"phrase1 phrase2\" term");

    assertQueryEquals("stop^3", qpAnalyzer, "");
    assertQueryEquals("stop", qpAnalyzer, "");
    assertQueryEquals("(stop)^3", qpAnalyzer, "");
    assertQueryEquals("((stop))^3", qpAnalyzer, "");
    assertQueryEquals("(stop^3)", qpAnalyzer, "");
    assertQueryEquals("((stop)^3)", qpAnalyzer, "");
    assertQueryEquals("(stop)", qpAnalyzer, "");
    assertQueryEquals("((stop))", qpAnalyzer, "");
    assertTrue(getQuery("term term term", qpAnalyzer) instanceof BooleanQuery);
    assertTrue(getQuery("term +stop", qpAnalyzer) instanceof TermQuery);
  }
=======
public void testQPA() throws Exception {
    assertQueryEquals("term term^3.0 term", qpAnalyzer, "term term^3.0 term");
    assertQueryEquals("term stop^3.0 term", qpAnalyzer, "term term");

    assertQueryEquals("term term term", qpAnalyzer, "term term term");
    assertQueryEquals("term +stop term", qpAnalyzer, "term term");
    assertQueryEquals("term -stop term", qpAnalyzer, "term term");

    assertQueryEquals("drop AND (stop) AND roll", qpAnalyzer, "+drop +roll");
    assertQueryEquals("term +(stop) term", qpAnalyzer, "term term");
    assertQueryEquals("term -(stop) term", qpAnalyzer, "term term");

    assertQueryEquals("drop AND stop AND roll", qpAnalyzer, "+drop +roll");
    assertQueryEquals("term phrase term", qpAnalyzer,
        "term phrase1 phrase2 term");

    assertQueryEquals("term AND NOT phrase term", qpAnalyzer,
        "+term -(phrase1 phrase2) term");

    assertQueryEquals("stop^3", qpAnalyzer, "");
    assertQueryEquals("stop", qpAnalyzer, "");
    assertQueryEquals("(stop)^3", qpAnalyzer, "");
    assertQueryEquals("((stop))^3", qpAnalyzer, "");
    assertQueryEquals("(stop^3)", qpAnalyzer, "");
    assertQueryEquals("((stop)^3)", qpAnalyzer, "");
    assertQueryEquals("(stop)", qpAnalyzer, "");
    assertQueryEquals("((stop))", qpAnalyzer, "");
    assertTrue(getQuery("term term term", qpAnalyzer) instanceof BooleanQuery);
    assertTrue(getQuery("term +stop", qpAnalyzer) instanceof TermQuery);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627985216/fstmerge_var2_6802792867317454464

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testQPA() throws Exception {
    assertQueryEquals("term term term", qpAnalyzer, "term term term");
    assertQueryEquals("term +stop term", qpAnalyzer, "term term");
    assertQueryEquals("term -stop term", qpAnalyzer, "term term");
    assertQueryEquals("drop AND stop AND roll", qpAnalyzer, "+drop +roll");
    assertQueryEquals("term phrase term", qpAnalyzer,
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627985611/fstmerge_var1_4117163479903085517
        "term (phrase1 phrase2) term");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627985611/fstmerge_base_7235258736979274611
                      "term \"phrase1 phrase2\" term");
=======
                      "term (phrase1 phrase2) term");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627985611/fstmerge_var2_1479879604829776147
    // note the parens in this next assertion differ from the original
    // QueryParser behavior
    assertQueryEquals("term AND NOT phrase term", qpAnalyzer,
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627985611/fstmerge_var1_4117163479903085517
        "(+term -(phrase1 phrase2)) term");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627985611/fstmerge_base_7235258736979274611
                      "(+term -\"phrase1 phrase2\") term");
=======
                      "(+term -(phrase1 phrase2)) term");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627985611/fstmerge_var2_1479879604829776147
    assertQueryEquals("stop", qpAnalyzer, "");
    assertQueryEquals("stop OR stop AND stop", qpAnalyzer, "");
    assertTrue(getQuery("term term term", qpAnalyzer) instanceof BooleanQuery);
    assertTrue(getQuery("term +stop", qpAnalyzer) instanceof TermQuery);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/precedence/TestPrecedenceQueryParser.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627988414/fstmerge_var1_3400250220010251270
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627988414/fstmerge_base_7564450778522745756
protected Query getFieldQuery(String field, String queryText)
      throws ParseException {
    throw new UnsupportedOperationException();
  }
=======
@Deprecated
  protected Query getFieldQuery(String field, String queryText) throws ParseException {
    return getFieldQuery(field, queryText, true);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627988414/fstmerge_var2_6450176095363477554

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/QueryParserWrapper.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627990517/fstmerge_var1_4445546054860362111
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627990517/fstmerge_base_4294625390628393631
protected Query getFieldQuery(String field, String queryText, int slop)
        throws ParseException {
    Query query = getFieldQuery(field, queryText);

    if (query instanceof PhraseQuery) {
      ((PhraseQuery) query).setSlop(slop);
    }
    if (query instanceof MultiPhraseQuery) {
      ((MultiPhraseQuery) query).setSlop(slop);
    }

    return query;
  }
=======
protected Query getFieldQuery(String field, String queryText, int slop)
        throws ParseException {
    Query query = getFieldQuery(field, queryText, true);

    if (query instanceof PhraseQuery) {
      ((PhraseQuery) query).setSlop(slop);
    }
    if (query instanceof MultiPhraseQuery) {
      ((MultiPhraseQuery) query).setSlop(slop);
    }

    return query;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627990517/fstmerge_var2_6026051081073878825

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/precedence/PrecedenceQueryParser.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627990565/fstmerge_var1_8761507514002344746
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627990565/fstmerge_base_8778055678016936796
final public Query Term(String field) throws ParseException {
  Token term, boost=null, fuzzySlop=null, goop1, goop2;
  boolean prefix = false;
  boolean wildcard = false;
  boolean fuzzy = false;
  Query q;
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case TERM:
    case PREFIXTERM:
    case WILDTERM:
    case NUMBER:
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case TERM:
        term = jj_consume_token(TERM);
        break;
      case PREFIXTERM:
        term = jj_consume_token(PREFIXTERM);
                             prefix=true;
        break;
      case WILDTERM:
        term = jj_consume_token(WILDTERM);
                           wildcard=true;
        break;
      case NUMBER:
        term = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[9] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case FUZZY_SLOP:
        fuzzySlop = jj_consume_token(FUZZY_SLOP);
                                fuzzy=true;
        break;
      default:
        jj_la1[10] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
        case FUZZY_SLOP:
          fuzzySlop = jj_consume_token(FUZZY_SLOP);
                                                         fuzzy=true;
          break;
        default:
          jj_la1[11] = jj_gen;
          ;
        }
        break;
      default:
        jj_la1[12] = jj_gen;
        ;
      }
       String termImage=discardEscapeChar(term.image);
       if (wildcard) {
       q = getWildcardQuery(field, termImage);
       } else if (prefix) {
         q = getPrefixQuery(field,
           discardEscapeChar(term.image.substring
          (0, term.image.length()-1)));
       } else if (fuzzy) {
          float fms = fuzzyMinSim;
          try {
            fms = Float.valueOf(fuzzySlop.image.substring(1)).floatValue();
          } catch (Exception ignored) { }
         if(fms < 0.0f || fms > 1.0f){
           {if (true) throw new ParseException("Minimum similarity for a FuzzyQuery has to be between 0.0f and 1.0f !");}
         }
         q = getFuzzyQuery(field, termImage, fms);
       } else {
         q = getFieldQuery(field, termImage);
       }
      break;
    case RANGEIN_START:
      jj_consume_token(RANGEIN_START);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEIN_GOOP:
        goop1 = jj_consume_token(RANGEIN_GOOP);
        break;
      case RANGEIN_QUOTED:
        goop1 = jj_consume_token(RANGEIN_QUOTED);
        break;
      default:
        jj_la1[13] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEIN_TO:
        jj_consume_token(RANGEIN_TO);
        break;
      default:
        jj_la1[14] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEIN_GOOP:
        goop2 = jj_consume_token(RANGEIN_GOOP);
        break;
      case RANGEIN_QUOTED:
        goop2 = jj_consume_token(RANGEIN_QUOTED);
        break;
      default:
        jj_la1[15] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      jj_consume_token(RANGEIN_END);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[16] = jj_gen;
        ;
      }
          if (goop1.kind == RANGEIN_QUOTED) {
            goop1.image = goop1.image.substring(1, goop1.image.length()-1);
          } else {
            goop1.image = discardEscapeChar(goop1.image);
          }
          if (goop2.kind == RANGEIN_QUOTED) {
            goop2.image = goop2.image.substring(1, goop2.image.length()-1);
      } else {
        goop2.image = discardEscapeChar(goop2.image);
      }
          q = getRangeQuery(field, goop1.image, goop2.image, true);
      break;
    case RANGEEX_START:
      jj_consume_token(RANGEEX_START);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEEX_GOOP:
        goop1 = jj_consume_token(RANGEEX_GOOP);
        break;
      case RANGEEX_QUOTED:
        goop1 = jj_consume_token(RANGEEX_QUOTED);
        break;
      default:
        jj_la1[17] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEEX_TO:
        jj_consume_token(RANGEEX_TO);
        break;
      default:
        jj_la1[18] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEEX_GOOP:
        goop2 = jj_consume_token(RANGEEX_GOOP);
        break;
      case RANGEEX_QUOTED:
        goop2 = jj_consume_token(RANGEEX_QUOTED);
        break;
      default:
        jj_la1[19] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      jj_consume_token(RANGEEX_END);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[20] = jj_gen;
        ;
      }
          if (goop1.kind == RANGEEX_QUOTED) {
            goop1.image = goop1.image.substring(1, goop1.image.length()-1);
          } else {
            goop1.image = discardEscapeChar(goop1.image);
          }
          if (goop2.kind == RANGEEX_QUOTED) {
            goop2.image = goop2.image.substring(1, goop2.image.length()-1);
      } else {
        goop2.image = discardEscapeChar(goop2.image);
      }

          q = getRangeQuery(field, goop1.image, goop2.image, false);
      break;
    case QUOTED:
      term = jj_consume_token(QUOTED);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case FUZZY_SLOP:
        fuzzySlop = jj_consume_token(FUZZY_SLOP);
        break;
      default:
        jj_la1[21] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[22] = jj_gen;
        ;
      }
         int s = phraseSlop;

         if (fuzzySlop != null) {
           try {
             s = Float.valueOf(fuzzySlop.image.substring(1)).intValue();
           }
           catch (Exception ignored) { }
         }
         q = getFieldQuery(field, term.image.substring(1, term.image.length()-1), s);
      break;
    default:
      jj_la1[23] = jj_gen;
      jj_consume_token(-1);
      throw new ParseException();
    }
    if (boost != null) {
      float f = (float) 1.0;
      try {
        f = Float.valueOf(boost.image).floatValue();
      }
      catch (Exception ignored) {
    /* Should this be handled somehow? (defaults to "no boost", if
     * boost number is invalid)
     */
      }

      // avoid boosting null queries, such as those caused by stop words
      if (q != null) {
        q.setBoost(f);
      }
    }
    {if (true) return q;}
    throw new Error("Missing return statement in function");
  }
=======
final public Query Term(String field) throws ParseException {
  Token term, boost=null, fuzzySlop=null, goop1, goop2;
  boolean prefix = false;
  boolean wildcard = false;
  boolean fuzzy = false;
  Query q;
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case TERM:
    case PREFIXTERM:
    case WILDTERM:
    case NUMBER:
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case TERM:
        term = jj_consume_token(TERM);
        break;
      case PREFIXTERM:
        term = jj_consume_token(PREFIXTERM);
                             prefix=true;
        break;
      case WILDTERM:
        term = jj_consume_token(WILDTERM);
                           wildcard=true;
        break;
      case NUMBER:
        term = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[9] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case FUZZY_SLOP:
        fuzzySlop = jj_consume_token(FUZZY_SLOP);
                                fuzzy=true;
        break;
      default:
        jj_la1[10] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
        case FUZZY_SLOP:
          fuzzySlop = jj_consume_token(FUZZY_SLOP);
                                                         fuzzy=true;
          break;
        default:
          jj_la1[11] = jj_gen;
          ;
        }
        break;
      default:
        jj_la1[12] = jj_gen;
        ;
      }
       String termImage=discardEscapeChar(term.image);
       if (wildcard) {
       q = getWildcardQuery(field, termImage);
       } else if (prefix) {
         q = getPrefixQuery(field,
           discardEscapeChar(term.image.substring
          (0, term.image.length()-1)));
       } else if (fuzzy) {
          float fms = fuzzyMinSim;
          try {
            fms = Float.valueOf(fuzzySlop.image.substring(1)).floatValue();
          } catch (Exception ignored) { }
         if(fms < 0.0f || fms > 1.0f){
           {if (true) throw new ParseException("Minimum similarity for a FuzzyQuery has to be between 0.0f and 1.0f !");}
         }
         q = getFuzzyQuery(field, termImage, fms);
       } else {
         q = getFieldQuery(field, termImage, false);
       }
      break;
    case RANGEIN_START:
      jj_consume_token(RANGEIN_START);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEIN_GOOP:
        goop1 = jj_consume_token(RANGEIN_GOOP);
        break;
      case RANGEIN_QUOTED:
        goop1 = jj_consume_token(RANGEIN_QUOTED);
        break;
      default:
        jj_la1[13] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEIN_TO:
        jj_consume_token(RANGEIN_TO);
        break;
      default:
        jj_la1[14] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEIN_GOOP:
        goop2 = jj_consume_token(RANGEIN_GOOP);
        break;
      case RANGEIN_QUOTED:
        goop2 = jj_consume_token(RANGEIN_QUOTED);
        break;
      default:
        jj_la1[15] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      jj_consume_token(RANGEIN_END);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[16] = jj_gen;
        ;
      }
          if (goop1.kind == RANGEIN_QUOTED) {
            goop1.image = goop1.image.substring(1, goop1.image.length()-1);
          } else {
            goop1.image = discardEscapeChar(goop1.image);
          }
          if (goop2.kind == RANGEIN_QUOTED) {
            goop2.image = goop2.image.substring(1, goop2.image.length()-1);
      } else {
        goop2.image = discardEscapeChar(goop2.image);
      }
          q = getRangeQuery(field, goop1.image, goop2.image, true);
      break;
    case RANGEEX_START:
      jj_consume_token(RANGEEX_START);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEEX_GOOP:
        goop1 = jj_consume_token(RANGEEX_GOOP);
        break;
      case RANGEEX_QUOTED:
        goop1 = jj_consume_token(RANGEEX_QUOTED);
        break;
      default:
        jj_la1[17] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEEX_TO:
        jj_consume_token(RANGEEX_TO);
        break;
      default:
        jj_la1[18] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEEX_GOOP:
        goop2 = jj_consume_token(RANGEEX_GOOP);
        break;
      case RANGEEX_QUOTED:
        goop2 = jj_consume_token(RANGEEX_QUOTED);
        break;
      default:
        jj_la1[19] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      jj_consume_token(RANGEEX_END);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[20] = jj_gen;
        ;
      }
          if (goop1.kind == RANGEEX_QUOTED) {
            goop1.image = goop1.image.substring(1, goop1.image.length()-1);
          } else {
            goop1.image = discardEscapeChar(goop1.image);
          }
          if (goop2.kind == RANGEEX_QUOTED) {
            goop2.image = goop2.image.substring(1, goop2.image.length()-1);
      } else {
        goop2.image = discardEscapeChar(goop2.image);
      }

          q = getRangeQuery(field, goop1.image, goop2.image, false);
      break;
    case QUOTED:
      term = jj_consume_token(QUOTED);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case FUZZY_SLOP:
        fuzzySlop = jj_consume_token(FUZZY_SLOP);
        break;
      default:
        jj_la1[21] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[22] = jj_gen;
        ;
      }
         int s = phraseSlop;

         if (fuzzySlop != null) {
           try {
             s = Float.valueOf(fuzzySlop.image.substring(1)).intValue();
           }
           catch (Exception ignored) { }
         }
         q = getFieldQuery(field, term.image.substring(1, term.image.length()-1), s);
      break;
    default:
      jj_la1[23] = jj_gen;
      jj_consume_token(-1);
      throw new ParseException();
    }
    if (boost != null) {
      float f = (float) 1.0;
      try {
        f = Float.valueOf(boost.image).floatValue();
      }
      catch (Exception ignored) {
    /* Should this be handled somehow? (defaults to "no boost", if
     * boost number is invalid)
     */
      }

      // avoid boosting null queries, such as those caused by stop words
      if (q != null) {
        q.setBoost(f);
      }
    }
    {if (true) return q;}
    throw new Error("Missing return statement in function");
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627990565/fstmerge_var2_9129265064334342196

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/precedence/PrecedenceQueryParser.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ private static final Comparator<Object> termComparator = new Comparator<Object>() {
    @SuppressWarnings("unchecked")
    public int compare(Object o1, Object o2) {
      if (o1 instanceof Map.Entry<?,?>) o1 = ((Map.Entry<?,?>) o1).getKey();
      if (o2 instanceof Map.Entry<?,?>) o2 = ((Map.Entry<?,?>) o2).getKey();
      if (o1 == o2) return 0;
      return ((Comparable) o1).compareTo((Comparable) o2);
    }
  }; ##FSTMerge## private static final Comparator termComparator = new Comparator() {
    public int compare(Object o1, Object o2) {
      if (o1 instanceof Map.Entry<?,?>) o1 = ((Map.Entry<?,?>) o1).getKey();
      if (o2 instanceof Map.Entry<?,?>) o2 = ((Map.Entry<?,?>) o2).getKey();
      if (o1 == o2) return 0;
      return ((String) o1).compareTo((String) o2);
    }
  }; ##FSTMerge## private static final Comparator termComparator = new Comparator() {
    public int compare(Object o1, Object o2) {
      if (o1 instanceof Map.Entry<?,?>) o1 = ((Map.Entry<?,?>) o1).getKey();
      if (o2 instanceof Map.Entry<?,?>) o2 = ((Map.Entry<?,?>) o2).getKey();
      if (o1 == o2) return 0;
      return ((Comparable) o1).compareTo((Comparable) o2);
    }
  };
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testSplitRR() throws Exception {
    MultiPassIndexSplitter splitter = new MultiPassIndexSplitter();
    Directory[] dirs = new Directory[]{
            newDirectory(),
            newDirectory(),
            newDirectory()
    };
    splitter.split(input, dirs, false);
    IndexReader ir;
    ir = IndexReader.open(dirs[0], true);
    assertTrue(ir.numDocs() - NUM_DOCS / 3 <= 1); // rounding error
    Document doc = ir.document(0);
    assertEquals("0", doc.get("id"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992721/fstmerge_base_7352494714845049908
    Term t;
    TermEnum te;
    t = new Term("id", "1");
    te = ir.terms(t);
    assertNotSame(t, te.term());
=======
    TermsEnum te = MultiFields.getTerms(ir, "id").iterator();
    assertEquals(TermsEnum.SeekStatus.NOT_FOUND, te.seek(new BytesRef("1")));
    assertNotSame("1", te.term().utf8ToString());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992721/fstmerge_var2_5413518003333503129
    ir.close();
    ir = IndexReader.open(dirs[1], true);
    assertTrue(ir.numDocs() - NUM_DOCS / 3 <= 1);
    doc = ir.document(0);
    assertEquals("1", doc.get("id"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992721/fstmerge_base_7352494714845049908
    t = new Term("id", "0");
    te = ir.terms(t);
    assertNotSame(t, te.term());
=======
    te = MultiFields.getTerms(ir, "id").iterator();
    assertEquals(TermsEnum.SeekStatus.NOT_FOUND, te.seek(new BytesRef("0")));

    assertNotSame("0", te.term().utf8ToString());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992721/fstmerge_var2_5413518003333503129
    ir.close();
    ir = IndexReader.open(dirs[2], true);
    assertTrue(ir.numDocs() - NUM_DOCS / 3 <= 1);
    doc = ir.document(0);
    assertEquals("2", doc.get("id"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992721/fstmerge_var1_3109288470163859885

    te = MultiFields.getTerms(ir, "id").iterator();
    assertEquals(TermsEnum.SeekStatus.NOT_FOUND, te.seek(new BytesRef("1")));
    assertNotSame("1", te.term());

    assertEquals(TermsEnum.SeekStatus.NOT_FOUND, te.seek(new BytesRef("0")));
    assertNotSame("0", te.term().utf8ToString());
    ir.close();
    for (Directory d : dirs)
      d.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992721/fstmerge_base_7352494714845049908
    t = new Term("id", "1");
    te = ir.terms(t);
    assertNotSame(t, te.term());
    t = new Term("id", "0");
    te = ir.terms(t);
    assertNotSame(t, te.term());    
=======

    te = MultiFields.getTerms(ir, "id").iterator();
    assertEquals(TermsEnum.SeekStatus.NOT_FOUND, te.seek(new BytesRef("1")));
    assertNotSame("1", te.term());

    assertEquals(TermsEnum.SeekStatus.NOT_FOUND, te.seek(new BytesRef("0")));
    assertNotSame("0", te.term().utf8ToString());    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992721/fstmerge_var2_5413518003333503129
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/misc/src/test/org/apache/lucene/index/TestMultiPassIndexSplitter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testSplitSeq() throws Exception {
    MultiPassIndexSplitter splitter = new MultiPassIndexSplitter();
    Directory[] dirs = new Directory[]{
            newDirectory(),
            newDirectory(),
            newDirectory()
    };
    splitter.split(input, dirs, true);
    IndexReader ir;
    ir = IndexReader.open(dirs[0], true);
    assertTrue(ir.numDocs() - NUM_DOCS / 3 <= 1);
    Document doc = ir.document(0);
    assertEquals("0", doc.get("id"));
    int start = ir.numDocs();
    ir.close();
    ir = IndexReader.open(dirs[1], true);
    assertTrue(ir.numDocs() - NUM_DOCS / 3 <= 1);
    doc = ir.document(0);
    assertEquals(start + "", doc.get("id"));
    start += ir.numDocs();
    ir.close();
    ir = IndexReader.open(dirs[2], true);
    assertTrue(ir.numDocs() - NUM_DOCS / 3 <= 1);
    doc = ir.document(0);
    assertEquals(start + "", doc.get("id"));
    // make sure the deleted doc is not here
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992726/fstmerge_var1_8467393554061510101
    TermsEnum te = MultiFields.getTerms(ir, "id").iterator();
    Term t = new Term("id", (NUM_DOCS - 1) + "");
    assertEquals(TermsEnum.SeekStatus.NOT_FOUND, te.seek(new BytesRef(t.text())));
    assertNotSame(t.text(), te.term().utf8ToString());
    ir.close();
    for (Directory d : dirs)
      d.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992726/fstmerge_base_3272387235699475568
    Term t;
    TermEnum te;
    t = new Term("id", (NUM_DOCS - 1) + "");
    te = ir.terms(t);
    assertNotSame(t, te.term());    
=======
    TermsEnum te = MultiFields.getTerms(ir, "id").iterator();
    Term t = new Term("id", (NUM_DOCS - 1) + "");
    assertEquals(TermsEnum.SeekStatus.NOT_FOUND, te.seek(new BytesRef(t.text())));
    assertNotSame(t.text(), te.term().utf8ToString());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992726/fstmerge_var2_4101431467616091072
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/misc/src/test/org/apache/lucene/index/TestMultiPassIndexSplitter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992796/fstmerge_var1_1414737762097404257
public void testCodec() throws Exception {
    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());
    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer());
    
    cfg.setCodecProvider(new AppendingCodecProvider());
    ((LogMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);
    IndexWriter writer = new IndexWriter(dir, cfg);
    Document doc = new Document();
    doc.add(newField("f", text, Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);
    writer.commit();
    writer.addDocument(doc);
    writer.optimize();
    writer.close();
    IndexReader reader = IndexReader.open(dir, null, true, 1, new AppendingCodecProvider());
    assertEquals(2, reader.numDocs());
    doc = reader.document(0);
    assertEquals(text, doc.get("f"));
    Fields fields = MultiFields.getFields(reader);
    Terms terms = fields.terms("f");
    assertNotNull(terms);
    TermsEnum te = terms.iterator();
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("quick")));
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("brown")));
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("fox")));
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("jumped")));
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("over")));
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("lazy")));
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("dog")));
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("the")));
    DocsEnum de = te.docs(null, null);
    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);
    assertEquals(2, de.freq());
    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);
    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);
    reader.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992796/fstmerge_base_4063013507758422527
=======
public void testCodec() throws Exception {
    Directory dir = new AppendingRAMDirectory();
    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer());
    
    cfg.setCodecProvider(new AppendingCodecProvider());
    ((LogMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);
    IndexWriter writer = new IndexWriter(dir, cfg);
    Document doc = new Document();
    doc.add(new Field("f", text, Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);
    writer.commit();
    writer.addDocument(doc);
    writer.optimize();
    writer.close();
    IndexReader reader = IndexReader.open(dir, null, true, 1, new AppendingCodecProvider());
    assertEquals(2, reader.numDocs());
    doc = reader.document(0);
    assertEquals(text, doc.get("f"));
    Fields fields = MultiFields.getFields(reader);
    Terms terms = fields.terms("f");
    assertNotNull(terms);
    TermsEnum te = terms.iterator();
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("quick")));
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("brown")));
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("fox")));
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("jumped")));
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("over")));
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("lazy")));
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("dog")));
    assertEquals(SeekStatus.FOUND, te.seek(new BytesRef("the")));
    DocsEnum de = te.docs(null, null);
    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);
    assertEquals(2, de.freq());
    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);
    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);
    reader.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992796/fstmerge_var2_5779331478412116693

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/misc/src/test/org/apache/lucene/index/codecs/appending/TestAppendingCodec.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992801/fstmerge_var1_9148736117113285119
@Override
  public IndexInput openInput(String name, int bufferSize) throws IOException {
    ensureOpen();
    return new DirectIOLinuxIndexInput(new File(getDirectory(), name), forcedBufferSize == 0 ? bufferSize : forcedBufferSize);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992801/fstmerge_base_1782988223972031311
=======
@Override
  public IndexInput openInput(String name, int bufferSize) throws IOException {
    ensureOpen();
    return new DirectIOLinuxIndexInput(new File(getDirectory(), name), bufferSize);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992801/fstmerge_var2_21929359678045261

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/misc/src/java/org/apache/lucene/store/DirectIOLinuxDirectory.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992806/fstmerge_var1_3648986668559513095
@Override
  public IndexOutput createOutput(String name) throws IOException {
    ensureOpen();
    ensureCanWrite(name);
    return new DirectIOLinuxIndexOutput(new File(getDirectory(), name), forcedBufferSize == 0 ? BufferedIndexOutput.BUFFER_SIZE : forcedBufferSize);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992806/fstmerge_base_8572167318120728229
=======
@Override
  public IndexOutput createOutput(String name) throws IOException {
    ensureOpen();
    ensureCanWrite(name);
    return new DirectIOLinuxIndexOutput(new File(getDirectory(), name), 4096);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992806/fstmerge_var2_7760650750282862575

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/misc/src/java/org/apache/lucene/store/DirectIOLinuxDirectory.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992812/fstmerge_var1_7432537435571923374
public DirectIOLinuxIndexOutput(File path, int bufferSize) throws IOException {
      //this.path = path;
      FileDescriptor fd = NativePosixUtil.open_direct(path.toString(), false);
      fos = new FileOutputStream(fd);
      //fos = new FileOutputStream(path);
      channel = fos.getChannel();
      buffer = ByteBuffer.allocateDirect(bufferSize);
      this.bufferSize = bufferSize;
      isOpen = true;
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992812/fstmerge_base_6688737272269818984
=======
public DirectIOLinuxIndexOutput(File path, int bufferSize) throws IOException {
      //this.path = path;
      bufferSize = 1024*1024;
      FileDescriptor fd = NativePosixUtil.open_direct(path.toString(), false);
      fos = new FileOutputStream(fd);
      //fos = new FileOutputStream(path);
      channel = fos.getChannel();
      buffer = ByteBuffer.allocateDirect(bufferSize);
      this.bufferSize = bufferSize;
      isOpen = true;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992812/fstmerge_var2_1846297655471426961

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/misc/src/java/org/apache/lucene/store/DirectIOLinuxDirectory.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992856/fstmerge_var1_1823223799371620192
public DirectIOLinuxIndexInput(File path, int bufferSize) throws IOException {
      FileDescriptor fd = NativePosixUtil.open_direct(path.toString(), true);
      fis = new FileInputStream(fd);
      channel = fis.getChannel();
      this.bufferSize = bufferSize;
      buffer = ByteBuffer.allocateDirect(bufferSize);
      isOpen = true;
      isClone = false;
      filePos = -bufferSize;
      bufferPos = bufferSize;
      //System.out.println("D open " + path + " this=" + this);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992856/fstmerge_base_8142572926729240516
=======
public DirectIOLinuxIndexInput(File path, int bufferSize) throws IOException {
      bufferSize = 1024*1024;
      FileDescriptor fd = NativePosixUtil.open_direct(path.toString(), true);
      fis = new FileInputStream(fd);
      channel = fis.getChannel();
      this.bufferSize = bufferSize;
      buffer = ByteBuffer.allocateDirect(bufferSize);
      isOpen = true;
      isClone = false;
      filePos = -bufferSize;
      bufferPos = bufferSize;
      //System.out.println("D open " + path + " this=" + this);
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627992856/fstmerge_var2_4347739856886014639

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/misc/src/java/org/apache/lucene/store/DirectIOLinuxDirectory.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627993064/fstmerge_var1_7167083828118089581
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627993064/fstmerge_base_1182340224545519318
public void reSetNorms(String field) throws IOException {
    String fieldName = StringHelper.intern(field);
    int[] termCounts = new int[0];
    
    IndexReader reader = null;
    TermEnum termEnum = null;
    TermDocs termDocs = null;
    try {
      reader = IndexReader.open(dir, false);
      termCounts = new int[reader.maxDoc()];
      try {
        termEnum = reader.terms(new Term(field));
        try {
          termDocs = reader.termDocs();
          do {
            Term term = termEnum.term();
            if (term != null && term.field().equals(fieldName)) {
              termDocs.seek(termEnum.term());
              while (termDocs.next()) {
                termCounts[termDocs.doc()] += termDocs.freq();
              }
            }
          } while (termEnum.next());
        } finally {
          if (null != termDocs) termDocs.close();
        }
      } finally {
        if (null != termEnum) termEnum.close();
      }
    } finally {
      if (null != reader) reader.close();
    }
    
    try {
      reader = IndexReader.open(dir, false); 
      for (int d = 0; d < termCounts.length; d++) {
        if (! reader.isDeleted(d)) {
          byte norm = Similarity.encodeNorm(sim.lengthNorm(fieldName, termCounts[d]));
          reader.setNorm(d, fieldName, norm);
        }
      }
    } finally {
      if (null != reader) reader.close();
    }
  }
=======
public void reSetNorms(String field) throws IOException {
    String fieldName = StringHelper.intern(field);
    int[] termCounts = new int[0];
    
    IndexReader reader = IndexReader.open(dir, false);
    try {

      termCounts = new int[reader.maxDoc()];
      Bits delDocs = MultiFields.getDeletedDocs(reader);
      DocsEnum docs = null;

      Terms terms = MultiFields.getTerms(reader, field);
      if (terms != null) {
        TermsEnum termsEnum = terms.iterator();
        while(termsEnum.next() != null) {
          docs = termsEnum.docs(delDocs, docs);
          int doc;
          while ((doc = docs.nextDoc()) != DocsEnum.NO_MORE_DOCS) {
            termCounts[doc] += docs.freq();
          }
        }
      }

      for (int d = 0; d < termCounts.length; d++) {
        if (! reader.isDeleted(d)) {
          byte norm = Similarity.encodeNorm(sim.lengthNorm(fieldName, termCounts[d]));
          reader.setNorm(d, fieldName, norm);
        }
      }
    } finally {
      reader.close();
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627993064/fstmerge_var2_8238387377326528739

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/misc/src/java/org/apache/lucene/misc/LengthNormModifier.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627993421/fstmerge_var1_7964293280105156318
@Override
  protected void readHeader(IndexInput in) throws IOException {
    CodecUtil.checkHeader(in, AppendingTermsDictWriter.CODEC_NAME,
      PrefixCodedTermsWriter.VERSION_START, PrefixCodedTermsWriter.VERSION_CURRENT);    
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627993421/fstmerge_base_8971742423971475700
=======
@Override
  protected void readHeader(IndexInput in) throws IOException {
    CodecUtil.checkHeader(in, AppendingTermsDictWriter.CODEC_NAME,
      StandardTermsDictWriter.VERSION_START, StandardTermsDictWriter.VERSION_CURRENT);    
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627993421/fstmerge_var2_2761968052845266371

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/misc/src/java/org/apache/lucene/index/codecs/appending/AppendingTermsDictReader.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627993435/fstmerge_var1_3171832499682924619
@Override
  public FieldsConsumer fieldsConsumer(SegmentWriteState state)
          throws IOException {
    PostingsWriterBase docsWriter = new StandardPostingsWriter(state);
    boolean success = false;
    AppendingTermsIndexWriter indexWriter = null;
    try {
      indexWriter = new AppendingTermsIndexWriter(state);
      success = true;
    } finally {
      if (!success) {
        docsWriter.close();
      }
    }
    success = false;
    try {
      FieldsConsumer ret = new AppendingTermsDictWriter(indexWriter, state, docsWriter, BytesRef.getUTF8SortedAsUnicodeComparator());
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          docsWriter.close();
        } finally {
          indexWriter.close();
        }
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627993435/fstmerge_base_2394327478029577277
=======
@Override
  public FieldsConsumer fieldsConsumer(SegmentWriteState state)
          throws IOException {
    StandardPostingsWriter docsWriter = new StandardPostingsWriterImpl(state);
    boolean success = false;
    AppendingTermsIndexWriter indexWriter = null;
    try {
      indexWriter = new AppendingTermsIndexWriter(state);
      success = true;
    } finally {
      if (!success) {
        docsWriter.close();
      }
    }
    success = false;
    try {
      FieldsConsumer ret = new AppendingTermsDictWriter(indexWriter, state, docsWriter, BytesRef.getUTF8SortedAsUnicodeComparator());
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          docsWriter.close();
        } finally {
          indexWriter.close();
        }
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627993435/fstmerge_var2_1704859327314014817

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/misc/src/java/org/apache/lucene/index/codecs/appending/AppendingCodec.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627993440/fstmerge_var1_2783321224618964422
@Override
  public FieldsProducer fieldsProducer(SegmentReadState state)
          throws IOException {
    PostingsReaderBase docsReader = new StandardPostingsReader(state.dir, state.segmentInfo, state.readBufferSize, state.codecId);
    TermsIndexReaderBase indexReader;

    boolean success = false;
    try {
      indexReader = new AppendingTermsIndexReader(state.dir,
              state.fieldInfos,
              state.segmentInfo.name,
              state.termsIndexDivisor,
              BytesRef.getUTF8SortedAsUnicodeComparator(),
              state.codecId);
      success = true;
    } finally {
      if (!success) {
        docsReader.close();
      }
    }
    success = false;
    try {
      FieldsProducer ret = new AppendingTermsDictReader(indexReader,
              state.dir, state.fieldInfos, state.segmentInfo.name,
              docsReader,
              state.readBufferSize,
              BytesRef.getUTF8SortedAsUnicodeComparator(),
              StandardCodec.TERMS_CACHE_SIZE,
              state.codecId);
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          docsReader.close();
        } finally {
          indexReader.close();
        }
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627993440/fstmerge_base_3539074967068927988
=======
@Override
  public FieldsProducer fieldsProducer(SegmentReadState state)
          throws IOException {
    StandardPostingsReader docsReader = new StandardPostingsReaderImpl(state.dir, state.segmentInfo, state.readBufferSize);
    StandardTermsIndexReader indexReader;

    boolean success = false;
    try {
      indexReader = new AppendingTermsIndexReader(state.dir,
              state.fieldInfos,
              state.segmentInfo.name,
              state.termsIndexDivisor,
              BytesRef.getUTF8SortedAsUnicodeComparator());
      success = true;
    } finally {
      if (!success) {
        docsReader.close();
      }
    }
    success = false;
    try {
      FieldsProducer ret = new AppendingTermsDictReader(indexReader,
              state.dir, state.fieldInfos, state.segmentInfo.name,
              docsReader,
              state.readBufferSize,
              BytesRef.getUTF8SortedAsUnicodeComparator(),
              StandardCodec.TERMS_CACHE_SIZE);
      success = true;
      return ret;
    } finally {
      if (!success) {
        try {
          docsReader.close();
        } finally {
          indexReader.close();
        }
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627993440/fstmerge_var2_8432344414759910813

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/misc/src/java/org/apache/lucene/index/codecs/appending/AppendingCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627996076/fstmerge_var1_7373790707646307769
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627996076/fstmerge_base_8781862424420102808
public static void setIndexWriterConfig(IndexWriter writer, Config config) throws IOException {

    final String mergeScheduler = config.get("merge.scheduler",
                                             "org.apache.lucene.index.ConcurrentMergeScheduler");
    if (mergeScheduler.equals(NoMergeScheduler.class.getName())) {
      writer.setMergeScheduler(NoMergeScheduler.INSTANCE);
    } else {
      try {
        writer.setMergeScheduler(Class.forName(mergeScheduler).asSubclass(MergeScheduler.class).newInstance());
      } catch (Exception e) {
        throw new RuntimeException("unable to instantiate class '" + mergeScheduler + "' as merge scheduler", e);
      }
      
      if (mergeScheduler.equals("org.apache.lucene.index.ConcurrentMergeScheduler")) {
        ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) writer.getMergeScheduler();
        int v = config.get("concurrent.merge.scheduler.max.thread.count", -1);
        if (v != -1) {
          cms.setMaxThreadCount(v);
        }
        v = config.get("concurrent.merge.scheduler.max.merge.count", -1);
        if (v != -1) {
          cms.setMaxMergeCount(v);
        }
      }
    }

    final String mergePolicy = config.get("merge.policy",
                                          "org.apache.lucene.index.LogByteSizeMergePolicy");
    boolean isCompound = config.get("compound", true);
    if (mergePolicy.equals(NoMergePolicy.class.getName())) {
      writer.setMergePolicy(isCompound ? NoMergePolicy.COMPOUND_FILES : NoMergePolicy.NO_COMPOUND_FILES);
    } else {
      try {
        writer.setMergePolicy(Class.forName(mergePolicy).asSubclass(MergePolicy.class).newInstance());
      } catch (Exception e) {
        throw new RuntimeException("unable to instantiate class '" + mergePolicy + "' as merge policy", e);
      }
      writer.setUseCompoundFile(isCompound);
      writer.setMergeFactor(config.get("merge.factor",OpenIndexTask.DEFAULT_MERGE_PFACTOR));
    }
    writer.setMaxFieldLength(config.get("max.field.length",OpenIndexTask.DEFAULT_MAX_FIELD_LENGTH));

    final double ramBuffer = config.get("ram.flush.mb",OpenIndexTask.DEFAULT_RAM_FLUSH_MB);
    final int maxBuffered = config.get("max.buffered",OpenIndexTask.DEFAULT_MAX_BUFFERED);
    if (maxBuffered == IndexWriterConfig.DISABLE_AUTO_FLUSH) {
      writer.setRAMBufferSizeMB(ramBuffer);
      writer.setMaxBufferedDocs(maxBuffered);
    } else {
      writer.setMaxBufferedDocs(maxBuffered);
      writer.setRAMBufferSizeMB(ramBuffer);
    }
    
    String infoStreamVal = config.get("writer.info.stream", null);
    if (infoStreamVal != null) {
      if (infoStreamVal.equals("SystemOut")) {
        writer.setInfoStream(System.out);
      } else if (infoStreamVal.equals("SystemErr")) {
        writer.setInfoStream(System.err);
      } else {
        File f = new File(infoStreamVal).getAbsoluteFile();
        writer.setInfoStream(new PrintStream(new BufferedOutputStream(new FileOutputStream(f))));
      }
    }
  }
=======
public static void setIndexWriterConfig(IndexWriter writer, Config config) throws IOException {

    final String mergeScheduler = config.get("merge.scheduler",
                                             "org.apache.lucene.index.ConcurrentMergeScheduler");
    if (mergeScheduler.equals(NoMergeScheduler.class.getName())) {
      writer.getConfig().setMergeScheduler(NoMergeScheduler.INSTANCE);
    } else {
      try {
        writer.getConfig().setMergeScheduler(Class.forName(mergeScheduler).asSubclass(MergeScheduler.class).newInstance());
      } catch (Exception e) {
        throw new RuntimeException("unable to instantiate class '" + mergeScheduler + "' as merge scheduler", e);
      }
      
      if (mergeScheduler.equals("org.apache.lucene.index.ConcurrentMergeScheduler")) {
        ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) writer.getConfig().getMergeScheduler();
        int v = config.get("concurrent.merge.scheduler.max.thread.count", -1);
        if (v != -1) {
          cms.setMaxThreadCount(v);
        }
        v = config.get("concurrent.merge.scheduler.max.merge.count", -1);
        if (v != -1) {
          cms.setMaxMergeCount(v);
        }
      }
    }

    final String mergePolicy = config.get("merge.policy",
                                          "org.apache.lucene.index.LogByteSizeMergePolicy");
    boolean isCompound = config.get("compound", true);
    if (mergePolicy.equals(NoMergePolicy.class.getName())) {
      writer.getConfig().setMergePolicy(isCompound ? NoMergePolicy.COMPOUND_FILES : NoMergePolicy.NO_COMPOUND_FILES);
    } else {
      try {
        writer.getConfig().setMergePolicy(Class.forName(mergePolicy).asSubclass(MergePolicy.class).newInstance());
      } catch (Exception e) {
        throw new RuntimeException("unable to instantiate class '" + mergePolicy + "' as merge policy", e);
      }
      if (writer.getConfig().getMergePolicy() instanceof LogMergePolicy) {
        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(isCompound);
        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(config.get("merge.factor",OpenIndexTask.DEFAULT_MERGE_PFACTOR));
      }
    }
    writer.getConfig().setMaxFieldLength(config.get("max.field.length",OpenIndexTask.DEFAULT_MAX_FIELD_LENGTH));

    final double ramBuffer = config.get("ram.flush.mb",OpenIndexTask.DEFAULT_RAM_FLUSH_MB);
    final int maxBuffered = config.get("max.buffered",OpenIndexTask.DEFAULT_MAX_BUFFERED);
    if (maxBuffered == IndexWriterConfig.DISABLE_AUTO_FLUSH) {
      writer.setRAMBufferSizeMB(ramBuffer);
      writer.setMaxBufferedDocs(maxBuffered);
    } else {
      writer.setMaxBufferedDocs(maxBuffered);
      writer.setRAMBufferSizeMB(ramBuffer);
    }
    
    String infoStreamVal = config.get("writer.info.stream", null);
    if (infoStreamVal != null) {
      if (infoStreamVal.equals("SystemOut")) {
        writer.setInfoStream(System.out);
      } else if (infoStreamVal.equals("SystemErr")) {
        writer.setInfoStream(System.err);
      } else {
        File f = new File(infoStreamVal).getAbsoluteFile();
        writer.setInfoStream(new PrintStream(new BufferedOutputStream(new FileOutputStream(f))));
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627996076/fstmerge_var2_3685429021988770278

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java
Conflict type: LineBasedMCFd
Conflict body: 
protected String getPreTag( int num ){
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627998882/fstmerge_var1_1836335056239949120
    return getPreTag( preTags, num );
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627998882/fstmerge_base_5945412168966723970
    return preTags.length > num ? preTags[num] : preTags[0];
=======
    int n = num % preTags.length;
    return preTags[n];
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627998882/fstmerge_var2_7022437009903710393
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/BaseFragmentsBuilder.java
Conflict type: LineBasedMCFd
Conflict body: 
protected String getPostTag( int num ){
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627998887/fstmerge_var1_2721394460380218291
    return getPostTag( postTags, num );
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627998887/fstmerge_base_2884703565191583170
    return postTags.length > num ? postTags[num] : postTags[0];
=======
    int n = num % postTags.length;
    return postTags[n];
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627998887/fstmerge_var2_3798235787360782822
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/BaseFragmentsBuilder.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
	public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999817/fstmerge_var1_7339264033773669509
		directory = newDirectory();
		RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999817/fstmerge_base_2435261848349335404
		directory = new RAMDirectory();
		IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
		directory = new RAMDirectory();
		RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999817/fstmerge_var2_3309459909362169363
		
		//Add series of docs with filterable fields : url, text and dates  flags
		addDoc(writer, "http://lucene.apache.org", "lucene 1.4.3 available", "20040101");
		addDoc(writer, "http://lucene.apache.org", "New release pending", "20040102");
		addDoc(writer, "http://lucene.apache.org", "Lucene 1.9 out now", "20050101");		
		addDoc(writer, "http://www.bar.com", "Local man bites dog", "20040101");
		addDoc(writer, "http://www.bar.com", "Dog bites local man", "20040102");
		addDoc(writer, "http://www.bar.com", "Dog uses Lucene", "20050101");
		addDoc(writer, "http://lucene.apache.org", "Lucene 2.0 out", "20050101");
		addDoc(writer, "http://lucene.apache.org", "Oops. Lucene 2.1 out", "20050102");
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999817/fstmerge_base_2435261848349335404
		
		writer.close();
		reader=IndexReader.open(directory, true);			
=======

                // Until we fix LUCENE-2348, the index must
                // have only 1 segment:
                writer.optimize();

		reader = writer.getReader();
		writer.close();			
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999817/fstmerge_var2_3309459909362169363
		searcher =new IndexSearcher(reader);
		
	}

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/DuplicateFilterTest.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999827/fstmerge_var1_2009329103843125910
private void addDoc(RandomIndexWriter writer, String url, String text, String date) throws IOException
	{
		Document doc=new Document();
		doc.add(newField(KEY_FIELD,url,Field.Store.YES,Field.Index.NOT_ANALYZED));
		doc.add(newField("text",text,Field.Store.YES,Field.Index.ANALYZED));
		doc.add(newField("date",date,Field.Store.YES,Field.Index.ANALYZED));
		writer.addDocument(doc);
	}
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999827/fstmerge_base_1539592775198832965
=======
private void addDoc(RandomIndexWriter writer, String url, String text, String date) throws IOException
	{
		Document doc=new Document();
		doc.add(new Field(KEY_FIELD,url,Field.Store.YES,Field.Index.NOT_ANALYZED));
		doc.add(new Field("text",text,Field.Store.YES,Field.Index.ANALYZED));
		doc.add(new Field("date",date,Field.Store.YES,Field.Index.ANALYZED));
		writer.addDocument(doc);
	}
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999827/fstmerge_var2_2695817303638412948

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/DuplicateFilterTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
	public void setUp() throws Exception	{
	  super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999857/fstmerge_var1_3998375155291644080
		directory = newDirectory();
		RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999857/fstmerge_base_2910663020953265264
		directory = new RAMDirectory();
		IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
=======
		directory = new RAMDirectory();
		RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999857/fstmerge_var2_1246360346669334276
		
		//Add series of docs with misspelt names
		addDoc(writer, "jonathon smythe","1");
		addDoc(writer, "jonathan smith","2");
		addDoc(writer, "johnathon smyth","3");
		addDoc(writer, "johnny smith","4" );
		addDoc(writer, "jonny smith","5" );
		addDoc(writer, "johnathon smythe","6");
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999857/fstmerge_base_2910663020953265264
	
=======
		reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999857/fstmerge_var2_1246360346669334276
		writer.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999857/fstmerge_base_2910663020953265264
		searcher=new IndexSearcher(directory, true);			
=======
		searcher=new IndexSearcher(reader);			
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999857/fstmerge_var2_1246360346669334276
	}

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/FuzzyLikeThisQueryTest.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999862/fstmerge_var1_3647537871947910033
@Override
	public void tearDown() throws Exception {
	  searcher.close();
	  reader.close();
	  directory.close();
	  super.tearDown();
	}
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999862/fstmerge_base_7530024672264658542
=======
@Override
	protected void tearDown() throws Exception {
	  searcher.close();
	  reader.close();
	  directory.close();
	  super.tearDown();
	}
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999862/fstmerge_var2_4636597207997740471

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/FuzzyLikeThisQueryTest.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999868/fstmerge_var1_3552002240958169876
private void addDoc(RandomIndexWriter writer, String name, String id) throws IOException
	{
		Document doc=new Document();
		doc.add(newField("name",name,Field.Store.YES,Field.Index.ANALYZED));
		doc.add(newField("id",id,Field.Store.YES,Field.Index.ANALYZED));
		writer.addDocument(doc);
	}
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999868/fstmerge_base_7629540140336113190
=======
private void addDoc(RandomIndexWriter writer, String name, String id) throws IOException
	{
		Document doc=new Document();
		doc.add(new Field("name",name,Field.Store.YES,Field.Index.ANALYZED));
		doc.add(new Field("id",id,Field.Store.YES,Field.Index.ANALYZED));
		writer.addDocument(doc);
	}
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999868/fstmerge_var2_1898966684193953891

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/FuzzyLikeThisQueryTest.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testMissingTerms() throws Exception {
		String fieldName="field1";
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999909/fstmerge_var1_7039933029030793907
		Directory rd=newDirectory();
		RandomIndexWriter w = new RandomIndexWriter(random, rd);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999909/fstmerge_base_4246634470443020718
		RAMDirectory rd=new RAMDirectory();
		IndexWriter w = new IndexWriter(rd, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
		RAMDirectory rd=new RAMDirectory();
		RandomIndexWriter w = new RandomIndexWriter(newRandom(), rd);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999909/fstmerge_var2_3671401591151182168
		for (int i = 0; i < 100; i++) {
			Document doc=new Document();
			int term=i*10; //terms are units of 10;
			doc.add(newField(fieldName,""+term,Field.Store.YES,Field.Index.NOT_ANALYZED));
			w.addDocument(doc);			
		}
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999909/fstmerge_var1_7039933029030793907
		IndexReader reader = new SlowMultiReaderWrapper(w.getReader());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999909/fstmerge_base_4246634470443020718
=======
		IndexReader reader = w.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999909/fstmerge_var2_3671401591151182168
		w.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999909/fstmerge_base_4246634470443020718
		IndexReader reader = IndexReader.open(rd, true);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999909/fstmerge_var2_3671401591151182168
		
		TermsFilter tf=new TermsFilter();
		tf.addTerm(new Term(fieldName,"19"));
		OpenBitSet bits = (OpenBitSet)tf.getDocIdSet(reader);
		assertEquals("Must match nothing", 0, bits.cardinality());

		tf.addTerm(new Term(fieldName,"20"));
		bits = (OpenBitSet)tf.getDocIdSet(reader);
		assertEquals("Must match 1", 1, bits.cardinality());
		
		tf.addTerm(new Term(fieldName,"10"));
		bits = (OpenBitSet)tf.getDocIdSet(reader);
		assertEquals("Must match 2", 2, bits.cardinality());
		
		tf.addTerm(new Term(fieldName,"00"));
		bits = (OpenBitSet)tf.getDocIdSet(reader);
		assertEquals("Must match 2", 2, bits.cardinality());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999909/fstmerge_base_4246634470443020718
				
=======
		
		reader.close();
		rd.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999909/fstmerge_var2_3671401591151182168
	}

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
	public void setUp() throws Exception {
	  super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999915/fstmerge_var1_1872911481844259162
		directory = newDirectory();
		RandomIndexWriter writer = new RandomIndexWriter(random, directory, new MockAnalyzer(MockTokenizer.WHITESPACE, false));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999915/fstmerge_base_1453935425751400324
		directory = new RAMDirectory();
		IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
=======
		directory = new RAMDirectory();
		RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, new MockAnalyzer(MockTokenizer.WHITESPACE, false));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999915/fstmerge_var2_5504647383896274975
		
		//Add series of docs with filterable fields : acces rights, prices, dates and "in-stock" flags
		addDoc(writer, "admin guest", "010", "20040101","Y");
		addDoc(writer, "guest", "020", "20040101","Y");
		addDoc(writer, "guest", "020", "20050101","Y");
		addDoc(writer, "admin", "020", "20050101","Maybe");
		addDoc(writer, "admin guest", "030", "20050101","N");
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999915/fstmerge_var1_1872911481844259162
		reader = new SlowMultiReaderWrapper(writer.getReader());
		writer.close();	
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999915/fstmerge_base_1453935425751400324
		
		writer.close();
		reader=IndexReader.open(directory, true);			
=======
		reader = writer.getReader();
		writer.close();	
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999915/fstmerge_var2_5504647383896274975
	}

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/BooleanFilterTest.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999920/fstmerge_var1_4656572434331630861
@Override
	public void tearDown() throws Exception {
	  reader.close();
	  directory.close();
	  super.tearDown();
	}
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999920/fstmerge_base_5697437247989679037
=======
@Override
	protected void tearDown() throws Exception {
	  reader.close();
	  directory.close();
	  super.tearDown();
	}
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999920/fstmerge_var2_8149863821267503744

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/BooleanFilterTest.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999925/fstmerge_var1_8532818716390370203
private void addDoc(RandomIndexWriter writer, String accessRights, String price, String date, String inStock) throws IOException
	{
		Document doc=new Document();
		doc.add(newField("accessRights",accessRights,Field.Store.YES,Field.Index.ANALYZED));
		doc.add(newField("price",price,Field.Store.YES,Field.Index.ANALYZED));
		doc.add(newField("date",date,Field.Store.YES,Field.Index.ANALYZED));
		doc.add(newField("inStock",inStock,Field.Store.YES,Field.Index.ANALYZED));
		writer.addDocument(doc);
	}
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999925/fstmerge_base_2890597676628004934
=======
private void addDoc(RandomIndexWriter writer, String accessRights, String price, String date, String inStock) throws IOException
	{
		Document doc=new Document();
		doc.add(new Field("accessRights",accessRights,Field.Store.YES,Field.Index.ANALYZED));
		doc.add(new Field("price",price,Field.Store.YES,Field.Index.ANALYZED));
		doc.add(new Field("date",date,Field.Store.YES,Field.Index.ANALYZED));
		doc.add(new Field("inStock",inStock,Field.Store.YES,Field.Index.ANALYZED));
		writer.addDocument(doc);
	}
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999925/fstmerge_var2_993125824923587465

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/BooleanFilterTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999990/fstmerge_var1_7949409794975084172
    directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999990/fstmerge_base_2354432160020682731
    directory = new RAMDirectory();
    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));

=======
    random = newRandom();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999990/fstmerge_var2_7331861446668123818
    Calendar cal = new GregorianCalendar();
    cal.clear();
    cal.setTimeInMillis(1041397200000L); // 2003 January 01

    for (int i = 0; i < MAX; i++) {
      Document doc = new Document();
      doc.add(newField("key", "" + (i + 1), Field.Store.YES, Field.Index.NOT_ANALYZED));
      doc.add(newField("owner", (i < MAX / 2) ? "bob" : "sue", Field.Store.YES, Field.Index.NOT_ANALYZED));
      doc.add(newField("date", cal.getTime().toString(), Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);

      cal.add(Calendar.DATE, 1);
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999990/fstmerge_base_2354432160020682731

=======
    reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999990/fstmerge_var2_7331861446668123818
    writer.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999990/fstmerge_base_2354432160020682731
    searcher = new IndexSearcher(directory, true);
=======
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419627999990/fstmerge_var2_7331861446668123818

    // query for everything to make life easier
    BooleanQuery bq = new BooleanQuery();
    bq.add(new TermQuery(new Term("owner", "bob")), BooleanClause.Occur.SHOULD);
    bq.add(new TermQuery(new Term("owner", "sue")), BooleanClause.Occur.SHOULD);
    query = bq;

    // date filter matches everything too
    //Date pastTheEnd = parseDate("2099 Jan 1");
    // dateFilter = DateFilter.Before("date", pastTheEnd);
    // just treat dates as strings and select the whole range for now...
    dateFilter = new TermRangeFilter("date","","ZZZZ",true,true);

    bobFilter = new QueryWrapperFilter(
        new TermQuery(new Term("owner", "bob")));
    sueFilter = new QueryWrapperFilter(
        new TermQuery(new Term("owner", "sue")));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/ChainedFilterTest.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testWithCachingFilter() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000039/fstmerge_var1_5679209732461734062
    Directory dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
    IndexReader reader = writer.getReader();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000039/fstmerge_base_4842215319703605583
    Directory dir = new RAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    Directory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
    IndexReader reader = writer.getReader();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000039/fstmerge_var2_5670159970457208423
    writer.close();
  
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000039/fstmerge_base_4842215319703605583
    Searcher searcher = new IndexSearcher(dir, true);
=======
    Searcher searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000039/fstmerge_var2_5670159970457208423
  
    Query query = new TermQuery(new Term("none", "none"));
  
    QueryWrapperFilter queryFilter = new QueryWrapperFilter(query);
    CachingWrapperFilter cachingFilter = new CachingWrapperFilter(queryFilter);
  
    searcher.search(query, cachingFilter, 1);
  
    CachingWrapperFilter cachingFilter2 = new CachingWrapperFilter(queryFilter);
    Filter[] chain = new Filter[2];
    chain[0] = cachingFilter;
    chain[1] = cachingFilter2;
    ChainedFilter cf = new ChainedFilter(chain);
  
    // throws java.lang.ClassCastException: org.apache.lucene.util.OpenBitSet cannot be cast to java.util.BitSet
    searcher.search(new MatchAllDocsQuery(), cf, 1);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000039/fstmerge_base_4842215319703605583
=======
    searcher.close();
    reader.close();
    dir.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000039/fstmerge_var2_5670159970457208423
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/ChainedFilterTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000061/fstmerge_var1_8672473264473289200
    directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
    Document doc = new Document();
    doc.add(newField(FN, "the quick brown fox jumps over the lazy dog", Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000061/fstmerge_base_3358807522207378474
    RAMDirectory directory = new RAMDirectory();
    try {
      IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
          TEST_VERSION_CURRENT, new MockAnalyzer()));
      Document doc = new Document();
      doc.add(new Field(FN, "the quick brown fox jumps over the lazy dog", Field.Store.NO, Field.Index.ANALYZED));
      writer.addDocument(doc);
      writer.optimize();
      writer.close();
      searcher = new IndexSearcher(directory, true);
    } catch (Exception e) {
      fail(e.toString());
    }
=======
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    Document doc = new Document();
    doc.add(new Field(FN, "the quick brown fox jumps over the lazy dog", Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000061/fstmerge_var2_1292994184221849563
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestRegexQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testMatchAll() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000087/fstmerge_var1_6835505326573726704
    Terms terms = MultiFields.getTerms(searcher.getIndexReader(), FN);
    TermsEnum te = new RegexQuery(new Term(FN, "jum.")).getTermsEnum(terms, new AttributeSource() /*dummy*/);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000087/fstmerge_base_1293562097366707242
    TermEnum terms = new RegexQuery(new Term(FN, "jum.")).getEnum(searcher.getIndexReader());
=======
    TermsEnum terms = new RegexQuery(new Term(FN, "jum.")).getTermsEnum(searcher.getIndexReader());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000087/fstmerge_var2_1746513465129992265
    // no term should match
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000087/fstmerge_var1_6835505326573726704
    assertNull(te.next());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000087/fstmerge_base_1293562097366707242
    assertNull(terms.term());
    assertFalse(terms.next());
=======
    assertNull(terms.next());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000087/fstmerge_var2_1746513465129992265
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestRegexQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000152/fstmerge_var1_1834856925108989930
  public void setUp() throws Exception {
    super.setUp();
    directory = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
    
    // Add series of docs with specific information for MoreLikeThis
    addDoc(writer, "lucene");
    addDoc(writer, "lucene release");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000152/fstmerge_base_479234906339409958
    protected void setUp() throws Exception {
      super.setUp();
	directory = new RAMDirectory();
	IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    
    // Add series of docs with specific information for MoreLikeThis
    addDoc(writer, "lucene");
    addDoc(writer, "lucene release");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000152/fstmerge_var2_2575730846432408221

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000152/fstmerge_base_479234906339409958
	// Add series of docs with specific information for MoreLikeThis
	addDoc(writer, "lucene");
	addDoc(writer, "lucene release");

	writer.close();
	reader = IndexReader.open(directory, true);
	searcher = new IndexSearcher(reader);

    }
=======
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000152/fstmerge_var2_2575730846432408221

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/similar/TestMoreLikeThis.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000157/fstmerge_var1_911237891390022559
  public void tearDown() throws Exception {
    reader.close();
    searcher.close();
    directory.close();
    super.tearDown();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000157/fstmerge_base_3242245596142435624
    protected void tearDown() throws Exception {
	reader.close();
	searcher.close();
	directory.close();
  super.tearDown();
    }
=======
  protected void tearDown() throws Exception {
    reader.close();
    searcher.close();
    directory.close();
    super.tearDown();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000157/fstmerge_var2_7664893779584231302

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/similar/TestMoreLikeThis.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000162/fstmerge_var1_6192575117960547035
private void addDoc(RandomIndexWriter writer, String text) throws IOException {
    Document doc = new Document();
    doc.add(newField("text", text, Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000162/fstmerge_base_2377731970485844250
=======
private void addDoc(RandomIndexWriter writer, String text) throws IOException {
    Document doc = new Document();
    doc.add(new Field("text", text, Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000162/fstmerge_var2_6143165323467294375

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/test/org/apache/lucene/search/similar/TestMoreLikeThis.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000182/fstmerge_base_6600263411488485528
  public DocIdSet getDocIdSet(IndexReader reader) throws IOException
	{
=======
  public DocIdSet getDocIdSet(IndexReader reader) throws IOException {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000182/fstmerge_var2_8605598561277974036
    OpenBitSet result=new OpenBitSet(reader.maxDoc());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000182/fstmerge_var1_2205858808481409647
    Fields fields = reader.fields();
    BytesRef br = new BytesRef();
    Bits delDocs = reader.getDeletedDocs();
    if (fields != null) {
      String lastField = null;
      Terms termsC = null;
      TermsEnum termsEnum = null;
      DocsEnum docs = null;
      for (Iterator<Term> iter = terms.iterator(); iter.hasNext();) {
        Term term = iter.next();
        if (term.field() != lastField) {
          termsC = fields.terms(term.field());
          termsEnum = termsC.iterator();
          lastField = term.field();
        }

        if (terms != null) {
          br.copy(term.bytes());
          if (termsEnum.seek(br) == TermsEnum.SeekStatus.FOUND) {
            docs = termsEnum.docs(delDocs, docs);
            while(docs.nextDoc() != DocsEnum.NO_MORE_DOCS) {
              result.set(docs.docID());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000182/fstmerge_base_6600263411488485528
        TermDocs td = reader.termDocs();
        try
        {
            for (Iterator<Term> iter = terms.iterator(); iter.hasNext();)
            {
                Term term = iter.next();
                td.seek(term);
                while (td.next())
                {
                    result.set(td.doc());
                }
=======
    Fields fields = MultiFields.getFields(reader);
    BytesRef br = new BytesRef();
    Bits delDocs = MultiFields.getDeletedDocs(reader);
    if (fields != null) {
      String lastField = null;
      Terms termsC = null;
      TermsEnum termsEnum = null;
      DocsEnum docs = null;
      for (Iterator<Term> iter = terms.iterator(); iter.hasNext();) {
        Term term = iter.next();
        if (term.field() != lastField) {
          termsC = fields.terms(term.field());
          termsEnum = termsC.iterator();
          lastField = term.field();
        }

        if (terms != null) {
          br.copy(term.bytes());
          if (termsEnum.seek(br) == TermsEnum.SeekStatus.FOUND) {
            docs = termsEnum.docs(delDocs, docs);
            while(docs.nextDoc() != DocsEnum.NO_MORE_DOCS) {
              result.set(docs.docID());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000182/fstmerge_var2_8605598561277974036
            }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000182/fstmerge_base_6600263411488485528
=======
          }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000182/fstmerge_var2_8605598561277974036
        }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000182/fstmerge_base_6600263411488485528
        finally
        {
            td.close();
        }
        return result;
	}
=======
      }
    }
    return result;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000182/fstmerge_var2_8605598561277974036

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/java/org/apache/lucene/search/TermsFilter.java
Conflict type: SameIdFd
Conflict body: 
~~FSTMerge~~ private RegexCapabilities.RegexMatcher regexImpl; ##FSTMerge## ##FSTMerge## private RegexCapabilities regexImpl;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/RegexTermsEnum.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000671/fstmerge_var1_6436133281907989751
@Override
  protected AcceptStatus accept(BytesRef term) {
    if (term.startsWith(prefixRef)) {
      // TODO: set BoostAttr based on distance of
      // searchTerm.text() and term().text()
      return regexImpl.match(term) ? AcceptStatus.YES : AcceptStatus.NO;
    } else {
      return AcceptStatus.NO;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000671/fstmerge_base_3798334690612221500
=======
@Override
  protected AcceptStatus accept(BytesRef term) {
    if (term.startsWith(prefixRef)) {
      // TODO: set BoostAttr based on distance of
      // searchTerm.text() and term().text()
      String text = term.utf8ToString();
      return regexImpl.match(text) ? AcceptStatus.YES : AcceptStatus.NO;
    } else {
      return AcceptStatus.NO;
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628000671/fstmerge_var2_2348108335007427199

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/RegexTermsEnum.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001964/fstmerge_var1_1969101171526011934
@Test
  public void testLatLonType() throws Exception {
    String fieldName = "home_ll";
    setupDocs(fieldName);
    //Try some edge cases
    checkHits(fieldName, "1,1", 175, 3, 5, 6, 7);
    checkHits(fieldName, "0,179.8", 200, 2, 8, 9);
    checkHits(fieldName, "89.8, 50", 200, 2, 10, 11);//this goes over the north pole
    checkHits(fieldName, "-89.8, 50", 200, 2, 12, 13);//this goes over the south pole
    //try some normal cases
    checkHits(fieldName, "33.0,-80.0", 300, 2);
    //large distance
    checkHits(fieldName, "1,1", 5000, 3, 5, 6, 7);
    //Because we are generating a box based on the west/east longitudes and the south/north latitudes, which then
    //translates to a range query, which is slightly more inclusive.  Thus, even though 0.0 is 15.725 kms away,
    //it will be included, b/c of the box calculation.
    checkHits(fieldName, false, "0.1,0.1", 15, 2, 5, 6);
   //try some more
    clearIndex();
    assertU(adoc("id", "14", fieldName, "0,5"));
    assertU(adoc("id", "15", fieldName, "0,15"));
    //3000KM from 0,0, see http://www.movable-type.co.uk/scripts/latlong.html
    assertU(adoc("id", "16", fieldName, "18.71111,19.79750"));
    assertU(adoc("id", "17", fieldName, "44.043900,-95.436643"));
    assertU(commit());

    checkHits(fieldName, "0,0", 1000, 1, 14);
    checkHits(fieldName, "0,0", 2000, 2, 14, 15);
    checkHits(fieldName, false, "0,0", 3000, 3, 14, 15, 16);
    checkHits(fieldName, "0,0", 3001, 3, 14, 15, 16);
    checkHits(fieldName, "0,0", 3000.1, 3, 14, 15, 16);

    //really fine grained distance and reflects some of the vagaries of how we are calculating the box
    checkHits(fieldName, "43.517030,-96.789603", 109, 0);

    // falls outside of the real distance, but inside the bounding box   
    checkHits(fieldName, true, "43.517030,-96.789603", 110, 0);
    checkHits(fieldName, false, "43.517030,-96.789603", 110, 1, 17);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001964/fstmerge_base_1476708778286324650
=======
@Test
  public void testLatLonType() throws Exception {
    String fieldName = "home_ll";
    setupDocs(fieldName);
    //Try some edge cases
    checkHits(fieldName, "1,1", 175, 3, 5, 6, 7);
    checkHits(fieldName, "0,179.8", 200, 2, 8, 9);
    checkHits(fieldName, "89.8, 50", 200, 2, 10, 11);//this goes over the north pole
    checkHits(fieldName, "-89.8, 50", 200, 2, 12, 13);//this goes over the south pole
    //try some normal cases
    checkHits(fieldName, "33.0,-80.0", 300, 2);
    //large distance
    checkHits(fieldName, "1,1", 5000, 3, 5, 6, 7);
    //Try alternate distance
    checkHits(fieldName, "0.1,0.1", 15, 1, 6);

  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001964/fstmerge_var2_3348394401006689584

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/search/SpatialFilterTest.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001968/fstmerge_var1_837050279315861057
private void checkHits(String fieldName, String pt, double distance, int count, int ... docIds) {
    checkHits(fieldName, true, pt, distance, count, docIds);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001968/fstmerge_base_4665707771470316324
=======
private void checkHits(String fieldName, String pt, double distance, int count, int ... docIds) {
    String [] tests = new String[docIds != null && docIds.length > 0 ? docIds.length + 1 : 1];
    tests[0] = "*[count(//doc)=" + count + "]";
    if (docIds != null && docIds.length > 0) {
      int i = 1;
      for (int docId : docIds) {
        tests[i++] = "//result/doc/int[@name='id'][.='" + docId + "']";
      }
    }
    assertQ(req("fl", "id", "q","*:*", "rows", "1000", "fq", "{!sfilt fl=" +fieldName +"}",
            "pt", pt, "d", String.valueOf(distance)),
            tests);//
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001968/fstmerge_var2_927383175122830131

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/search/SpatialFilterTest.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001974/fstmerge_var1_2954176849354149892
@BeforeClass
  public static void beforeClass() throws Exception {
    initCore("solrconfig.xml", "schema12.xml");
    createIndex();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001974/fstmerge_base_7616256213235106582
=======
@BeforeClass
  public static void beforeClass() throws Exception {
    initCore("solrconfig.xml", "schema12.xml");
    createIndex();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001974/fstmerge_var2_4215968568369004655

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/search/TestSolrQueryParser.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001979/fstmerge_var1_2945808994316816448
public static void createIndex() {
    String v;
    v="how now brown cow";
    assertU(adoc("id","1", "text",v,  "text_np",v));
    v="now cow";
    assertU(adoc("id","2", "text",v,  "text_np",v));
    assertU(commit());
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001979/fstmerge_base_6971451968646994851
=======
public static void createIndex() {
    String v;
    v="how now brown cow";
    assertU(adoc("id","1", "text",v,  "text_np",v));
    v="now cow";
    assertU(adoc("id","2", "text",v,  "text_np",v));
    assertU(commit());
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001979/fstmerge_var2_5741034834201705059

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/search/TestSolrQueryParser.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001984/fstmerge_var1_2021878255547519073
@Test
  public void testPhrase() {
    // should generate a phrase of "now cow" and match only one doc
    assertQ(req("q","text:now-cow", "indent","true")
        ,"//*[@numFound='1']"
    );
    // should generate a query of (now OR cow) and match both docs
    assertQ(req("q","text_np:now-cow", "indent","true")
        ,"//*[@numFound='2']"
    );
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001984/fstmerge_base_3745627685801294413
=======
@Test
  public void testPhrase() {
    // should generate a phrase of "now cow" and match only one doc
    assertQ(req("q","text:now-cow", "indent","true")
        ,"//*[@numFound='1']"
    );
    // should generate a query of (now OR cow) and match both docs
    assertQ(req("q","text_np:now-cow", "indent","true")
        ,"//*[@numFound='2']"
    );
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628001984/fstmerge_var2_1607020150618625201

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/search/TestSolrQueryParser.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002417/fstmerge_base_4519379476110025081
public void testGeneral() throws Exception {
=======
@Test
  public void testGeneral() throws Exception {
    clearIndex();
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002417/fstmerge_var2_8142262117698866945
    assertU(adoc("id","1", "a_tdt","2009-08-31T12:10:10.123Z", "b_tdt","2009-08-31T12:10:10.124Z"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002417/fstmerge_base_4519379476110025081
    assertU(adoc("id","2"));
=======
    assertU(adoc("id","2", "a_t","how now brown cow"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002417/fstmerge_var2_8142262117698866945
    assertU(commit()); // create more than one segment
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002417/fstmerge_base_4519379476110025081
    assertU(adoc("id","3"));
=======
    assertU(adoc("id","3", "a_t","brown cow"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002417/fstmerge_var2_8142262117698866945
    assertU(adoc("id","4"));
    assertU(commit()); // create more than one segment
    assertU(adoc("id","5"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002417/fstmerge_base_4519379476110025081
    assertU(adoc("id","6"));
=======
    assertU(adoc("id","6", "a_t","cow cow cow cow cow"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002417/fstmerge_var2_8142262117698866945
    assertU(commit());

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002417/fstmerge_base_4519379476110025081
=======
    // test relevancy functions
    assertQ(req("fl","*,score","q", "{!func}numdocs()", "fq","id:6"), "//float[@name='score']='6.0'");
    assertQ(req("fl","*,score","q", "{!func}maxdoc()", "fq","id:6"), "//float[@name='score']='6.0'");
    assertQ(req("fl","*,score","q", "{!func}docfreq(a_t,cow)", "fq","id:6"), "//float[@name='score']='3.0'");
    assertQ(req("fl","*,score","q", "{!func}docfreq('a_t','cow')", "fq","id:6"), "//float[@name='score']='3.0'");
    assertQ(req("fl","*,score","q", "{!func}docfreq($field,$value)", "fq","id:6", "field","a_t", "value","cow"), "//float[@name='score']='3.0'");
    assertQ(req("fl","*,score","q", "{!func}termfreq(a_t,cow)", "fq","id:6"), "//float[@name='score']='5.0'");
    Similarity similarity = new DefaultSimilarity();
    assertQ(req("fl","*,score","q", "{!func}idf(a_t,cow)", "fq","id:6"),
        "//float[@name='score']='" + similarity.idf(3,6)  + "'");
    assertQ(req("fl","*,score","q", "{!func}tf(a_t,cow)", "fq","id:6"),
        "//float[@name='score']='" + similarity.tf(5)  + "'");
    assertQ(req("fl","*,score","q", "{!func}norm(a_t)", "fq","id:2"),
        "//float[@name='score']='" + similarity.lengthNorm("a_t",4)  + "'");  // sqrt(4)==2 and is exactly representable when quantized to a byte

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002417/fstmerge_var2_8142262117698866945
    // test that ord and rord are working on a global index basis, not just
    // at the segment level (since Lucene 2.9 has switched to per-segment searching)
    assertQ(req("fl","*,score","q", "{!func}ord(id)", "fq","id:6"), "//float[@name='score']='6.0'");
    assertQ(req("fl","*,score","q", "{!func}top(ord(id))", "fq","id:6"), "//float[@name='score']='6.0'");
    assertQ(req("fl","*,score","q", "{!func}rord(id)", "fq","id:1"),"//float[@name='score']='6.0'");
    assertQ(req("fl","*,score","q", "{!func}top(rord(id))", "fq","id:1"),"//float[@name='score']='6.0'");


    // test that we can subtract dates to millisecond precision
    assertQ(req("fl","*,score","q", "{!func}ms(a_tdt,b_tdt)", "fq","id:1"), "//float[@name='score']='-1.0'");
    assertQ(req("fl","*,score","q", "{!func}ms(b_tdt,a_tdt)", "fq","id:1"), "//float[@name='score']='1.0'");
    assertQ(req("fl","*,score","q", "{!func}ms(2009-08-31T12:10:10.125Z,2009-08-31T12:10:10.124Z)", "fq","id:1"), "//float[@name='score']='1.0'");
    assertQ(req("fl","*,score","q", "{!func}ms(2009-08-31T12:10:10.124Z,a_tdt)", "fq","id:1"), "//float[@name='score']='1.0'");
    assertQ(req("fl","*,score","q", "{!func}ms(2009-08-31T12:10:10.125Z,b_tdt)", "fq","id:1"), "//float[@name='score']='1.0'");

    assertQ(req("fl","*,score","q", "{!func}ms(2009-08-31T12:10:10.125Z/SECOND,2009-08-31T12:10:10.124Z/SECOND)", "fq","id:1"), "//float[@name='score']='0.0'");

    // test that we can specify "NOW"
    assertQ(req("fl","*,score","q", "{!func}ms(NOW)", "NOW","1000"), "//float[@name='score']='1000.0'");


    for (int i=100; i<112; i++) {
      assertU(adoc("id",""+i, "text","batman"));
    }
    assertU(commit());
    assertU(adoc("id","120", "text","batman superman"));   // in a segment by itself
    assertU(commit());

    // batman and superman have the same idf in single-doc segment, but very different in the complete index.
    String q ="{!func}query($qq)";
    String fq="id:120"; 
    assertQ(req("fl","*,score","q", q, "qq","text:batman", "fq",fq), "//float[@name='score']<'1.0'");
    assertQ(req("fl","*,score","q", q, "qq","text:superman", "fq",fq), "//float[@name='score']>'1.0'");

    // test weighting through a function range query
    assertQ(req("fl","*,score", "q", "{!frange l=1 u=10}query($qq)", "qq","text:superman"), "//*[@numFound='1']");

    // test weighting through a complex function
    q ="{!func}sub(div(sum(0.0,product(1,query($qq))),1),0)";
    assertQ(req("fl","*,score","q", q, "qq","text:batman", "fq",fq), "//float[@name='score']<'1.0'");
    assertQ(req("fl","*,score","q", q, "qq","text:superman", "fq",fq), "//float[@name='score']>'1.0'");

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002417/fstmerge_var1_2344511910356516317

    // test full param dereferencing
    assertQ(req("fl","*,score","q", "{!func}add($v1,$v2)", "v1","add($v3,$v4)", "v2","1", "v3","2", "v4","5"
        , "fq","id:1"), "//float[@name='score']='8.0'");

    // test ability to parse multiple values
    assertQ(req("fl","*,score","q", "{!func}dist(2,vector(1,1),$pt)", "pt","3,1"
        , "fq","id:1"), "//float[@name='score']='2.0'");

    // test that extra stuff after a function causes an error
    try {
      assertQ(req("fl","*,score","q", "{!func}10 wow dude ignore_exception"));
      fail();
    } catch (Exception e) {
      // OK
    }

    purgeFieldCache(FieldCache.DEFAULT);   // avoid FC insanity
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002417/fstmerge_base_4519379476110025081
    doTestDegreeRads();
    doTestFuncs();
=======

    purgeFieldCache(FieldCache.DEFAULT);   // avoid FC insanity
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002417/fstmerge_var2_8142262117698866945
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/search/function/TestFunctionQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testHaversine() throws Exception {
    clearIndex();
    assertU(adoc("id", "1", "x_td", "0", "y_td", "0", "gh_s", GeoHashUtils.encode(32.7693246, -79.9289094)));
    assertU(adoc("id", "2", "x_td", "0", "y_td", String.valueOf(Math.PI / 2), "gh_s", GeoHashUtils.encode(32.7693246, -78.9289094)));
    assertU(adoc("id", "3", "x_td", String.valueOf(Math.PI / 2), "y_td", String.valueOf(Math.PI / 2), "gh_s", GeoHashUtils.encode(32.7693246, -80.9289094)));
    assertU(adoc("id", "4", "x_td", String.valueOf(Math.PI / 4), "y_td", String.valueOf(Math.PI / 4), "gh_s", GeoHashUtils.encode(32.7693246, -81.9289094)));
    assertU(adoc("id", "5", "x_td", "45.0", "y_td", "45.0",
            "gh_s", GeoHashUtils.encode(32.7693246, -81.9289094)));
    assertU(adoc("id", "6", "point_hash", "32.5, -79.0", "point", "32.5, -79.0"));
    assertU(adoc("id", "7", "point_hash", "32.6, -78.0", "point", "32.6, -78.0"));
    assertU(commit());
    //Get the haversine distance between the point 0,0 and the docs above assuming a radius of 1
    assertQ(req("fl", "*,score", "q", "{!func}hsin(1, false, x_td, y_td, 0, 0)", "fq", "id:1"), "//float[@name='score']='0.0'");
    assertQ(req("fl", "*,score", "q", "{!func}hsin(1, false, x_td, y_td, 0, 0)", "fq", "id:2"), "//float[@name='score']='" + (float) (Math.PI / 2) + "'");
    assertQ(req("fl", "*,score", "q", "{!func}hsin(1, false, x_td, y_td, 0, 0)", "fq", "id:3"), "//float[@name='score']='" + (float) (Math.PI / 2) + "'");
    assertQ(req("fl", "*,score", "q", "{!func}hsin(1, false, x_td, y_td, 0, 0)", "fq", "id:4"), "//float[@name='score']='1.0471976'");
    assertQ(req("fl", "*,score", "q", "{!func}hsin(1, true, x_td, y_td, 0, 0)", "fq", "id:5"), "//float[@name='score']='1.0471976'");
    //SOLR-2114
    assertQ(req("fl", "*,score", "q", "{!func}hsin(6371.009, true, point, vector(0, 0))", "fq", "id:6"), "//float[@name='score']='8977.814'");
    
    //Geo Hash Haversine
    //Can verify here: http://www.movable-type.co.uk/scripts/latlong.html, but they use a slightly different radius for the earth, so just be close
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002459/fstmerge_base_5573237885928958535
    assertQ(req("fl", "*,score", "q", "{!func}ghhsin(" + Constants.EARTH_RADIUS_KM + ", gh_s, \"" + GeoHashUtils.encode(32, -79) +
            "\",)", "fq", "id:1"), "//float[@name='score']='122.309006'");
=======
    assertQ(req("fl", "*,score", "q", "{!func}ghhsin(" + DistanceUtils.EARTH_MEAN_RADIUS_KM + ", gh_s, \"" + GeoHashUtils.encode(32, -79) +
            "\",)", "fq", "id:1"), "//float[@name='score']='122.171875'");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002459/fstmerge_var2_8281658832184867779

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002459/fstmerge_base_5573237885928958535
    assertQ(req("fl", "id,point_hash,score", "q", "{!func}recip(ghhsin(" + Constants.EARTH_RADIUS_KM + ", point_hash, \"" + GeoHashUtils.encode(32, -79) + "\"), 1, 1, 0)"),
=======
    assertQ(req("fl", "id,point_hash,score", "q", "{!func}recip(ghhsin(" + DistanceUtils.EARTH_MEAN_RADIUS_KM + ", point_hash, \"" + GeoHashUtils.encode(32, -79) + "\"), 1, 1, 0)"),
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002459/fstmerge_var2_8281658832184867779
            "//*[@numFound='7']", 
            "//result/doc[1]/str[@name='id'][.='6']",
            "//result/doc[2]/str[@name='id'][.='7']"//all the rest don't matter
            );


<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002459/fstmerge_var1_1815148169374240105
    assertQ(req("fl", "*,score", "q", "{!func}ghhsin(" + DistanceUtils.EARTH_MEAN_RADIUS_KM + ", gh_s, geohash(32, -79))", "fq", "id:1"), "//float[@name='score']='122.171875'");

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002459/fstmerge_base_5573237885928958535
    assertQ(req("fl", "*,score", "q", "{!func}ghhsin(" + Constants.EARTH_RADIUS_KM + ", gh_s, geohash(32, -79))", "fq", "id:1"), "//float[@name='score']='122.309006'");
=======
    assertQ(req("fl", "*,score", "q", "{!func}ghhsin(" + DistanceUtils.EARTH_MEAN_RADIUS_KM + ", gh_s, geohash(32, -79))", "fq", "id:1"), "//float[@name='score']='122.171875'");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628002459/fstmerge_var2_8281658832184867779
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/search/function/distance/DistanceFunctionTest.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628004302/fstmerge_var1_7506812591240309328
public void setUp() throws Exception {
    super.setUp();
    log.info("####SETUP_START " + getName());
    ignoreException("ignore_exception");
    factoryProp = System.getProperty("solr.directoryFactory");
    if (factoryProp == null) {
      System.setProperty("solr.directoryFactory","solr.RAMDirectoryFactory");
    }
    dataDir = new File(TEMP_DIR,
            getClass().getName() + "-" + System.currentTimeMillis());
    dataDir.mkdirs();

    String configFile = getSolrConfigFile();
    if (configFile != null) {

      solrConfig = h.createConfig(getSolrConfigFile());
      h = new TestHarness( dataDir.getAbsolutePath(),
              solrConfig,
              getSchemaFile());
      lrf = h.getRequestFactory
              ("standard",0,20,"version","2.2");
    }
    log.info("####SETUP_END " + getName());
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628004302/fstmerge_base_404544135658274344
=======
public void setUp() throws Exception {
    super.setUp();
    log.info("####SETUP_START " + getName());
    ignoreException("ignore_exception");
    factoryProp = System.getProperty("solr.directoryFactory");
    if (factoryProp == null) {
      System.setProperty("solr.directoryFactory","solr.RAMDirectoryFactory");
    }
    dataDir = new File(System.getProperty("java.io.tmpdir")
            + System.getProperty("file.separator")
            + getClass().getName() + "-" + System.currentTimeMillis());
    dataDir.mkdirs();

    String configFile = getSolrConfigFile();
    if (configFile != null) {

      solrConfig = h.createConfig(getSolrConfigFile());
      h = new TestHarness( dataDir.getAbsolutePath(),
              solrConfig,
              getSchemaFile());
      lrf = h.getRequestFactory
              ("standard",0,20,"version","2.2");
    }
    log.info("####SETUP_END " + getName());
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628004302/fstmerge_var2_7753248642541075160

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/util/AbstractSolrTestCase.java
Conflict type: LineBasedMCFd
Conflict body: 
public void setUp() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628005077/fstmerge_var1_8199781770800194256
    super.setUp();

    dataDir = new File(TEMP_DIR,
        getClass().getName() + "-" + System.currentTimeMillis() + System.getProperty("file.separator") + "solr"
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628005077/fstmerge_base_8265878771647350140
    dataDir = new File(System.getProperty("java.io.tmpdir")
        + System.getProperty("file.separator")
        + getClass().getName() + "-" + System.currentTimeMillis() + System.getProperty("file.separator") + "solr"
=======
    super.setUp();
    dataDir = new File(System.getProperty("java.io.tmpdir")
        + System.getProperty("file.separator")
        + getClass().getName() + "-" + System.currentTimeMillis() + System.getProperty("file.separator") + "solr"
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628005077/fstmerge_var2_4462838736244272355
        + System.getProperty("file.separator") + "data");
    dataDir.mkdirs();

    solrConfig = h.createConfig("solrconfig.xml");
    h = new TestHarness( dataDir.getAbsolutePath(),
        solrConfig,
        "schema12.xml");
    lrf = h.getRequestFactory
    ("standard",0,20,"version","2.2");
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/core/TestArbitraryIndexDir.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006418/fstmerge_var1_6680040128756092191
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006418/fstmerge_base_5930885451988731509
public void setUp() throws Exception {
    super.setUp();    
    master = new SolrInstance("master", null);
    master.setUp();
    masterJetty = createJetty(master);
    masterClient = createNewSolrServer(masterJetty.getLocalPort());

    slave = new SolrInstance("slave", masterJetty.getLocalPort());
    slave.setUp();
    slaveJetty = createJetty(slave);
    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());
  }
=======
@Before
  public void setUp() throws Exception {
    super.setUp();
    masterClient.deleteByQuery("*:*");
    masterClient.commit();
    rQuery(0, "*:*", masterClient);
    slaveClient.deleteByQuery("*:*");
    slaveClient.commit();
    rQuery(0, "*:*", slaveClient);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006418/fstmerge_var2_7395315383522406132

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/handler/TestReplicationHandler.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_var1_4600017613152554709
@Test
  public void testIndexAndConfigReplication() throws Exception {
    clearIndexWithReplication();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_base_4588206409616533688
public void testIndexAndConfigReplication() throws Exception {
=======
@Test
  public void testIndexAndConfigReplication() throws Exception {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_var2_1578559821030429444

    nDocs--;
    for (int i = 0; i < nDocs; i++)
      index(masterClient, "id", i, "name", "name = " + i);

    masterClient.commit();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_var1_4600017613152554709
    NamedList masterQueryRsp = rQuery(nDocs, "*:*", masterClient);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_base_4588206409616533688
    NamedList masterQueryRsp = query("*:*", masterClient);
=======
    NamedList masterQueryRsp = rQuery(500, "*:*", masterClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_var2_1578559821030429444
    SolrDocumentList masterQueryResult = (SolrDocumentList) masterQueryRsp.get("response");
    assertEquals(nDocs, masterQueryResult.getNumFound());

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_base_4588206409616533688
    //sleep for pollinterval time 3s, to let slave pull data.
    Thread.sleep(3000);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_var2_1578559821030429444
    //get docs from slave and check if number is equal to master
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_var1_4600017613152554709
    NamedList slaveQueryRsp = rQuery(nDocs, "*:*", slaveClient);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_base_4588206409616533688
    NamedList slaveQueryRsp = query("*:*", slaveClient);
=======
    NamedList slaveQueryRsp = rQuery(500, "*:*", slaveClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_var2_1578559821030429444
    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_var1_4600017613152554709
    assertEquals(nDocs, slaveQueryResult.getNumFound());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_base_4588206409616533688

    if (slaveQueryResult.getNumFound() == 0) {
      //try sleeping again in case of slower comp
      Thread.sleep(5000);

      slaveQueryRsp = query("*:*", slaveClient);
      slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
    }

    assertEquals(500, slaveQueryResult.getNumFound());
=======
    assertEquals(500, slaveQueryResult.getNumFound());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_var2_1578559821030429444

    //compare results
    String cmp = TestDistributedSearch.compare(masterQueryResult, slaveQueryResult, 0, null);
    assertEquals(null, cmp);

    //start config files replication test
    masterClient.deleteByQuery("*:*");
    masterClient.commit();

    //change the schema on master
    copyFile(new File(CONF_DIR + "schema-replication2.xml"), new File(master.getConfDir(), "schema.xml"));

    masterJetty.stop();

    masterJetty = createJetty(master);
    masterClient = createNewSolrServer(masterJetty.getLocalPort());

    copyFile(new File(SLAVE_CONFIG), new File(slave.getConfDir(), "solrconfig.xml"), masterJetty.getLocalPort());

    slaveJetty.stop();
    slaveJetty = createJetty(slave);
    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());

    //add a doc with new field and commit on master to trigger snappull from slave.
    index(masterClient, "id", "2000", "name", "name = " + 2000, "newname", "newname = " + 2000);
    masterClient.commit();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_base_4588206409616533688
    //sleep for 3s for replication to happen.
    Thread.sleep(3000);
=======
    NamedList masterQueryRsp2 = rQuery(1, "*:*", masterClient);
    SolrDocumentList masterQueryResult2 = (SolrDocumentList) masterQueryRsp2.get("response");
    assertEquals(1, masterQueryResult2.getNumFound());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_var2_1578559821030429444

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_base_4588206409616533688
    slaveQueryRsp = query("*:*", slaveClient);
=======
    slaveQueryRsp = rQuery(1, "*:*", slaveClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006452/fstmerge_var2_1578559821030429444
    SolrDocument d = ((SolrDocumentList) slaveQueryRsp.get("response")).get(0);
    assertEquals("newname = 2000", (String) d.getFieldValue("newname"));

  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/handler/TestReplicationHandler.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_var1_6497864597952647105
@Test
  public void testIndexAndConfigAliasReplication() throws Exception {
    clearIndexWithReplication();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_base_3890874356288727868
public void testIndexAndConfigAliasReplication() throws Exception {
=======
@Test
  public void testIndexAndConfigAliasReplication() throws Exception {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_var2_3105633790859087993

    nDocs--;
    for (int i = 0; i < nDocs; i++)
      index(masterClient, "id", i, "name", "name = " + i);

    masterClient.commit();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_var1_6497864597952647105
    NamedList masterQueryRsp = rQuery(nDocs, "*:*", masterClient);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_base_3890874356288727868
    NamedList masterQueryRsp = query("*:*", masterClient);
=======
    NamedList masterQueryRsp = rQuery(500, "*:*", masterClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_var2_3105633790859087993
    SolrDocumentList masterQueryResult = (SolrDocumentList) masterQueryRsp.get("response");
    assertEquals(nDocs, masterQueryResult.getNumFound());

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_base_3890874356288727868
    //sleep for pollinterval time 3s, to let slave pull data.
    Thread.sleep(3000);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_var2_3105633790859087993
    //get docs from slave and check if number is equal to master
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_var1_6497864597952647105
    NamedList slaveQueryRsp = rQuery(nDocs, "*:*", slaveClient);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_base_3890874356288727868
    NamedList slaveQueryRsp = query("*:*", slaveClient);
=======
    NamedList slaveQueryRsp = rQuery(500, "*:*", slaveClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_var2_3105633790859087993
    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_var1_6497864597952647105
    assertEquals(nDocs, slaveQueryResult.getNumFound());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_base_3890874356288727868
    if (slaveQueryResult.getNumFound() == 0) {
      //try sleeping again in case of slower comp
      Thread.sleep(5000);

      slaveQueryRsp = query("*:*", slaveClient);
      slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
    }

    assertEquals(500, slaveQueryResult.getNumFound());
=======
    assertEquals(500, slaveQueryResult.getNumFound());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_var2_3105633790859087993

    //compare results
    String cmp = TestDistributedSearch.compare(masterQueryResult, slaveQueryResult, 0, null);
    assertEquals(null, cmp);

    //start config files replication test
    //clear master index
    masterClient.deleteByQuery("*:*");
    masterClient.commit();

    //change solrconfig on master
    copyFile(new File(CONF_DIR + "solrconfig-master1.xml"), new File(master.getConfDir(), "solrconfig.xml"));

    //change schema on master
    copyFile(new File(CONF_DIR + "schema-replication2.xml"), new File(master.getConfDir(), "schema.xml"));

    //keep a copy of the new schema
    copyFile(new File(CONF_DIR + "schema-replication2.xml"), new File(master.getConfDir(), "schema-replication2.xml"));

    masterJetty.stop();

    masterJetty = createJetty(master);
    masterClient = createNewSolrServer(masterJetty.getLocalPort());

    copyFile(new File(SLAVE_CONFIG), new File(slave.getConfDir(), "solrconfig.xml"), masterJetty.getLocalPort());

    slaveJetty.stop();
    slaveJetty = createJetty(slave);
    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());

    //add a doc with new field and commit on master to trigger snappull from slave.
    index(masterClient, "id", "2000", "name", "name = " + 2000, "newname", "newname = " + 2000);
    masterClient.commit();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_var1_6497864597952647105

    NamedList masterQueryRsp2 = rQuery(1, "*:*", masterClient);
    SolrDocumentList masterQueryResult2 = (SolrDocumentList) masterQueryRsp2.get("response");
    assertEquals(1, masterQueryResult2.getNumFound());

    NamedList slaveQueryRsp2 = rQuery(1, "*:*", slaveClient);
    SolrDocumentList slaveQueryResult2 = (SolrDocumentList) slaveQueryRsp2.get("response");
    assertEquals(1, slaveQueryResult2.getNumFound());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_base_3890874356288727868

    //sleep for 3s for replication to happen.
    Thread.sleep(3000);
=======
    
    NamedList masterQueryRsp2 = rQuery(1, "*:*", masterClient);
    SolrDocumentList masterQueryResult2 = (SolrDocumentList) masterQueryRsp2.get("response");
    assertEquals(1, masterQueryResult2.getNumFound());
    
    NamedList slaveQueryRsp2 = rQuery(1, "*:*", slaveClient);
    SolrDocumentList slaveQueryResult2 = (SolrDocumentList) slaveQueryRsp2.get("response");
    assertEquals(1, slaveQueryResult2.getNumFound());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_var2_3105633790859087993

    index(slaveClient, "id", "2000", "name", "name = " + 2001, "newname", "newname = " + 2001);
    slaveClient.commit();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_base_3890874356288727868
    slaveQueryRsp = query("*:*", slaveClient);
=======
    slaveQueryRsp = rQuery(1, "*:*", slaveClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006458/fstmerge_var2_3105633790859087993
    SolrDocument d = ((SolrDocumentList) slaveQueryRsp.get("response")).get(0);
    assertEquals("newname = 2001", (String) d.getFieldValue("newname"));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/handler/TestReplicationHandler.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_var1_7723613609520312668
@Test
  public void testStopPoll() throws Exception {
    clearIndexWithReplication();

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_base_9154633825541572755
public void testStopPoll() throws Exception {
=======
@Test
  public void testStopPoll() throws Exception {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_var2_288497438835725300
    // Test:
    // setup master/slave.
    // stop polling on slave, add a doc to master and verify slave hasn't picked it.
    nDocs--;
    for (int i = 0; i < nDocs; i++)
      index(masterClient, "id", i, "name", "name = " + i);

    masterClient.commit();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_var1_7723613609520312668
    NamedList masterQueryRsp = rQuery(nDocs, "*:*", masterClient);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_base_9154633825541572755
    NamedList masterQueryRsp = query("*:*", masterClient);
=======
    NamedList masterQueryRsp = rQuery(500, "*:*", masterClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_var2_288497438835725300
    SolrDocumentList masterQueryResult = (SolrDocumentList) masterQueryRsp.get("response");
    assertEquals(nDocs, masterQueryResult.getNumFound());

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_base_9154633825541572755
    //sleep for pollinterval time 3s, to let slave pull data.
    Thread.sleep(3000);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_var2_288497438835725300
    //get docs from slave and check if number is equal to master
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_var1_7723613609520312668
    NamedList slaveQueryRsp = rQuery(nDocs, "*:*", slaveClient);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_base_9154633825541572755
    NamedList slaveQueryRsp = query("*:*", slaveClient);
=======
    NamedList slaveQueryRsp = rQuery(500, "*:*", slaveClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_var2_288497438835725300
    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
    assertEquals(nDocs, slaveQueryResult.getNumFound());

    //compare results
    String cmp = TestDistributedSearch.compare(masterQueryResult, slaveQueryResult, 0, null);
    assertEquals(null, cmp);

    // start stop polling test
    String slaveURL = "http://localhost:" + slaveJetty.getLocalPort() + "/solr/replication?command=disablepoll";
    URL url = new URL(slaveURL);
    InputStream stream = url.openStream();
    try {
      stream.close();
    } catch (IOException e) {
      //e.printStackTrace();
    }
    index(masterClient, "id", 501, "name", "name = " + 501);
    masterClient.commit();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_var1_7723613609520312668

    //get docs from master and check if number is equal to master
    masterQueryRsp = rQuery(nDocs+1, "*:*", masterClient);
    masterQueryResult = (SolrDocumentList) masterQueryRsp.get("response");
    assertEquals(nDocs+1, masterQueryResult.getNumFound());
    
    // NOTE: this test is wierd, we want to verify it DOESNT replicate...
    // for now, add a sleep for this.., but the logic is wierd.
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_base_9154633825541572755
    //sleep for pollinterval time 3s, to let slave pull data.
=======

    //get docs from master and check if number is equal to master
    masterQueryRsp = rQuery(501, "*:*", masterClient);
    masterQueryResult = (SolrDocumentList) masterQueryRsp.get("response");
    assertEquals(501, masterQueryResult.getNumFound());
    
    // NOTE: this test is wierd, we want to verify it DOESNT replicate...
    // for now, add a sleep for this.., but the logic is wierd.
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_var2_288497438835725300
    Thread.sleep(3000);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_var1_7723613609520312668
    
    //get docs from slave and check if number is not equal to master; polling is disabled
    slaveQueryRsp = rQuery(nDocs, "*:*", slaveClient);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_base_9154633825541572755
    //get docs from slave and check if number is equal to master
    slaveQueryRsp = query("*:*", slaveClient);
=======
    
    //get docs from slave and check if number is not equal to master; polling is disabled
    slaveQueryRsp = rQuery(500, "*:*", slaveClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_var2_288497438835725300
    slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_var1_7723613609520312668
    assertEquals(nDocs, slaveQueryResult.getNumFound());

    // re-enable replication
    slaveURL = "http://localhost:" + slaveJetty.getLocalPort() + "/solr/replication?command=enablepoll";
    url = new URL(slaveURL);
    stream = url.openStream();
    try {
      stream.close();
    } catch (IOException e) {
      //e.printStackTrace();
    }

    slaveQueryRsp = rQuery(nDocs+1, "*:*", slaveClient);
    slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
    assertEquals(nDocs+1, slaveQueryResult.getNumFound());   
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_base_9154633825541572755
    assertEquals(500, slaveQueryResult.getNumFound());
    //get docs from slave and check if number is equal to master
    slaveQueryRsp = query("*:*", masterClient);
    slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
    assertEquals(501, slaveQueryResult.getNumFound());
=======
    assertEquals(500, slaveQueryResult.getNumFound());

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006464/fstmerge_var2_288497438835725300
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/handler/TestReplicationHandler.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006470/fstmerge_base_6895331584488320430
public void testSnapPullWithMasterUrl() throws Exception {
=======
@Test
  public void testSnapPullWithMasterUrl() throws Exception {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006470/fstmerge_var2_8606865337912340995
    //change solrconfig on slave
    //this has no entry for pollinginterval
    copyFile(new File(CONF_DIR + "solrconfig-slave1.xml"), new File(slave.getConfDir(), "solrconfig.xml"), masterJetty.getLocalPort());
    slaveJetty.stop();
    slaveJetty = createJetty(slave);
    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());

    masterClient.deleteByQuery("*:*");
    nDocs--;
    for (int i = 0; i < nDocs; i++)
      index(masterClient, "id", i, "name", "name = " + i);

    masterClient.commit();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006470/fstmerge_var1_8102775415996909919
    NamedList masterQueryRsp = rQuery(nDocs, "*:*", masterClient);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006470/fstmerge_base_6895331584488320430
    NamedList masterQueryRsp = query("*:*", masterClient);
=======
    NamedList masterQueryRsp = rQuery(500, "*:*", masterClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006470/fstmerge_var2_8606865337912340995
    SolrDocumentList masterQueryResult = (SolrDocumentList) masterQueryRsp.get("response");
    assertEquals(nDocs, masterQueryResult.getNumFound());

    // snappull
    String masterUrl = "http://localhost:" + slaveJetty.getLocalPort() + "/solr/replication?command=fetchindex&masterUrl=";
    masterUrl += "http://localhost:" + masterJetty.getLocalPort() + "/solr/replication";
    URL url = new URL(masterUrl);
    InputStream stream = url.openStream();
    try {
      stream.close();
    } catch (IOException e) {
      //e.printStackTrace();
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006470/fstmerge_base_6895331584488320430
    Thread.sleep(3000);
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006470/fstmerge_var2_8606865337912340995
    //get docs from slave and check if number is equal to master
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006470/fstmerge_var1_8102775415996909919
    NamedList slaveQueryRsp = rQuery(nDocs, "*:*", slaveClient);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006470/fstmerge_base_6895331584488320430
    NamedList slaveQueryRsp = query("*:*", slaveClient);
=======
    NamedList slaveQueryRsp = rQuery(500, "*:*", slaveClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006470/fstmerge_var2_8606865337912340995
    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
    assertEquals(nDocs, slaveQueryResult.getNumFound());
    //compare results
    String cmp = TestDistributedSearch.compare(masterQueryResult, slaveQueryResult, 0, null);
    assertEquals(null, cmp);

    // NOTE: at this point, the slave is not polling any more
    // restore it.
    copyFile(new File(CONF_DIR + "solrconfig-slave.xml"), new File(slave.getConfDir(), "solrconfig.xml"), masterJetty.getLocalPort());
    slaveJetty.stop();
    slaveJetty = createJetty(slave);
    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/handler/TestReplicationHandler.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006475/fstmerge_base_51881863866399122
public void testReplicateAfterStartup() throws Exception {
=======
@Test
  public void testReplicateAfterStartup() throws Exception {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006475/fstmerge_var2_1008663823276676053
    //stop slave
    slaveJetty.stop();

    nDocs--;
    masterClient.deleteByQuery("*:*");
    for (int i = 0; i < nDocs; i++)
      index(masterClient, "id", i, "name", "name = " + i);

    masterClient.commit();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006475/fstmerge_var1_3384375049268162848
    NamedList masterQueryRsp = rQuery(nDocs, "*:*", masterClient);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006475/fstmerge_base_51881863866399122
    NamedList masterQueryRsp = query("*:*", masterClient);
=======
    NamedList masterQueryRsp = rQuery(500, "*:*", masterClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006475/fstmerge_var2_1008663823276676053
    SolrDocumentList masterQueryResult = (SolrDocumentList) masterQueryRsp.get("response");
    assertEquals(nDocs, masterQueryResult.getNumFound());

    //change solrconfig having 'replicateAfter startup' option on master
    copyFile(new File(CONF_DIR + "solrconfig-master2.xml"),
            new File(master.getConfDir(), "solrconfig.xml"));

    masterJetty.stop();

    masterJetty = createJetty(master);
    masterClient = createNewSolrServer(masterJetty.getLocalPort());

    copyFile(new File(SLAVE_CONFIG), new File(slave.getConfDir(), "solrconfig.xml"), masterJetty.getLocalPort());

    //start slave
    slaveJetty = createJetty(slave);
    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006475/fstmerge_base_51881863866399122
    //sleep for pollinterval time 3s, to let slave pull data.
    Thread.sleep(3000);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006475/fstmerge_var2_1008663823276676053
    //get docs from slave and check if number is equal to master
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006475/fstmerge_var1_3384375049268162848
    NamedList slaveQueryRsp = rQuery(nDocs, "*:*", slaveClient);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006475/fstmerge_base_51881863866399122
    NamedList slaveQueryRsp = query("*:*", slaveClient);
=======
    NamedList slaveQueryRsp = rQuery(500, "*:*", slaveClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006475/fstmerge_var2_1008663823276676053
    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
    assertEquals(nDocs, slaveQueryResult.getNumFound());

    //compare results
    String cmp = TestDistributedSearch.compare(masterQueryResult, slaveQueryResult, 0, null);
    assertEquals(null, cmp);

    // NOTE: the master only replicates after startup now!
    // revert that change.
    copyFile(new File(CONF_DIR + "solrconfig-master.xml"), new File(master.getConfDir(), "solrconfig.xml"));    
    masterJetty.stop();
    masterJetty = createJetty(master);
    masterClient = createNewSolrServer(masterJetty.getLocalPort());
    copyFile(new File(SLAVE_CONFIG), new File(slave.getConfDir(), "solrconfig.xml"), masterJetty.getLocalPort());
    //start slave
    slaveJetty.stop();
    slaveJetty = createJetty(slave);
    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/handler/TestReplicationHandler.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_var1_2477716466489396530
@Test
  public void testReplicateAfterWrite2Slave() throws Exception {
    clearIndexWithReplication();
    nDocs--;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_base_9145279477948974572
public void testReplicateAfterWrite2Slave() throws Exception {
    //add 50 docs to master
    int nDocs = 50;
=======
@Test
  public void testReplicateAfterWrite2Slave() throws Exception {
    //add 50 docs to master
    int nDocs = 50;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_var2_6326653402135319943
    for (int i = 0; i < nDocs; i++) {
      index(masterClient, "id", i, "name", "name = " + i);
    }

    String masterUrl = "http://localhost:" + masterJetty.getLocalPort() + "/solr/replication?command=disableReplication";
    URL url = new URL(masterUrl);
    InputStream stream = url.openStream();
    try {
      stream.close();
    } catch (IOException e) {
      //e.printStackTrace();
    }

    masterClient.commit();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_var1_2477716466489396530
    NamedList masterQueryRsp = rQuery(nDocs, "*:*", masterClient);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_base_9145279477948974572
    NamedList masterQueryRsp = query("*:*", masterClient);
=======
    NamedList masterQueryRsp = rQuery(50, "*:*", masterClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_var2_6326653402135319943
    SolrDocumentList masterQueryResult = (SolrDocumentList) masterQueryRsp.get("response");
    assertEquals(nDocs, masterQueryResult.getNumFound());

    // Make sure that both the index version and index generation on the slave is
    // higher than that of the master, just to make the test harder.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_base_9145279477948974572
    Thread.sleep(100);
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_var2_6326653402135319943
    index(slaveClient, "id", 551, "name", "name = " + 551);
    slaveClient.commit(true, true);
    index(slaveClient, "id", 552, "name", "name = " + 552);
    slaveClient.commit(true, true);
    index(slaveClient, "id", 553, "name", "name = " + 553);
    slaveClient.commit(true, true);
    index(slaveClient, "id", 554, "name", "name = " + 554);
    slaveClient.commit(true, true);
    index(slaveClient, "id", 555, "name", "name = " + 555);
    slaveClient.commit(true, true);


    //this doc is added to slave so it should show an item w/ that result
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_var1_2477716466489396530
    SolrDocumentList slaveQueryResult = null;
    NamedList slaveQueryRsp;
    slaveQueryRsp = rQuery(1, "id:555", slaveClient);
    slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_base_9145279477948974572
    NamedList slaveQueryRsp = query("id:555", slaveClient);
    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
=======
    NamedList slaveQueryRsp = rQuery(1, "id:555", slaveClient);
    SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_var2_6326653402135319943
    assertEquals(1, slaveQueryResult.getNumFound());

    masterUrl = "http://localhost:" + masterJetty.getLocalPort() + "/solr/replication?command=enableReplication";
    url = new URL(masterUrl);
    stream = url.openStream();
    try {
      stream.close();
    } catch (IOException e) {
      //e.printStackTrace();
    }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_base_9145279477948974572
    //sleep for pollinterval time 3s, to let slave pull data.
    Thread.sleep(3000);
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_var2_6326653402135319943
    //the slave should have done a full copy of the index so the doc with id:555 should not be there in the slave now
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_base_9145279477948974572
    slaveQueryRsp = query("id:555", slaveClient);
=======
    slaveQueryRsp = rQuery(0, "id:555", slaveClient);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006480/fstmerge_var2_6326653402135319943
    slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
    assertEquals(0, slaveQueryResult.getNumFound());

    // make sure we replicated the correct index from the master
    slaveQueryRsp = rQuery(nDocs, "*:*", slaveClient);
    slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
    assertEquals(nDocs, slaveQueryResult.getNumFound());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/handler/TestReplicationHandler.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006485/fstmerge_base_3383836844279529400
public void testBackup() throws Exception {
=======
@Test
  public void testBackup() throws Exception {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006485/fstmerge_var2_2559434524354226390

    masterJetty.stop();
    copyFile(new File(CONF_DIR + "solrconfig-master1.xml"), new File(master.getConfDir(), "solrconfig.xml"));

    masterJetty = createJetty(master);
    masterClient = createNewSolrServer(masterJetty.getLocalPort());


    nDocs--;
    masterClient.deleteByQuery("*:*");
    for (int i = 0; i < nDocs; i++)
      index(masterClient, "id", i, "name", "name = " + i);

    masterClient.commit();
   
    class BackupThread extends Thread {
      volatile String fail = null;
      public void run() {
        String masterUrl = "http://localhost:" + masterJetty.getLocalPort() + "/solr/replication?command=" + ReplicationHandler.CMD_BACKUP;
        URL url;
        InputStream stream = null;
        try {
          url = new URL(masterUrl);
          stream = url.openStream();
          stream.close();
        } catch (Exception e) {
          fail = e.getMessage();
        } finally {
          IOUtils.closeQuietly(stream);
        }

      };
    };
    BackupThread backupThread = new BackupThread();
    backupThread.start();
    
    File dataDir = new File(master.getDataDir());
    class CheckStatus extends Thread {
      volatile String fail = null;
      volatile String response = null;
      volatile boolean success = false;
      public void run() {
        String masterUrl = "http://localhost:" + masterJetty.getLocalPort() + "/solr/replication?command=" + ReplicationHandler.CMD_DETAILS;
        URL url;
        InputStream stream = null;
        try {
          url = new URL(masterUrl);
          stream = url.openStream();
          response = IOUtils.toString(stream);
          if(response.contains("<str name=\"status\">success</str>")) {
            success = true;
          }
          stream.close();
        } catch (Exception e) {
          fail = e.getMessage();
        } finally {
          IOUtils.closeQuietly(stream);
        }

      };
    };
    int waitCnt = 0;
    CheckStatus checkStatus = new CheckStatus();
    while(true) {
      checkStatus.run();
      if(checkStatus.fail != null) {
        fail(checkStatus.fail);
      }
      if(checkStatus.success) {
        break;
      }
      Thread.sleep(200);
      if(waitCnt == 10) {
        fail("Backup success not detected:" + checkStatus.response);
      }
      waitCnt++;
    }
    
    if(backupThread.fail != null) {
      fail(backupThread.fail);
    }

    File[] files = dataDir.listFiles(new FilenameFilter() {
      
      public boolean accept(File dir, String name) {
        if(name.startsWith("snapshot")) {
          return true;
        }
        return false;
      }
    });
    assertEquals(1, files.length);
    File snapDir = files[0];
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006485/fstmerge_base_3383836844279529400

    IndexSearcher searcher = new IndexSearcher(new SimpleFSDirectory(snapDir.getAbsoluteFile(), null), true);
=======
    Directory dir = new SimpleFSDirectory(snapDir.getAbsoluteFile());
    IndexSearcher searcher = new IndexSearcher(dir, true);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006485/fstmerge_var2_2559434524354226390
    TopDocs hits = searcher.search(new MatchAllDocsQuery(), 1);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006485/fstmerge_var1_4540143158654550363
    assertEquals(nDocs, hits.totalHits);
    searcher.close();
    dir.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006485/fstmerge_base_3383836844279529400
    assertEquals(500, hits.totalHits);
=======
    assertEquals(500, hits.totalHits);
    searcher.close();
    dir.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006485/fstmerge_var2_2559434524354226390
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/handler/TestReplicationHandler.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void beforeClass() throws Exception {
    initCore("solrconfig.xml","schema.xml");

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006751/fstmerge_var1_3518047623382607304
    assertU(adoc("id", "0",
            "test_posofftv", "This is a title and another title",
            "test_basictv", "This is a title and another title",
            "test_notv", "This is a title and another title",
            "test_postv", "This is a title and another title",
            "test_offtv", "This is a title and another title"
    ));
    assertU(adoc("id", "1",
            "test_posofftv", "The quick reb fox jumped over the lazy brown dogs.",
            "test_basictv", "The quick reb fox jumped over the lazy brown dogs.",
            "test_notv", "The quick reb fox jumped over the lazy brown dogs.",
            "test_postv", "The quick reb fox jumped over the lazy brown dogs.",
            "test_offtv", "The quick reb fox jumped over the lazy brown dogs."
    ));
    assertU(adoc("id", "2",
            "test_posofftv", "This is a document",
            "test_basictv", "This is a document",
            "test_notv", "This is a document",
            "test_postv", "This is a document",
            "test_offtv", "This is a document"
    ));
    assertU(adoc("id", "3",
            "test_posofftv", "another document",
            "test_basictv", "another document",
            "test_notv", "another document",
            "test_postv", "another document",
            "test_offtv", "another document"
    ));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006751/fstmerge_base_1308300099725172524
    assertNull(h.validateUpdate(adoc("id", "0", "test_posofftv", "This is a title and another title")));
    assertNull(h.validateUpdate(adoc("id", "1", "test_posofftv",
            "The quick reb fox jumped over the lazy brown dogs.")));
    assertNull(h.validateUpdate(adoc("id", "2", "test_posofftv", "This is a document")));
    assertNull(h.validateUpdate(adoc("id", "3", "test_posofftv", "another document")));
=======
    assertNull(h.validateUpdate(adoc("id", "0",
            "test_posofftv", "This is a title and another title",
            "test_basictv", "This is a title and another title",
            "test_notv", "This is a title and another title",
            "test_postv", "This is a title and another title",
            "test_offtv", "This is a title and another title"
    )));
    assertNull(h.validateUpdate(adoc("id", "1",
            "test_posofftv", "The quick reb fox jumped over the lazy brown dogs.",
            "test_basictv", "The quick reb fox jumped over the lazy brown dogs.",
            "test_notv", "The quick reb fox jumped over the lazy brown dogs.",
            "test_postv", "The quick reb fox jumped over the lazy brown dogs.",
            "test_offtv", "The quick reb fox jumped over the lazy brown dogs."
    )));
    assertNull(h.validateUpdate(adoc("id", "2",
            "test_posofftv", "This is a document",
            "test_basictv", "This is a document",
            "test_notv", "This is a document",
            "test_postv", "This is a document",
            "test_offtv", "This is a document"
    )));
    assertNull(h.validateUpdate(adoc("id", "3",
            "test_posofftv", "another document",
            "test_basictv", "another document",
            "test_notv", "another document",
            "test_postv", "another document",
            "test_offtv", "another document"
    )));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006751/fstmerge_var2_7648991063236722640
    //bunch of docs that are variants on blue
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006751/fstmerge_var1_3518047623382607304
    assertU(adoc("id", "4",
            "test_posofftv", "blue",
            "test_basictv", "blue",
            "test_notv", "blue",
            "test_postv", "blue",
            "test_offtv", "blue"
    ));
    assertU(adoc("id", "5",
            "test_posofftv", "blud",
            "test_basictv", "blud",
            "test_notv", "blud",
            "test_postv", "blud",
            "test_offtv", "blud"
    ));
    assertU(adoc("id", "6",
            "test_posofftv", "boue",
            "test_basictv", "boue",
            "test_notv", "boue",
            "test_postv", "boue",
            "test_offtv", "boue"
    ));
    assertU(adoc("id", "7",
            "test_posofftv", "glue",
            "test_basictv", "glue",
            "test_notv", "glue",
            "test_postv", "glue",
            "test_offtv", "glue"
    ));
    assertU(adoc("id", "8",
            "test_posofftv", "blee",
            "test_basictv", "blee",
            "test_notv", "blee",
            "test_postv", "blee",
            "test_offtv", "blee"
    ));
    assertU(adoc("id", "9",
            "test_posofftv", "blah",
            "test_basictv", "blah",
            "test_notv", "blah",
            "test_postv", "blah",
            "test_offtv", "blah"
    ));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006751/fstmerge_base_1308300099725172524
    assertNull(h.validateUpdate(adoc("id", "4", "test_posofftv", "blue")));
    assertNull(h.validateUpdate(adoc("id", "5", "test_posofftv", "blud")));
    assertNull(h.validateUpdate(adoc("id", "6", "test_posofftv", "boue")));
    assertNull(h.validateUpdate(adoc("id", "7", "test_posofftv", "glue")));
    assertNull(h.validateUpdate(adoc("id", "8", "test_posofftv", "blee")));
    assertNull(h.validateUpdate(adoc("id", "9", "test_posofftv", "blah")));
=======
    assertNull(h.validateUpdate(adoc("id", "4",
            "test_posofftv", "blue",
            "test_basictv", "blue",
            "test_notv", "blue",
            "test_postv", "blue",
            "test_offtv", "blue"
    )));
    assertNull(h.validateUpdate(adoc("id", "5",
            "test_posofftv", "blud",
            "test_basictv", "blud",
            "test_notv", "blud",
            "test_postv", "blud",
            "test_offtv", "blud"
    )));
    assertNull(h.validateUpdate(adoc("id", "6",
            "test_posofftv", "boue",
            "test_basictv", "boue",
            "test_notv", "boue",
            "test_postv", "boue",
            "test_offtv", "boue"
    )));
    assertNull(h.validateUpdate(adoc("id", "7",
            "test_posofftv", "glue",
            "test_basictv", "glue",
            "test_notv", "glue",
            "test_postv", "glue",
            "test_offtv", "glue"
    )));
    assertNull(h.validateUpdate(adoc("id", "8",
            "test_posofftv", "blee",
            "test_basictv", "blee",
            "test_notv", "blee",
            "test_postv", "blee",
            "test_offtv", "blee"
    )));
    assertNull(h.validateUpdate(adoc("id", "9",
            "test_posofftv", "blah",
            "test_basictv", "blah",
            "test_notv", "blah",
            "test_postv", "blah",
            "test_offtv", "blah"
    )));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006751/fstmerge_var2_7648991063236722640

    assertNull(h.validateUpdate(commit()));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/handler/component/TermVectorComponentTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testBasics() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006758/fstmerge_var1_4137521729227154730
    assertJQ(req("json.nl","map", "qt",tv, "q", "id:0", TermVectorComponent.COMPONENT_NAME, "true", TermVectorParams.TF, "true")
       ,"/termVectors=={'doc-0':{'uniqueKey':'0'," +
            " 'test_basictv':{'anoth':{'tf':1},'titl':{'tf':2}}," +
            " 'test_offtv':{'anoth':{'tf':1},'titl':{'tf':2}}," +
            " 'test_posofftv':{'anoth':{'tf':1},'titl':{'tf':2}}," +
            " 'test_postv':{'anoth':{'tf':1},'titl':{'tf':2}}}," +
            " 'uniqueKeyFieldName':'id'}"
    );
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006758/fstmerge_base_1326936215819566237
    SolrCore core = h.getCore();
    SearchComponent tvComp = core.getSearchComponent("tvComponent");
    assertTrue("tvComp is null and it shouldn't be", tvComp != null);
    ModifiableSolrParams params = new ModifiableSolrParams();
    params.add(CommonParams.Q, "id:0");
    params.add(CommonParams.QT, "tvrh");
    params.add(TermVectorParams.TF, "true");
    params.add(TermVectorComponent.COMPONENT_NAME, "true");
    SolrRequestHandler handler = core.getRequestHandler("tvrh");
    SolrQueryResponse rsp;
    rsp = new SolrQueryResponse();
    rsp.add("responseHeader", new SimpleOrderedMap());
    handler.handleRequest(new LocalSolrQueryRequest(core, params), rsp);
    NamedList values = rsp.getValues();
    NamedList termVectors = (NamedList) values.get(TermVectorComponent.TERM_VECTORS);
    assertTrue("termVectors is null and it shouldn't be", termVectors != null);
    // System.out.println("TVs:" + termVectors);
    NamedList doc = (NamedList) termVectors.getVal(0);
    assertTrue("doc is null and it shouldn't be", doc != null);
    assertTrue(doc.size() + " does not equal: " + 2, doc.size() == 2);
    NamedList field = (NamedList) doc.get("test_posofftv");
    assertTrue("field is null and it shouldn't be", field != null);
    assertTrue(field.size() + " does not equal: " + 2, field.size() == 2);
    NamedList titl = (NamedList) field.get("titl");
    assertTrue("titl is null and it shouldn't be", titl != null);
    assertTrue(titl.get("tf") + " does not equal: " + 2, ((Integer) titl.get("tf")) == 2);
    //there should not be any positions or offsets
    NamedList positions = (NamedList) titl.get("positions");
    assertTrue("positions is not null and it should be", positions == null);
    NamedList offsets = (NamedList) titl.get("offsets");
    assertTrue("offsets is not null and it should be", offsets == null);
    String uniqueKeyFieldName = (String) termVectors.getVal(1);
    assertTrue("uniqueKeyFieldName is null and it shouldn't be", uniqueKeyFieldName != null);
    assertTrue(uniqueKeyFieldName + " is not equal to " + "id", uniqueKeyFieldName.equals("id") == true);

=======
    SolrCore core = h.getCore();
    SearchComponent tvComp = core.getSearchComponent("tvComponent");
    assertTrue("tvComp is null and it shouldn't be", tvComp != null);
    ModifiableSolrParams params = new ModifiableSolrParams();
    params.add(CommonParams.Q, "id:0");
    params.add(CommonParams.QT, "tvrh");
    params.add(TermVectorParams.TF, "true");
    params.add(TermVectorComponent.COMPONENT_NAME, "true");
    SolrRequestHandler handler = core.getRequestHandler("tvrh");
    SolrQueryResponse rsp;
    rsp = new SolrQueryResponse();
    rsp.add("responseHeader", new SimpleOrderedMap());
    handler.handleRequest(new LocalSolrQueryRequest(core, params), rsp);
    NamedList values = rsp.getValues();
    NamedList termVectors = (NamedList) values.get(TermVectorComponent.TERM_VECTORS);
    assertTrue("termVectors is null and it shouldn't be", termVectors != null);
    if (VERBOSE) System.out.println("TVs:" + termVectors);
    NamedList doc = (NamedList) termVectors.getVal(0);
    assertTrue("doc is null and it shouldn't be", doc != null);
    assertEquals(doc.size(), 5);
    NamedList field = (NamedList) doc.get("test_posofftv");
    assertTrue("field is null and it shouldn't be", field != null);
    assertTrue(field.size() + " does not equal: " + 2, field.size() == 2);
    NamedList titl = (NamedList) field.get("titl");
    assertTrue("titl is null and it shouldn't be", titl != null);
    assertTrue(titl.get("tf") + " does not equal: " + 2, ((Integer) titl.get("tf")) == 2);
    //there should not be any positions or offsets
    NamedList positions = (NamedList) titl.get("positions");
    assertTrue("positions is not null and it should be", positions == null);
    NamedList offsets = (NamedList) titl.get("offsets");
    assertTrue("offsets is not null and it should be", offsets == null);
    String uniqueKeyFieldName = (String) termVectors.getVal(1);
    assertTrue("uniqueKeyFieldName is null and it shouldn't be", uniqueKeyFieldName != null);
    assertTrue(uniqueKeyFieldName + " is not equal to " + "id", uniqueKeyFieldName.equals("id") == true);

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006758/fstmerge_var2_7595606905973613765
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/handler/component/TermVectorComponentTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testOptions() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006764/fstmerge_var1_2598429746619310360
    assertJQ(req("json.nl","map", "qt",tv, "q", "id:0", TermVectorComponent.COMPONENT_NAME, "true"
       , TermVectorParams.TF, "true", TermVectorParams.DF, "true", TermVectorParams.OFFSETS, "true", TermVectorParams.POSITIONS, "true", TermVectorParams.TF_IDF, "true")
       ,"/termVectors/doc-0/test_posofftv/anoth=={'tf':1, 'offsets':{'start':20, 'end':27}, 'positions':{'position':1}, 'df':2, 'tf-idf':0.5}"
    );    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006764/fstmerge_base_6107775843986578507
    SolrCore core = h.getCore();
    SearchComponent tvComp = core.getSearchComponent("tvComponent");
    assertTrue("tvComp is null and it shouldn't be", tvComp != null);
    ModifiableSolrParams params = new ModifiableSolrParams();
    params.add(CommonParams.Q, "id:0");
    params.add(CommonParams.QT, "tvrh");
    params.add(TermVectorParams.TF, "true");
    params.add(TermVectorParams.DF, "true");
    params.add(TermVectorParams.OFFSETS, "true");
    params.add(TermVectorParams.POSITIONS, "true");
    params.add(TermVectorParams.TF_IDF, "true");
    params.add(TermVectorComponent.COMPONENT_NAME, "true");

    SolrRequestHandler handler = core.getRequestHandler("tvrh");
    SolrQueryResponse rsp;
    rsp = new SolrQueryResponse();
    rsp.add("responseHeader", new SimpleOrderedMap());
    handler.handleRequest(new LocalSolrQueryRequest(core, params), rsp);
    NamedList values = rsp.getValues();
    NamedList termVectors = (NamedList) values.get(TermVectorComponent.TERM_VECTORS);
    assertTrue("termVectors is null and it shouldn't be", termVectors != null);
    // System.out.println("TVs: " + termVectors);
    NamedList doc = (NamedList) termVectors.getVal(0);
    assertTrue("doc is null and it shouldn't be", doc != null);
    assertTrue(doc.size() + " does not equal: " + 2, doc.size() == 2);
    NamedList offtv = (NamedList) doc.get("test_posofftv");
    assertTrue("offtv is null and it shouldn't be", offtv != null);
    assertTrue("offtv Size: " + offtv.size() + " is not: " + 2, offtv.size() == 2);
    NamedList another = (NamedList) offtv.get("anoth");
    NamedList offsets = (NamedList) another.get("offsets");
    assertTrue("offsets is null and it shouldn't be", offsets != null);
    assertTrue("offsets Size: " + offsets.size() + " is not greater than: " + 0, offsets.size() > 0);
    NamedList pos = (NamedList) another.get("positions");
    assertTrue("pos is null and it shouldn't be", pos != null);
    assertTrue("pos Size: " + pos.size() + " is not greater than: " + 0, pos.size() > 0);
    Integer df = (Integer) another.get("df");
    assertTrue("df is null and it shouldn't be", df != null);
    assertTrue(df + " does not equal: " + 2, df == 2);
    Double tfIdf = (Double) another.get("tf-idf");
    assertTrue("tfIdf is null and it shouldn't be", tfIdf != null);
    assertTrue(tfIdf + " does not equal: " + 0.5, tfIdf == 0.5);


=======
    SolrCore core = h.getCore();
    SearchComponent tvComp = core.getSearchComponent("tvComponent");
    assertTrue("tvComp is null and it shouldn't be", tvComp != null);
    ModifiableSolrParams params = new ModifiableSolrParams();
    params.add(CommonParams.Q, "id:0");
    params.add(CommonParams.QT, "tvrh");
    params.add(TermVectorParams.TF, "true");
    params.add(TermVectorParams.DF, "true");
    params.add(TermVectorParams.OFFSETS, "true");
    params.add(TermVectorParams.POSITIONS, "true");
    params.add(TermVectorParams.TF_IDF, "true");
    params.add(TermVectorComponent.COMPONENT_NAME, "true");

    SolrRequestHandler handler = core.getRequestHandler("tvrh");
    SolrQueryResponse rsp;
    rsp = new SolrQueryResponse();
    rsp.add("responseHeader", new SimpleOrderedMap());
    handler.handleRequest(new LocalSolrQueryRequest(core, params), rsp);
    NamedList values = rsp.getValues();
    NamedList termVectors = (NamedList) values.get(TermVectorComponent.TERM_VECTORS);
    assertTrue("termVectors is null and it shouldn't be", termVectors != null);
    // System.out.println("TVs: " + termVectors);
    NamedList doc = (NamedList) termVectors.getVal(0);
    assertTrue("doc is null and it shouldn't be", doc != null);
    assertEquals(doc.size(), 5);
    NamedList offtv = (NamedList) doc.get("test_posofftv");
    assertTrue("offtv is null and it shouldn't be", offtv != null);
    assertTrue("offtv Size: " + offtv.size() + " is not: " + 2, offtv.size() == 2);
    NamedList another = (NamedList) offtv.get("anoth");
    NamedList offsets = (NamedList) another.get("offsets");
    assertTrue("offsets is null and it shouldn't be", offsets != null);
    assertTrue("offsets Size: " + offsets.size() + " is not greater than: " + 0, offsets.size() > 0);
    NamedList pos = (NamedList) another.get("positions");
    assertTrue("pos is null and it shouldn't be", pos != null);
    assertTrue("pos Size: " + pos.size() + " is not greater than: " + 0, pos.size() > 0);
    Integer df = (Integer) another.get("df");
    assertTrue("df is null and it shouldn't be", df != null);
    assertTrue(df + " does not equal: " + 2, df == 2);
    Double tfIdf = (Double) another.get("tf-idf");
    assertTrue("tfIdf is null and it shouldn't be", tfIdf != null);
    assertTrue(tfIdf + " does not equal: " + 0.5, tfIdf == 0.5);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006764/fstmerge_var2_901797856818642931
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/handler/component/TermVectorComponentTest.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006770/fstmerge_var1_1131956649828457780
@Test
  public void testPerField() throws Exception {
    assertJQ(req("json.nl","map", "qt",tv, "q", "id:0", TermVectorComponent.COMPONENT_NAME, "true"
        ,TermVectorParams.TF, "true", TermVectorParams.DF, "true", TermVectorParams.OFFSETS, "true", TermVectorParams.POSITIONS, "true", TermVectorParams.TF_IDF, "true"
        ,TermVectorParams.FIELDS, "test_basictv,test_notv,test_postv,test_offtv,test_posofftv"
        ,"f.test_posofftv." + TermVectorParams.POSITIONS, "false"
        ,"f.test_offtv." + TermVectorParams.OFFSETS, "false"
        ,"f.test_basictv." + TermVectorParams.DF, "false"
        ,"f.test_basictv." + TermVectorParams.TF, "false"
        ,"f.test_basictv." + TermVectorParams.TF_IDF, "false"
        )
    ,"/termVectors/doc-0/test_basictv=={'anoth':{},'titl':{}}"
    ,"/termVectors/doc-0/test_postv/anoth=={'tf':1, 'positions':{'position':1}, 'df':2, 'tf-idf':0.5}"
    ,"/termVectors/doc-0/test_offtv/anoth=={'tf':1, 'df':2, 'tf-idf':0.5}"
    ,"/termVectors/warnings=={ 'noTermVectors':['test_notv'], 'noPositions':['test_basictv', 'test_offtv'], 'noOffsets':['test_basictv', 'test_postv']}"
    );
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006770/fstmerge_base_325668280667136613
=======
@Test
  public void testPerField() throws Exception {
    SolrCore core = h.getCore();
    SearchComponent tvComp = core.getSearchComponent("tvComponent");
    assertTrue("tvComp is null and it shouldn't be", tvComp != null);
    ModifiableSolrParams params = new ModifiableSolrParams();
    params.add(CommonParams.Q, "id:0");
    params.add(CommonParams.QT, "tvrh");
    params.add(TermVectorParams.FIELDS, "test_basictv,test_notv,test_postv,test_offtv,test_posofftv");
    params.add(TermVectorParams.TF, "true");
    params.add(TermVectorParams.DF, "true");
    params.add(TermVectorParams.OFFSETS, "true");
    params.add(TermVectorParams.POSITIONS, "true");
    params.add(TermVectorParams.TF_IDF, "true");
    params.add(TermVectorComponent.COMPONENT_NAME, "true");
    //per field
    params.add("f.test_posofftv." + TermVectorParams.POSITIONS, "false");
    params.add("f.test_offtv." + TermVectorParams.OFFSETS, "false");
    params.add("f.test_basictv." + TermVectorParams.DF, "false");
    params.add("f.test_basictv." + TermVectorParams.TF, "false");
    params.add("f.test_basictv." + TermVectorParams.TF_IDF, "false");
    SolrRequestHandler handler = core.getRequestHandler("tvrh");
    SolrQueryResponse rsp;
    rsp = new SolrQueryResponse();
    rsp.add("responseHeader", new SimpleOrderedMap());
    handler.handleRequest(new LocalSolrQueryRequest(core, params), rsp);
    NamedList values = rsp.getValues();
    NamedList termVectors = (NamedList) values.get(TermVectorComponent.TERM_VECTORS);
    assertTrue("termVectors is null and it shouldn't be", termVectors != null);
    if (VERBOSE) System.out.println("TVs: " + termVectors);
    NamedList doc = (NamedList) termVectors.get("doc-0");
    assertTrue("doc is null and it shouldn't be", doc != null);
    assertEquals(doc.size(), 5);
    NamedList vec;
    NamedList another;
    NamedList offsets;
    NamedList pos;
    Integer df;
    Double val;
    vec = (NamedList) doc.get("test_posofftv");
    assertNotNull(vec);
    assertEquals(vec.size(), 2);
    another = (NamedList) vec.get("anoth");
    offsets = (NamedList) another.get("offsets");
    assertNotNull(offsets);
    assertTrue(offsets.size() > 0);
    pos = (NamedList) another.get("positions");
    //positions should be null, since we turned them off
    assertNull(pos);
    df = (Integer) another.get("df");
    assertNotNull(df);
    assertTrue(df == 2);
    val = (Double) another.get("tf-idf");
    assertTrue("tfIdf is null and it shouldn't be", val != null);
    assertTrue(val + " does not equal: " + 0.5, val == 0.5);
    //Try out the other fields, too
    vec = (NamedList) doc.get("test_offtv");
    assertNotNull(vec);
    assertEquals(vec.size(), 2);
    another = (NamedList) vec.get("anoth");
    offsets = (NamedList) another.get("offsets");
    assertNull(offsets);
    pos = (NamedList) another.get("positions");
    //positions should be null, since we turned them off
    assertNull(vec.toString(), pos);
    df = (Integer) another.get("df");
    assertNotNull(df);
    assertTrue(df == 2);
    val = (Double) another.get("tf-idf");
    assertTrue("tfIdf is null and it shouldn't be", val != null);
    assertTrue(val + " does not equal: " + 0.5, val == 0.5);
    vec = (NamedList) doc.get("test_basictv");
    assertNotNull(vec);
    assertEquals(vec.size(), 2);
    another = (NamedList) vec.get("anoth");
    offsets = (NamedList) another.get("offsets");
    assertNull(offsets);
    pos = (NamedList) another.get("positions");
    assertNull(pos);
    df = (Integer) another.get("df");
    assertNull(df);
    val = (Double) another.get("tf-idf");
    assertNull(val);
    val = (Double) another.get("tf");
    assertNull(val);
    //Now validate we have error messages
    NamedList warnings = (NamedList) termVectors.get("warnings");
    assertNotNull(warnings);
    List<String> theList;
    theList = (List<String>) warnings.get("noTermVectors");
    assertNotNull(theList);
    assertEquals(theList.size(), 1);
    theList = (List<String>) warnings.get("noPositions");
    assertNotNull(theList);
    assertEquals(theList.size(), 2);
    theList = (List<String>) warnings.get("noOffsets");
    assertNotNull(theList);
    assertEquals(theList.size(), 2);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006770/fstmerge_var2_4354477984513626064

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/handler/component/TermVectorComponentTest.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006776/fstmerge_var1_7036957393775528384
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006776/fstmerge_base_2755287534539438261
@Test
  public void testNoFields() throws Exception {
    SolrCore core = h.getCore();
    SearchComponent tvComp = core.getSearchComponent("tvComponent");
    assertTrue("tvComp is null and it shouldn't be", tvComp != null);
    ModifiableSolrParams params = new ModifiableSolrParams();
    params.add(CommonParams.Q, "id:0");
    params.add(CommonParams.QT, "tvrh");
    params.add(TermVectorParams.TF, "true");
    //Pass in a field that doesn't exist on the doc, thus, no vectors should be returned
    params.add(TermVectorParams.FIELDS, "foo");
    params.add(TermVectorComponent.COMPONENT_NAME, "true");
    SolrRequestHandler handler = core.getRequestHandler("tvrh");
    SolrQueryResponse rsp;
    rsp = new SolrQueryResponse();
    rsp.add("responseHeader", new SimpleOrderedMap());
    handler.handleRequest(new LocalSolrQueryRequest(core, params), rsp);
    NamedList values = rsp.getValues();
    NamedList termVectors = (NamedList) values.get(TermVectorComponent.TERM_VECTORS);
    assertTrue("termVectors is null and it shouldn't be", termVectors != null);
    NamedList doc = (NamedList) termVectors.getVal(0);
    assertTrue("doc is null and it shouldn't be", doc != null);
    assertTrue(doc.size() + " does not equal: " + 1, doc.size() == 1);
  }
=======
@Test
  public void testNoFields() throws Exception {
    ignoreException("undefined field: foo");
    SolrCore core = h.getCore();
    SearchComponent tvComp = core.getSearchComponent("tvComponent");
    assertTrue("tvComp is null and it shouldn't be", tvComp != null);
    ModifiableSolrParams params = new ModifiableSolrParams();
    params.add(CommonParams.Q, "id:0");
    params.add(CommonParams.QT, "tvrh");
    params.add(TermVectorParams.TF, "true");
    //Pass in a field that doesn't exist on the doc, thus, no vectors should be returned
    params.add(TermVectorParams.FIELDS, "foo");
    params.add(TermVectorComponent.COMPONENT_NAME, "true");
    SolrRequestHandler handler = core.getRequestHandler("tvrh");
    SolrQueryResponse rsp;
    rsp = new SolrQueryResponse();
    rsp.add("responseHeader", new SimpleOrderedMap());
    handler.handleRequest(new LocalSolrQueryRequest(core, params), rsp);
    Exception exception = rsp.getException();
    assertNotNull(exception);
    resetExceptionIgnores();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006776/fstmerge_var2_1625488142919681641

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/handler/component/TermVectorComponentTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testSorting() throws IOException
  {
    assertU(adoc("id", "a", "title", "ipod",           "str_s", "a" ));
    assertU(adoc("id", "b", "title", "ipod ipod",      "str_s", "b" ));
    assertU(adoc("id", "c", "title", "ipod ipod ipod", "str_s", "c" ));

    assertU(adoc("id", "x", "title", "boosted",                 "str_s", "x" ));
    assertU(adoc("id", "y", "title", "boosted boosted",         "str_s", "y" ));
    assertU(adoc("id", "z", "title", "boosted boosted boosted", "str_s", "z" ));
    assertU(commit());
    
    String query = "title:ipod";
    
    Map<String,String> args = new HashMap<String, String>();
    args.put( CommonParams.Q, query );
    args.put( CommonParams.QT, "/elevate" );
    args.put( CommonParams.FL, "id,score" );
    args.put( "indent", "true" );
    //args.put( CommonParams.FL, "id,title,score" );
    SolrQueryRequest req = new LocalSolrQueryRequest( h.getCore(), new MapSolrParams( args) );
    IndexReader reader = req.getSearcher().getReader();
    QueryElevationComponent booster = (QueryElevationComponent)req.getCore().getSearchComponent( "elevate" );

    assertQ("Make sure standard sort works as expected", req
            ,"//*[@numFound='3']"
            ,"//result/doc[1]/str[@name='id'][.='a']"
            ,"//result/doc[2]/str[@name='id'][.='b']"
            ,"//result/doc[3]/str[@name='id'][.='c']"
            );
    
    // Explicitly set what gets boosted
    booster.elevationCache.clear();
    booster.setTopQueryResults( reader, query, new String[] { "x", "y", "z" }, null );


    assertQ("All six should make it", req
            ,"//*[@numFound='6']"
            ,"//result/doc[1]/str[@name='id'][.='x']"
            ,"//result/doc[2]/str[@name='id'][.='y']"
            ,"//result/doc[3]/str[@name='id'][.='z']"
            ,"//result/doc[4]/str[@name='id'][.='a']"
            ,"//result/doc[5]/str[@name='id'][.='b']"
            ,"//result/doc[6]/str[@name='id'][.='c']"
            );
    
    booster.elevationCache.clear();
    
    // now switch the order:
    booster.setTopQueryResults( reader, query, new String[] { "a", "x" }, null );
    assertQ("All four should make it", req
            ,"//*[@numFound='4']"
            ,"//result/doc[1]/str[@name='id'][.='a']"
            ,"//result/doc[2]/str[@name='id'][.='x']"
            ,"//result/doc[3]/str[@name='id'][.='b']"
            ,"//result/doc[4]/str[@name='id'][.='c']"
            );
    
    // Test reverse sort
    args.put( CommonParams.SORT, "score asc" );
    assertQ("All four should make it", req
        ,"//*[@numFound='4']"
        ,"//result/doc[4]/str[@name='id'][.='a']"
        ,"//result/doc[3]/str[@name='id'][.='x']"
        ,"//result/doc[2]/str[@name='id'][.='b']"
        ,"//result/doc[1]/str[@name='id'][.='c']"
        );
    
    // Try normal sort by 'id'
    // default 'forceBoost' should be false
    assertEquals( false, booster.forceElevation );
    args.put( CommonParams.SORT, "str_s asc" );
    assertQ( null, req
        ,"//*[@numFound='4']"
        ,"//result/doc[1]/str[@name='id'][.='a']"
        ,"//result/doc[2]/str[@name='id'][.='b']"
        ,"//result/doc[3]/str[@name='id'][.='c']"
        ,"//result/doc[4]/str[@name='id'][.='x']"
        );
    
    booster.forceElevation = true;
    assertQ( null, req
        ,"//*[@numFound='4']"
        ,"//result/doc[1]/str[@name='id'][.='a']"
        ,"//result/doc[2]/str[@name='id'][.='x']"
        ,"//result/doc[3]/str[@name='id'][.='b']"
        ,"//result/doc[4]/str[@name='id'][.='c']"
        );
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006802/fstmerge_base_6185860222743478696
    
=======

    //Test exclusive (not to be confused with exclusion)
    args.put(QueryElevationParams.EXCLUSIVE, "true");
    booster.setTopQueryResults( reader, query, new String[] { "x", "a" },  new String[] {} );
    assertQ( null, req
        ,"//*[@numFound='2']"
        ,"//result/doc[1]/str[@name='id'][.='x']"
        ,"//result/doc[2]/str[@name='id'][.='a']"            
        );

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006802/fstmerge_var2_4754163346587830469
    // Test exclusion
    booster.elevationCache.clear();
    args.remove( CommonParams.SORT );
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006802/fstmerge_base_6185860222743478696
=======
    args.remove( QueryElevationParams.EXCLUSIVE);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006802/fstmerge_var2_4754163346587830469
    booster.setTopQueryResults( reader, query, new String[] { "x" },  new String[] { "a" } );
    assertQ( null, req
        ,"//*[@numFound='3']"
        ,"//result/doc[1]/str[@name='id'][.='x']"
        ,"//result/doc[2]/str[@name='id'][.='b']"
        ,"//result/doc[3]/str[@name='id'][.='c']"
        );
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006802/fstmerge_var1_3678908972532319728


    req.close();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006802/fstmerge_base_6185860222743478696
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628006802/fstmerge_var2_4754163346587830469
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/handler/component/QueryElevationComponentTest.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628007026/fstmerge_var1_4781866236168801235
@BeforeClass
  public static void beforeClass() throws Exception {
    initCore("solrconfig.xml","schema12.xml");
    createIndex();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628007026/fstmerge_base_5204581953496513578
=======
@BeforeClass
  public static void beforeClass() throws Exception {
    initCore("solrconfig.xml","schema12.xml");
    createIndex();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628007026/fstmerge_var2_2317229507494793331

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/response/TestCSVResponseWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628007032/fstmerge_var1_3657130658675938248
public static void createIndex() {
    assertU(adoc("id","1", "foo_i","-1", "foo_s","hi", "foo_l","12345678987654321", "foo_b","false", "foo_f","1.414","foo_d","-1.0E300","foo_dt","2000-01-02T03:04:05Z"));
    assertU(adoc("id","2", "v_ss","hi",  "v_ss","there", "v2_ss","nice", "v2_ss","output"));
    assertU(commit());
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628007032/fstmerge_base_5042944129724535663
=======
public static void createIndex() {
    assertU(adoc("id","1", "foo_i","-1", "foo_s","hi", "foo_l","12345678987654321", "foo_b","false", "foo_f","1.414","foo_d","-1.0E300","foo_dt","2000-01-02T03:04:05Z"));
    assertU(adoc("id","2", "v_ss","hi",  "v_ss","there", "v2_ss","nice", "v2_ss","output"));
    assertU(commit());
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628007032/fstmerge_var2_4653387011180535441

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/response/TestCSVResponseWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628007036/fstmerge_var1_946978245952985269
@Test
  public void testCSVOutput() throws Exception {
    // test our basic types,and that fields come back in the requested order
    assertEquals("id,foo_s,foo_i,foo_l,foo_b,foo_f,foo_d,foo_dt\n1,hi,-1,12345678987654321,false,1.414,-1.0E300,2000-01-02T03:04:05Z\n"
    , h.query(req("q","id:1", "wt","csv", "fl","id,foo_s,foo_i,foo_l,foo_b,foo_f,foo_d,foo_dt")));

    // test retrieving score, csv.header
    assertEquals("1,0.0,hi\n"
    , h.query(req("q","id:1^0", "wt","csv", "csv.header","false", "fl","id,score,foo_s")));

    // test multivalued
    assertEquals("2,\"hi,there\"\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "fl","id,v_ss")));

    // test separator change
    assertEquals("2|\"hi|there\"\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.separator","|", "fl","id,v_ss")));

    // test mv separator change
    assertEquals("2,hi|there\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.mv.separator","|", "fl","id,v_ss")));

    // test mv separator change for a single field
    assertEquals("2,hi|there,nice:output\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.mv.separator","|", "f.v2_ss.csv.separator",":", "fl","id,v_ss,v2_ss")));

    // test retrieving fields from index
    String result = h.query(req("q","*:*", "wt","csv", "csv.header","true", "fl","*,score"));
    for (String field : "id,foo_s,foo_i,foo_l,foo_b,foo_f,foo_d,foo_dt,v_ss,v2_ss,score".split(",")) {
      assertTrue(result.indexOf(field) >= 0);
    }

    // test null values
    assertEquals("2,,hi|there\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.mv.separator","|", "fl","id,foo_s,v_ss")));

    // test alternate null value
    assertEquals("2,NULL,hi|there\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.mv.separator","|", "csv.null","NULL","fl","id,foo_s,v_ss")));

    // test alternate newline
    assertEquals("2,\"hi,there\"\r\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.newline","\r\n", "fl","id,v_ss")));

    // test alternate encapsulator
    assertEquals("2,'hi,there'\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.encapsulator","'", "fl","id,v_ss")));

    // test using escape instead of encapsulator
    assertEquals("2,hi\\,there\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.escape","\\", "fl","id,v_ss")));

    // test multiple lines
    assertEquals("1,,hi\n2,\"hi,there\",\n"
    , h.query(req("q","id:[1 TO 2]", "wt","csv", "csv.header","false", "fl","id,v_ss,foo_s")));


    // now test SolrDocumentList
    SolrDocument d = new SolrDocument();
    SolrDocument d1 = d;
    d.addField("id","1");
    d.addField("foo_i",-1);
    d.addField("foo_s","hi");
    d.addField("foo_l","12345678987654321L");
    d.addField("foo_b",false);
    d.addField("foo_f",1.414f);
    d.addField("foo_d",-1.0E300);
    d.addField("foo_dt", DateUtil.parseDate("2000-01-02T03:04:05Z"));
    d.addField("score", "2.718");

    d = new SolrDocument();
    SolrDocument d2 = d;
    d.addField("id","2");
    d.addField("v_ss","hi");
    d.addField("v_ss","there");
    d.addField("v2_ss","nice");
    d.addField("v2_ss","output");
    d.addField("score", "89.83");

    SolrDocumentList sdl = new SolrDocumentList();
    sdl.add(d1);
    sdl.add(d2);
    
    SolrQueryRequest req = req("q","*:*");
    SolrQueryResponse rsp = new SolrQueryResponse();
    rsp.add("response", sdl);
    QueryResponseWriter w = new CSVResponseWriter();
    
    SolrPluginUtils.setReturnFields("id,foo_s", rsp);
    StringWriter buf = new StringWriter();
    w.write(buf, req, rsp);
    assertEquals("id,foo_s\n1,hi\n2,\n", buf.toString());

    // try scores
    SolrPluginUtils.setReturnFields("id,score,foo_s", rsp);
    buf = new StringWriter();
    w.write(buf, req, rsp);
    assertEquals("id,score,foo_s\n1,2.718,hi\n2,89.83,\n", buf.toString());

    // get field values from docs... should be ordered and not include score unless requested
    SolrPluginUtils.setReturnFields("*", rsp);
    buf = new StringWriter();
    w.write(buf, req, rsp);
    assertEquals("id,foo_i,foo_s,foo_l,foo_b,foo_f,foo_d,foo_dt,v_ss,v2_ss\n" +
        "1,-1,hi,12345678987654321L,false,1.414,-1.0E300,2000-01-02T03:04:05Z,,\n" +
        "2,,,,,,,,\"hi,there\",\"nice,output\"\n",
      buf.toString());
    

    // get field values and scores - just check that the scores are there... we don't guarantee where
    SolrPluginUtils.setReturnFields("*,score", rsp);
    buf = new StringWriter();
    w.write(buf, req, rsp);
    String s = buf.toString();
    assertTrue(s.indexOf("score") >=0 && s.indexOf("2.718") > 0 && s.indexOf("89.83") > 0 );

    req.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628007036/fstmerge_base_7191001836324241372
=======
@Test
  public void testCSVOutput() throws Exception {
    // test our basic types,and that fields come back in the requested order
    assertEquals("id,foo_s,foo_i,foo_l,foo_b,foo_f,foo_d,foo_dt\n1,hi,-1,12345678987654321,false,1.414,-1.0E300,2000-01-02T03:04:05Z\n"
    , h.query(req("q","id:1", "wt","csv", "fl","id,foo_s,foo_i,foo_l,foo_b,foo_f,foo_d,foo_dt")));

    // test retrieving score, csv.header
    assertEquals("1,0.0,hi\n"
    , h.query(req("q","id:1^0", "wt","csv", "csv.header","false", "fl","id,score,foo_s")));

    // test multivalued
    assertEquals("2,\"hi,there\"\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "fl","id,v_ss")));

    // test separator change
    assertEquals("2|\"hi|there\"\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.separator","|", "fl","id,v_ss")));

    // test mv separator change
    assertEquals("2,hi|there\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.mv.separator","|", "fl","id,v_ss")));

    // test mv separator change for a single field
    assertEquals("2,hi|there,nice:output\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.mv.separator","|", "f.v2_ss.csv.separator",":", "fl","id,v_ss,v2_ss")));

    // test retrieving fields from index
    String result = h.query(req("q","*:*", "wt","csv", "csv.header","true", "fl","*,score"));
    for (String field : "id,foo_s,foo_i,foo_l,foo_b,foo_f,foo_d,foo_dt,v_ss,v2_ss,score".split(",")) {
      assertTrue(result.indexOf(field) >= 0);
    }

    // test null values
    assertEquals("2,,hi|there\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.mv.separator","|", "fl","id,foo_s,v_ss")));

    // test alternate null value
    assertEquals("2,NULL,hi|there\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.mv.separator","|", "csv.null","NULL","fl","id,foo_s,v_ss")));

    // test alternate newline
    assertEquals("2,\"hi,there\"\r\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.newline","\r\n", "fl","id,v_ss")));

    // test alternate encapsulator
    assertEquals("2,'hi,there'\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.encapsulator","'", "fl","id,v_ss")));

    // test using escape instead of encapsulator
    assertEquals("2,hi\\,there\n"
    , h.query(req("q","id:2", "wt","csv", "csv.header","false", "csv.escape","\\", "fl","id,v_ss")));

    // test multiple lines
    assertEquals("1,,hi\n2,\"hi,there\",\n"
    , h.query(req("q","id:[1 TO 2]", "wt","csv", "csv.header","false", "fl","id,v_ss,foo_s")));


    // now test SolrDocumentList
    SolrDocument d = new SolrDocument();
    SolrDocument d1 = d;
    d.addField("id","1");
    d.addField("foo_i",-1);
    d.addField("foo_s","hi");
    d.addField("foo_l","12345678987654321L");
    d.addField("foo_b",false);
    d.addField("foo_f",1.414f);
    d.addField("foo_d",-1.0E300);
    d.addField("foo_dt", DateUtil.parseDate("2000-01-02T03:04:05Z"));
    d.addField("score", "2.718");

    d = new SolrDocument();
    SolrDocument d2 = d;
    d.addField("id","2");
    d.addField("v_ss","hi");
    d.addField("v_ss","there");
    d.addField("v2_ss","nice");
    d.addField("v2_ss","output");
    d.addField("score", "89.83");

    SolrDocumentList sdl = new SolrDocumentList();
    sdl.add(d1);
    sdl.add(d2);
    
    SolrQueryRequest req = req("q","*:*");
    SolrQueryResponse rsp = new SolrQueryResponse();
    rsp.add("response", sdl);
    QueryResponseWriter w = new CSVResponseWriter();
    
    SolrPluginUtils.setReturnFields("id,foo_s", rsp);
    StringWriter buf = new StringWriter();
    w.write(buf, req, rsp);
    assertEquals("id,foo_s\n1,hi\n2,\n", buf.toString());

    // try scores
    SolrPluginUtils.setReturnFields("id,score,foo_s", rsp);
    buf = new StringWriter();
    w.write(buf, req, rsp);
    assertEquals("id,score,foo_s\n1,2.718,hi\n2,89.83,\n", buf.toString());

    // get field values from docs... should be ordered and not include score unless requested
    SolrPluginUtils.setReturnFields("*", rsp);
    buf = new StringWriter();
    w.write(buf, req, rsp);
    assertEquals("id,foo_i,foo_s,foo_l,foo_b,foo_f,foo_d,foo_dt,v_ss,v2_ss\n" +
        "1,-1,hi,12345678987654321L,false,1.414,-1.0E300,2000-01-02T03:04:05Z,,\n" +
        "2,,,,,,,,\"hi,there\",\"nice,output\"\n",
      buf.toString());
    

    // get field values and scores - just check that the scores are there... we don't guarantee where
    SolrPluginUtils.setReturnFields("*,score", rsp);
    buf = new StringWriter();
    w.write(buf, req, rsp);
    String s = buf.toString();
    assertTrue(s.indexOf("score") >=0 && s.indexOf("2.718") > 0 && s.indexOf("89.83") > 0 );
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628007036/fstmerge_var2_6574198158842890051

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/test/org/apache/solr/response/TestCSVResponseWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628010661/fstmerge_var1_8608110097546663862
@Override
  public Query parse() throws ParseException {
    //if more than one, we need to treat them as a point...
    //TODO: Should we accept multiple fields
    String[] fields = localParams.getParams("f");
    if (fields == null || fields.length == 0) {
      String field = getParam(SpatialParams.FIELD);
      if (field == null)
        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, " missing sfield for spatial request");
      fields = new String[] {field};
    }
    
    String pointStr = getParam(SpatialParams.POINT);
    if (pointStr == null) {
      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, SpatialParams.POINT + " missing.");
    }

    double dist = -1;
    String distS = getParam(SpatialParams.DISTANCE);
    if (distS != null) dist = Double.parseDouble(distS);

    if (dist < 0) {
      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, SpatialParams.DISTANCE + " must be >= 0");
    }

    String measStr = localParams.get(SpatialParams.MEASURE);
    //TODO: Need to do something with Measures
    Query result = null;
    //fields is valid at this point
    if (fields.length == 1) {
      SchemaField sf = req.getSchema().getField(fields[0]);
      FieldType type = sf.getType();

      if (type instanceof SpatialQueryable) {
        double radius = localParams.getDouble(SpatialParams.SPHERE_RADIUS, DistanceUtils.EARTH_MEAN_RADIUS_KM);
        SpatialOptions opts = new SpatialOptions(pointStr, dist, sf, measStr, radius, DistanceUnits.KILOMETERS);
        opts.bbox = bbox;
        result = ((SpatialQueryable)type).createSpatialQuery(this, opts);
      } else {
        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, "The field " + fields[0]
                + " does not support spatial filtering");
      }
    } else {// fields.length > 1
      //TODO: Not sure about this just yet, is there a way to delegate, or do we just have a helper class?
      //Seems like we could just use FunctionQuery, but then what about scoring
      /*List<ValueSource> sources = new ArrayList<ValueSource>(fields.length);
      for (String field : fields) {
        SchemaField sf = schema.getField(field);
        sources.add(sf.getType().getValueSource(sf, this));
      }
      MultiValueSource vs = new VectorValueSource(sources);
      ValueSourceRangeFilter rf = new ValueSourceRangeFilter(vs, "0", String.valueOf(dist), true, true);
      result = new SolrConstantScoreQuery(rf);*/
    }

    return result;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628010661/fstmerge_base_7524365357649398511
=======
@Override
  public Query parse() throws ParseException {
    //if more than one, we need to treat them as a point...
    //TODO: Should we accept multiple fields
    String[] fields = localParams.getParams(CommonParams.FL);
    if (fields == null || fields.length == 0) {
      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, CommonParams.FL + " is not properly specified");
    }
    String pointStr = params.get(SpatialParams.POINT);
    if (pointStr == null) {
      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, SpatialParams.POINT + " is not properly specified");
    }

    double dist = params.getDouble(SpatialParams.DISTANCE, -1);
    if (dist < 0) {
      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, SpatialParams.DISTANCE + " must be >= 0");
    }
    IndexSchema schema = req.getSchema();

    String measStr = localParams.get(SpatialParams.MEASURE);
    //TODO: Need to do something with Measures
    Query result = null;
    //fields is valid at this point
    if (fields.length == 1) {
      SchemaField sf = schema.getField(fields[0]);
      FieldType type = sf.getType();

      if (type instanceof SpatialQueryable) {
        double radius = localParams.getDouble(SpatialParams.SPHERE_RADIUS, DistanceUtils.EARTH_MEAN_RADIUS_KM);
        SpatialOptions opts = new SpatialOptions(pointStr, dist, sf, measStr, radius, DistanceUnits.KILOMETERS);
        result = ((SpatialQueryable)type).createSpatialQuery(this, opts);
      } else {
        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, "The field " + fields[0]
                + " does not support spatial filtering");
      }
    } else {// fields.length > 1
      //TODO: Not sure about this just yet, is there a way to delegate, or do we just have a helper class?
      //Seems like we could just use FunctionQuery, but then what about scoring
      /*List<ValueSource> sources = new ArrayList<ValueSource>(fields.length);
      for (String field : fields) {
        SchemaField sf = schema.getField(field);
        sources.add(sf.getType().getValueSource(sf, this));
      }
      MultiValueSource vs = new VectorValueSource(sources);
      ValueSourceRangeFilter rf = new ValueSourceRangeFilter(vs, "0", String.valueOf(dist), true, true);
      result = new SolrConstantScoreQuery(rf);*/
    }

    return result;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628010661/fstmerge_var2_6979211642296797118

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/search/SpatialFilterQParser.java
Conflict type: SameIdFd
Conflict body: 
~~FSTMerge~~ public static String NAME = "geofilt"; ##FSTMerge## ##FSTMerge## public static String NAME = "sfilt";
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/search/SpatialFilterQParserPlugin.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628010992/fstmerge_var1_1707750291604951896
@Override
  public QParser createParser(String qstr, SolrParams localParams,
                              SolrParams params, SolrQueryRequest req) {

    return new SpatialFilterQParser(qstr, localParams, params, req, false);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628010992/fstmerge_base_3241331241322545989
=======
@Override
  public QParser createParser(String qstr, SolrParams localParams,
                              SolrParams params, SolrQueryRequest req) {

    return new SpatialFilterQParser(qstr, localParams, params, req);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628010992/fstmerge_var2_8046800794032332082

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/search/SpatialFilterQParserPlugin.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628011451/fstmerge_var1_2893233759624539071
public DocSet getDocSet(Query query, DocsEnumState deState) throws IOException {
    // Get the absolute value (positive version) of this query.  If we
    // get back the same reference, we know it's positive.
    Query absQ = QueryUtils.getAbs(query);
    boolean positive = query==absQ;

    if (filterCache != null) {
      DocSet absAnswer = filterCache.get(absQ);
      if (absAnswer!=null) {
        if (positive) return absAnswer;
        else return getPositiveDocSet(matchAllDocsQuery).andNot(absAnswer);
      }
    }

    DocSet absAnswer = getDocSetNC(absQ, null, deState);
    DocSet answer = positive ? absAnswer : getPositiveDocSet(matchAllDocsQuery, deState).andNot(absAnswer);

    if (filterCache != null) {
      // cache negative queries as positive
      filterCache.put(absQ, absAnswer);
    }

    return answer;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628011451/fstmerge_base_3391798205296075065
=======
public DocSet getDocSet(Query query, DocsEnumState deState) throws IOException {
    // Get the absolute value (positive version) of this query.  If we
    // get back the same reference, we know it's positive.
    Query absQ = QueryUtils.getAbs(query);
    boolean positive = query==absQ;

    if (filterCache != null) {
      DocSet absAnswer = (DocSet)filterCache.get(absQ);
      if (absAnswer!=null) {
        if (positive) return absAnswer;
        else return getPositiveDocSet(matchAllDocsQuery).andNot(absAnswer);
      }
    }

    DocSet absAnswer = getDocSetNC(absQ, null, deState);
    DocSet answer = positive ? absAnswer : getPositiveDocSet(matchAllDocsQuery, deState).andNot(absAnswer);

    if (filterCache != null) {
      // cache negative queries as positive
      filterCache.put(absQ, absAnswer);
    }

    return answer;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628011451/fstmerge_var2_7904136330601787397

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/search/SolrIndexSearcher.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628011461/fstmerge_var1_3764345954644730983
DocSet getPositiveDocSet(Query q, DocsEnumState deState) throws IOException {
    DocSet answer;
    if (filterCache != null) {
      answer = filterCache.get(q);
      if (answer!=null) return answer;
    }
    answer = getDocSetNC(q,null,deState);
    if (filterCache != null) filterCache.put(q,answer);
    return answer;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628011461/fstmerge_base_4186566263191859138
=======
DocSet getPositiveDocSet(Query q, DocsEnumState deState) throws IOException {
    DocSet answer;
    if (filterCache != null) {
      answer = (DocSet)filterCache.get(q);
      if (answer!=null) return answer;
    }
    answer = getDocSetNC(q,null,deState);
    if (filterCache != null) filterCache.put(q,answer);
    return answer;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628011461/fstmerge_var2_8934805836543684300

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/search/SolrIndexSearcher.java
Conflict type: LineBasedMCFd
Conflict body: 
public SolrQueryParser(QParser parser, String defaultField, Analyzer analyzer) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628012679/fstmerge_var1_575532108358446563
    super(parser.getReq().getSchema().getSolrConfig().getLuceneVersion("luceneMatchVersion", Version.LUCENE_30), defaultField, analyzer);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628012679/fstmerge_base_1698817936232778303
    super(Version.LUCENE_24, defaultField, analyzer);
=======
    super(parser.getReq().getSchema().getSolrConfig().getLuceneVersion("luceneMatchVersion", Version.LUCENE_24), defaultField, analyzer);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628012679/fstmerge_var2_5185596315339393602
    this.schema = parser.getReq().getSchema();
    this.parser = parser;
    this.defaultField = defaultField;
    setLowercaseExpandedTerms(false);
    setEnablePositionIncrements(true);
    checkAllowLeadingWildcards();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/search/SolrQueryParser.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628012694/fstmerge_var1_7325694396766989400
@Override
  protected Query getFieldQuery(String field, String queryText, boolean quoted) throws ParseException {
    checkNullField(field);
    // intercept magic field name of "_" to use as a hook for our
    // own functions.
    if (field.charAt(0) == '_') {
      if ("_val_".equals(field)) {
        if (parser==null) {
          return QueryParsing.parseFunction(queryText, schema);
        } else {
          QParser nested = parser.subQuery(queryText, "func");
          return nested.getQuery();
        }
      } else if ("_query_".equals(field) && parser != null) {
        return parser.subQuery(queryText, null).getQuery();
      }
    }
    SchemaField sf = schema.getFieldOrNull(field);
    if (sf != null) {
      FieldType ft = sf.getType();
      // delegate to type for everything except TextField
      if (ft instanceof TextField) {
        return super.getFieldQuery(field, queryText, quoted || ((TextField)ft).getAutoGeneratePhraseQueries());
      } else {
        return sf.getType().getFieldQuery(parser, sf, queryText);
      }
    }

    // default to a normal field query
    return super.getFieldQuery(field, queryText, quoted);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628012694/fstmerge_base_6842997744743445511
=======
protected Query getFieldQuery(String field, String queryText, boolean quoted) throws ParseException {
    checkNullField(field);
    // intercept magic field name of "_" to use as a hook for our
    // own functions.
    if (field.charAt(0) == '_') {
      if ("_val_".equals(field)) {
        if (parser==null) {
          return QueryParsing.parseFunction(queryText, schema);
        } else {
          QParser nested = parser.subQuery(queryText, "func");
          return nested.getQuery();
        }
      } else if ("_query_".equals(field) && parser != null) {
        return parser.subQuery(queryText, null).getQuery();
      }
    }
    SchemaField sf = schema.getFieldOrNull(field);
    if (sf != null) {
      FieldType ft = sf.getType();
      // delegate to type for everything except TextField
      if (ft instanceof TextField) {
        return super.getFieldQuery(field, queryText, quoted || ((TextField)ft).getAutoGeneratePhraseQueries());
      } else {
        return sf.getType().getFieldQuery(parser, sf, queryText);
      }
    }

    // default to a normal field query
    return super.getFieldQuery(field, queryText, quoted);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628012694/fstmerge_var2_633212066945455002

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/search/SolrQueryParser.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ public static final Object[] standardPlugins = {
    LuceneQParserPlugin.NAME, LuceneQParserPlugin.class,
    OldLuceneQParserPlugin.NAME, OldLuceneQParserPlugin.class,
    FunctionQParserPlugin.NAME, FunctionQParserPlugin.class,
    PrefixQParserPlugin.NAME, PrefixQParserPlugin.class,
    BoostQParserPlugin.NAME, BoostQParserPlugin.class,
    DisMaxQParserPlugin.NAME, DisMaxQParserPlugin.class,
    ExtendedDismaxQParserPlugin.NAME, ExtendedDismaxQParserPlugin.class,
    FieldQParserPlugin.NAME, FieldQParserPlugin.class,
    RawQParserPlugin.NAME, RawQParserPlugin.class,
    TermQParserPlugin.NAME, TermQParserPlugin.class,
    NestedQParserPlugin.NAME, NestedQParserPlugin.class,
    FunctionRangeQParserPlugin.NAME, FunctionRangeQParserPlugin.class,
    SpatialFilterQParserPlugin.NAME, SpatialFilterQParserPlugin.class,
    SpatialBoxQParserPlugin.NAME, SpatialBoxQParserPlugin.class,
  }; ##FSTMerge## public static final Object[] standardPlugins = {
    LuceneQParserPlugin.NAME, LuceneQParserPlugin.class,
    OldLuceneQParserPlugin.NAME, OldLuceneQParserPlugin.class,
    FunctionQParserPlugin.NAME, FunctionQParserPlugin.class,
    PrefixQParserPlugin.NAME, PrefixQParserPlugin.class,
    BoostQParserPlugin.NAME, BoostQParserPlugin.class,
    DisMaxQParserPlugin.NAME, DisMaxQParserPlugin.class,
    ExtendedDismaxQParserPlugin.NAME, ExtendedDismaxQParserPlugin.class,
    FieldQParserPlugin.NAME, FieldQParserPlugin.class,
    RawQParserPlugin.NAME, RawQParserPlugin.class,
    NestedQParserPlugin.NAME, NestedQParserPlugin.class,
    FunctionRangeQParserPlugin.NAME, FunctionRangeQParserPlugin.class,
  }; ##FSTMerge## public static final Object[] standardPlugins = {
    LuceneQParserPlugin.NAME, LuceneQParserPlugin.class,
    OldLuceneQParserPlugin.NAME, OldLuceneQParserPlugin.class,
    FunctionQParserPlugin.NAME, FunctionQParserPlugin.class,
    PrefixQParserPlugin.NAME, PrefixQParserPlugin.class,
    BoostQParserPlugin.NAME, BoostQParserPlugin.class,
    DisMaxQParserPlugin.NAME, DisMaxQParserPlugin.class,
    ExtendedDismaxQParserPlugin.NAME, ExtendedDismaxQParserPlugin.class,
    FieldQParserPlugin.NAME, FieldQParserPlugin.class,
    RawQParserPlugin.NAME, RawQParserPlugin.class,
    NestedQParserPlugin.NAME, NestedQParserPlugin.class,
    FunctionRangeQParserPlugin.NAME, FunctionRangeQParserPlugin.class,
    SpatialFilterQParserPlugin.NAME, SpatialFilterQParserPlugin.class,
  };
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/search/QParserPlugin.java
Conflict type: LineBasedMCFd
Conflict body: 
private static float[] getFloats(FileFloatSource ffs, IndexReader reader) {
    float[] vals = new float[reader.maxDoc()];
    if (ffs.defVal != 0) {
      Arrays.fill(vals, ffs.defVal);
    }
    InputStream is;
    String fname = "external_" + ffs.field.getName();
    try {
      is = VersionedFile.getLatestFile(ffs.dataDir, fname);
    } catch (IOException e) {
      // log, use defaults
      SolrCore.log.error("Error opening external value source file: " +e);
      return vals;
    }

    BufferedReader r = new BufferedReader(new InputStreamReader(is));

    String idName = StringHelper.intern(ffs.keyField.getName());
    FieldType idType = ffs.keyField.getType();

    // warning: lucene's termEnum.skipTo() is not optimized... it simply does a next()
    // because of this, simply ask the reader for a new termEnum rather than
    // trying to use skipTo()

    List<String> notFound = new ArrayList<String>();
    int notFoundCount=0;
    int otherErrors=0;

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_var1_5303954724633653590
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_base_8512377853362491400
    TermDocs termDocs = null;
    Term protoTerm = new Term(idName, "");
    TermEnum termEnum = null;
    // Number of times to try termEnum.next() before resorting to skip
    int numTimesNext = 10;

=======
    // Number of times to try termEnum.next() before resorting to skip
    int numTimesNext = 10;

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_var2_7869692718986086403
    char delimiter='=';
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_base_8512377853362491400
    String termVal;
    boolean hasNext=true;
    String prevKey="";
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_var2_7869692718986086403

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_var1_5303954724633653590
    BytesRef internalKey = new BytesRef();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_base_8512377853362491400
    String lastVal="\uFFFF\uFFFF\uFFFF\uFFFF\uFFFF\uFFFF\uFFFF\uFFFF";
=======
    BytesRef lastVal=new BytesRef("\uFFFF\uFFFF\uFFFF\uFFFF\uFFFF\uFFFF\uFFFF\uFFFF\uFFFF");
    BytesRef internalKey = new BytesRef();
    BytesRef prevKey=new BytesRef();
    BytesRef tmp;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_var2_7869692718986086403

    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_var1_5303954724633653590
      TermsEnum termsEnum = MultiFields.getTerms(reader, idName).iterator();
      DocsEnum docsEnum = null;

      // removing deleted docs shouldn't matter
      // final Bits delDocs = MultiFields.getDeletedDocs(reader);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_base_8512377853362491400
      termDocs = reader.termDocs();
      termEnum = reader.terms(protoTerm);
      Term t = termEnum.term();
      if (t != null && t.field() == idName) { // intern'd comparison
        termVal = t.text();
      } else {
        termVal = lastVal;
      }

=======
      TermsEnum termsEnum = MultiFields.getTerms(reader, idName).iterator();
      DocsEnum docsEnum = null;
      BytesRef t = termsEnum.next();
      if (t==null) t=lastVal;
      final Bits delDocs = MultiFields.getDeletedDocs(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_var2_7869692718986086403

      for (String line; (line=r.readLine())!=null;) {
        int delimIndex = line.indexOf(delimiter);
        if (delimIndex < 0) continue;

        int endIndex = line.length();
        String key = line.substring(0, delimIndex);
        String val = line.substring(delimIndex+1, endIndex);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_var1_5303954724633653590
        idType.readableToIndexed(key, internalKey);

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_base_8512377853362491400
        String internalKey = idType.toInternal(key);
=======
        tmp = prevKey; prevKey=internalKey; internalKey=tmp;
        idType.readableToIndexed(key, internalKey);

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_var2_7869692718986086403
        float fval;
        try {
          fval=Float.parseFloat(val);
        } catch (Exception e) {
          if (++otherErrors<=10) {
            SolrCore.log.error( "Error loading external value source + fileName + " + e
              + (otherErrors<10 ? "" : "\tSkipping future errors for this file.")
            );
          }
          continue;  // go to next line in file.. leave values as default.
        }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_var1_5303954724633653590
        if (termsEnum.seek(internalKey, false) != TermsEnum.SeekStatus.FOUND) {
          if (notFoundCount<10) {  // collect first 10 not found for logging
            notFound.add(key);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_base_8512377853362491400
        if (sorted) {
          // make sure this key is greater than the previous key
          sorted = internalKey.compareTo(prevKey) >= 0;
          prevKey = internalKey;

          if (sorted) {
            int countNext = 0;
            for(;;) {
              int cmp = internalKey.compareTo(termVal);
              if (cmp == 0) {
                termDocs.seek(termEnum);
                while (termDocs.next()) {
                  vals[termDocs.doc()] = fval;
                }
                break;
              } else if (cmp < 0) {
                // term enum has already advanced past current key... we didn't find it.
                if (notFoundCount<10) {  // collect first 10 not found for logging
                  notFound.add(key);
                }
                notFoundCount++;
                break;
              } else {
                // termEnum is less than our current key, so skip ahead

                // try next() a few times to see if we hit or pass the target.
                // Lucene's termEnum.skipTo() is currently unoptimized (it just does next())
                // so the best thing is to simply ask the reader for a new termEnum(target)
                // if we really need to skip.
                if (++countNext > numTimesNext) {
                  termEnum = reader.terms(protoTerm.createTerm(internalKey));
                  t = termEnum.term();
                } else {
                  hasNext = termEnum.next();
                  t = hasNext ? termEnum.term() : null;
                }

                if (t != null && t.field() == idName) { // intern'd comparison
                  termVal = t.text();
                } else {
                  termVal = lastVal;
                }
              }
            } // end for(;;)
=======
        if (sorted) {
          // make sure this key is greater than the previous key
          sorted = internalKey.compareTo(prevKey) >= 0;

          if (sorted) {
            int countNext = 0;
            for(;;) {
              int cmp = internalKey.compareTo(t);
              if (cmp == 0) {
                docsEnum = termsEnum.docs(delDocs, docsEnum);
                int doc;
                while ((doc = docsEnum.nextDoc()) != DocsEnum.NO_MORE_DOCS) {
                  vals[doc] = fval;
                }
                break;
              } else if (cmp < 0) {
                // term enum has already advanced past current key... we didn't find it.
                if (notFoundCount<10) {  // collect first 10 not found for logging
                  notFound.add(key);
                }
                notFoundCount++;
                break;
              } else {
                // termEnum is less than our current key, so skip ahead

                // try next() a few times to see if we hit or pass the target.
                // Lucene's termEnum.skipTo() is currently unoptimized (it just does next())
                // so the best thing is to simply ask the reader for a new termEnum(target)
                // if we really need to skip.
                if (++countNext > numTimesNext) {
                  termsEnum.seek(internalKey);
                  t = termsEnum.term();
                } else {
                  t = termsEnum.next();
                }

                if (t==null) t = lastVal;
              }
            } // end for(;;)
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_var2_7869692718986086403
          }
          notFoundCount++;
          continue;
        }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_var1_5303954724633653590
        docsEnum = termsEnum.docs(null, docsEnum);
        int doc;
        while ((doc = docsEnum.nextDoc()) != DocsEnum.NO_MORE_DOCS) {
          vals[doc] = fval;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_base_8512377853362491400
        if (!sorted) {
          termEnum = reader.terms(protoTerm.createTerm(internalKey));
          t = termEnum.term();
          if (t != null && t.field() == idName  // intern'd comparison
                  && internalKey.equals(t.text()))
          {
            termDocs.seek (termEnum);
            while (termDocs.next()) {
              vals[termDocs.doc()] = fval;
            }
          } else {
            if (notFoundCount<10) {  // collect first 10 not found for logging
              notFound.add(key);
            }
            notFoundCount++;
          }
=======
        if (!sorted) {
          TermsEnum.SeekStatus result = termsEnum.seek(internalKey);
          t = termsEnum.term();
          if (result == TermsEnum.SeekStatus.FOUND) {
            docsEnum = termsEnum.docs(delDocs, docsEnum);
            int doc;
            while ((doc = docsEnum.nextDoc()) != DocsEnum.NO_MORE_DOCS) {
              vals[doc] = fval;
            }
          } else {
            if (notFoundCount<10) {  // collect first 10 not found for logging
              notFound.add(key);
            }
            notFoundCount++;
          }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_var2_7869692718986086403
        }
      }

    } catch (IOException e) {
      // log, use defaults
      SolrCore.log.error("Error loading external value source: " +e);
    } finally {
      // swallow exceptions on close so we don't override any
      // exceptions that happened in the loop
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_base_8512377853362491400
      if (termDocs!=null) try{termDocs.close();}catch(Exception e){}
      if (termEnum!=null) try{termEnum.close();}catch(Exception e){}
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628013778/fstmerge_var2_7869692718986086403
      try{r.close();}catch(Exception e){}
    }

    SolrCore.log.info("Loaded external value source " + fname
      + (notFoundCount==0 ? "" : " :"+notFoundCount+" missing keys "+notFound)
    );

    return vals;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/search/function/FileFloatSource.java
Conflict type: SameIdFd
Conflict body: 
~~FSTMerge~~ private String encoding; ##FSTMerge## ##FSTMerge## private String encoding = "UTF-8";
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/analysis/HyphenationCompoundWordTokenFilterFactory.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628016259/fstmerge_var1_2983290386278901144
public void inform(ResourceLoader loader) {
    InputStream stream = null;
    try {
      if (dictFile != null) // the dictionary can be empty.
        dictionary = getWordSet(loader, dictFile, false);
      // TODO: Broken, because we cannot resolve real system id
      // ResourceLoader should also supply method like ClassLoader to get resource URL
      stream = loader.openResource(hypFile);
      final InputSource is = new InputSource(stream);
      is.setEncoding(encoding); // if it's null let xml parser decide
      is.setSystemId(hypFile);
      hyphenator = HyphenationCompoundWordTokenFilter.getHyphenationTree(is);
    } catch (Exception e) { // TODO: getHyphenationTree really shouldn't throw "Exception"
      throw new RuntimeException(e);
    } finally {
      IOUtils.closeQuietly(stream);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628016259/fstmerge_base_1400488524677817923
=======
public void inform(ResourceLoader loader) {
    Reader reader = null;
    try {
      if (dictFile != null) // the dictionary can be empty.
        dictionary = getWordSet(loader, dictFile, false);
      
      InputStream hyph = loader.openResource(hypFile);
      reader = new InputStreamReader(hyph, encoding);
      hyphenator = HyphenationCompoundWordTokenFilter.getHyphenationTree(reader);
    } catch (Exception e) { // TODO: getHyphenationTree really shouldnt throw "Exception"
      throw new RuntimeException(e);
    } finally {
      IOUtils.closeQuietly(reader);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628016259/fstmerge_var2_1811304518365892421

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/analysis/HyphenationCompoundWordTokenFilterFactory.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628017721/fstmerge_var1_715493525822935945
public String next() {
      if (!hasNextCalled && !hasNext()) {
        return null;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628017721/fstmerge_base_317190024115489917
public Object next() {
      if (!hasNextCalled) {
        hasNext();
=======
public Object next() {
      if (!hasNextCalled && !hasNext()) {
        return null;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628017721/fstmerge_var2_2380565913565739146
      }
      hasNextCalled = false;

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628017721/fstmerge_base_317190024115489917
      try {
        termEnum.next();
      } catch (IOException e) {
        throw new RuntimeException(e);
      }

      return (actualTerm != null) ? actualTerm.text() : null;
=======
      return (actualTerm != null) ? actualTerm.utf8ToString() : null;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628017721/fstmerge_var2_2380565913565739146
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/util/HighFrequencyDictionary.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628018515/fstmerge_var1_3003786655556719643
protected Query getFieldQuery(String field, String queryText, boolean quoted)
      throws ParseException {

      if (aliases.containsKey(field)) {

        Alias a = aliases.get(field);
        DisjunctionMaxQuery q = new DisjunctionMaxQuery(a.tie);

        /* we might not get any valid queries from delegation,
         * in which case we should return null
         */
        boolean ok = false;

        for (String f : a.fields.keySet()) {

          Query sub = getFieldQuery(f,queryText,quoted);
          if (null != sub) {
            if (null != a.fields.get(f)) {
              sub.setBoost(a.fields.get(f));
            }
            q.add(sub);
            ok = true;
          }
        }
        return ok ? q : null;

      } else {
        try {
          return super.getFieldQuery(field, queryText, quoted);
        } catch (Exception e) {
          return null;
        }
      }
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628018515/fstmerge_base_2864020178869535839
=======
protected Query getFieldQuery(String field, String queryText, boolean quoted)
      throws ParseException {
            
      if (aliases.containsKey(field)) {
                
        Alias a = aliases.get(field);
        DisjunctionMaxQuery q = new DisjunctionMaxQuery(a.tie);

        /* we might not get any valid queries from delegation,
         * in which case we should return null
         */
        boolean ok = false;
                
        for (String f : a.fields.keySet()) {

          Query sub = getFieldQuery(f,queryText,quoted);
          if (null != sub) {
            if (null != a.fields.get(f)) {
              sub.setBoost(a.fields.get(f));
            }
            q.add(sub);
            ok = true;
          }
        }
        return ok ? q : null;

      } else {
        try {
          return super.getFieldQuery(field, queryText, quoted);
        } catch (Exception e) {
          return null;
        }
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628018515/fstmerge_var2_714090290234589815

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/util/SolrPluginUtils.java
Conflict type: LineBasedMCFd
Conflict body: 
public SolrCore create(CoreDescriptor dcore)  throws ParserConfigurationException, IOException, SAXException {
    // Make the instanceDir relative to the cores instanceDir if not absolute
    File idir = new File(dcore.getInstanceDir());
    if (!idir.isAbsolute()) {
      idir = new File(solrHome, dcore.getInstanceDir());
    }
    String instanceDir = idir.getPath();
    
    // Initialize the solr config
    SolrResourceLoader solrLoader = null;
    
    SolrConfig config = null;
    String zkConfigName = null;
    if(zkController == null) {
      solrLoader = new SolrResourceLoader(instanceDir, libLoader, getCoreProps(instanceDir, dcore.getPropertiesName(),dcore.getCoreProperties()));
      config = new SolrConfig(solrLoader, dcore.getConfigName(), null);
    } else {
      try {
        String collection = dcore.getCloudDescriptor().getCollectionName();
        zkController.createCollectionZkNode(dcore.getCloudDescriptor());
        // zkController.createCollectionZkNode(collection);
        zkConfigName = zkController.readConfigName(collection);
        if (zkConfigName == null) {
          log.error("Could not find config name for collection:" + collection);
          throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,
              "Could not find config name for collection:" + collection);
        }
        solrLoader = new ZkSolrResourceLoader(instanceDir, zkConfigName, libLoader, getCoreProps(instanceDir, dcore.getPropertiesName(),dcore.getCoreProperties()), zkController);
        config = getSolrConfigFromZk(zkConfigName, dcore.getConfigName(), solrLoader);
      } catch (KeeperException e) {
        log.error("", e);
        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,
            "", e);
      } catch (InterruptedException e) {
        // Restore the interrupted status
        Thread.currentThread().interrupt();
        log.error("", e);
        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,
            "", e);
      }
    }
    
    IndexSchema schema = null;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628019541/fstmerge_var1_3738250993583672446
    if (indexSchemaCache != null) {
      if (zkController != null) {
        File schemaFile = new File(dcore.getSchemaName());
        if (!schemaFile.isAbsolute()) {
          schemaFile = new File(solrLoader.getInstanceDir() + "conf"
              + File.separator + dcore.getSchemaName());
        }
        if (schemaFile.exists()) {
          String key = schemaFile.getAbsolutePath()
              + ":"
              + new SimpleDateFormat("yyyyMMddHHmmss", Locale.US).format(new Date(
                  schemaFile.lastModified()));
          schema = indexSchemaCache.get(key);
          if (schema == null) {
            log.info("creating new schema object for core: " + dcore.name);
            schema = new IndexSchema(config, dcore.getSchemaName(), null);
            indexSchemaCache.put(key, schema);
          } else {
            log.info("re-using schema object for core: " + dcore.name);
          }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628019541/fstmerge_base_2838198456475091350
    if(indexSchemaCache != null){
      //schema sharing is enabled. so check if it already is loaded
      File schemaFile = new File(dcore.getSchemaName());
      if (!schemaFile.isAbsolute()) {
        schemaFile = new File(solrLoader.getInstanceDir() + "conf" + File.separator + dcore.getSchemaName());
      }
      if(schemaFile. exists()){
        String key = schemaFile.getAbsolutePath()+":"+new SimpleDateFormat("yyyyMMddhhmmss", Locale.US).format(new Date(schemaFile.lastModified()));
        schema = indexSchemaCache.get(key);
        if(schema == null){
          log.info("creating new schema object for core: " + dcore.name);
          schema = new IndexSchema(config, dcore.getSchemaName(), null);
          indexSchemaCache.put(key,schema);
        } else {
          log.info("re-using schema object for core: " + dcore.name);
=======
    if(indexSchemaCache != null){
      //schema sharing is enabled. so check if it already is loaded
      File schemaFile = new File(dcore.getSchemaName());
      if (!schemaFile.isAbsolute()) {
        schemaFile = new File(solrLoader.getInstanceDir() + "conf" + File.separator + dcore.getSchemaName());
      }
      if(schemaFile. exists()){
        String key = schemaFile.getAbsolutePath()+":"+new SimpleDateFormat("yyyyMMddHHmmss", Locale.US).format(new Date(schemaFile.lastModified()));
        schema = indexSchemaCache.get(key);
        if(schema == null){
          log.info("creating new schema object for core: " + dcore.name);
          schema = new IndexSchema(config, dcore.getSchemaName(), null);
          indexSchemaCache.put(key,schema);
        } else {
          log.info("re-using schema object for core: " + dcore.name);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628019541/fstmerge_var2_6912205216529857499
        }
      } else {
        // TODO: handle caching from ZooKeeper - perhaps using ZooKeepers versioning
        // Don't like this cache though - how does it empty as last modified changes?
      }
    }
    if(schema == null){
      if(zkController != null) {
        try {
          schema = getSchemaFromZk(zkConfigName, dcore.getSchemaName(), config, solrLoader);
        } catch (KeeperException e) {
          log.error("", e);
          throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,
              "", e);
        } catch (InterruptedException e) {
          // Restore the interrupted status
          Thread.currentThread().interrupt();
          log.error("", e);
          throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,
              "", e);
        }
      } else {
        schema = new IndexSchema(config, dcore.getSchemaName(), null);
      }
    }
    String dataDir = null;

    SolrCore core = new SolrCore(dcore.getName(), dataDir, config, schema, dcore);
    return core;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/core/CoreContainer.java
Conflict type: LineBasedMCFd
Conflict body: 
public void close() {
    int count = refCount.decrementAndGet();
    if (count > 0) return; // close is called often, and only actually closes if nothing is using it.
    if (count < 0) {
      log.error("Too many close [count:{}] on {}. Please report this exception to solr-user@lucene.apache.org", count, this );
      return;
    }
    log.info(logid+" CLOSING SolrCore " + this);


    if( closeHooks != null ) {
       for( CloseHook hook : closeHooks ) {
         try {
           hook.close( this );
         } catch (Throwable e) {
           SolrException.log(log, e);           
         }
      }
    }


    try {
      infoRegistry.clear();
    } catch (Exception e) {
      SolrException.log(log, e);
    }
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628019927/fstmerge_base_6787476793014856370
      closeSearcher();
=======
      updateHandler.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628019927/fstmerge_var2_2554776764695122643
    } catch (Exception e) {
      SolrException.log(log,e);
    }
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628019927/fstmerge_var1_7395881014247030198
      searcherExecutor.shutdown();
      if (!searcherExecutor.awaitTermination(60, TimeUnit.SECONDS)) {
        log.error("Timeout waiting for searchExecutor to terminate");
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628019927/fstmerge_base_6787476793014856370
      searcherExecutor.shutdown();
=======
      closeSearcher();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628019927/fstmerge_var2_2554776764695122643
    } catch (Exception e) {
      SolrException.log(log,e);
    }
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628019927/fstmerge_var1_7395881014247030198
      // Since we waited for the searcherExecutor to shut down,
      // there should be no more searchers warming in the background
      // that we need to take care of.
      //
      // For the case that a searcher was registered *before* warming
      // then the searchExecutor will throw an exception when getSearcher()
      // tries to use it, and the exception handling code should close it.
      closeSearcher();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628019927/fstmerge_base_6787476793014856370
      updateHandler.close();
=======
      searcherExecutor.shutdown();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628019927/fstmerge_var2_2554776764695122643
    } catch (Exception e) {
      SolrException.log(log,e);
    }


  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/core/SolrCore.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628021545/fstmerge_var1_2916272999003104094
@Override
  public Query createSpatialQuery(QParser parser, SpatialOptions options) {
    double[] point = null;
    try {
      point = DistanceUtils.parseLatitudeLongitude(options.pointStr);
    } catch (InvalidGeoException e) {
      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);
    }

    // lat & lon in degrees
    double latCenter = point[LAT];
    double lonCenter = point[LONG];

    point[0] = point[0] * DistanceUtils.DEGREES_TO_RADIANS;
    point[1] = point[1] * DistanceUtils.DEGREES_TO_RADIANS;
    //Get the distance

    double[] tmp = new double[2];
    //these calculations aren't totally accurate, but it should be good enough
    //TODO: Optimize to do in single calculations.  Would need to deal with poles, prime meridian, etc.
    double [] north = DistanceUtils.pointOnBearing(point[LAT], point[LONG], options.distance, 0, tmp, options.radius);
    //This returns the point as radians, but we need degrees b/c that is what the field is stored as
    double ur_lat = north[LAT] * DistanceUtils.RADIANS_TO_DEGREES;//get it now, as we are going to reuse tmp
    double [] east = DistanceUtils.pointOnBearing(point[LAT], point[LONG], options.distance, DistanceUtils.DEG_90_AS_RADS, tmp, options.radius);
    double ur_lon = east[LONG] * DistanceUtils.RADIANS_TO_DEGREES;
    double [] south = DistanceUtils.pointOnBearing(point[LAT], point[LONG], options.distance, DistanceUtils.DEG_180_AS_RADS, tmp, options.radius);
    double ll_lat = south[LAT] * DistanceUtils.RADIANS_TO_DEGREES;
    double [] west = DistanceUtils.pointOnBearing(point[LAT], point[LONG], options.distance, DistanceUtils.DEG_270_AS_RADS, tmp, options.radius);
    double ll_lon = west[LONG] * DistanceUtils.RADIANS_TO_DEGREES;
    

    //TODO: can we reuse our bearing calculations?
    double angDist = DistanceUtils.angularDistance(options.distance,
            options.radius);//in radians

    double latMin = -90.0, latMax = 90.0, lonMin = -180.0, lonMax = 180.0;
    double lon2Min = -180.0, lon2Max = 180.0;  // optional second longitude restriction

    // for the poles, do something slightly different - a polar "cap".
    // Also, note point[LAT] is in radians, but ur and ll are in degrees
    if (point[LAT] + angDist > DistanceUtils.DEG_90_AS_RADS) { // we cross the north pole
      //we don't need a longitude boundary at all
      latMin = Math.min(ll_lat, ur_lat);
    } else if (point[LAT] - angDist < -DistanceUtils.DEG_90_AS_RADS) { // we cross the south pole
      latMax = Math.max(ll_lat, ur_lat);
    } else {
      // set the latitude restriction as normal
      latMin = ll_lat;
      latMax = ur_lat;

      if (ll_lon > ur_lon) {
         // we crossed the +-180 deg longitude... need to make
        // range queries of (-180 TO ur) OR (ll TO 180)
        lonMin = -180;
        lonMax = ur_lon;
        lon2Min = ll_lon;
        lon2Max = 180;
      } else {
        lonMin = ll_lon;
        lonMax = ur_lon;
      }
    }


    // Now that we've figured out the ranges, build them!
    SchemaField latField = subField(options.field, LAT);
    SchemaField lonField = subField(options.field, LONG);

    if (options.bbox) {
      BooleanQuery result = new BooleanQuery();  // only used if box==true

      Query latRange = latField.getType().getRangeQuery(parser, latField,
                String.valueOf(latMin),
                String.valueOf(latMax),
                true, true);
      result.add(latRange, BooleanClause.Occur.MUST);

      if (lonMin != -180 || lonMax != 180) {
        Query lonRange = lonField.getType().getRangeQuery(parser, lonField,
                String.valueOf(lonMin),
                String.valueOf(lonMax),
                true, true);
        if (lon2Min != -180 || lon2Max != 180) {
          // another valid longitude range
          BooleanQuery bothLons = new BooleanQuery();
          bothLons.add(lonRange, BooleanClause.Occur.SHOULD);

          lonRange = lonField.getType().getRangeQuery(parser, lonField,
                String.valueOf(lon2Min),
                String.valueOf(lon2Max),
                true, true);
          bothLons.add(lonRange, BooleanClause.Occur.SHOULD);

          lonRange = bothLons;
        }

        result.add(lonRange, BooleanClause.Occur.MUST);
      }

      return result;
    }


    SpatialDistanceQuery spatial = new SpatialDistanceQuery();
    spatial.origField = options.field.getName();
    spatial.latSource = latField.getType().getValueSource(latField, parser);
    spatial.lonSource = lonField.getType().getValueSource(lonField, parser);
    spatial.latMin = latMin;
    spatial.latMax = latMax;
    spatial.lonMin = lonMin;
    spatial.lonMax = lonMax;
    spatial.lon2Min = lon2Min;
    spatial.lon2Max = lon2Max;
    spatial.lon2 = lon2Min != -180 || lon2Max != 180;

    spatial.latCenter = latCenter;
    spatial.lonCenter = lonCenter;
    spatial.dist = options.distance;
    spatial.planetRadius = options.radius;

    spatial.calcDist = !options.bbox;

    return spatial;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628021545/fstmerge_base_7122949113318277928
=======
@Override
  public Query createSpatialQuery(QParser parser, SpatialOptions options) {
    BooleanQuery result = new BooleanQuery();
    double[] point = new double[0];
    try {
      point = DistanceUtils.parseLatitudeLongitude(options.pointStr);
    } catch (InvalidGeoException e) {
      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);
    }

    //Get the distance
    double[] ur;
    double[] ll;
    if (options.measStr == null || options.measStr.equals("hsin")) {
      ur = DistanceUtils.latLonCornerDegs(point[LAT], point[LONG], options.distance, null, true, options.radius);
      ll = DistanceUtils.latLonCornerDegs(point[LAT], point[LONG], options.distance, null, false, options.radius);
    } else {
      ur = DistanceUtils.vectorBoxCorner(point, null, options.distance, true);
      ll = DistanceUtils.vectorBoxCorner(point, null, options.distance, false);
    }

    SchemaField subSF;
    Query range;

    double angDistDegs = DistanceUtils.angularDistance(options.distance,
            DistanceUtils.EARTH_MEAN_RADIUS_MI) * DistanceUtils.RADIANS_TO_DEGREES;
    //for the poles, do something slightly different
    if (point[LAT] + angDistDegs > 90.0) { //we cross the north pole
      //we don't need a longitude boundary at all

      double minLat = Math.min(ll[LAT], ur[LAT]);
      subSF = subField(options.field, LAT);
      range = subSF.getType().getRangeQuery(parser, subSF,
              String.valueOf(minLat),
              "90", true, true);
      result.add(range, BooleanClause.Occur.MUST);
    } else if (point[LAT] - angDistDegs < -90.0) {//we cross the south pole
      subSF = subField(options.field, LAT);
      double maxLat = Math.max(ll[LAT], ur[LAT]);
      range = subSF.getType().getRangeQuery(parser, subSF,
              "-90", String.valueOf(maxLat), true, true);
      result.add(range, BooleanClause.Occur.MUST);
    } else{
        //Latitude
        //we may need to generate multiple queries depending on the range
        //Are we crossing the 180 deg. longitude, if so, we need to do some special things
        if (ll[LONG] > 0.0 && ur[LONG] < 0.0) {
          //TODO: refactor into common code, etc.
          //Now check other side of the Equator
          if (ll[LAT] < 0.0 && ur[LAT] > 0.0) {
            addEquatorialBoundary(parser, options, result, ur[LAT], ll[LAT]);
          } //check poles
          else {
            subSF = subField(options.field, LAT);
            //not crossing the equator
            range = subSF.getType().getRangeQuery(parser, subSF,
                    String.valueOf(ll[LAT]),
                    String.valueOf(ur[LAT]), true, true);
            result.add(range, BooleanClause.Occur.MUST);
          }
          //Longitude
          addMeridianBoundary(parser, options, result, ur[LONG], ll[LONG], "180.0", "-180.0");

        } else if (ll[LONG] < 0.0 && ur[LONG] > 0.0) {//prime meridian (0 degrees
          //Now check other side of the Equator
          if (ll[LAT] < 0.0 && ur[LAT] > 0.0) {
            addEquatorialBoundary(parser, options, result, ur[LAT], ll[LAT]);
          } else {
            subSF = subField(options.field, LAT);
            //not crossing the equator
            range = subSF.getType().getRangeQuery(parser, subSF,
                    String.valueOf(ll[LAT]),
                    String.valueOf(ur[LAT]), true, true);
            result.add(range, BooleanClause.Occur.MUST);
          }
          //Longitude
          addMeridianBoundary(parser, options, result, ur[LONG], ll[LONG], "0.0", ".0");

        } else {// we are all in the Eastern or Western hemi
          //Now check other side of the Equator
          if (ll[LAT] < 0.0 && ur[LAT] > 0.0) {
            addEquatorialBoundary(parser, options, result, ur[LAT], ll[LAT]);
          } else {//we are all in either the Northern or the Southern Hemi.
            //TODO: nice to move this up so that it is the first thing and we can avoid the extra checks since
            //this is actually the most likely case
            subSF = subField(options.field, LAT);
            range = subSF.getType().getRangeQuery(parser, subSF,
                    String.valueOf(ll[LAT]),
                    String.valueOf(ur[LAT]), true, true);
            result.add(range, BooleanClause.Occur.MUST);

          }
          //Longitude, all in the same hemi
          subSF = subField(options.field, LONG);
          range = subSF.getType().getRangeQuery(parser, subSF,
                  String.valueOf(ll[LONG]),
                  String.valueOf(ur[LONG]), true, true);
          result.add(range, BooleanClause.Occur.MUST);
        }
      }

      return result;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628021545/fstmerge_var2_3476498523653329743

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/schema/LatLonType.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628021572/fstmerge_var1_7009866218929986917
@Override
  public SortField getSortField(SchemaField field, boolean top) {
    throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Sorting not supported on LatLonType " + field.getName());
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628021572/fstmerge_base_4007216449202208620
=======
@Override
  public SortField getSortField(SchemaField field, boolean top) {
    throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Sorting not supported on SpatialTileField " + field.getName());
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628021572/fstmerge_var2_8474226258366239762

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/schema/LatLonType.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628021577/fstmerge_var1_1516003841796220078
@Override
  public Field createField(SchemaField field, String externalVal, float boost) {
    throw new UnsupportedOperationException("LatLonType uses multiple fields.  field=" + field.getName());
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628021577/fstmerge_base_4004884108992025540
=======
@Override
  public Field createField(SchemaField field, String externalVal, float boost) {
    throw new UnsupportedOperationException("SpatialTileField uses multiple fields.  field=" + field.getName());
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628021577/fstmerge_var2_2433308304349248631

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/schema/LatLonType.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628026655/fstmerge_var1_6907509273182818909
public void write(Writer writer, SolrQueryRequest request, SolrQueryResponse response) throws IOException {
    VelocityEngine engine = getEngine(request);  // TODO: have HTTP headers available for configuring engine

    Template template = getTemplate(engine, request);

    VelocityContext context = new VelocityContext();

    context.put("request", request);

    // Turn the SolrQueryResponse into a SolrResponse.
    // QueryResponse has lots of conveniences suitable for a view
    // Problem is, which SolrResponse class to use?
    // One patch to SOLR-620 solved this by passing in a class name as
    // as a parameter and using reflection and Solr's class loader to
    // create a new instance.  But for now the implementation simply
    // uses QueryResponse, and if it chokes in a known way, fall back
    // to bare bones SolrResponseBase.
    // TODO: Can this writer know what the handler class is?  With echoHandler=true it can get its string name at least
    SolrResponse rsp = new QueryResponse();
    NamedList<Object> parsedResponse = BinaryResponseWriter.getParsedResponse(request, response);
    try {
      rsp.setResponse(parsedResponse);

      // page only injected if QueryResponse works
      context.put("page", new PageTool(request, response));  // page tool only makes sense for a SearchHandler request... *sigh*
    } catch (ClassCastException e) {
      // known edge case where QueryResponse's extraction assumes "response" is a SolrDocumentList
      // (AnalysisRequestHandler emits a "response")
      e.printStackTrace();
      rsp = new SolrResponseBase();
      rsp.setResponse(parsedResponse);
    }
    context.put("response", rsp);

    // Velocity context tools - TODO: make these pluggable
    context.put("esc", new EscapeTool());
    context.put("date", new ComparisonDateTool());
    context.put("list", new ListTool());
    context.put("math", new MathTool());
    context.put("number", new NumberTool());
    context.put("sort", new SortTool());

    context.put("engine", engine);  // for $engine.resourceExists(...)

    String layout_template = request.getParams().get("v.layout");
    String json_wrapper = request.getParams().get("v.json");
    boolean wrap_response = (layout_template != null) || (json_wrapper != null);

    // create output, optionally wrap it into a json object
    if (wrap_response) {
      StringWriter stringWriter = new StringWriter();
      template.merge(context, stringWriter);

      if (layout_template != null) {
        context.put("content", stringWriter.toString());
        stringWriter = new StringWriter();
        try {
          engine.getTemplate(layout_template + ".vm").merge(context, stringWriter);
        } catch (Exception e) {
          throw new IOException(e.getMessage());
        }
      }

      if (json_wrapper != null) {
        writer.write(request.getParams().get("v.json") + "(");
        writer.write(getJSONWrap(stringWriter.toString()));
        writer.write(')');
      } else {  // using a layout, but not JSON wrapping
        writer.write(stringWriter.toString());
      }
    } else {
      template.merge(context, writer);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628026655/fstmerge_base_4705571855381103913
=======
public void write(Writer writer, SolrQueryRequest request, SolrQueryResponse response) throws IOException {
    VelocityEngine engine = getEngine(request);  // TODO: have HTTP headers available for configuring engine

    Template template = getTemplate(engine, request);

    VelocityContext context = new VelocityContext();

    context.put("request", request);

    // Turn the SolrQueryResponse into a SolrResponse.
    // QueryResponse has lots of conveniences suitable for a view
    // Problem is, which SolrResponse class to use?
    // One patch to SOLR-620 solved this by passing in a class name as
    // as a parameter and using reflection and Solr's class loader to
    // create a new instance.  But for now the implementation simply
    // uses QueryResponse, and if it chokes in a known way, fall back
    // to bare bones SolrResponseBase.
    // TODO: Can this writer know what the handler class is?  With echoHandler=true it can get its string name at least
    SolrResponse rsp = new QueryResponse();
    NamedList<Object> parsedResponse = new EmbeddedSolrServer(request.getCore()).getParsedResponse(request, response);
    try {
      rsp.setResponse(parsedResponse);

      // page only injected if QueryResponse works
      context.put("page", new PageTool(request, response));  // page tool only makes sense for a SearchHandler request... *sigh*
    } catch (ClassCastException e) {
      // known edge case where QueryResponse's extraction assumes "response" is a SolrDocumentList
      // (AnalysisRequestHandler emits a "response")
      e.printStackTrace();
      rsp = new SolrResponseBase();
      rsp.setResponse(parsedResponse);
    }
    context.put("response", rsp);

    // Velocity context tools - TODO: make these pluggable
    context.put("esc", new EscapeTool());
    context.put("date", new ComparisonDateTool());
    context.put("list", new ListTool());
    context.put("math", new MathTool());
    context.put("number", new NumberTool());
    context.put("sort", new SortTool());

    context.put("engine", engine);  // for $engine.resourceExists(...)

    String layout_template = request.getParams().get("v.layout");
    String json_wrapper = request.getParams().get("v.json");
    boolean wrap_response = (layout_template != null) || (json_wrapper != null);

    // create output, optionally wrap it into a json object
    if (wrap_response) {
      StringWriter stringWriter = new StringWriter();
      template.merge(context, stringWriter);

      if (layout_template != null) {
        context.put("content", stringWriter.toString());
        stringWriter = new StringWriter();
        try {
          engine.getTemplate(layout_template + ".vm").merge(context, stringWriter);
        } catch (Exception e) {
          throw new IOException(e.getMessage());
        }
      }

      if (json_wrapper != null) {
        writer.write(request.getParams().get("v.json") + "(");
        writer.write(getJSONWrap(stringWriter.toString()));
        writer.write(')');
      } else {  // using a layout, but not JSON wrapping
        writer.write(stringWriter.toString());
      }
    } else {
      template.merge(context, writer);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628026655/fstmerge_var2_8818384966352056576

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/response/VelocityResponseWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628027800/fstmerge_var1_1844305450628780739
public PageTool(SolrQueryRequest request, SolrQueryResponse response) {
    String rows = request.getParams().get("rows");

    if (rows != null) {
      results_per_page = new Integer(rows);
    }
    //TODO: Handle group by results
    Object docs = response.getValues().get("response");
    if (docs != null) {
      if (docs instanceof DocSlice) {
        DocSlice doc_slice = (DocSlice) docs;
        results_found = doc_slice.matches();
        start = doc_slice.offset();
      } else {
        SolrDocumentList doc_list = (SolrDocumentList) docs;
        results_found = doc_list.getNumFound();
        start = doc_list.getStart();
      }
    }

    page_count = (int) Math.ceil(results_found / (double) results_per_page);
    current_page_number = (int) Math.ceil(start / (double) results_per_page) + (page_count > 0 ? 1 : 0);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628027800/fstmerge_base_8847975718305285133
=======
public PageTool(SolrQueryRequest request, SolrQueryResponse response) {
    String rows = request.getParams().get("rows");

    if (rows != null) {
      results_per_page = new Integer(rows);
    }

    Object docs = response.getValues().get("response");
    if (docs != null) {
      if (docs instanceof DocSlice) {
        DocSlice doc_slice = (DocSlice) docs;
        results_found = doc_slice.matches();
        start = doc_slice.offset();
      } else {
        SolrDocumentList doc_list = (SolrDocumentList) docs;
        results_found = doc_list.getNumFound();
        start = doc_list.getStart();
      }
    }

    page_count = (int) Math.ceil(results_found / (double) results_per_page);
    current_page_number = (int) Math.ceil(start / (double) results_per_page) + (page_count > 0 ? 1 : 0);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628027800/fstmerge_var2_8579038352821081072

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/response/PageTool.java
Conflict type: LineBasedMCFd
Conflict body: 
public static NamedList getFieldCacheCounts(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort, String prefix) throws IOException {
    // TODO: If the number of terms is high compared to docs.size(), and zeros==false,
    //  we should use an alternate strategy to avoid
    //  1) creating another huge int[] for the counts
    //  2) looping over that huge int[] looking for the rare non-zeros.
    //
    // Yet another variation: if docs.size() is small and termvectors are stored,
    // then use them instead of the FieldCache.
    //

    // TODO: this function is too big and could use some refactoring, but
    // we also need a facet cache, and refactoring of SimpleFacets instead of
    // trying to pass all the various params around.

    FieldType ft = searcher.getSchema().getFieldType(fieldName);
    NamedList res = new NamedList();

    FieldCache.DocTermsIndex si = FieldCache.DEFAULT.getTermsIndex(searcher.getReader(), fieldName);

    final BytesRef prefixRef;
    if (prefix == null) {
      prefixRef = null;
    } else if (prefix.length()==0) {
      prefix = null;
      prefixRef = null;
    } else {
      prefixRef = new BytesRef(prefix);
    }

    final BytesRef br = new BytesRef();

    int startTermIndex, endTermIndex;
    if (prefix!=null) {
      startTermIndex = si.binarySearchLookup(prefixRef, br);
      if (startTermIndex<0) startTermIndex=-startTermIndex-1;
      prefixRef.append(ByteUtils.bigTerm);
      endTermIndex = si.binarySearchLookup(prefixRef, br);
      assert endTermIndex < 0;
      endTermIndex = -endTermIndex-1;
    } else {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628027982/fstmerge_base_4323038731776654446
      startTermIndex=1;
=======
      startTermIndex=0;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628027982/fstmerge_var2_8529865123369311232
      endTermIndex=si.numOrd();
    }

    final int nTerms=endTermIndex-startTermIndex;
    int missingCount = -1; 

    CharArr spare = new CharArr();
    if (nTerms>0 && docs.size() >= mincount) {

      // count collection array only needs to be as big as the number of terms we are
      // going to collect counts for.
      final int[] counts = new int[nTerms];

      DocIterator iter = docs.iterator();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628027982/fstmerge_var1_4010605821623056839

      PackedInts.Reader ordReader = si.getDocToOrd();
      if (ordReader instanceof Direct32) {
        int[] ords = ((Direct32)ordReader).getArray();
        if (prefix==null) {
          while (iter.hasNext()) {
            counts[ords[iter.nextDoc()]]++;
          }
        } else {
          while (iter.hasNext()) {
            int term = ords[iter.nextDoc()];
            int arrIdx = term-startTermIndex;
            if (arrIdx>=0 && arrIdx<nTerms) counts[arrIdx]++;
          }
        }
      } else if (ordReader instanceof Direct16) {
        short[] ords = ((Direct16)ordReader).getArray();
        if (prefix==null) {
          while (iter.hasNext()) {
            counts[ords[iter.nextDoc()] & 0xffff]++;
          }
        } else {
          while (iter.hasNext()) {
            int term = ords[iter.nextDoc()] & 0xffff;
            int arrIdx = term-startTermIndex;
            if (arrIdx>=0 && arrIdx<nTerms) counts[arrIdx]++;
          }
        }
      } else if (ordReader instanceof Direct8) {
        byte[] ords = ((Direct8)ordReader).getArray();
        if (prefix==null) {
          while (iter.hasNext()) {
            counts[ords[iter.nextDoc()] & 0xff]++;
          }
        } else {
          while (iter.hasNext()) {
            int term = ords[iter.nextDoc()] & 0xff;
            int arrIdx = term-startTermIndex;
            if (arrIdx>=0 && arrIdx<nTerms) counts[arrIdx]++;
          }
        }
      } else {
        while (iter.hasNext()) {
          int term = si.getOrd(iter.nextDoc());
          int arrIdx = term-startTermIndex;
          if (arrIdx>=0 && arrIdx<nTerms) counts[arrIdx]++;
        }
      }

      if (startTermIndex == 0) {
        missingCount = counts[0];
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628027982/fstmerge_base_4323038731776654446
      while (iter.hasNext()) {
        int term = si.getOrd(iter.nextDoc());
        int arrIdx = term-startTermIndex;
        if (arrIdx>=0 && arrIdx<nTerms) counts[arrIdx]++;
=======

      PackedInts.Reader ordReader = si.getDocToOrd();
      if (ordReader instanceof Direct32) {
        int[] ords = ((Direct32)ordReader).getArray();
        if (prefix==null) {
          while (iter.hasNext()) {
            counts[ords[iter.nextDoc()]]++;
          }
        } else {
          while (iter.hasNext()) {
            int term = ords[iter.nextDoc()];
            int arrIdx = term-startTermIndex;
            if (arrIdx>=0 && arrIdx<nTerms) counts[arrIdx]++;
          }
        }
      } else if (ordReader instanceof Direct16) {
        short[] ords = ((Direct16)ordReader).getArray();
        if (prefix==null) {
          while (iter.hasNext()) {
            counts[ords[iter.nextDoc()] & 0xffff]++;
          }
        } else {
          while (iter.hasNext()) {
            int term = ords[iter.nextDoc()] & 0xffff;
            int arrIdx = term-startTermIndex;
            if (arrIdx>=0 && arrIdx<nTerms) counts[arrIdx]++;
          }
        }
      } else if (ordReader instanceof Direct8) {
        byte[] ords = ((Direct8)ordReader).getArray();
        if (prefix==null) {
          while (iter.hasNext()) {
            counts[ords[iter.nextDoc()] & 0xff]++;
          }
        } else {
          while (iter.hasNext()) {
            int term = ords[iter.nextDoc()] & 0xff;
            int arrIdx = term-startTermIndex;
            if (arrIdx>=0 && arrIdx<nTerms) counts[arrIdx]++;
          }
        }
      } else {
        while (iter.hasNext()) {
          int term = si.getOrd(iter.nextDoc());
          int arrIdx = term-startTermIndex;
          if (arrIdx>=0 && arrIdx<nTerms) counts[arrIdx]++;
        }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628027982/fstmerge_var2_8529865123369311232
      }

      // IDEA: we could also maintain a count of "other"... everything that fell outside
      // of the top 'N'

      int off=offset;
      int lim=limit>=0 ? limit : Integer.MAX_VALUE;

      if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {
        int maxsize = limit>0 ? offset+limit : Integer.MAX_VALUE-1;
        maxsize = Math.min(maxsize, nTerms);
        LongPriorityQueue queue = new LongPriorityQueue(Math.min(maxsize,1000), maxsize, Long.MIN_VALUE);

        int min=mincount-1;  // the smallest value in the top 'N' values
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628027982/fstmerge_base_4323038731776654446
        for (int i=0; i<nTerms; i++) {
=======
        for (int i=(startTermIndex==0)?1:0; i<nTerms; i++) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628027982/fstmerge_var2_8529865123369311232
          int c = counts[i];
          if (c>min) {
            // NOTE: we use c>min rather than c>=min as an optimization because we are going in
            // index order, so we already know that the keys are ordered.  This can be very
            // important if a lot of the counts are repeated (like zero counts would be).

            // smaller term numbers sort higher, so subtract the term number instead
            long pair = (((long)c)<<32) + (Integer.MAX_VALUE - i);
            boolean displaced = queue.insert(pair);
            if (displaced) min=(int)(queue.top() >>> 32);
          }
        }

        // if we are deep paging, we don't have to order the highest "offset" counts.
        int collectCount = Math.max(0, queue.size() - off);
        assert collectCount <= lim;

        // the start and end indexes of our list "sorted" (starting with the highest value)
        int sortedIdxStart = queue.size() - (collectCount - 1);
        int sortedIdxEnd = queue.size() + 1;
        final long[] sorted = queue.sort(collectCount);

        for (int i=sortedIdxStart; i<sortedIdxEnd; i++) {
          long pair = sorted[i];
          int c = (int)(pair >>> 32);
          int tnum = Integer.MAX_VALUE - (int)pair;

          spare.reset();
          ft.indexedToReadable(si.lookup(startTermIndex+tnum, br), spare);
          res.add(spare.toString(), c);
        }
      
      } else {
        // add results in index order
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628027982/fstmerge_base_4323038731776654446
        int i=0;
=======
        int i=(startTermIndex==0)?1:0;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628027982/fstmerge_var2_8529865123369311232
        if (mincount<=0) {
          // if mincount<=0, then we won't discard any terms and we know exactly
          // where to start.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628027982/fstmerge_base_4323038731776654446
          i=off;
=======
          i+=off;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628027982/fstmerge_var2_8529865123369311232
          off=0;
        }

        for (; i<nTerms; i++) {          
          int c = counts[i];
          if (c<mincount || --off>=0) continue;
          if (--lim<0) break;
          spare.reset();
          ft.indexedToReadable(si.lookup(startTermIndex+i, br), spare);
          res.add(spare.toString(), c);
        }
      }
    }

    if (missing) {
      if (missingCount < 0) {
        missingCount = getFieldMissingCount(searcher,docs,fieldName);
      }
      res.add(null, missingCount);
    }
    
    return res;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/request/SimpleFacets.java
Conflict type: LineBasedMCFd
Conflict body: 
public NamedList getCounts(SolrIndexSearcher searcher, DocSet baseDocs, int offset, int limit, Integer mincount, boolean missing, String sort, String prefix) throws IOException {
    use.incrementAndGet();

    FieldType ft = searcher.getSchema().getFieldType(field);

    NamedList res = new NamedList();  // order is important

    DocSet docs = baseDocs;
    int baseSize = docs.size();
    int maxDoc = searcher.maxDoc();

    if (baseSize >= mincount) {

      final int[] index = this.index;
      // tricky: we add more more element than we need because we will reuse this array later
      // for ordering term ords before converting to term labels.
      final int[] counts = new int[numTermsInField + 1];

      //
      // If there is prefix, find it's start and end term numbers
      //
      int startTerm = 0;
      int endTerm = numTermsInField;  // one past the end

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_base_5138311639263442151
      NumberedTermEnum te = ti.getEnumerator(searcher.getReader());
=======
      NumberedTermsEnum te = ti.getEnumerator(searcher.getReader());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_var2_3806119358870879696
      if (prefix != null && prefix.length() > 0) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_var1_978909846661441924
        BytesRef prefixBr = new BytesRef(prefix);
        te.skipTo(prefixBr);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_base_5138311639263442151
        te.skipTo(prefix);
=======
        te.skipTo(new BytesRef(prefix));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_var2_3806119358870879696
        startTerm = te.getTermNumber();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_var1_978909846661441924
        prefixBr.append(ByteUtils.bigTerm);
        te.skipTo(prefixBr);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_base_5138311639263442151
        te.skipTo(prefix + "\uffff\uffff\uffff\uffff");
=======
        te.skipTo(new BytesRef(prefix + "\uffff\uffff\uffff\uffff"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_var2_3806119358870879696
        endTerm = te.getTermNumber();
      }

      /***********
      // Alternative 2: get the docSet of the prefix (could take a while) and
      // then do the intersection with the baseDocSet first.
      if (prefix != null && prefix.length() > 0) {
        docs = searcher.getDocSet(new ConstantScorePrefixQuery(new Term(field, ft.toInternal(prefix))), docs);
        // The issue with this method are problems of returning 0 counts for terms w/o
        // the prefix.  We can't just filter out those terms later because it may
        // mean that we didn't collect enough terms in the queue (in the sorted case).
      }
      ***********/

      boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0
              && startTerm==0 && endTerm==numTermsInField
              && docs instanceof BitDocSet;

      if (doNegative) {
        OpenBitSet bs = (OpenBitSet)((BitDocSet)docs).getBits().clone();
        bs.flip(0, maxDoc);
        // TODO: when iterator across negative elements is available, use that
        // instead of creating a new bitset and inverting.
        docs = new BitDocSet(bs, maxDoc - baseSize);
        // simply negating will mean that we have deleted docs in the set.
        // that should be OK, as their entries in our table should be empty.
      }

      // For the biggest terms, do straight set intersections
      for (TopTerm tt : bigTerms.values()) {
        // TODO: counts could be deferred if sorted==false
        if (tt.termNum >= startTerm && tt.termNum < endTerm) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_base_5138311639263442151
          counts[tt.termNum] = searcher.numDocs(new TermQuery(tt.term), docs);
=======
          counts[tt.termNum] = searcher.numDocs(new TermQuery(new Term(ti.field, tt.term)), docs);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_var2_3806119358870879696
        }
      }

      // TODO: we could short-circuit counting altogether for sorted faceting
      // where we already have enough terms from the bigTerms

      // TODO: we could shrink the size of the collection array, and
      // additionally break when the termNumber got above endTerm, but
      // it would require two extra conditionals in the inner loop (although
      // they would be predictable for the non-prefix case).
      // Perhaps a different copy of the code would be warranted.

      if (termInstances > 0) {
        DocIterator iter = docs.iterator();
        while (iter.hasNext()) {
          int doc = iter.nextDoc();
          int code = index[doc];

          if ((code & 0xff)==1) {
            int pos = code>>>8;
            int whichArray = (doc >>> 16) & 0xff;
            byte[] arr = tnums[whichArray];
            int tnum = 0;
            for(;;) {
              int delta = 0;
              for(;;) {
                byte b = arr[pos++];
                delta = (delta << 7) | (b & 0x7f);
                if ((b & 0x80) == 0) break;
              }
              if (delta == 0) break;
              tnum += delta - TNUM_OFFSET;
              counts[tnum]++;
            }
          } else {
            int tnum = 0;
            int delta = 0;
            for (;;) {
              delta = (delta << 7) | (code & 0x7f);
              if ((code & 0x80)==0) {
                if (delta==0) break;
                tnum += delta - TNUM_OFFSET;
                counts[tnum]++;
                delta = 0;
              }
              code >>>= 8;
            }
          }
        }
      }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_base_5138311639263442151
=======
      CharArr spare = new CharArr();

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_var2_3806119358870879696
      int off=offset;
      int lim=limit>=0 ? limit : Integer.MAX_VALUE;

      if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {
        int maxsize = limit>0 ? offset+limit : Integer.MAX_VALUE-1;
        maxsize = Math.min(maxsize, numTermsInField);
        LongPriorityQueue queue = new LongPriorityQueue(Math.min(maxsize,1000), maxsize, Long.MIN_VALUE);

        int min=mincount-1;  // the smallest value in the top 'N' values
        for (int i=startTerm; i<endTerm; i++) {
          int c = doNegative ? maxTermCounts[i] - counts[i] : counts[i];
          if (c>min) {
            // NOTE: we use c>min rather than c>=min as an optimization because we are going in
            // index order, so we already know that the keys are ordered.  This can be very
            // important if a lot of the counts are repeated (like zero counts would be).

            // smaller term numbers sort higher, so subtract the term number instead
            long pair = (((long)c)<<32) + (Integer.MAX_VALUE - i);
            boolean displaced = queue.insert(pair);
            if (displaced) min=(int)(queue.top() >>> 32);
          }
        }

        // now select the right page from the results
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_var1_978909846661441924

        // if we are deep paging, we don't have to order the highest "offset" counts.
        int collectCount = Math.max(0, queue.size() - off);
        assert collectCount <= lim;

        // the start and end indexes of our list "sorted" (starting with the highest value)
        int sortedIdxStart = queue.size() - (collectCount - 1);
        int sortedIdxEnd = queue.size() + 1;
        final long[] sorted = queue.sort(collectCount);

        final int[] indirect = counts;  // reuse the counts array for the index into the tnums array
        assert indirect.length >= sortedIdxEnd;

        for (int i=sortedIdxStart; i<sortedIdxEnd; i++) {
          long pair = sorted[i];
          int c = (int)(pair >>> 32);
          int tnum = Integer.MAX_VALUE - (int)pair;

          indirect[i] = i;   // store the index for indirect sorting
          sorted[i] = tnum;  // reuse the "sorted" array to store the term numbers for indirect sorting

          // add a null label for now... we'll fill it in later.
          res.add(null, c);
        }

        // now sort the indexes by the term numbers
        PrimUtils.sort(sortedIdxStart, sortedIdxEnd, indirect, new PrimUtils.IntComparator() {
          @Override
          public int compare(int a, int b) {
            return (int)sorted[a] - (int)sorted[b];
          }

          @Override
          public boolean lessThan(int a, int b) {
            return sorted[a] < sorted[b];
          }

          @Override
          public boolean equals(int a, int b) {
            return sorted[a] == sorted[b];
          }
        });

        // convert the term numbers to term values and set as the label
        for (int i=sortedIdxStart; i<sortedIdxEnd; i++) {
          int idx = indirect[i];
          int tnum = (int)sorted[idx];
          String label = getReadableValue(getTermValue(te, tnum), ft, spare);
          res.setName(idx - sortedIdxStart, label);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_base_5138311639263442151
        for (Long p : queue) {
          if (--off>=0) continue;
          if (--lim<0) break;
          int c = -(int)(p.longValue() >>> 32);
          //int tnum = 0x7fffffff - (int)p.longValue();  // use if priority queue
          int tnum = (int)p.longValue();
          String label = ft.indexedToReadable(getTermText(te, tnum));
          res.add(label, c);
=======
        for (Long p : queue) {
          if (--off>=0) continue;
          if (--lim<0) break;
          int c = -(int)(p.longValue() >>> 32);
          //int tnum = 0x7fffffff - (int)p.longValue();  // use if priority queue
          int tnum = (int)p.longValue();
          String label = getReadableValue(getTermValue(te, tnum), ft, spare);
          res.add(label, c);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_var2_3806119358870879696
        }

      } else {
        // add results in index order
        int i=startTerm;
        if (mincount<=0) {
          // if mincount<=0, then we won't discard any terms and we know exactly
          // where to start.
          i=startTerm+off;
          off=0;
        }

        for (; i<endTerm; i++) {
          int c = doNegative ? maxTermCounts[i] - counts[i] : counts[i];
          if (c<mincount || --off>=0) continue;
          if (--lim<0) break;

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_base_5138311639263442151
          String label = ft.indexedToReadable(getTermText(te, i));
=======
          String label = getReadableValue(getTermValue(te, i), ft, spare);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628028293/fstmerge_var2_3806119358870879696
          res.add(label, c);
        }
      }

      te.close();
    }


    if (missing) {
      // TODO: a faster solution for this?
      res.add(null, SimpleFacets.getFieldMissingCount(searcher, baseDocs, field));
    }

    return res;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/src/java/org/apache/solr/request/UnInvertedField.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033044/fstmerge_var1_8162892014784226383
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033044/fstmerge_base_5256476381698579360
@Test
  @Ignore
  public void basic() throws Exception {
    JdbcDataSource dataSource = new JdbcDataSource();
    Properties p = new Properties();
    p.put("driver", "com.mysql.jdbc.Driver");
    p.put("url", "jdbc:mysql://localhost/autos");
    p.put("user", "root");
    p.put("password", "");

    List<Map<String, String>> flds = new ArrayList<Map<String, String>>();
    Map<String, String> f = new HashMap<String, String>();
    f.put("column", "trim_id");
    f.put("type", "long");
    flds.add(f);
    f = new HashMap<String, String>();
    f.put("column", "msrp");
    f.put("type", "float");
    flds.add(f);

    Context c = AbstractDataImportHandlerTest.getContext(null, null,
            dataSource, Context.FULL_DUMP, flds, null);
    dataSource.init(c, p);
    Iterator<Map<String, Object>> i = dataSource
            .getData("select make,model,year,msrp,trim_id from atrimlisting where make='Acura'");
    int count = 0;
    Object msrp = null;
    Object trim_id = null;
    while (i.hasNext()) {
      Map<String, Object> map = i.next();
      msrp = map.get("msrp");
      trim_id = map.get("trim_id");
      count++;
    }
    Assert.assertEquals(5, count);
    Assert.assertEquals(Float.class, msrp.getClass());
    Assert.assertEquals(Long.class, trim_id.getClass());
  }
=======
@Test
  @Ignore
  public void basic() throws Exception {
    JdbcDataSource dataSource = new JdbcDataSource();
    Properties p = new Properties();
    p.put("driver", "com.mysql.jdbc.Driver");
    p.put("url", "jdbc:mysql://localhost/autos");
    p.put("user", "root");
    p.put("password", "");

    List<Map<String, String>> flds = new ArrayList<Map<String, String>>();
    Map<String, String> f = new HashMap<String, String>();
    f.put("column", "trim_id");
    f.put("type", "long");
    flds.add(f);
    f = new HashMap<String, String>();
    f.put("column", "msrp");
    f.put("type", "float");
    flds.add(f);

    Context c = AbstractDataImportHandlerTestCase.getContext(null, null,
            dataSource, Context.FULL_DUMP, flds, null);
    dataSource.init(c, p);
    Iterator<Map<String, Object>> i = dataSource
            .getData("select make,model,year,msrp,trim_id from atrimlisting where make='Acura'");
    int count = 0;
    Object msrp = null;
    Object trim_id = null;
    while (i.hasNext()) {
      Map<String, Object> map = i.next();
      msrp = map.get("msrp");
      trim_id = map.get("trim_id");
      count++;
    }
    Assert.assertEquals(5, count);
    Assert.assertEquals(Float.class, msrp.getClass());
    Assert.assertEquals(Long.class, trim_id.getClass());
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033044/fstmerge_var2_4714417382185347095

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestJdbcDataSource.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void simple() throws Exception {
    List<Map<String, String>> flds = new ArrayList<Map<String, String>>();
    Map<String, String> f = new HashMap<String, String>();
    // <field column="dsc" clob="true" name="description" />
    f.put(DataImporter.COLUMN, "dsc");
    f.put(ClobTransformer.CLOB, "true");
    f.put(DataImporter.NAME, "description");
    flds.add(f);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033049/fstmerge_var1_7636592024106867393
    Context ctx = getContext(null, new VariableResolverImpl(), null, Context.FULL_DUMP, flds, Collections.EMPTY_MAP);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033049/fstmerge_base_4866864464485864964
    Context ctx = AbstractDataImportHandlerTest.getContext(null, new VariableResolverImpl(), null, Context.FULL_DUMP, flds, Collections.EMPTY_MAP);
=======
    Context ctx = AbstractDataImportHandlerTestCase.getContext(null, new VariableResolverImpl(), null, Context.FULL_DUMP, flds, Collections.EMPTY_MAP);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033049/fstmerge_var2_2118725599416021934
    Transformer t = new ClobTransformer();
    Map<String, Object> row = new HashMap<String, Object>();
    Clob clob = (Clob) Proxy.newProxyInstance(this.getClass().getClassLoader(), new Class[]{Clob.class}, new InvocationHandler() {
      public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        if (method.getName().equals("getCharacterStream")) {
          return new StringReader("hello!");
        }
        return null;
      }
    });

    row.put("dsc", clob);
    t.transformRow(row, ctx);
    assertEquals("hello!", row.get("dsc"));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestClobTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033065/fstmerge_var1_5239693588990441324
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033065/fstmerge_base_7878107928610842829
@Test
  public void commaSeparated() {
    List<Map<String, String>> fields = new ArrayList<Map<String, String>>();
    // <field column="col1" sourceColName="a" splitBy="," />
    fields.add(getField("col1", "string", null, "a", ","));
    Context context = AbstractDataImportHandlerTest.getContext(null, null, null, Context.FULL_DUMP, fields, null);

    Map<String, Object> src = new HashMap<String, Object>();
    src.put("a", "a,bb,cc,d");

    Map<String, Object> result = new RegexTransformer().transformRow(src, context);
    Assert.assertEquals(2, result.size());
    Assert.assertEquals(4, ((List) result.get("col1")).size());
  }
=======
@Test
  public void commaSeparated() {
    List<Map<String, String>> fields = new ArrayList<Map<String, String>>();
    // <field column="col1" sourceColName="a" splitBy="," />
    fields.add(getField("col1", "string", null, "a", ","));
    Context context = AbstractDataImportHandlerTestCase.getContext(null, null, null, Context.FULL_DUMP, fields, null);

    Map<String, Object> src = new HashMap<String, Object>();
    src.put("a", "a,bb,cc,d");

    Map<String, Object> result = new RegexTransformer().transformRow(src, context);
    Assert.assertEquals(2, result.size());
    Assert.assertEquals(4, ((List) result.get("col1")).size());
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033065/fstmerge_var2_1959180141457397736

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestRegexTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033071/fstmerge_var1_3439789928131920405
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033071/fstmerge_base_2656364285472208007
@Test
  public void groupNames() {
    List<Map<String, String>> fields = new ArrayList<Map<String, String>>();
    // <field column="col1" regex="(\w*)(\w*) (\w*)" groupNames=",firstName,lastName"/>
    Map<String ,String > m = new HashMap<String, String>();
    m.put(COLUMN,"fullName");
    m.put(GROUP_NAMES,",firstName,lastName");
    m.put(REGEX,"(\\w*) (\\w*) (\\w*)");
    fields.add(m);
    Context context = AbstractDataImportHandlerTest.getContext(null, null, null, Context.FULL_DUMP, fields, null);
    Map<String, Object> src = new HashMap<String, Object>();
    src.put("fullName", "Mr Noble Paul");

    Map<String, Object> result = new RegexTransformer().transformRow(src, context);
    Assert.assertEquals("Noble", result.get("firstName"));
    Assert.assertEquals("Paul", result.get("lastName"));
    src= new HashMap<String, Object>();
    List<String> l= new ArrayList();
    l.add("Mr Noble Paul") ;
    l.add("Mr Shalin Mangar") ;
    src.put("fullName", l);
    result = new RegexTransformer().transformRow(src, context);
    List l1 = (List) result.get("firstName");
    List l2 = (List) result.get("lastName");
    Assert.assertEquals("Noble", l1.get(0));
    Assert.assertEquals("Shalin", l1.get(1));
    Assert.assertEquals("Paul", l2.get(0));
    Assert.assertEquals("Mangar", l2.get(1));
  }
=======
@Test
  public void groupNames() {
    List<Map<String, String>> fields = new ArrayList<Map<String, String>>();
    // <field column="col1" regex="(\w*)(\w*) (\w*)" groupNames=",firstName,lastName"/>
    Map<String ,String > m = new HashMap<String, String>();
    m.put(COLUMN,"fullName");
    m.put(GROUP_NAMES,",firstName,lastName");
    m.put(REGEX,"(\\w*) (\\w*) (\\w*)");
    fields.add(m);
    Context context = AbstractDataImportHandlerTestCase.getContext(null, null, null, Context.FULL_DUMP, fields, null);
    Map<String, Object> src = new HashMap<String, Object>();
    src.put("fullName", "Mr Noble Paul");

    Map<String, Object> result = new RegexTransformer().transformRow(src, context);
    Assert.assertEquals("Noble", result.get("firstName"));
    Assert.assertEquals("Paul", result.get("lastName"));
    src= new HashMap<String, Object>();
    List<String> l= new ArrayList();
    l.add("Mr Noble Paul") ;
    l.add("Mr Shalin Mangar") ;
    src.put("fullName", l);
    result = new RegexTransformer().transformRow(src, context);
    List l1 = (List) result.get("firstName");
    List l2 = (List) result.get("lastName");
    Assert.assertEquals("Noble", l1.get(0));
    Assert.assertEquals("Shalin", l1.get(1));
    Assert.assertEquals("Paul", l2.get(0));
    Assert.assertEquals("Mangar", l2.get(1));
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033071/fstmerge_var2_6279973079586898971

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestRegexTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033076/fstmerge_var1_4994755423686230541
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033076/fstmerge_base_2229951088875308030
@Test
  public void replaceWith() {
    List<Map<String, String>> fields = new ArrayList<Map<String, String>>();
    // <field column="name" regexp="'" replaceWith="''" />
    Map<String, String> fld = getField("name", "string", "'", null, null);
    fld.put(REPLACE_WITH, "''");
    fields.add(fld);
    Context context = AbstractDataImportHandlerTest.getContext(null, null,
            null, Context.FULL_DUMP, fields, null);

    Map<String, Object> src = new HashMap<String, Object>();
    String s = "D'souza";
    src.put("name", s);

    Map<String, Object> result = new RegexTransformer().transformRow(src,
            context);
    Assert.assertEquals("D''souza", result.get("name"));
  }
=======
@Test
  public void replaceWith() {
    List<Map<String, String>> fields = new ArrayList<Map<String, String>>();
    // <field column="name" regexp="'" replaceWith="''" />
    Map<String, String> fld = getField("name", "string", "'", null, null);
    fld.put(REPLACE_WITH, "''");
    fields.add(fld);
    Context context = AbstractDataImportHandlerTestCase.getContext(null, null,
            null, Context.FULL_DUMP, fields, null);

    Map<String, Object> src = new HashMap<String, Object>();
    String s = "D'souza";
    src.put("name", s);

    Map<String, Object> result = new RegexTransformer().transformRow(src,
            context);
    Assert.assertEquals("D''souza", result.get("name"));
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033076/fstmerge_var2_2910676063600380225

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestRegexTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033082/fstmerge_var1_5345663392428043713
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033082/fstmerge_base_5433504184585675245
@Test
  public void mileage() {
    // init a whole pile of fields
    List<Map<String, String>> fields = getFields();

    // add another regex which reuses result from previous regex again!
    // <field column="hltCityMPG" sourceColName="rowdata" regexp="(${e.city_mileage})" />
    Map<String, String> fld = getField("hltCityMPG", "string",
            ".*(${e.city_mileage})", "rowdata", null);
    fld.put(REPLACE_WITH, "*** $1 ***");
    fields.add(fld);

    //  **ATTEMPTS** a match WITHOUT a replaceWith
    // <field column="t1" sourceColName="rowdata" regexp="duff" />
    fld = getField("t1", "string","duff", "rowdata", null);
    fields.add(fld);

    //  **ATTEMPTS** a match WITH a replaceWith
    // <field column="t2" sourceColName="rowdata" regexp="duff" replaceWith="60"/>
    fld = getField("t2", "string","duff", "rowdata", null);
    fld.put(REPLACE_WITH, "60");
    fields.add(fld);

    //  regex WITH both replaceWith and groupName (groupName ignored!)
    // <field column="t3" sourceColName="rowdata" regexp="(Range)" />
    fld = getField("t3", "string","(Range)", "rowdata", null);
    fld.put(REPLACE_WITH, "range");
    fld.put(GROUP_NAMES,"t4,t5");
    fields.add(fld);

    Map<String, Object> row = new HashMap<String, Object>();
    String s = "Fuel Economy Range: 26 mpg Hwy, 19 mpg City";
    row.put("rowdata", s);

    VariableResolverImpl resolver = new VariableResolverImpl();
    resolver.addNamespace("e", row);
    Map<String, String> eAttrs = AbstractDataImportHandlerTest.createMap("name", "e");
    Context context = AbstractDataImportHandlerTest.getContext(null, resolver, null, Context.FULL_DUMP, fields, eAttrs);

    Map<String, Object> result = new RegexTransformer().transformRow(row, context);
    Assert.assertEquals(5, result.size());
    Assert.assertEquals(s, result.get("rowdata"));
    Assert.assertEquals("26", result.get("highway_mileage"));
    Assert.assertEquals("19", result.get("city_mileage"));
    Assert.assertEquals("*** 19 *** mpg City", result.get("hltCityMPG"));
    Assert.assertEquals("Fuel Economy range: 26 mpg Hwy, 19 mpg City", result.get("t3"));
  }
=======
@Test
  public void mileage() {
    // init a whole pile of fields
    List<Map<String, String>> fields = getFields();

    // add another regex which reuses result from previous regex again!
    // <field column="hltCityMPG" sourceColName="rowdata" regexp="(${e.city_mileage})" />
    Map<String, String> fld = getField("hltCityMPG", "string",
            ".*(${e.city_mileage})", "rowdata", null);
    fld.put(REPLACE_WITH, "*** $1 ***");
    fields.add(fld);

    //  **ATTEMPTS** a match WITHOUT a replaceWith
    // <field column="t1" sourceColName="rowdata" regexp="duff" />
    fld = getField("t1", "string","duff", "rowdata", null);
    fields.add(fld);

    //  **ATTEMPTS** a match WITH a replaceWith
    // <field column="t2" sourceColName="rowdata" regexp="duff" replaceWith="60"/>
    fld = getField("t2", "string","duff", "rowdata", null);
    fld.put(REPLACE_WITH, "60");
    fields.add(fld);

    //  regex WITH both replaceWith and groupName (groupName ignored!)
    // <field column="t3" sourceColName="rowdata" regexp="(Range)" />
    fld = getField("t3", "string","(Range)", "rowdata", null);
    fld.put(REPLACE_WITH, "range");
    fld.put(GROUP_NAMES,"t4,t5");
    fields.add(fld);

    Map<String, Object> row = new HashMap<String, Object>();
    String s = "Fuel Economy Range: 26 mpg Hwy, 19 mpg City";
    row.put("rowdata", s);

    VariableResolverImpl resolver = new VariableResolverImpl();
    resolver.addNamespace("e", row);
    Map<String, String> eAttrs = AbstractDataImportHandlerTestCase.createMap("name", "e");
    Context context = AbstractDataImportHandlerTestCase.getContext(null, resolver, null, Context.FULL_DUMP, fields, eAttrs);

    Map<String, Object> result = new RegexTransformer().transformRow(row, context);
    Assert.assertEquals(5, result.size());
    Assert.assertEquals(s, result.get("rowdata"));
    Assert.assertEquals("26", result.get("highway_mileage"));
    Assert.assertEquals("19", result.get("city_mileage"));
    Assert.assertEquals("*** 19 *** mpg City", result.get("hltCityMPG"));
    Assert.assertEquals("Fuel Economy range: 26 mpg Hwy, 19 mpg City", result.get("t3"));
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033082/fstmerge_var2_4829404818564148190

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestRegexTransformer.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033116/fstmerge_var1_7765932456178735023
@Override
  @Before
  public void setUp() throws Exception {
    super.setUp();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033116/fstmerge_base_4958032520102349627
=======
@Override
  public void setUp() throws Exception {
    super.setUp();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033116/fstmerge_var2_8198880594176894822

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/AbstractDataImportHandlerTestCase.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033122/fstmerge_var1_6424392605509169351
@Override
  @After
  public void tearDown() throws Exception {
    // remove dataimport.properties
    File f = new File("solr/conf/dataimport.properties");
    log.info("Looking for dataimport.properties at: " + f.getAbsolutePath());
    if (f.exists()) {
      log.info("Deleting dataimport.properties");
      if (!f.delete())
        log.warn("Could not delete dataimport.properties");
    }
    super.tearDown();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033122/fstmerge_base_1064132800205382746
=======
@Override
  public void tearDown() throws Exception {
    // remove dataimport.properties
    File f = new File("solr/conf/dataimport.properties");
    log.info("Looking for dataimport.properties at: " + f.getAbsolutePath());
    if (f.exists()) {
      log.info("Deleting dataimport.properties");
      if (!f.delete())
        log.warn("Could not delete dataimport.properties");
    }
    super.tearDown();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033122/fstmerge_var2_4611706669284462174

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/AbstractDataImportHandlerTestCase.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void multiTransformer() {
    List<Map<String, String>> fields = new ArrayList<Map<String, String>>();
    Map<String, String> entity = new HashMap<String, String>();
    entity.put("transformer", T1.class.getName() + "," + T2.class.getName()
            + "," + T3.class.getName());
    fields.add(getField("A", null, null, null, null));
    fields.add(getField("B", null, null, null, null));

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033653/fstmerge_var1_1449598446985444105
    Context context = getContext(null, null, new MockDataSource(), Context.FULL_DUMP,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033653/fstmerge_base_5415710630859353807
    Context context = AbstractDataImportHandlerTest.getContext(null, null, new MockDataSource(), Context.FULL_DUMP,
=======
    Context context = AbstractDataImportHandlerTestCase.getContext(null, null, new MockDataSource(), Context.FULL_DUMP,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033653/fstmerge_var2_4241145340220908275
            fields, entity);
    Map<String, Object> src = new HashMap<String, Object>();
    src.put("A", "NA");
    src.put("B", "NA");
    EntityProcessorWrapper sep = new EntityProcessorWrapper(new SqlEntityProcessor(), null);
    sep.init(context);
    Map<String, Object> res = sep.applyTransformer(src);
    assertNotNull(res.get("T1"));
    assertNotNull(res.get("T2"));
    assertNotNull(res.get("T3"));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestEntityProcessorBase.java
Conflict type: LineBasedMCFd
Conflict body: 
private Context getContext(String funcName, String script) {
    List<Map<String, String>> fields = new ArrayList<Map<String, String>>();
    Map<String, String> entity = new HashMap<String, String>();
    entity.put("name", "hello");
    entity.put("transformer", "script:" + funcName);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033674/fstmerge_var1_7126982973676232390
    TestContext context = getContext(null, null, null,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033674/fstmerge_base_2943834288085884113
    AbstractDataImportHandlerTest.TestContext context = AbstractDataImportHandlerTest.getContext(null, null, null,
=======
    AbstractDataImportHandlerTestCase.TestContext context = AbstractDataImportHandlerTestCase.getContext(null, null, null,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033674/fstmerge_var2_5005682402670505671
            Context.FULL_DUMP, fields, entity);
    context.script = script;
    context.scriptlang = "JavaScript";
    return context;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestScriptTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  @SuppressWarnings("unchecked")
  public void testSimple() throws IOException {
    File tmpdir = File.createTempFile("test", "tmp", TEMP_DIR);
    tmpdir.delete();
    tmpdir.mkdir();
    tmpdir.deleteOnExit();
    createFile(tmpdir, "a.xml", "a.xml".getBytes(), false);
    createFile(tmpdir, "b.xml", "b.xml".getBytes(), false);
    createFile(tmpdir, "c.props", "c.props".getBytes(), false);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033692/fstmerge_var1_7993077719903465082
    Map attrs = createMap(
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033692/fstmerge_base_8268092276311912971
    Map attrs = AbstractDataImportHandlerTest.createMap(
=======
    Map attrs = AbstractDataImportHandlerTestCase.createMap(
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033692/fstmerge_var2_1141412736827828027
            FileListEntityProcessor.FILE_NAME, "xml$",
            FileListEntityProcessor.BASE_DIR, tmpdir.getAbsolutePath());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033692/fstmerge_var1_7993077719903465082
    Context c = getContext(null,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033692/fstmerge_base_8268092276311912971
    Context c = AbstractDataImportHandlerTest.getContext(null,
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033692/fstmerge_var2_1141412736827828027
            new VariableResolverImpl(), null, Context.FULL_DUMP, Collections.EMPTY_LIST, attrs);
    FileListEntityProcessor fileListEntityProcessor = new FileListEntityProcessor();
    fileListEntityProcessor.init(c);
    List<String> fList = new ArrayList<String>();
    while (true) {
      Map<String, Object> f = fileListEntityProcessor.nextRow();
      if (f == null)
        break;
      fList.add((String) f.get(FileListEntityProcessor.ABSOLUTE_FILE));
    }
    assertEquals(2, fList.size());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestFileListEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testBiggerSmallerFiles() throws IOException {
    File tmpdir = File.createTempFile("test", "tmp", TEMP_DIR);
    tmpdir.delete();
    tmpdir.mkdir();
    tmpdir.deleteOnExit();
    long minLength = Long.MAX_VALUE;
    String smallestFile = "";
    byte[] content = "abcdefgij".getBytes("UTF-8");
    createFile(tmpdir, "a.xml", content, false);
    if (minLength > content.length) {
      minLength = content.length;
      smallestFile = "a.xml";
    }
    content = "abcdefgij".getBytes("UTF-8");
    createFile(tmpdir, "b.xml", content, false);
    if (minLength > content.length) {
      minLength = content.length;
      smallestFile = "b.xml";
    }
    content = "abc".getBytes("UTF-8");
    createFile(tmpdir, "c.props", content, false);
    if (minLength > content.length) {
      minLength = content.length;
      smallestFile = "c.props";
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033697/fstmerge_var1_113162799978216187
    Map attrs = createMap(
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033697/fstmerge_base_693225782795550840
    Map attrs = AbstractDataImportHandlerTest.createMap(
=======
    Map attrs = AbstractDataImportHandlerTestCase.createMap(
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033697/fstmerge_var2_7164015634631292689
            FileListEntityProcessor.FILE_NAME, ".*",
            FileListEntityProcessor.BASE_DIR, tmpdir.getAbsolutePath(),
            FileListEntityProcessor.BIGGER_THAN, String.valueOf(minLength));
    List<String> fList = getFiles(null, attrs);
    assertEquals(2, fList.size());
    Set<String> l = new HashSet<String>();
    l.add(new File(tmpdir, "a.xml").getAbsolutePath());
    l.add(new File(tmpdir, "b.xml").getAbsolutePath());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033697/fstmerge_var1_113162799978216187
    assertEquals(l, new HashSet<String>(fList));
    attrs = createMap(
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033697/fstmerge_base_693225782795550840
    Assert.assertEquals(l, new HashSet<String>(fList));
    attrs = AbstractDataImportHandlerTest.createMap(
=======
    Assert.assertEquals(l, new HashSet<String>(fList));
    attrs = AbstractDataImportHandlerTestCase.createMap(
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033697/fstmerge_var2_7164015634631292689
            FileListEntityProcessor.FILE_NAME, ".*",
            FileListEntityProcessor.BASE_DIR, tmpdir.getAbsolutePath(),
            FileListEntityProcessor.SMALLER_THAN, String.valueOf(minLength+1));
    fList = getFiles(null, attrs);
    l.clear();
    l.add(new File(tmpdir, smallestFile).getAbsolutePath());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033697/fstmerge_var1_113162799978216187
    assertEquals(l, new HashSet<String>(fList));
    attrs = createMap(
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033697/fstmerge_base_693225782795550840
    Assert.assertEquals(l, new HashSet<String>(fList));
    attrs = AbstractDataImportHandlerTest.createMap(
=======
    Assert.assertEquals(l, new HashSet<String>(fList));
    attrs = AbstractDataImportHandlerTestCase.createMap(
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033697/fstmerge_var2_7164015634631292689
            FileListEntityProcessor.FILE_NAME, ".*",
            FileListEntityProcessor.BASE_DIR, tmpdir.getAbsolutePath(),
            FileListEntityProcessor.SMALLER_THAN, "${a.x}");
    VariableResolverImpl resolver = new VariableResolverImpl();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033697/fstmerge_var1_113162799978216187
    resolver.addNamespace("a", createMap("x", "4"));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033697/fstmerge_base_693225782795550840
    resolver.addNamespace("a", AbstractDataImportHandlerTest.createMap("x", "4"));
=======
    resolver.addNamespace("a", AbstractDataImportHandlerTestCase.createMap("x", "4"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033697/fstmerge_var2_7164015634631292689
    fList = getFiles(resolver, attrs);
    assertEquals(l, new HashSet<String>(fList));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestFileListEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@SuppressWarnings("unchecked")
  static List<String> getFiles(VariableResolverImpl resolver, Map attrs) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033702/fstmerge_var1_4559833976893128078
    Context c = getContext(null,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033702/fstmerge_base_2038129579709528220
    Context c = AbstractDataImportHandlerTest.getContext(null,
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033702/fstmerge_var2_3276036437518743711
            resolver, null, Context.FULL_DUMP, Collections.EMPTY_LIST, attrs);
    FileListEntityProcessor fileListEntityProcessor = new FileListEntityProcessor();
    fileListEntityProcessor.init(c);
    List<String> fList = new ArrayList<String>();
    while (true) {
      Map<String, Object> f = fileListEntityProcessor.nextRow();
      if (f == null)
        break;
      fList.add((String) f.get(FileListEntityProcessor.ABSOLUTE_FILE));
    }
    return fList;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestFileListEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  @Ignore("Known Locale/TZ problems: see https://issues.apache.org/jira/browse/SOLR-1916")
  public void testNTOT() throws IOException {
    File tmpdir = File.createTempFile("test", "tmp", TEMP_DIR);
    tmpdir.delete();
    tmpdir.mkdir();
    tmpdir.deleteOnExit();
    createFile(tmpdir, "a.xml", "a.xml".getBytes(), true);
    createFile(tmpdir, "b.xml", "b.xml".getBytes(), true);
    createFile(tmpdir, "c.props", "c.props".getBytes(), true);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033707/fstmerge_var1_1450799005543394739
    Map attrs = createMap(
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033707/fstmerge_base_7825972173990357753
    Map attrs = AbstractDataImportHandlerTest.createMap(
=======
    Map attrs = AbstractDataImportHandlerTestCase.createMap(
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033707/fstmerge_var2_5144360587226305375
            FileListEntityProcessor.FILE_NAME, "xml$",
            FileListEntityProcessor.BASE_DIR, tmpdir.getAbsolutePath(),
            FileListEntityProcessor.OLDER_THAN, "'NOW'");
    List<String> fList = getFiles(null, attrs);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033707/fstmerge_var1_1450799005543394739
    assertEquals(2, fList.size());
    attrs = createMap(
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033707/fstmerge_base_7825972173990357753
    Assert.assertEquals(2, fList.size());
    attrs = AbstractDataImportHandlerTest.createMap(
=======
    Assert.assertEquals(2, fList.size());
    attrs = AbstractDataImportHandlerTestCase.createMap(
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033707/fstmerge_var2_5144360587226305375
            FileListEntityProcessor.FILE_NAME, ".xml$",
            FileListEntityProcessor.BASE_DIR, tmpdir.getAbsolutePath(),
            FileListEntityProcessor.NEWER_THAN, "'NOW-2HOURS'");
    fList = getFiles(null, attrs);
    assertEquals(2, fList.size());

    // Use a variable for newerThan
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033707/fstmerge_var1_1450799005543394739
    attrs = createMap(
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033707/fstmerge_base_7825972173990357753
    attrs = AbstractDataImportHandlerTest.createMap(
=======
    attrs = AbstractDataImportHandlerTestCase.createMap(
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033707/fstmerge_var2_5144360587226305375
            FileListEntityProcessor.FILE_NAME, ".xml$",
            FileListEntityProcessor.BASE_DIR, tmpdir.getAbsolutePath(),
            FileListEntityProcessor.NEWER_THAN, "${a.x}");
    VariableResolverImpl resolver = new VariableResolverImpl();
    String lastMod = DataImporter.DATE_TIME_FORMAT.get().format(new Date(System.currentTimeMillis() - 50000));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033707/fstmerge_var1_1450799005543394739
    resolver.addNamespace("a", createMap("x", lastMod));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033707/fstmerge_base_7825972173990357753
    resolver.addNamespace("a", AbstractDataImportHandlerTest.createMap("x", lastMod));
=======
    resolver.addNamespace("a", AbstractDataImportHandlerTestCase.createMap("x", lastMod));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033707/fstmerge_var2_5144360587226305375
    createFile(tmpdir, "t.xml", "t.xml".getBytes(), false);
    fList = getFiles(resolver, attrs);
    assertEquals(1, fList.size());
    assertEquals("File name must be t.xml", new File(tmpdir, "t.xml").getAbsolutePath(), fList.get(0));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestFileListEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testRECURSION() throws IOException {
    File tmpdir = File.createTempFile("test", "tmp", TEMP_DIR);
    tmpdir.delete();
    tmpdir.mkdir();
    tmpdir.deleteOnExit();
    File childdir = new File(tmpdir + "/child" );
    childdir.mkdirs();
    childdir.deleteOnExit();
    createFile(childdir, "a.xml", "a.xml".getBytes(), true);
    createFile(childdir, "b.xml", "b.xml".getBytes(), true);
    createFile(childdir, "c.props", "c.props".getBytes(), true);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033712/fstmerge_var1_2568482790834541275
    Map attrs = createMap(
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033712/fstmerge_base_8056343828136398385
    Map attrs = AbstractDataImportHandlerTest.createMap(
=======
    Map attrs = AbstractDataImportHandlerTestCase.createMap(
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033712/fstmerge_var2_5397074960617541790
            FileListEntityProcessor.FILE_NAME, "^.*\\.xml$",
            FileListEntityProcessor.BASE_DIR, childdir.getAbsolutePath(),
            FileListEntityProcessor.RECURSIVE, "true");
    List<String> fList = getFiles(null, attrs);
    assertEquals(2, fList.size());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestFileListEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void withoutWhereClause() {
    List fields = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033775/fstmerge_var1_1293948629499089164
    fields.add(createMap("column", "id"));
    fields.add(createMap("column", "desc"));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033775/fstmerge_base_5719937290214219860
    fields.add(AbstractDataImportHandlerTest.createMap("column", "id"));
    fields.add(AbstractDataImportHandlerTest.createMap("column", "desc"));
=======
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "id"));
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "desc"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033775/fstmerge_var2_3072230047067985753
    String q = "select * from x where id=${x.id}";
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033775/fstmerge_var1_1293948629499089164
    Map<String, String> entityAttrs = createMap("query", q);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033775/fstmerge_base_5719937290214219860
    Map<String, String> entityAttrs = AbstractDataImportHandlerTest.createMap(
            "query", q);
=======
    Map<String, String> entityAttrs = AbstractDataImportHandlerTestCase.createMap(
            "query", q);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033775/fstmerge_var2_3072230047067985753
    MockDataSource ds = new MockDataSource();
    VariableResolverImpl vr = new VariableResolverImpl();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033775/fstmerge_var1_1293948629499089164
    vr.addNamespace("x", createMap("id", 1));
    Context context = getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033775/fstmerge_base_5719937290214219860
    vr.addNamespace("x", AbstractDataImportHandlerTest.createMap("id", 1));
    Context context = AbstractDataImportHandlerTest.getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
=======
    vr.addNamespace("x", AbstractDataImportHandlerTestCase.createMap("id", 1));
    Context context = AbstractDataImportHandlerTestCase.getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033775/fstmerge_var2_3072230047067985753
    List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033775/fstmerge_var1_1293948629499089164
    rows.add(createMap("id", 1, "desc", "one"));
    rows.add(createMap("id", 1, "desc", "another one"));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033775/fstmerge_base_5719937290214219860
    rows.add(AbstractDataImportHandlerTest.createMap("id", 1, "desc", "one"));
    rows.add(AbstractDataImportHandlerTest.createMap("id", 1, "desc",
            "another one"));
=======
    rows.add(AbstractDataImportHandlerTestCase.createMap("id", 1, "desc", "one"));
    rows.add(AbstractDataImportHandlerTestCase.createMap("id", 1, "desc",
            "another one"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033775/fstmerge_var2_3072230047067985753
    MockDataSource.setIterator(vr.replaceTokens(q), rows.iterator());
    EntityProcessor csep = new EntityProcessorWrapper( new CachedSqlEntityProcessor(), null);
    csep.init(context);
    rows = new ArrayList<Map<String, Object>>();
    while (true) {
      Map<String, Object> r = csep.nextRow();
      if (r == null)
        break;
      rows.add(r);
    }
    assertEquals(2, rows.size());
    ds.close();
    csep.init(context);
    rows = new ArrayList<Map<String, Object>>();
    while (true) {
      Map<String, Object> r = csep.nextRow();
      if (r == null)
        break;
      rows.add(r);
    }
    assertEquals(2, rows.size());
    assertEquals(2, rows.get(0).size());
    assertEquals(2, rows.get(1).size());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestCachedSqlEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void withoutWhereClauseWithTransformers() {
    List fields = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033780/fstmerge_var1_5158226176282589912
    fields.add(createMap("column", "id"));
    fields.add(createMap("column", "desc"));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033780/fstmerge_base_6120712885768838101
    fields.add(AbstractDataImportHandlerTest.createMap("column", "id"));
    fields.add(AbstractDataImportHandlerTest.createMap("column", "desc"));
=======
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "id"));
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "desc"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033780/fstmerge_var2_1302974611132936362
    String q = "select * from x where id=${x.id}";
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033780/fstmerge_var1_5158226176282589912
    Map<String, String> entityAttrs = createMap(
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033780/fstmerge_base_6120712885768838101
    Map<String, String> entityAttrs = AbstractDataImportHandlerTest.createMap(
=======
    Map<String, String> entityAttrs = AbstractDataImportHandlerTestCase.createMap(
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033780/fstmerge_var2_1302974611132936362
            "query", q, "transformer", UppercaseTransformer.class.getName());
    MockDataSource ds = new MockDataSource();
    VariableResolverImpl vr = new VariableResolverImpl();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033780/fstmerge_var1_5158226176282589912
    vr.addNamespace("x", createMap("id", 1));
    Context context = getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033780/fstmerge_base_6120712885768838101
    vr.addNamespace("x", AbstractDataImportHandlerTest.createMap("id", 1));
    Context context = AbstractDataImportHandlerTest.getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
=======
    vr.addNamespace("x", AbstractDataImportHandlerTestCase.createMap("id", 1));
    Context context = AbstractDataImportHandlerTestCase.getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033780/fstmerge_var2_1302974611132936362
    List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033780/fstmerge_var1_5158226176282589912
    rows.add(createMap("id", 1, "desc", "one"));
    rows.add(createMap("id", 1, "desc", "another one"));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033780/fstmerge_base_6120712885768838101
    rows.add(AbstractDataImportHandlerTest.createMap("id", 1, "desc", "one"));
    rows.add(AbstractDataImportHandlerTest.createMap("id", 1, "desc",
            "another one"));
=======
    rows.add(AbstractDataImportHandlerTestCase.createMap("id", 1, "desc", "one"));
    rows.add(AbstractDataImportHandlerTestCase.createMap("id", 1, "desc",
            "another one"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033780/fstmerge_var2_1302974611132936362
    MockDataSource.setIterator(vr.replaceTokens(q), rows.iterator());
    EntityProcessor csep = new EntityProcessorWrapper( new CachedSqlEntityProcessor(), null);
    csep.init(context);
    rows = new ArrayList<Map<String, Object>>();
    while (true) {
      Map<String, Object> r = csep.nextRow();
      if (r == null)
        break;
      rows.add(r);
    }
    assertEquals(2, rows.size());
    ds.close();
    csep.init(context);
    rows = new ArrayList<Map<String, Object>>();
    while (true) {
      Map<String, Object> r = csep.nextRow();
      if (r == null)
        break;
      rows.add(r);
      assertEquals(r.get("desc").toString().toUpperCase(Locale.ENGLISH), r.get("desc"));
    }
    assertEquals(2, rows.size());
    assertEquals(2, rows.get(0).size());
    assertEquals(2, rows.get(1).size());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestCachedSqlEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void withoutWhereClauseWithMultiRowTransformer() {
    List fields = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033786/fstmerge_var1_5096997294986893804
    fields.add(createMap("column", "id"));
    fields.add(createMap("column", "desc"));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033786/fstmerge_base_440224832520558124
    fields.add(AbstractDataImportHandlerTest.createMap("column", "id"));
    fields.add(AbstractDataImportHandlerTest.createMap("column", "desc"));
=======
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "id"));
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "desc"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033786/fstmerge_var2_8858771812714862164
    String q = "select * from x where id=${x.id}";
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033786/fstmerge_var1_5096997294986893804
    Map<String, String> entityAttrs = createMap(
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033786/fstmerge_base_440224832520558124
    Map<String, String> entityAttrs = AbstractDataImportHandlerTest.createMap(
=======
    Map<String, String> entityAttrs = AbstractDataImportHandlerTestCase.createMap(
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033786/fstmerge_var2_8858771812714862164
            "query", q, "transformer", DoubleTransformer.class.getName());
    MockDataSource ds = new MockDataSource();
    VariableResolverImpl vr = new VariableResolverImpl();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033786/fstmerge_var1_5096997294986893804
    vr.addNamespace("x", createMap("id", 1));
    Context context = getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033786/fstmerge_base_440224832520558124
    vr.addNamespace("x", AbstractDataImportHandlerTest.createMap("id", 1));
    Context context = AbstractDataImportHandlerTest.getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
=======
    vr.addNamespace("x", AbstractDataImportHandlerTestCase.createMap("id", 1));
    Context context = AbstractDataImportHandlerTestCase.getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033786/fstmerge_var2_8858771812714862164
    List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033786/fstmerge_var1_5096997294986893804
    rows.add(createMap("id", 1, "desc", "one"));
    rows.add(createMap("id", 1, "desc", "another one"));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033786/fstmerge_base_440224832520558124
    rows.add(AbstractDataImportHandlerTest.createMap("id", 1, "desc", "one"));
    rows.add(AbstractDataImportHandlerTest.createMap("id", 1, "desc",
            "another one"));
=======
    rows.add(AbstractDataImportHandlerTestCase.createMap("id", 1, "desc", "one"));
    rows.add(AbstractDataImportHandlerTestCase.createMap("id", 1, "desc",
            "another one"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033786/fstmerge_var2_8858771812714862164
    MockDataSource.setIterator(vr.replaceTokens(q), rows.iterator());
    EntityProcessor csep = new EntityProcessorWrapper( new CachedSqlEntityProcessor(), null);
    csep.init(context);
    rows = new ArrayList<Map<String, Object>>();
    while (true) {
      Map<String, Object> r = csep.nextRow();
      if (r == null)
        break;
      rows.add(r);
    }
    assertEquals(4, rows.size());
    ds.close();
    csep.init(context);
    rows = new ArrayList<Map<String, Object>>();
    while (true) {
      Map<String, Object> r = csep.nextRow();
      if (r == null)
        break;
      rows.add(r);
    }
    assertEquals(4, rows.size());
    assertEquals(2, rows.get(0).size());
    assertEquals(2, rows.get(1).size());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestCachedSqlEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void withWhereClause() {
    List fields = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033802/fstmerge_var1_7056362437526672889
    fields.add(createMap("column", "id"));
    fields.add(createMap("column", "desc"));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033802/fstmerge_base_1842037967605269858
    fields.add(AbstractDataImportHandlerTest.createMap("column", "id"));
    fields.add(AbstractDataImportHandlerTest.createMap("column", "desc"));
=======
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "id"));
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "desc"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033802/fstmerge_var2_4387804018020093434
    String q = "select * from x";
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033802/fstmerge_var1_7056362437526672889
    Map<String, String> entityAttrs = createMap(
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033802/fstmerge_base_1842037967605269858
    Map<String, String> entityAttrs = AbstractDataImportHandlerTest.createMap(
=======
    Map<String, String> entityAttrs = AbstractDataImportHandlerTestCase.createMap(
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033802/fstmerge_var2_4387804018020093434
            "query", q, EntityProcessorBase.CACHE_KEY,"id", EntityProcessorBase.CACHE_LOOKUP ,"x.id");
    MockDataSource ds = new MockDataSource();
    VariableResolverImpl vr = new VariableResolverImpl();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033802/fstmerge_var1_7056362437526672889
    Map xNamespace = createMap("id", 0);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033802/fstmerge_base_1842037967605269858
    Map xNamespace = AbstractDataImportHandlerTest.createMap("id", 0);
=======
    Map xNamespace = AbstractDataImportHandlerTestCase.createMap("id", 0);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033802/fstmerge_var2_4387804018020093434
    vr.addNamespace("x", xNamespace);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033802/fstmerge_var1_7056362437526672889
    Context context = getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033802/fstmerge_base_1842037967605269858
    Context context = AbstractDataImportHandlerTest.getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
=======
    Context context = AbstractDataImportHandlerTestCase.getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033802/fstmerge_var2_4387804018020093434
    doWhereTest(q, context, ds, xNamespace);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestCachedSqlEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void withKeyAndLookup() {
    List fields = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033807/fstmerge_var1_6917322027727927922
    fields.add(createMap("column", "id"));
    fields.add(createMap("column", "desc"));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033807/fstmerge_base_2643913847943073369
    fields.add(AbstractDataImportHandlerTest.createMap("column", "id"));
    fields.add(AbstractDataImportHandlerTest.createMap("column", "desc"));
=======
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "id"));
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "desc"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033807/fstmerge_var2_5266280718462898558
    String q = "select * from x";
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033807/fstmerge_var1_6917322027727927922
    Map<String, String> entityAttrs = createMap("query", q, "where", "id=x.id");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033807/fstmerge_base_2643913847943073369
    Map<String, String> entityAttrs = AbstractDataImportHandlerTest.createMap("query", q, "where", "id=x.id");
=======
    Map<String, String> entityAttrs = AbstractDataImportHandlerTestCase.createMap("query", q, "where", "id=x.id");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033807/fstmerge_var2_5266280718462898558
    MockDataSource ds = new MockDataSource();
    VariableResolverImpl vr = new VariableResolverImpl();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033807/fstmerge_var1_6917322027727927922
    Map xNamespace = createMap("id", 0);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033807/fstmerge_base_2643913847943073369
    Map xNamespace = AbstractDataImportHandlerTest.createMap("id", 0);
=======
    Map xNamespace = AbstractDataImportHandlerTestCase.createMap("id", 0);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033807/fstmerge_var2_5266280718462898558
    vr.addNamespace("x", xNamespace);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033807/fstmerge_var1_6917322027727927922
    Context context = getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033807/fstmerge_base_2643913847943073369
    Context context = AbstractDataImportHandlerTest.getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
=======
    Context context = AbstractDataImportHandlerTestCase.getContext(null, vr, ds, Context.FULL_DUMP, fields, entityAttrs);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033807/fstmerge_var2_5266280718462898558
    doWhereTest(q, context, ds, xNamespace);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestCachedSqlEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
private void doWhereTest(String q, Context context, MockDataSource ds, Map xNamespace) {
    List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033812/fstmerge_var1_5761325001043535473
    rows.add(createMap("id", 1, "desc", "one"));
    rows.add(createMap("id", 2, "desc", "two"));
    rows.add(createMap("id", 2, "desc", "another two"));
    rows.add(createMap("id", 3, "desc", "three"));
    rows.add(createMap("id", 3, "desc", "another three"));
    rows.add(createMap("id", 3, "desc", "another another three"));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033812/fstmerge_base_7286931225218291417
    rows.add(AbstractDataImportHandlerTest.createMap("id", 1, "desc", "one"));
    rows.add(AbstractDataImportHandlerTest.createMap("id", 2, "desc", "two"));
    rows.add(AbstractDataImportHandlerTest.createMap("id", 2, "desc",
            "another two"));
    rows.add(AbstractDataImportHandlerTest.createMap("id", 3, "desc", "three"));
    rows.add(AbstractDataImportHandlerTest.createMap("id", 3, "desc", "another three"));
    rows.add(AbstractDataImportHandlerTest.createMap("id", 3, "desc", "another another three"));
=======
    rows.add(AbstractDataImportHandlerTestCase.createMap("id", 1, "desc", "one"));
    rows.add(AbstractDataImportHandlerTestCase.createMap("id", 2, "desc", "two"));
    rows.add(AbstractDataImportHandlerTestCase.createMap("id", 2, "desc",
            "another two"));
    rows.add(AbstractDataImportHandlerTestCase.createMap("id", 3, "desc", "three"));
    rows.add(AbstractDataImportHandlerTestCase.createMap("id", 3, "desc", "another three"));
    rows.add(AbstractDataImportHandlerTestCase.createMap("id", 3, "desc", "another another three"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628033812/fstmerge_var2_1413460319877292256
    MockDataSource.setIterator(q, rows.iterator());
    EntityProcessor csep = new EntityProcessorWrapper(new CachedSqlEntityProcessor(), null);
    csep.init(context);
    rows = new ArrayList<Map<String, Object>>();
    while (true) {
      Map<String, Object> r = csep.nextRow();
      if (r == null)
        break;
      rows.add(r);
    }
    assertEquals(0, rows.size());
    ds.close();

    csep.init(context);
    rows = new ArrayList<Map<String, Object>>();
    xNamespace.put("id", 2);
    while (true) {
      Map<String, Object> r = csep.nextRow();
      if (r == null)
        break;
      rows.add(r);
    }
    assertEquals(2, rows.size());

    csep.init(context);
    rows = new ArrayList<Map<String, Object>>();
    xNamespace.put("id", 3);
    while (true) {
      Map<String, Object> r = csep.nextRow();
      if (r == null)
        break;
      rows.add(r);
    }
    assertEquals(3, rows.size());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestCachedSqlEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  @SuppressWarnings("unchecked")
  public void testTransformRow() {
    List fields = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_var1_37049977306934071
    fields.add(createMap("column", "firstName"));
    fields.add(createMap("column", "lastName"));
    fields.add(createMap("column", "middleName"));
    fields.add(createMap("column", "name",
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_base_6291894708233224297
    fields.add(AbstractDataImportHandlerTest.createMap("column", "firstName"));
    fields.add(AbstractDataImportHandlerTest.createMap("column", "lastName"));
    fields.add(AbstractDataImportHandlerTest.createMap("column", "middleName"));
    fields.add(AbstractDataImportHandlerTest.createMap("column", "name",
=======
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "firstName"));
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "lastName"));
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "middleName"));
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "name",
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_var2_1241722011264243172
            TemplateTransformer.TEMPLATE,
            "${e.lastName}, ${e.firstName} ${e.middleName}"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_var1_37049977306934071
    fields.add(createMap("column", "emails",
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_base_6291894708233224297
    fields.add(AbstractDataImportHandlerTest.createMap("column", "emails",
=======
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "emails",
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_var2_1241722011264243172
            TemplateTransformer.TEMPLATE,
            "${e.mail}"));

    // test reuse of template output in another template 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_var1_37049977306934071
    fields.add(createMap("column", "mrname",
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_base_6291894708233224297
    fields.add(AbstractDataImportHandlerTest.createMap("column", "mrname",
=======
    fields.add(AbstractDataImportHandlerTestCase.createMap("column", "mrname",
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_var2_1241722011264243172
            TemplateTransformer.TEMPLATE,"Mr ${e.name}"));

    List<String> mails = Arrays.asList(new String[]{"a@b.com", "c@d.com"});
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_var1_37049977306934071
    Map row = createMap(
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_base_6291894708233224297
    Map row = AbstractDataImportHandlerTest.createMap(
=======
    Map row = AbstractDataImportHandlerTestCase.createMap(
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_var2_1241722011264243172
            "firstName", "Shalin",
            "middleName", "Shekhar", 
            "lastName", "Mangar",
            "mail", mails);

    VariableResolverImpl resolver = new VariableResolverImpl();
    resolver.addNamespace("e", row);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_var1_37049977306934071
    Map<String, String> entityAttrs = createMap("name", "e");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_base_6291894708233224297
    Map<String, String> entityAttrs = AbstractDataImportHandlerTest.createMap(
            "name", "e");
=======
    Map<String, String> entityAttrs = AbstractDataImportHandlerTestCase.createMap(
            "name", "e");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_var2_1241722011264243172

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_var1_37049977306934071
    Context context = getContext(null, resolver,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_base_6291894708233224297
    Context context = AbstractDataImportHandlerTest.getContext(null, resolver,
=======
    Context context = AbstractDataImportHandlerTestCase.getContext(null, resolver,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034060/fstmerge_var2_1241722011264243172
            null, Context.FULL_DUMP, fields, entityAttrs);
    new TemplateTransformer().transformRow(row, context);
    assertEquals("Mangar, Shalin Shekhar", row.get("name"));
    assertEquals("Mr Mangar, Shalin Shekhar", row.get("mrname"));
    assertEquals(mails,row.get("emails"));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestTemplateTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  @SuppressWarnings("unchecked")
  public void testTransformRow_SingleNumber() {
    char GERMAN_GROUPING_SEP = new DecimalFormatSymbols(Locale.GERMANY).getGroupingSeparator();
    List l = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034065/fstmerge_var1_6331650812466356078
    l.add(createMap("column", "num",
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034065/fstmerge_base_71434098809052564
    l.add(AbstractDataImportHandlerTest.createMap("column", "num",
=======
    l.add(AbstractDataImportHandlerTestCase.createMap("column", "num",
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034065/fstmerge_var2_1343508507983178813
            NumberFormatTransformer.FORMAT_STYLE, NumberFormatTransformer.NUMBER));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034065/fstmerge_var1_6331650812466356078
    l.add(createMap("column", "localizedNum",
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034065/fstmerge_base_71434098809052564
    l.add(AbstractDataImportHandlerTest.createMap("column", "localizedNum",
=======
    l.add(AbstractDataImportHandlerTestCase.createMap("column", "localizedNum",
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034065/fstmerge_var2_1343508507983178813
            NumberFormatTransformer.FORMAT_STYLE, NumberFormatTransformer.NUMBER, NumberFormatTransformer.LOCALE, "de-DE"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034065/fstmerge_var1_6331650812466356078
    Context c = getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = createMap("num", "123" + GROUPING_SEP + "567", "localizedNum", "123" + GERMAN_GROUPING_SEP + "567");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034065/fstmerge_base_71434098809052564
    Context c = AbstractDataImportHandlerTest.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTest.createMap("num", "123" + GROUPING_SEP + "567", "localizedNum", "123" + GERMAN_GROUPING_SEP + "567");
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTestCase.createMap("num", "123" + GROUPING_SEP + "567", "localizedNum", "123" + GERMAN_GROUPING_SEP + "567");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034065/fstmerge_var2_1343508507983178813
    new NumberFormatTransformer().transformRow(m, c);
    assertEquals(new Long(123567), m.get("num"));
    assertEquals(new Long(123567), m.get("localizedNum"));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestNumberFormatTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  @SuppressWarnings("unchecked")
  public void testTransformRow_MultipleNumbers() throws Exception {
    List fields = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034070/fstmerge_var1_5014768380584520693
    fields.add(createMap(DataImporter.COLUMN, "inputs"));
    fields.add(createMap(DataImporter.COLUMN,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034070/fstmerge_base_6039705161443259297
    fields.add(AbstractDataImportHandlerTest.createMap(DataImporter.COLUMN,
            "inputs"));
    fields.add(AbstractDataImportHandlerTest.createMap(DataImporter.COLUMN,
=======
    fields.add(AbstractDataImportHandlerTestCase.createMap(DataImporter.COLUMN,
            "inputs"));
    fields.add(AbstractDataImportHandlerTestCase.createMap(DataImporter.COLUMN,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034070/fstmerge_var2_3109646201661910519
            "outputs", RegexTransformer.SRC_COL_NAME, "inputs",
            NumberFormatTransformer.FORMAT_STYLE, NumberFormatTransformer.NUMBER));

    List inputs = new ArrayList();
    inputs.add("123" + GROUPING_SEP + "567");
    inputs.add("245" + GROUPING_SEP + "678");
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034070/fstmerge_var1_5014768380584520693
    Map row = createMap("inputs", inputs);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034070/fstmerge_base_6039705161443259297
    Map row = AbstractDataImportHandlerTest.createMap("inputs", inputs);
=======
    Map row = AbstractDataImportHandlerTestCase.createMap("inputs", inputs);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034070/fstmerge_var2_3109646201661910519

    VariableResolverImpl resolver = new VariableResolverImpl();
    resolver.addNamespace("e", row);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034070/fstmerge_var1_5014768380584520693
    Context context = getContext(null, resolver, null, Context.FULL_DUMP, fields, null);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034070/fstmerge_base_6039705161443259297
    Context context = AbstractDataImportHandlerTest.getContext(null, resolver, null, Context.FULL_DUMP, fields, null);
=======
    Context context = AbstractDataImportHandlerTestCase.getContext(null, resolver, null, Context.FULL_DUMP, fields, null);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034070/fstmerge_var2_3109646201661910519
    new NumberFormatTransformer().transformRow(row, context);

    List output = new ArrayList();
    output.add(new Long(123567));
    output.add(new Long(245678));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034070/fstmerge_var1_5014768380584520693
    Map outputRow = createMap("inputs", inputs, "outputs", output);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034070/fstmerge_base_6039705161443259297
    Map outputRow = AbstractDataImportHandlerTest.createMap("inputs", inputs,
            "outputs", output);
=======
    Map outputRow = AbstractDataImportHandlerTestCase.createMap("inputs", inputs,
            "outputs", output);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034070/fstmerge_var2_3109646201661910519

    assertEquals(outputRow, row);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestNumberFormatTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test(expected = DataImportHandlerException.class)
  @SuppressWarnings("unchecked")
  public void testTransformRow_InvalidInput1_Number() {
    List l = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034075/fstmerge_var1_8555291292399151075
    l.add(createMap("column", "num",
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034075/fstmerge_base_1459221289997845889
    l.add(AbstractDataImportHandlerTest.createMap("column", "num",
=======
    l.add(AbstractDataImportHandlerTestCase.createMap("column", "num",
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034075/fstmerge_var2_7904416269975093740
            NumberFormatTransformer.FORMAT_STYLE, NumberFormatTransformer.NUMBER));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034075/fstmerge_var1_8555291292399151075
    Context c = getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = createMap("num", "123" + GROUPING_SEP + "5a67");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034075/fstmerge_base_1459221289997845889
    Context c = AbstractDataImportHandlerTest.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTest.createMap("num", "123" + GROUPING_SEP + "5a67");
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTestCase.createMap("num", "123" + GROUPING_SEP + "5a67");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034075/fstmerge_var2_7904416269975093740
    new NumberFormatTransformer().transformRow(m, c);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestNumberFormatTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test(expected = DataImportHandlerException.class)
  @SuppressWarnings("unchecked")
  public void testTransformRow_InvalidInput2_Number() {
    List l = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034080/fstmerge_var1_8945855103081401462
    l.add(createMap("column", "num",
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034080/fstmerge_base_3108627524084075380
    l.add(AbstractDataImportHandlerTest.createMap("column", "num",
=======
    l.add(AbstractDataImportHandlerTestCase.createMap("column", "num",
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034080/fstmerge_var2_8817797552004010273
            NumberFormatTransformer.FORMAT_STYLE, NumberFormatTransformer.NUMBER));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034080/fstmerge_var1_8945855103081401462
    Context c = getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = createMap("num", "123" + GROUPING_SEP + "567b");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034080/fstmerge_base_3108627524084075380
    Context c = AbstractDataImportHandlerTest.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTest.createMap("num", "123" + GROUPING_SEP + "567b");
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTestCase.createMap("num", "123" + GROUPING_SEP + "567b");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034080/fstmerge_var2_8817797552004010273
    new NumberFormatTransformer().transformRow(m, c);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestNumberFormatTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test(expected = DataImportHandlerException.class)
  @SuppressWarnings("unchecked")
  public void testTransformRow_InvalidInput2_Currency() {
    List l = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034085/fstmerge_var1_323081336458695910
    l.add(createMap("column", "num",
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034085/fstmerge_base_6240044912260800493
    l.add(AbstractDataImportHandlerTest.createMap("column", "num",
=======
    l.add(AbstractDataImportHandlerTestCase.createMap("column", "num",
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034085/fstmerge_var2_269411284784877330
            NumberFormatTransformer.FORMAT_STYLE, NumberFormatTransformer.CURRENCY));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034085/fstmerge_var1_323081336458695910
    Context c = getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = createMap("num", "123" + GROUPING_SEP + "567b");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034085/fstmerge_base_6240044912260800493
    Context c = AbstractDataImportHandlerTest.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTest.createMap("num", "123" + GROUPING_SEP + "567b");
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTestCase.createMap("num", "123" + GROUPING_SEP + "567b");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034085/fstmerge_var2_269411284784877330
    new NumberFormatTransformer().transformRow(m, c);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestNumberFormatTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test(expected = DataImportHandlerException.class)
  @SuppressWarnings("unchecked")
  public void testTransformRow_InvalidInput1_Percent() {
    List l = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034090/fstmerge_var1_3400067784256520536
    l.add(createMap("column", "num",
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034090/fstmerge_base_6122444206071696087
    l.add(AbstractDataImportHandlerTest.createMap("column", "num",
=======
    l.add(AbstractDataImportHandlerTestCase.createMap("column", "num",
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034090/fstmerge_var2_4385992058108702328
            NumberFormatTransformer.FORMAT_STYLE, NumberFormatTransformer.PERCENT));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034090/fstmerge_var1_3400067784256520536
    Context c = getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = createMap("num", "123" + GROUPING_SEP + "5a67");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034090/fstmerge_base_6122444206071696087
    Context c = AbstractDataImportHandlerTest.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTest.createMap("num", "123" + GROUPING_SEP + "5a67");
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTestCase.createMap("num", "123" + GROUPING_SEP + "5a67");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034090/fstmerge_var2_4385992058108702328
    new NumberFormatTransformer().transformRow(m, c);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestNumberFormatTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test(expected = DataImportHandlerException.class)
  @SuppressWarnings("unchecked")
  public void testTransformRow_InvalidInput3_Currency() {
    List l = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034095/fstmerge_var1_7199418009851460768
    l.add(createMap("column", "num",
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034095/fstmerge_base_8098557875253653446
    l.add(AbstractDataImportHandlerTest.createMap("column", "num",
=======
    l.add(AbstractDataImportHandlerTestCase.createMap("column", "num",
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034095/fstmerge_var2_3061616495444018783
            NumberFormatTransformer.FORMAT_STYLE, NumberFormatTransformer.CURRENCY));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034095/fstmerge_var1_7199418009851460768
    Context c = getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = createMap("num", "123" + DECIMAL_SEP + "456" + DECIMAL_SEP + "789");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034095/fstmerge_base_8098557875253653446
    Context c = AbstractDataImportHandlerTest.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTest.createMap(
            "num", "123" + DECIMAL_SEP + "456" + DECIMAL_SEP + "789");
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTestCase.createMap(
            "num", "123" + DECIMAL_SEP + "456" + DECIMAL_SEP + "789");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034095/fstmerge_var2_3061616495444018783
    new NumberFormatTransformer().transformRow(m, c);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestNumberFormatTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test(expected = DataImportHandlerException.class)
  @SuppressWarnings("unchecked")
  public void testTransformRow_InvalidInput3_Number() {
    List l = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034100/fstmerge_var1_3677379841870644055
    l.add(createMap("column", "num",
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034100/fstmerge_base_8607415737629464398
    l.add(AbstractDataImportHandlerTest.createMap("column", "num",
=======
    l.add(AbstractDataImportHandlerTestCase.createMap("column", "num",
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034100/fstmerge_var2_6510238588834792425
            NumberFormatTransformer.FORMAT_STYLE, NumberFormatTransformer.NUMBER));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034100/fstmerge_var1_3677379841870644055
    Context c = getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = createMap("num", "123" + DECIMAL_SEP + "456" + DECIMAL_SEP + "789");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034100/fstmerge_base_8607415737629464398
    Context c = AbstractDataImportHandlerTest.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTest.createMap(
            "num", "123" + DECIMAL_SEP + "456" + DECIMAL_SEP + "789");
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTestCase.createMap(
            "num", "123" + DECIMAL_SEP + "456" + DECIMAL_SEP + "789");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034100/fstmerge_var2_6510238588834792425
    new NumberFormatTransformer().transformRow(m, c);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestNumberFormatTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  @SuppressWarnings("unchecked")
  public void testTransformRow_MalformedInput_Number() {
    List l = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034105/fstmerge_var1_6082185960253142902
    l.add(createMap("column", "num",
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034105/fstmerge_base_8907072710858584118
    l.add(AbstractDataImportHandlerTest.createMap("column", "num",
=======
    l.add(AbstractDataImportHandlerTestCase.createMap("column", "num",
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034105/fstmerge_var2_8181422882552868707
            NumberFormatTransformer.FORMAT_STYLE, NumberFormatTransformer.NUMBER));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034105/fstmerge_var1_6082185960253142902
    Context c = getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = createMap("num", "123" + GROUPING_SEP + GROUPING_SEP + "789");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034105/fstmerge_base_8907072710858584118
    Context c = AbstractDataImportHandlerTest.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTest.createMap(
            "num", "123" + GROUPING_SEP + GROUPING_SEP + "789");
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null, null, null, Context.FULL_DUMP, l, null);
    Map m = AbstractDataImportHandlerTestCase.createMap(
            "num", "123" + GROUPING_SEP + GROUPING_SEP + "789");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034105/fstmerge_var2_8181422882552868707
    new NumberFormatTransformer().transformRow(m, c);
    assertEquals(new Long(123789), m.get("num"));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestNumberFormatTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  @SuppressWarnings("unchecked")
  public void testTransformRow_SingleRow() throws Exception {
    List fields = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034129/fstmerge_var1_4418593767970682556
    fields.add(createMap(DataImporter.COLUMN, "lastModified"));
    fields.add(createMap(DataImporter.COLUMN,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034129/fstmerge_base_5311614632515886769
    fields.add(AbstractDataImportHandlerTest.createMap(DataImporter.COLUMN,
            "lastModified"));
    fields.add(AbstractDataImportHandlerTest.createMap(DataImporter.COLUMN,
=======
    fields.add(AbstractDataImportHandlerTestCase.createMap(DataImporter.COLUMN,
            "lastModified"));
    fields.add(AbstractDataImportHandlerTestCase.createMap(DataImporter.COLUMN,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034129/fstmerge_var2_4707166939201068133
            "dateAdded", RegexTransformer.SRC_COL_NAME, "lastModified",
            DateFormatTransformer.DATE_TIME_FMT, "MM/dd/yyyy"));

    SimpleDateFormat format = new SimpleDateFormat("MM/dd/yyyy");
    Date now = format.parse(format.format(new Date()));

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034129/fstmerge_var1_4418593767970682556
    Map row = createMap("lastModified", format.format(now));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034129/fstmerge_base_5311614632515886769
    Map row = AbstractDataImportHandlerTest.createMap("lastModified", format
            .format(now));
=======
    Map row = AbstractDataImportHandlerTestCase.createMap("lastModified", format
            .format(now));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034129/fstmerge_var2_4707166939201068133

    VariableResolverImpl resolver = new VariableResolverImpl();
    resolver.addNamespace("e", row);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034129/fstmerge_var1_4418593767970682556
    Context context = getContext(null, resolver,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034129/fstmerge_base_5311614632515886769
    Context context = AbstractDataImportHandlerTest.getContext(null, resolver,
=======
    Context context = AbstractDataImportHandlerTestCase.getContext(null, resolver,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034129/fstmerge_var2_4707166939201068133
            null, Context.FULL_DUMP, fields, null);
    new DateFormatTransformer().transformRow(row, context);
    assertEquals(now, row.get("dateAdded"));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestDateFormatTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  @SuppressWarnings("unchecked")
  public void testTransformRow_MultipleRows() throws Exception {
    List fields = new ArrayList();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034135/fstmerge_var1_5009051767734881477
    fields.add(createMap(DataImporter.COLUMN, "lastModified"));
    fields.add(createMap(DataImporter.COLUMN,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034135/fstmerge_base_5583058761362486782
    fields.add(AbstractDataImportHandlerTest.createMap(DataImporter.COLUMN,
            "lastModified"));
    fields.add(AbstractDataImportHandlerTest.createMap(DataImporter.COLUMN,
=======
    fields.add(AbstractDataImportHandlerTestCase.createMap(DataImporter.COLUMN,
            "lastModified"));
    fields.add(AbstractDataImportHandlerTestCase.createMap(DataImporter.COLUMN,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034135/fstmerge_var2_4711408701586142600
            "dateAdded", RegexTransformer.SRC_COL_NAME, "lastModified",
            DateFormatTransformer.DATE_TIME_FMT, "MM/dd/yyyy hh:mm:ss.SSS"));

    SimpleDateFormat format = new SimpleDateFormat("MM/dd/yyyy hh:mm:ss.SSS");
    Date now1 = format.parse(format.format(new Date()));
    Date now2 = format.parse(format.format(new Date()));

    Map row = new HashMap();
    List list = new ArrayList();
    list.add(format.format(now1));
    list.add(format.format(now2));
    row.put("lastModified", list);

    VariableResolverImpl resolver = new VariableResolverImpl();
    resolver.addNamespace("e", row);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034135/fstmerge_var1_5009051767734881477
    Context context = getContext(null, resolver,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034135/fstmerge_base_5583058761362486782
    Context context = AbstractDataImportHandlerTest.getContext(null, resolver,
=======
    Context context = AbstractDataImportHandlerTestCase.getContext(null, resolver,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034135/fstmerge_var2_4711408701586142600
            null, Context.FULL_DUMP, fields, null);
    new DateFormatTransformer().transformRow(row, context);
    List output = new ArrayList();
    output.add(now1);
    output.add(now2);
    assertEquals(output, row.get("dateAdded"));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestDateFormatTransformer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034140/fstmerge_var1_2970003959553915136
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034140/fstmerge_base_8702532950082027422
@Test
  /************************************************************************/
  public void simple() throws IOException {

    /* we want to create the equiv of :-
     *  <entity name="list_all_files" 
     *           processor="LineEntityProcessor"
     *           fileName="dummy.lis"
     *           />
     */

    Map attrs = AbstractDataImportHandlerTest.createMap(
            LineEntityProcessor.URL, "dummy.lis",
            LineEntityProcessor.ACCEPT_LINE_REGEX, null,
            LineEntityProcessor.SKIP_LINE_REGEX, null
    );

    Context c = AbstractDataImportHandlerTest.getContext(
            null,                          //parentEntity
            new VariableResolverImpl(),  //resolver
            getDataSource(filecontents),   //parentDataSource
            Context.FULL_DUMP,                             //currProcess
            Collections.EMPTY_LIST,        //entityFields
            attrs                          //entityAttrs
    );
    LineEntityProcessor ep = new LineEntityProcessor();
    ep.init(c);

    /// call the entity processor to the list of lines
    System.out.print("\n");
    List<String> fList = new ArrayList<String>();
    while (true) {
      Map<String, Object> f = ep.nextRow();
      if (f == null) break;
      fList.add((String) f.get("rawLine"));
      System.out.print("     rawLine='" + f.get("rawLine") + "'\n");
    }
    Assert.assertEquals(24, fList.size());
  }
=======
@Test
  /************************************************************************/
  public void simple() throws IOException {

    /* we want to create the equiv of :-
     *  <entity name="list_all_files" 
     *           processor="LineEntityProcessor"
     *           fileName="dummy.lis"
     *           />
     */

    Map attrs = AbstractDataImportHandlerTestCase.createMap(
            LineEntityProcessor.URL, "dummy.lis",
            LineEntityProcessor.ACCEPT_LINE_REGEX, null,
            LineEntityProcessor.SKIP_LINE_REGEX, null
    );

    Context c = AbstractDataImportHandlerTestCase.getContext(
            null,                          //parentEntity
            new VariableResolverImpl(),  //resolver
            getDataSource(filecontents),   //parentDataSource
            Context.FULL_DUMP,                             //currProcess
            Collections.EMPTY_LIST,        //entityFields
            attrs                          //entityAttrs
    );
    LineEntityProcessor ep = new LineEntityProcessor();
    ep.init(c);

    /// call the entity processor to the list of lines
    System.out.print("\n");
    List<String> fList = new ArrayList<String>();
    while (true) {
      Map<String, Object> f = ep.nextRow();
      if (f == null) break;
      fList.add((String) f.get("rawLine"));
      System.out.print("     rawLine='" + f.get("rawLine") + "'\n");
    }
    Assert.assertEquals(24, fList.size());
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034140/fstmerge_var2_8048881275443501763

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestLineEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034145/fstmerge_var1_1941697115958460574
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034145/fstmerge_base_2364429762165705433
@Test
  /************************************************************************/
  public void only_xml_files() throws IOException {

    /* we want to create the equiv of :-
     *  <entity name="list_all_files" 
     *           processor="LineEntityProcessor"
     *           fileName="dummy.lis"
     *           acceptLineRegex="xml"
     *           />
     */
    Map attrs = AbstractDataImportHandlerTest.createMap(
            LineEntityProcessor.URL, "dummy.lis",
            LineEntityProcessor.ACCEPT_LINE_REGEX, "xml",
            LineEntityProcessor.SKIP_LINE_REGEX, null
    );

    Context c = AbstractDataImportHandlerTest.getContext(
            null,                          //parentEntity
            new VariableResolverImpl(),  //resolver
            getDataSource(filecontents),   //parentDataSource
            Context.FULL_DUMP,                             //currProcess
            Collections.EMPTY_LIST,        //entityFields
            attrs                          //entityAttrs
    );
    LineEntityProcessor ep = new LineEntityProcessor();
    ep.init(c);

    /// call the entity processor to the list of lines
    List<String> fList = new ArrayList<String>();
    while (true) {
      Map<String, Object> f = ep.nextRow();
      if (f == null) break;
      fList.add((String) f.get("rawLine"));
    }
    Assert.assertEquals(5, fList.size());
  }
=======
@Test
  /************************************************************************/
  public void only_xml_files() throws IOException {

    /* we want to create the equiv of :-
     *  <entity name="list_all_files" 
     *           processor="LineEntityProcessor"
     *           fileName="dummy.lis"
     *           acceptLineRegex="xml"
     *           />
     */
    Map attrs = AbstractDataImportHandlerTestCase.createMap(
            LineEntityProcessor.URL, "dummy.lis",
            LineEntityProcessor.ACCEPT_LINE_REGEX, "xml",
            LineEntityProcessor.SKIP_LINE_REGEX, null
    );

    Context c = AbstractDataImportHandlerTestCase.getContext(
            null,                          //parentEntity
            new VariableResolverImpl(),  //resolver
            getDataSource(filecontents),   //parentDataSource
            Context.FULL_DUMP,                             //currProcess
            Collections.EMPTY_LIST,        //entityFields
            attrs                          //entityAttrs
    );
    LineEntityProcessor ep = new LineEntityProcessor();
    ep.init(c);

    /// call the entity processor to the list of lines
    List<String> fList = new ArrayList<String>();
    while (true) {
      Map<String, Object> f = ep.nextRow();
      if (f == null) break;
      fList.add((String) f.get("rawLine"));
    }
    Assert.assertEquals(5, fList.size());
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034145/fstmerge_var2_2639175427730919312

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestLineEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034150/fstmerge_var1_875404638993261090
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034150/fstmerge_base_6445576681670672082
@Test
  /************************************************************************/
  public void only_xml_files_no_xsd() throws IOException {
    /* we want to create the equiv of :-
     *  <entity name="list_all_files" 
     *           processor="LineEntityProcessor"
     *           fileName="dummy.lis"
     *           acceptLineRegex="\\.xml"
     *           omitLineRegex="\\.xsd"
     *           />
     */
    Map attrs = AbstractDataImportHandlerTest.createMap(
            LineEntityProcessor.URL, "dummy.lis",
            LineEntityProcessor.ACCEPT_LINE_REGEX, "\\.xml",
            LineEntityProcessor.SKIP_LINE_REGEX, "\\.xsd"
    );

    Context c = AbstractDataImportHandlerTest.getContext(
            null,                          //parentEntity
            new VariableResolverImpl(),  //resolver
            getDataSource(filecontents),   //parentDataSource
            Context.FULL_DUMP,                             //currProcess
            Collections.EMPTY_LIST,        //entityFields
            attrs                          //entityAttrs
    );
    LineEntityProcessor ep = new LineEntityProcessor();
    ep.init(c);

    /// call the entity processor to walk the directory
    List<String> fList = new ArrayList<String>();
    while (true) {
      Map<String, Object> f = ep.nextRow();
      if (f == null) break;
      fList.add((String) f.get("rawLine"));
    }
    Assert.assertEquals(4, fList.size());
  }
=======
@Test
  /************************************************************************/
  public void only_xml_files_no_xsd() throws IOException {
    /* we want to create the equiv of :-
     *  <entity name="list_all_files" 
     *           processor="LineEntityProcessor"
     *           fileName="dummy.lis"
     *           acceptLineRegex="\\.xml"
     *           omitLineRegex="\\.xsd"
     *           />
     */
    Map attrs = AbstractDataImportHandlerTestCase.createMap(
            LineEntityProcessor.URL, "dummy.lis",
            LineEntityProcessor.ACCEPT_LINE_REGEX, "\\.xml",
            LineEntityProcessor.SKIP_LINE_REGEX, "\\.xsd"
    );

    Context c = AbstractDataImportHandlerTestCase.getContext(
            null,                          //parentEntity
            new VariableResolverImpl(),  //resolver
            getDataSource(filecontents),   //parentDataSource
            Context.FULL_DUMP,                             //currProcess
            Collections.EMPTY_LIST,        //entityFields
            attrs                          //entityAttrs
    );
    LineEntityProcessor ep = new LineEntityProcessor();
    ep.init(c);

    /// call the entity processor to walk the directory
    List<String> fList = new ArrayList<String>();
    while (true) {
      Map<String, Object> f = ep.nextRow();
      if (f == null) break;
      fList.add((String) f.get("rawLine"));
    }
    Assert.assertEquals(4, fList.size());
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034150/fstmerge_var2_8520541366319266347

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestLineEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034154/fstmerge_var1_8998838250928848926
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034154/fstmerge_base_3002191444372443959
@Test
  /************************************************************************/
  public void no_xsd_files() throws IOException {
    /* we want to create the equiv of :-
     *  <entity name="list_all_files" 
     *           processor="LineEntityProcessor"
     *           fileName="dummy.lis"
     *           omitLineRegex="\\.xsd"
     *           />
     */
    Map attrs = AbstractDataImportHandlerTest.createMap(
            LineEntityProcessor.URL, "dummy.lis",
            LineEntityProcessor.SKIP_LINE_REGEX, "\\.xsd"
    );

    Context c = AbstractDataImportHandlerTest.getContext(
            null,                          //parentEntity
            new VariableResolverImpl(),  //resolver
            getDataSource(filecontents),   //parentDataSource
            Context.FULL_DUMP,                             //currProcess
            Collections.EMPTY_LIST,        //entityFields
            attrs                          //entityAttrs
    );
    LineEntityProcessor ep = new LineEntityProcessor();
    ep.init(c);

    /// call the entity processor to walk the directory
    List<String> fList = new ArrayList<String>();
    while (true) {
      Map<String, Object> f = ep.nextRow();
      if (f == null) break;
      fList.add((String) f.get("rawLine"));
    }
    Assert.assertEquals(18, fList.size());
  }
=======
@Test
  /************************************************************************/
  public void no_xsd_files() throws IOException {
    /* we want to create the equiv of :-
     *  <entity name="list_all_files" 
     *           processor="LineEntityProcessor"
     *           fileName="dummy.lis"
     *           omitLineRegex="\\.xsd"
     *           />
     */
    Map attrs = AbstractDataImportHandlerTestCase.createMap(
            LineEntityProcessor.URL, "dummy.lis",
            LineEntityProcessor.SKIP_LINE_REGEX, "\\.xsd"
    );

    Context c = AbstractDataImportHandlerTestCase.getContext(
            null,                          //parentEntity
            new VariableResolverImpl(),  //resolver
            getDataSource(filecontents),   //parentDataSource
            Context.FULL_DUMP,                             //currProcess
            Collections.EMPTY_LIST,        //entityFields
            attrs                          //entityAttrs
    );
    LineEntityProcessor ep = new LineEntityProcessor();
    ep.init(c);

    /// call the entity processor to walk the directory
    List<String> fList = new ArrayList<String>();
    while (true) {
      Map<String, Object> f = ep.nextRow();
      if (f == null) break;
      fList.add((String) f.get("rawLine"));
    }
    Assert.assertEquals(18, fList.size());
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034154/fstmerge_var2_8629294763934387878

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestLineEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void withFieldsAndXpath() throws Exception {
    File tmpdir = File.createTempFile("test", "tmp", TEMP_DIR);
    tmpdir.delete();
    tmpdir.mkdir();
    tmpdir.deleteOnExit();
    createFile(tmpdir, "x.xsl", xsl.getBytes(), false);
    Map entityAttrs = createMap("name", "e", "url", "cd.xml",
            XPathEntityProcessor.FOR_EACH, "/catalog/cd");
    List fields = new ArrayList();
    fields.add(createMap("column", "title", "xpath", "/catalog/cd/title"));
    fields.add(createMap("column", "artist", "xpath", "/catalog/cd/artist"));
    fields.add(createMap("column", "year", "xpath", "/catalog/cd/year"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034171/fstmerge_var1_5838462622968295995
    Context c = getContext(null,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034171/fstmerge_base_391250138920262513
    Context c = AbstractDataImportHandlerTest.getContext(null,
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034171/fstmerge_var2_4356933703547860160
            new VariableResolverImpl(), getDataSource(cdData), Context.FULL_DUMP, fields, entityAttrs);
    XPathEntityProcessor xPathEntityProcessor = new XPathEntityProcessor();
    xPathEntityProcessor.init(c);
    List<Map<String, Object>> result = new ArrayList<Map<String, Object>>();
    while (true) {
      Map<String, Object> row = xPathEntityProcessor.nextRow();
      if (row == null)
        break;
      result.add(row);
    }
    assertEquals(3, result.size());
    assertEquals("Empire Burlesque", result.get(0).get("title"));
    assertEquals("Bonnie Tyler", result.get(1).get("artist"));
    assertEquals("1982", result.get(2).get("year"));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestXPathEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testMultiValued() throws Exception  {
    Map entityAttrs = createMap("name", "e", "url", "testdata.xml",
            XPathEntityProcessor.FOR_EACH, "/root");
    List fields = new ArrayList();
    fields.add(createMap("column", "a", "xpath", "/root/a", DataImporter.MULTI_VALUED, "true"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034176/fstmerge_var1_435519476136643867
    Context c = getContext(null,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034176/fstmerge_base_3868157370565540795
    Context c = AbstractDataImportHandlerTest.getContext(null,
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034176/fstmerge_var2_537077630942167426
            new VariableResolverImpl(), getDataSource(testXml), Context.FULL_DUMP, fields, entityAttrs);
    XPathEntityProcessor xPathEntityProcessor = new XPathEntityProcessor();
    xPathEntityProcessor.init(c);
    List<Map<String, Object>> result = new ArrayList<Map<String, Object>>();
    while (true) {
      Map<String, Object> row = xPathEntityProcessor.nextRow();
      if (row == null)
        break;
      result.add(row);
    }
    assertEquals(2, ((List)result.get(0).get("a")).size());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestXPathEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testMultiValuedFlatten() throws Exception  {
    Map entityAttrs = createMap("name", "e", "url", "testdata.xml",
            XPathEntityProcessor.FOR_EACH, "/root");
    List fields = new ArrayList();
    fields.add(createMap("column", "a", "xpath", "/root/a" ,"flatten","true"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034182/fstmerge_var1_4692329541885660541
    Context c = getContext(null,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034182/fstmerge_base_139522708113075477
    Context c = AbstractDataImportHandlerTest.getContext(null,
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034182/fstmerge_var2_5852921210782601377
            new VariableResolverImpl(), getDataSource(testXmlFlatten), Context.FULL_DUMP, fields, entityAttrs);
    XPathEntityProcessor xPathEntityProcessor = new XPathEntityProcessor();
    xPathEntityProcessor.init(c);
    Map<String, Object> result = null;
    while (true) {
      Map<String, Object> row = xPathEntityProcessor.nextRow();
      if (row == null)
        break;
      result = row;
    }
    assertEquals("1B2", result.get("a"));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestXPathEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void withFieldsAndXpathStream() throws Exception {
    final Object monitor = new Object();
    final boolean[] done = new boolean[1];
    
    Map entityAttrs = createMap("name", "e", "url", "cd.xml",
        XPathEntityProcessor.FOR_EACH, "/catalog/cd", "stream", "true", "batchSize","1");
    List fields = new ArrayList();
    fields.add(createMap("column", "title", "xpath", "/catalog/cd/title"));
    fields.add(createMap("column", "artist", "xpath", "/catalog/cd/artist"));
    fields.add(createMap("column", "year", "xpath", "/catalog/cd/year"));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034187/fstmerge_var1_8138956795186533796
    Context c = getContext(null,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034187/fstmerge_base_896701341355288409
    Context c = AbstractDataImportHandlerTest.getContext(null,
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034187/fstmerge_var2_721607725189586369
        new VariableResolverImpl(), getDataSource(cdData), Context.FULL_DUMP, fields, entityAttrs);
    XPathEntityProcessor xPathEntityProcessor = new XPathEntityProcessor() {
      private int count;
      
      @Override
      protected Map<String, Object> readRow(Map<String, Object> record,
          String xpath) {
        synchronized (monitor) {
          if (simulateSlowReader && !done[0]) {
            try {
              monitor.wait(100);
            } catch (InterruptedException e) {
              throw new RuntimeException(e);
            }
          }
        }
        
        return super.readRow(record, xpath);
      }
    };
    
    if (simulateSlowResultProcessor) {
      xPathEntityProcessor.blockingQueueSize = 1;
    }
    xPathEntityProcessor.blockingQueueTimeOut = 1;
    xPathEntityProcessor.blockingQueueTimeOutUnits = TimeUnit.MICROSECONDS;
    
    xPathEntityProcessor.init(c);
    List<Map<String, Object>> result = new ArrayList<Map<String, Object>>();
    while (true) {
      if (rowsToRead >= 0 && result.size() >= rowsToRead) {
        Thread.currentThread().interrupt();
      }
      Map<String, Object> row = xPathEntityProcessor.nextRow();
      if (row == null)
        break;
      result.add(row);
      if (simulateSlowResultProcessor) {
        synchronized (xPathEntityProcessor.publisherThread) {
          if (xPathEntityProcessor.publisherThread.isAlive()) {
            xPathEntityProcessor.publisherThread.wait(1000);
          }
        }
      }
    }
    
    synchronized (monitor) {
      done[0] = true;
      monitor.notify();
    }
    
    // confirm that publisher thread stops.
    xPathEntityProcessor.publisherThread.join(1000);
    assertEquals("Expected thread to stop", false, xPathEntityProcessor.publisherThread.isAlive());
    
    assertEquals(rowsToRead < 0 ? 3 : rowsToRead, result.size());
    
    if (rowsToRead < 0) {
      assertEquals("Empire Burlesque", result.get(0).get("title"));
      assertEquals("Bonnie Tyler", result.get(1).get("artist"));
      assertEquals("1982", result.get(2).get("year"));
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestXPathEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void withDefaultSolrAndXsl() throws Exception {
    File tmpdir = File.createTempFile("test", "tmp", TEMP_DIR);
    tmpdir.delete();
    tmpdir.mkdir();
    tmpdir.deleteOnExit();
    TestFileListEntityProcessor.createFile(tmpdir, "x.xsl", xsl.getBytes(),
            false);
    Map entityAttrs = createMap("name", "e",
            XPathEntityProcessor.USE_SOLR_ADD_SCHEMA, "true", "xsl", ""
            + new File(tmpdir, "x.xsl").getAbsolutePath(), "url", "cd.xml");
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034208/fstmerge_var1_1211559175719584217
    Context c = getContext(null,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034208/fstmerge_base_3815916869213584618
    Context c = AbstractDataImportHandlerTest.getContext(null,
=======
    Context c = AbstractDataImportHandlerTestCase.getContext(null,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034208/fstmerge_var2_7650231353293894730
            new VariableResolverImpl(), getDataSource(cdData), Context.FULL_DUMP, null, entityAttrs);
    XPathEntityProcessor xPathEntityProcessor = new XPathEntityProcessor();
    xPathEntityProcessor.init(c);
    List<Map<String, Object>> result = new ArrayList<Map<String, Object>>();
    while (true) {
      Map<String, Object> row = xPathEntityProcessor.nextRow();
      if (row == null)
        break;
      result.add(row);
    }
    assertEquals(3, result.size());
    assertEquals("Empire Burlesque", result.get(0).get("title"));
    assertEquals("Bonnie Tyler", result.get(1).get("artist"));
    assertEquals("1982", result.get(2).get("year"));
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestXPathEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034217/fstmerge_var1_1964188630064982456
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034217/fstmerge_base_8707619544048830980
@Test
  public void singleBatch() {
    SqlEntityProcessor sep = new SqlEntityProcessor();
    List<Map<String, Object>> rows = getRows(3);
    VariableResolverImpl vr = new VariableResolverImpl();
    HashMap<String, String> ea = new HashMap<String, String>();
    ea.put("query", "SELECT * FROM A");
    Context c = AbstractDataImportHandlerTest.getContext(null, vr, getDs(rows),
            Context.FULL_DUMP, null, ea);
    sep.init(c);
    int count = 0;
    while (true) {
      Map<String, Object> r = sep.nextRow();
      if (r == null)
        break;
      count++;
    }

    Assert.assertEquals(3, count);
  }
=======
@Test
  public void singleBatch() {
    SqlEntityProcessor sep = new SqlEntityProcessor();
    List<Map<String, Object>> rows = getRows(3);
    VariableResolverImpl vr = new VariableResolverImpl();
    HashMap<String, String> ea = new HashMap<String, String>();
    ea.put("query", "SELECT * FROM A");
    Context c = AbstractDataImportHandlerTestCase.getContext(null, vr, getDs(rows),
            Context.FULL_DUMP, null, ea);
    sep.init(c);
    int count = 0;
    while (true) {
      Map<String, Object> r = sep.nextRow();
      if (r == null)
        break;
      count++;
    }

    Assert.assertEquals(3, count);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034217/fstmerge_var2_3167378112142661999

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestSqlEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034223/fstmerge_var1_3071256906156170173
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034223/fstmerge_base_1769570893261003907
@Test
  public void tranformer() {
    EntityProcessor sep = new EntityProcessorWrapper( new SqlEntityProcessor(), null);
    List<Map<String, Object>> rows = getRows(2);
    VariableResolverImpl vr = new VariableResolverImpl();
    HashMap<String, String> ea = new HashMap<String, String>();
    ea.put("query", "SELECT * FROM A");
    ea.put("transformer", T.class.getName());

    sep.init(AbstractDataImportHandlerTest.getContext(null, vr, getDs(rows),
            Context.FULL_DUMP, null, ea));
    List<Map<String, Object>> rs = new ArrayList<Map<String, Object>>();
    Map<String, Object> r = null;
    while (true) {
      r = sep.nextRow();
      if (r == null)
        break;
      rs.add(r);

    }
    Assert.assertEquals(2, rs.size());
    Assert.assertNotNull(rs.get(0).get("T"));
  }
=======
@Test
  public void tranformer() {
    EntityProcessor sep = new EntityProcessorWrapper( new SqlEntityProcessor(), null);
    List<Map<String, Object>> rows = getRows(2);
    VariableResolverImpl vr = new VariableResolverImpl();
    HashMap<String, String> ea = new HashMap<String, String>();
    ea.put("query", "SELECT * FROM A");
    ea.put("transformer", T.class.getName());

    sep.init(AbstractDataImportHandlerTestCase.getContext(null, vr, getDs(rows),
            Context.FULL_DUMP, null, ea));
    List<Map<String, Object>> rs = new ArrayList<Map<String, Object>>();
    Map<String, Object> r = null;
    while (true) {
      r = sep.nextRow();
      if (r == null)
        break;
      rs.add(r);

    }
    Assert.assertEquals(2, rs.size());
    Assert.assertNotNull(rs.get(0).get("T"));
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034223/fstmerge_var2_8927877550444424891

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestSqlEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034228/fstmerge_var1_6647713536948692847
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034228/fstmerge_base_8470276391445288332
@Test
  public void tranformerWithReflection() {
    EntityProcessor sep = new EntityProcessorWrapper(new SqlEntityProcessor(), null);
    List<Map<String, Object>> rows = getRows(2);
    VariableResolverImpl vr = new VariableResolverImpl();
    HashMap<String, String> ea = new HashMap<String, String>();
    ea.put("query", "SELECT * FROM A");
    ea.put("transformer", T3.class.getName());

    sep.init(AbstractDataImportHandlerTest.getContext(null, vr, getDs(rows),
            Context.FULL_DUMP, null, ea));
    List<Map<String, Object>> rs = new ArrayList<Map<String, Object>>();
    Map<String, Object> r = null;
    while (true) {
      r = sep.nextRow();
      if (r == null)
        break;
      rs.add(r);

    }
    Assert.assertEquals(2, rs.size());
    Assert.assertNotNull(rs.get(0).get("T3"));
  }
=======
@Test
  public void tranformerWithReflection() {
    EntityProcessor sep = new EntityProcessorWrapper(new SqlEntityProcessor(), null);
    List<Map<String, Object>> rows = getRows(2);
    VariableResolverImpl vr = new VariableResolverImpl();
    HashMap<String, String> ea = new HashMap<String, String>();
    ea.put("query", "SELECT * FROM A");
    ea.put("transformer", T3.class.getName());

    sep.init(AbstractDataImportHandlerTestCase.getContext(null, vr, getDs(rows),
            Context.FULL_DUMP, null, ea));
    List<Map<String, Object>> rs = new ArrayList<Map<String, Object>>();
    Map<String, Object> r = null;
    while (true) {
      r = sep.nextRow();
      if (r == null)
        break;
      rs.add(r);

    }
    Assert.assertEquals(2, rs.size());
    Assert.assertNotNull(rs.get(0).get("T3"));
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034228/fstmerge_var2_2005582439301937381

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestSqlEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034232/fstmerge_var1_9201351415433085362
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034232/fstmerge_base_8115483412001535058
@Test
  public void tranformerList() {
    EntityProcessor sep = new EntityProcessorWrapper(new SqlEntityProcessor(),null);
    List<Map<String, Object>> rows = getRows(2);
    VariableResolverImpl vr = new VariableResolverImpl();

    HashMap<String, String> ea = new HashMap<String, String>();
    ea.put("query", "SELECT * FROM A");
    ea.put("transformer", T2.class.getName());
    sep.init(AbstractDataImportHandlerTest.getContext(null, vr, getDs(rows),
            Context.FULL_DUMP, null, ea));

    local.set(0);
    Map<String, Object> r = null;
    int count = 0;
    while (true) {
      r = sep.nextRow();
      if (r == null)
        break;
      count++;
    }
    Assert.assertEquals(2, (int) local.get());
    Assert.assertEquals(4, count);
  }
=======
@Test
  public void tranformerList() {
    EntityProcessor sep = new EntityProcessorWrapper(new SqlEntityProcessor(),null);
    List<Map<String, Object>> rows = getRows(2);
    VariableResolverImpl vr = new VariableResolverImpl();

    HashMap<String, String> ea = new HashMap<String, String>();
    ea.put("query", "SELECT * FROM A");
    ea.put("transformer", T2.class.getName());
    sep.init(AbstractDataImportHandlerTestCase.getContext(null, vr, getDs(rows),
            Context.FULL_DUMP, null, ea));

    local.set(0);
    Map<String, Object> r = null;
    int count = 0;
    while (true) {
      r = sep.nextRow();
      if (r == null)
        break;
      count++;
    }
    Assert.assertEquals(2, (int) local.get());
    Assert.assertEquals(4, count);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628034232/fstmerge_var2_5550122093729355965

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestSqlEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628037176/fstmerge_var1_6177368933851529280
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628037176/fstmerge_base_2461132972919354671
public void testWickedLongTerm() throws IOException {
    RAMDirectory dir = new RAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
      TEST_VERSION_CURRENT, new StandardAnalyzer(TEST_VERSION_CURRENT)));

    char[] chars = new char[IndexWriter.MAX_TERM_LENGTH];
    Arrays.fill(chars, 'x');
    Document doc = new Document();
    final String bigTerm = new String(chars);

    // This produces a too-long term:
    String contents = "abc xyz x" + bigTerm + " another term";
    doc.add(new Field("content", contents, Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);

    // Make sure we can add another normal document
    doc = new Document();
    doc.add(new Field("content", "abc bbb ccc", Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
    writer.close();

    IndexReader reader = IndexReader.open(dir, true);

    // Make sure all terms < max size were indexed
    assertEquals(2, reader.docFreq(new Term("content", "abc")));
    assertEquals(1, reader.docFreq(new Term("content", "bbb")));
    assertEquals(1, reader.docFreq(new Term("content", "term")));
    assertEquals(1, reader.docFreq(new Term("content", "another")));

    // Make sure position is still incremented when
    // massive term is skipped:
    TermPositions tps = reader.termPositions(new Term("content", "another"));
    assertTrue(tps.next());
    assertEquals(1, tps.freq());
    assertEquals(3, tps.nextPosition());

    // Make sure the doc that has the massive term is in
    // the index:
    assertEquals("document with wicked long term should is not in the index!", 2, reader.numDocs());

    reader.close();

    // Make sure we can add a document with exactly the
    // maximum length term, and search on that term:
    doc = new Document();
    doc.add(new Field("content", bigTerm, Field.Store.NO, Field.Index.ANALYZED));
    StandardAnalyzer sa = new StandardAnalyzer(TEST_VERSION_CURRENT);
    sa.setMaxTokenLength(100000);
    writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, sa));
    writer.addDocument(doc);
    writer.close();
    reader = IndexReader.open(dir, true);
    assertEquals(1, reader.docFreq(new Term("content", bigTerm)));
    reader.close();

    dir.close();
  }
=======
public void testWickedLongTerm() throws IOException {
    RAMDirectory dir = new RAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
      TEST_VERSION_CURRENT, new StandardAnalyzer(TEST_VERSION_CURRENT)));

    char[] chars = new char[IndexWriter.MAX_TERM_LENGTH];
    Arrays.fill(chars, 'x');
    Document doc = new Document();
    final String bigTerm = new String(chars);

    // This produces a too-long term:
    String contents = "abc xyz x" + bigTerm + " another term";
    doc.add(new Field("content", contents, Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);

    // Make sure we can add another normal document
    doc = new Document();
    doc.add(new Field("content", "abc bbb ccc", Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
    writer.close();

    IndexReader reader = IndexReader.open(dir, true);

    // Make sure all terms < max size were indexed
    assertEquals(2, reader.docFreq(new Term("content", "abc")));
    assertEquals(1, reader.docFreq(new Term("content", "bbb")));
    assertEquals(1, reader.docFreq(new Term("content", "term")));
    assertEquals(1, reader.docFreq(new Term("content", "another")));

    // Make sure position is still incremented when
    // massive term is skipped:
    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(reader,
                                                                MultiFields.getDeletedDocs(reader),
                                                                "content",
                                                                new BytesRef("another"));
    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);
    assertEquals(1, tps.freq());
    assertEquals(3, tps.nextPosition());

    // Make sure the doc that has the massive term is in
    // the index:
    assertEquals("document with wicked long term should is not in the index!", 2, reader.numDocs());

    reader.close();

    // Make sure we can add a document with exactly the
    // maximum length term, and search on that term:
    doc = new Document();
    doc.add(new Field("content", bigTerm, Field.Store.NO, Field.Index.ANALYZED));
    StandardAnalyzer sa = new StandardAnalyzer(TEST_VERSION_CURRENT);
    sa.setMaxTokenLength(100000);
    writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, sa));
    writer.addDocument(doc);
    writer.close();
    reader = IndexReader.open(dir, true);
    assertEquals(1, reader.docFreq(new Term("content", bigTerm)));
    reader.close();

    dir.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628037176/fstmerge_var2_9200473717026908584

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStandardAnalyzer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628038665/fstmerge_var1_9146644024176939530
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628038665/fstmerge_base_9042303412627882213
public void testStem()
    {
        for (int i = 0; i < words.size(); i++)
        {
            //if ( (i % 100) == 0 ) System.err.println(i);
            String realStem =
                RussianStemmer.stemWord(
                    words.get(i));
            assertEquals("unicode", stems.get(i), realStem);
        }
    }
=======
public void testStem() throws IOException {
    Analyzer a = new ReusableAnalyzerBase() {
      @Override
      protected TokenStreamComponents createComponents(String fieldName,
          Reader reader) {
        Tokenizer t = new KeywordTokenizer(reader);
        return new TokenStreamComponents(t, new RussianStemFilter(t));
      }
    };
    InputStream voc = getClass().getResourceAsStream("wordsUTF8.txt");
    InputStream out = getClass().getResourceAsStream("stemsUTF8.txt");
    assertVocabulary(a, voc, out);
    voc.close();
    out.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628038665/fstmerge_var2_1262986393142640111

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianStem.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628039177/fstmerge_var1_1292102948759457459
@SuppressWarnings("fallthrough")
  private int removePlural(char s[], int len) {
    if (len > 3 && s[len-1] == 'k')
      switch(s[len-2]) {
        case 'a':
        case 'o':
        case 'e': if (len > 4) return len - 2; /* intentional fallthru */
        default: return len - 1;
      }
    return len;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628039177/fstmerge_base_1126617766495298855
=======
private int removePlural(char s[], int len) {
    if (len > 3 && s[len-1] == 'k')
      switch(s[len-2]) {
        case 'a':
        case 'o':
        case 'e': if (len > 4) return len - 2; /* intentional fallthru */
        default: return len - 1;
      }
    return len;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628039177/fstmerge_var2_321360463217033102

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/modules/analysis/common/src/java/org/apache/lucene/analysis/hu/HungarianLightStemmer.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628044759/fstmerge_var1_1507931550797018576
@SuppressWarnings("fallthrough")
  public int stem(char s[], int len) {
    if (len < 3 || s[len-1] != 's')
      return len;
    
    switch(s[len-2]) {
      case 'u':
      case 's': return len;
      case 'e':
        if (len > 3 && s[len-3] == 'i' && s[len-4] != 'a' && s[len-4] != 'e') {
          s[len - 3] = 'y';
          return len - 2;
        }
        if (s[len-3] == 'i' || s[len-3] == 'a' || s[len-3] == 'o' || s[len-3] == 'e')
          return len; /* intentional fallthrough */
      default: return len - 1;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628044759/fstmerge_base_1400270652559872456
=======
public int stem(char s[], int len) {
    if (len < 3 || s[len-1] != 's')
      return len;
    
    switch(s[len-2]) {
      case 'u':
      case 's': return len;
      case 'e':
        if (len > 3 && s[len-3] == 'i' && s[len-4] != 'a' && s[len-4] != 'e') {
          s[len - 3] = 'y';
          return len - 2;
        }
        if (s[len-3] == 'i' || s[len-3] == 'a' || s[len-3] == 'o' || s[len-3] == 'e')
          return len;
      default: return len - 1;
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419628044759/fstmerge_var2_6494928445399968541

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ede7_249fd/rev_2ede7-249fd/modules/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishMinimalStemmer.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_24b7f_d968a/rev_24b7f-d968a.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_bb494_f78ba/rev_bb494-f78ba.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_9a0a3_8d888/rev_9a0a3-8d888.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630587080/fstmerge_var1_427989448962647892
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630587080/fstmerge_base_4670422888531378848
private void write(final FieldInfos fieldInfos, final Directory dir, final FieldData[] fields) throws Throwable {

    final int termIndexInterval = this.nextInt(13, 27);
    final SegmentCodecs codecInfo = SegmentCodecs.build(fieldInfos, CodecProvider.getDefault());
    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, 10000, termIndexInterval, codecInfo);

    final FieldsConsumer consumer = state.segmentCodecs.codec().fieldsConsumer(state);
    Arrays.sort(fields);
    for (final FieldData field : fields) {
      field.write(consumer);
    }
    consumer.close();
  }
=======
private void write(final FieldInfos fieldInfos, final Directory dir, final FieldData[] fields) throws Throwable {

    final int termIndexInterval = this.nextInt(13, 27);
    final SegmentCodecs codecInfo = SegmentCodecs.build(fieldInfos, CodecProvider.getDefault());
    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, 10000, termIndexInterval, codecInfo, new AtomicLong());
    final FieldsConsumer consumer = state.segmentCodecs.codec().fieldsConsumer(state);
    Arrays.sort(fields);
    for (final FieldData field : fields) {
      field.write(consumer);
    }
    consumer.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630587080/fstmerge_var2_3773495601367697601

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_9a0a3_8d888/rev_9a0a3-8d888/lucene/src/test/org/apache/lucene/index/TestCodecs.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630608001/fstmerge_var1_2696934403423176941
public SegmentWriteState(PrintStream infoStream, Directory directory, String segmentName, FieldInfos fieldInfos,
                           int numDocs, int termIndexInterval, SegmentCodecs segmentCodecs) {
    this.infoStream = infoStream;
    this.directory = directory;
    this.segmentName = segmentName;
    this.fieldInfos = fieldInfos;
    this.numDocs = numDocs;
    this.termIndexInterval = termIndexInterval;
    this.segmentCodecs = segmentCodecs;
    codecId = "";
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630608001/fstmerge_base_8440650041185013273
public SegmentWriteState(PrintStream infoStream, Directory directory, String segmentName, FieldInfos fieldInfos,
                           int numDocs, int termIndexInterval, SegmentCodecs segmentCodecs) {
    this.infoStream = infoStream;
    this.directory = directory;
    this.segmentName = segmentName;
    this.fieldInfos = fieldInfos;
    this.numDocs = numDocs;
    this.termIndexInterval = termIndexInterval;
    this.segmentCodecs = segmentCodecs;
    flushedFiles = new HashSet<String>();
    codecId = "";
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630608001/fstmerge_var2_2242178192739591348

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_9a0a3_8d888/rev_9a0a3-8d888/lucene/src/java/org/apache/lucene/index/SegmentWriteState.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630608703/fstmerge_var1_538966389919575516
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630608703/fstmerge_base_2052718500552315359
final Collection<String> getMergedFiles(final SegmentInfo info) throws IOException {
    Set<String> fileSet = new HashSet<String>();

    // Basic files
    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {
      fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
    }

    segmentWriteState.segmentCodecs.files(directory, info, fileSet);
    
    // Fieldable norm files
    int numFIs = fieldInfos.size();
    for (int i = 0; i < numFIs; i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed && !fi.omitNorms) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", IndexFileNames.NORMS_EXTENSION));
        break;
      }
    }

    // Vector files
    if (fieldInfos.hasVectors()) {
      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
      }
    }

    return fileSet;
  }
=======
final Collection<String> getMergedFiles(final SegmentInfo info) throws IOException {
    Set<String> fileSet = new HashSet<String>();

    // Basic files
    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {
      fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
    }
    segmentWriteState.segmentCodecs.files(directory, info, fileSet);
    
    // Fieldable norm files
    final int numFIs = fieldInfos.size();
    for (int i = 0; i < numFIs; i++) {
      final FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed && !fi.omitNorms) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", IndexFileNames.NORMS_EXTENSION));
        break;
      }
    }

    // Vector files
    if (fieldInfos.hasVectors()) {
      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
      }
    }

    return fileSet;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630608703/fstmerge_var2_8801216957031181805

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_9a0a3_8d888/rev_9a0a3-8d888/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630612877/fstmerge_var1_4281770018192451712
  public TermsConsumer addField(FieldInfo field) throws IOException {
    assert currentField == null || currentField.name.compareTo(field.name) < 0;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630612877/fstmerge_base_2177213725273481242
  public TermsConsumer addField(FieldInfo field) {
    assert currentField == null || currentField.name.compareTo(field.name) < 0;
=======
  public TermsConsumer addField(FieldInfo field) {
    assert currentField == null || currentField.name.compareTo(field.name) < 0 : "current field name " + (currentField == null? null: currentField.name) + " given: " +field.name;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630612877/fstmerge_var2_5003210963253492786
    currentField = field;
    TermsIndexWriterBase.FieldWriter fieldIndexWriter = termsIndexWriter.addField(field);
    TermsConsumer terms = new TermsWriter(fieldIndexWriter, field, postingsWriter);
    fields.add(terms);
    return terms;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_9a0a3_8d888/rev_9a0a3-8d888/lucene/src/java/org/apache/lucene/index/codecs/PrefixCodedTermsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630630888/fstmerge_var1_4791434176877423833
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630630888/fstmerge_base_6741570647347659085
@Override
  public void setParams(String sortField) {
    super.setParams(sortField);
    String[] fields = sortField.split(",");
    SortField[] sortFields = new SortField[fields.length];
    int upto = 0;
    for (int i = 0; i < fields.length; i++) {
      String field = fields[i];
      SortField sortField0;
      if (field.equals("doc")) {
        sortField0 = SortField.FIELD_DOC;
      } if (field.equals("score")) {
        sortField0 = SortField.FIELD_SCORE;
      } else if (field.equals("noscore")) {
        doScore = false;
        continue;
      } else if (field.equals("nomaxscore")) {
        doMaxScore = false;
        continue;
      } else {
        int index = field.lastIndexOf(":");
        String fieldName;
        String typeString;
        if (index != -1) {
          fieldName = field.substring(0, index);
          typeString = field.substring(1+index, field.length());
        } else {
          throw new RuntimeException("You must specify the sort type ie page:int,subject:string");
        }
        int type = getType(typeString);
        sortField0 = new SortField(fieldName, type);
      }
      sortFields[upto++] = sortField0;
    }

    if (upto < sortFields.length) {
      SortField[] newSortFields = new SortField[upto];
      System.arraycopy(sortFields, 0, newSortFields, 0, upto);
      sortFields = newSortFields;
    }
    this.sort = new Sort(sortFields);
  }
=======
@Override
  public void setParams(String sortField) {
    super.setParams(sortField);
    String[] fields = sortField.split(",");
    SortField[] sortFields = new SortField[fields.length];
    int upto = 0;
    for (int i = 0; i < fields.length; i++) {
      String field = fields[i];
      SortField sortField0;
      if (field.equals("doc")) {
        sortField0 = SortField.FIELD_DOC;
      } if (field.equals("score")) {
        sortField0 = SortField.FIELD_SCORE;
      } else if (field.equals("noscore")) {
        doScore = false;
        continue;
      } else if (field.equals("nomaxscore")) {
        doMaxScore = false;
        continue;
      } else {
        int index = field.lastIndexOf(":");
        String fieldName;
        String typeString;
        if (index != -1) {
          fieldName = field.substring(0, index);
          typeString = field.substring(1+index, field.length());
        } else {
          throw new RuntimeException("You must specify the sort type ie page:int,subject:string");
        }
        sortField0 = getSortField(fieldName, typeString);
      }
      sortFields[upto++] = sortField0;
    }

    if (upto < sortFields.length) {
      SortField[] newSortFields = new SortField[upto];
      System.arraycopy(sortFields, 0, newSortFields, 0, upto);
      sortFields = newSortFields;
    }
    
    this.sort = new Sort(sortFields);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630630888/fstmerge_var2_2751432328031799965

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_9a0a3_8d888/rev_9a0a3-8d888/lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchWithSortTask.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630632068/fstmerge_var1_4884822859375622356
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630632068/fstmerge_base_5924447274588926805
private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {

    final DocState ds = getDocState();
    final Document doc = reuseFields ? ds.doc : new Document();
    doc.getFields().clear();
    
    // Set ID_FIELD
    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);
    idField.setValue("doc" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));
    doc.add(idField);
    
    // Set NAME_FIELD
    String name = docData.getName();
    if (name == null) name = "";
    name = cnt < 0 ? name : name + "_" + cnt;
    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);
    nameField.setValue(name);
    doc.add(nameField);
    
    // Set DATE_FIELD
    String date = docData.getDate();
    if (date == null) {
      date = "";
    }
    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);
    dateField.setValue(date);
    doc.add(dateField);
    
    // Set TITLE_FIELD
    String title = docData.getTitle();
    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);
    titleField.setValue(title == null ? "" : title);
    doc.add(titleField);
    
    String body = docData.getBody();
    if (body != null && body.length() > 0) {
      String bdy;
      if (size <= 0 || size >= body.length()) {
        bdy = body; // use all
        docData.setBody(""); // nothing left
      } else {
        // attempt not to break words - if whitespace found within next 20 chars...
        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {
          if (Character.isWhitespace(body.charAt(n))) {
            size = n;
            break;
          }
        }
        bdy = body.substring(0, size); // use part
        docData.setBody(body.substring(size)); // some left
      }
      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);
      bodyField.setValue(bdy);
      doc.add(bodyField);
      
      if (storeBytes) {
        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);
        bytesField.setValue(bdy.getBytes("UTF-8"));
        doc.add(bytesField);
      }
    }

    if (indexProperties) {
      Properties props = docData.getProps();
      if (props != null) {
        for (final Map.Entry<Object,Object> entry : props.entrySet()) {
          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);
          f.setValue((String) entry.getValue());
          doc.add(f);
        }
        docData.setProps(null);
      }
    }
    
    //System.out.println("============== Created doc "+numDocsCreated+" :\n"+doc+"\n==========");
    return doc;
  }
=======
private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {
    Type valueType;
    final DocState ds = getDocState();
    final Document doc = reuseFields ? ds.doc : new Document();
    doc.getFields().clear();
    
    // Set ID_FIELD
    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);
    idField.setValue("doc" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));
    doc.add(idField);
    trySetIndexValues(idField);

    // Set NAME_FIELD
    String name = docData.getName();
    if (name == null) name = "";
    name = cnt < 0 ? name : name + "_" + cnt;
    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);
    nameField.setValue(name);
    trySetIndexValues(nameField);
    doc.add(nameField);
    
    // Set DATE_FIELD
    String date = docData.getDate();
    if (date == null) {
      date = "";
    }
    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);
    dateField.setValue(date);
    trySetIndexValues(dateField);
    doc.add(dateField);
    
    // Set TITLE_FIELD
    String title = docData.getTitle();
    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);
    titleField.setValue(title == null ? "" : title);
    trySetIndexValues(titleField);
    doc.add(titleField);
    
    String body = docData.getBody();
    if (body != null && body.length() > 0) {
      String bdy;
      if (size <= 0 || size >= body.length()) {
        bdy = body; // use all
        docData.setBody(""); // nothing left
      } else {
        // attempt not to break words - if whitespace found within next 20 chars...
        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {
          if (Character.isWhitespace(body.charAt(n))) {
            size = n;
            break;
          }
        }
        bdy = body.substring(0, size); // use part
        docData.setBody(body.substring(size)); // some left
      }
      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);
      bodyField.setValue(bdy);
      trySetIndexValues(bodyField);
      doc.add(bodyField);
      
      if (storeBytes) {
        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);
        bytesField.setValue(bdy.getBytes("UTF-8"));
        trySetIndexValues(bytesField);
        doc.add(bytesField);
        
      }
    }

    if (indexProperties) {
      Properties props = docData.getProps();
      if (props != null) {
        for (final Map.Entry<Object,Object> entry : props.entrySet()) {
          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);
          f.setValue((String) entry.getValue());
          trySetIndexValues(f);
          doc.add(f);
        }
        docData.setProps(null);
      }
    }
    
    //System.out.println("============== Created doc "+numDocsCreated+" :\n"+doc+"\n==========");
    return doc;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630632068/fstmerge_var2_8805141779846891359

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_9a0a3_8d888/rev_9a0a3-8d888/lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630632120/fstmerge_var1_4232427098029712625
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630632120/fstmerge_base_1983672816169729169
public void setConfig(Config config) {
    this.config = config;
    try {
      String sourceClass = config.get("content.source", "org.apache.lucene.benchmark.byTask.feeds.SingleDocSource");
      source = Class.forName(sourceClass).asSubclass(ContentSource.class).newInstance();
      source.setConfig(config);
    } catch (Exception e) {
      // Should not get here. Throw runtime exception.
      throw new RuntimeException(e);
    }

    boolean stored = config.get("doc.stored", false);
    boolean bodyStored = config.get("doc.body.stored", stored);
    boolean tokenized = config.get("doc.tokenized", true);
    boolean bodyTokenized = config.get("doc.body.tokenized", tokenized);
    boolean norms = config.get("doc.tokenized.norms", false);
    boolean bodyNorms = config.get("doc.body.tokenized.norms", true);
    boolean termVec = config.get("doc.term.vector", false);
    storeVal = (stored ? Field.Store.YES : Field.Store.NO);
    bodyStoreVal = (bodyStored ? Field.Store.YES : Field.Store.NO);
    if (tokenized) {
      indexVal = norms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;
    } else {
      indexVal = norms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;
    }

    if (bodyTokenized) {
      bodyIndexVal = bodyNorms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;
    } else {
      bodyIndexVal = bodyNorms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;
    }

    boolean termVecPositions = config.get("doc.term.vector.positions", false);
    boolean termVecOffsets = config.get("doc.term.vector.offsets", false);
    if (termVecPositions && termVecOffsets) {
      termVecVal = TermVector.WITH_POSITIONS_OFFSETS;
    } else if (termVecPositions) {
      termVecVal = TermVector.WITH_POSITIONS;
    } else if (termVecOffsets) {
      termVecVal = TermVector.WITH_OFFSETS;
    } else if (termVec) {
      termVecVal = TermVector.YES;
    } else {
      termVecVal = TermVector.NO;
    }
    storeBytes = config.get("doc.store.body.bytes", false);
    
    reuseFields = config.get("doc.reuse.fields", true);

    // In a multi-rounds run, it is important to reset DocState since settings
    // of fields may change between rounds, and this is the only way to reset
    // the cache of all threads.
    docState = new ThreadLocal<DocState>();
    
    indexProperties = config.get("doc.index.props", false);

    updateDocIDLimit = config.get("doc.random.id.limit", -1);
    if (updateDocIDLimit != -1) {
      r = new Random(179);
    }
  }
=======
public void setConfig(Config config) {
    this.config = config;
    try {
      String sourceClass = config.get("content.source", "org.apache.lucene.benchmark.byTask.feeds.SingleDocSource");
      source = Class.forName(sourceClass).asSubclass(ContentSource.class).newInstance();
      source.setConfig(config);
    } catch (Exception e) {
      // Should not get here. Throw runtime exception.
      throw new RuntimeException(e);
    }

    boolean stored = config.get("doc.stored", false);
    boolean bodyStored = config.get("doc.body.stored", stored);
    boolean tokenized = config.get("doc.tokenized", true);
    boolean bodyTokenized = config.get("doc.body.tokenized", tokenized);
    boolean norms = config.get("doc.tokenized.norms", false);
    boolean bodyNorms = config.get("doc.body.tokenized.norms", true);
    boolean termVec = config.get("doc.term.vector", false);
    fieldVauleMap = parseValueFields(config.get("doc.stored.values", null));
    storeVal = (stored ? Field.Store.YES : Field.Store.NO);
    bodyStoreVal = (bodyStored ? Field.Store.YES : Field.Store.NO);
    if (tokenized) {
      indexVal = norms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;
    } else {
      indexVal = norms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;
    }

    if (bodyTokenized) {
      bodyIndexVal = bodyNorms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;
    } else {
      bodyIndexVal = bodyNorms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;
    }

    boolean termVecPositions = config.get("doc.term.vector.positions", false);
    boolean termVecOffsets = config.get("doc.term.vector.offsets", false);
    if (termVecPositions && termVecOffsets) {
      termVecVal = TermVector.WITH_POSITIONS_OFFSETS;
    } else if (termVecPositions) {
      termVecVal = TermVector.WITH_POSITIONS;
    } else if (termVecOffsets) {
      termVecVal = TermVector.WITH_OFFSETS;
    } else if (termVec) {
      termVecVal = TermVector.YES;
    } else {
      termVecVal = TermVector.NO;
    }
    storeBytes = config.get("doc.store.body.bytes", false);
    
    reuseFields = config.get("doc.reuse.fields", true);

    // In a multi-rounds run, it is important to reset DocState since settings
    // of fields may change between rounds, and this is the only way to reset
    // the cache of all threads.
    docState = new ThreadLocal<DocState>();
    
    indexProperties = config.get("doc.index.props", false);
    updateDocIDLimit = config.get("doc.random.id.limit", -1);
    if (updateDocIDLimit != -1) {
      r = new Random(179);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630632120/fstmerge_var2_1564307810680907286

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_9a0a3_8d888/rev_9a0a3-8d888/lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630632440/fstmerge_var1_551725658804264252
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630632440/fstmerge_base_8404440599144016071
public SimpleQQParser(String qqNames[], String indexField) {
    this.qqNames = qqNames;
    this.indexField = indexField;
  }
=======
public SimpleQQParser(String qqName, String indexField) {
    this(new String[] { qqName }, indexField);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419630632440/fstmerge_var2_5056752178037881370

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_9a0a3_8d888/rev_9a0a3-8d888/lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/utils/SimpleQQParser.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1f4c6_23c62/rev_1f4c6-23c62.revisions
Conflict type: LineBasedMCFd
Conflict body: 
private SegmentInfo merge(SegmentInfo si1, SegmentInfo si2, String merged, boolean useCompoundFile)
   throws Exception {
      SegmentReader r1 = SegmentReader.get(true, si1, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);
      SegmentReader r2 = SegmentReader.get(true, si2, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);

      SegmentMerger merger = new SegmentMerger(si1.dir, IndexWriterConfig.DEFAULT_TERM_INDEX_INTERVAL, merged, null, CodecProvider.getDefault(), null, new FieldInfos());

      merger.add(r1);
      merger.add(r2);
      merger.merge();
      r1.close();
      r2.close();

      final SegmentInfo info = new SegmentInfo(merged, si1.docCount + si2.docCount, si1.dir,
                                               false, merger.fieldInfos().hasProx(), merger.getSegmentCodecs(),
                                               merger.fieldInfos().hasVectors());

      if (useCompoundFile) {
        Collection<String> filesToDelete = merger.createCompoundFile(merged + ".cfs", info);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631467279/fstmerge_var1_1433297646196086517
        info.setUseCompoundFile(true);
        for (final String fileToDelete : filesToDelete) 
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631467279/fstmerge_base_6671148321936044422
        for (final String fileToDelete : filesToDelete) 
=======
        for (final String fileToDelete : filesToDelete)
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631467279/fstmerge_var2_957245488562609216
          si1.dir.deleteFile(fileToDelete);
      }

      return info;
   }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1f4c6_23c62/rev_1f4c6-23c62/lucene/src/test/org/apache/lucene/index/TestDoc.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631486742/fstmerge_var1_4467182140230206351
synchronized SegmentInfo flush(IndexWriter writer, IndexFileDeleter deleter, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {

    // We change writer's segmentInfos:
    assert Thread.holdsLock(writer);

    waitIdle();

    if (numDocs == 0) {
      // nothing to do!
      if (infoStream != null) {
        message("flush: no docs; skipping");
      }
      // Lock order: IW -> DW -> BD
      pushDeletes(null, segmentInfos);
      return null;
    }

    if (aborting) {
      if (infoStream != null) {
        message("flush: skip because aborting is set");
      }
      return null;
    }

    boolean success = false;

    SegmentInfo newSegment;

    try {
      assert nextDocID == numDocs;
      assert waitQueue.numWaiting == 0;
      assert waitQueue.waitingBytes == 0;

      if (infoStream != null) {
        message("flush postings as segment " + segment + " numDocs=" + numDocs);
      }

      final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                                                 numDocs, writer.getConfig().getTermIndexInterval(),
                                                                 SegmentCodecs.build(fieldInfos, writer.codecs));

      newSegment = new SegmentInfo(segment, numDocs, directory, false, fieldInfos.hasProx(), flushState.segmentCodecs, false);

      Collection<DocConsumerPerThread> threads = new HashSet<DocConsumerPerThread>();
      for (DocumentsWriterThreadState threadState : threadStates) {
        threads.add(threadState.consumer);
      }

      double startMBUsed = bytesUsed()/1024./1024.;

      consumer.flush(threads, flushState);
      newSegment.setHasVectors(flushState.hasVectors);

      if (infoStream != null) {
        message("new segment has " + (flushState.hasVectors ? "vectors" : "no vectors"));
        message("flushedFiles=" + newSegment.files());
        message("flushed codecs=" + newSegment.getSegmentCodecs());
      }

      if (mergePolicy.useCompoundFile(segmentInfos, newSegment)) {
        final String cfsFileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        if (infoStream != null) {
          message("flush: create compound file \"" + cfsFileName + "\"");
        }

        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, cfsFileName);
        for(String fileName : newSegment.files()) {
          cfsWriter.addFile(fileName);
        }
        cfsWriter.close();
        deleter.deleteNewFiles(newSegment.files());
        newSegment.setUseCompoundFile(true);
      }

      if (infoStream != null) {
        message("flush: segment=" + newSegment);
        final double newSegmentSizeNoStore = newSegment.sizeInBytes(false)/1024./1024.;
        final double newSegmentSize = newSegment.sizeInBytes(true)/1024./1024.;
        message("  ramUsed=" + nf.format(startMBUsed) + " MB" +
                " newFlushedSize=" + nf.format(newSegmentSize) + " MB" +
                " (" + nf.format(newSegmentSizeNoStore) + " MB w/o doc stores)" +
                " docs/MB=" + nf.format(numDocs / newSegmentSize) +
                " new/old=" + nf.format(100.0 * newSegmentSizeNoStore / startMBUsed) + "%");
      }

      success = true;
    } finally {
      notifyAll();
      if (!success) {
        if (segment != null) {
          deleter.refresh(segment);
        }
        abort();
      }
    }

    doAfterFlush();

    // Lock order: IW -> DW -> BD
    pushDeletes(newSegment, segmentInfos);

    return newSegment;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631486742/fstmerge_base_6050033956759071723
synchronized SegmentInfo flush(IndexWriter writer, IndexFileDeleter deleter, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {

    // We change writer's segmentInfos:
    assert Thread.holdsLock(writer);

    waitIdle();

    if (numDocs == 0) {
      // nothing to do!
      if (infoStream != null) {
        message("flush: no docs; skipping");
      }
      // Lock order: IW -> DW -> BD
      pushDeletes(null, segmentInfos);
      return null;
    }

    if (aborting) {
      if (infoStream != null) {
        message("flush: skip because aborting is set");
      }
      return null;
    }

    boolean success = false;

    SegmentInfo newSegment;

    try {
      assert nextDocID == numDocs;
      assert waitQueue.numWaiting == 0;
      assert waitQueue.waitingBytes == 0;

      if (infoStream != null) {
        message("flush postings as segment " + segment + " numDocs=" + numDocs);
      }

      final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                                                 numDocs, writer.getConfig().getTermIndexInterval(),
                                                                 SegmentCodecs.build(fieldInfos, writer.codecs));

      newSegment = new SegmentInfo(segment, numDocs, directory, false, fieldInfos.hasProx(), flushState.segmentCodecs, false);

      Collection<DocConsumerPerThread> threads = new HashSet<DocConsumerPerThread>();
      for (DocumentsWriterThreadState threadState : threadStates) {
        threads.add(threadState.consumer);
      }

      double startMBUsed = bytesUsed()/1024./1024.;

      consumer.flush(threads, flushState);
      newSegment.setHasVectors(flushState.hasVectors);

      if (infoStream != null) {
        message("new segment has " + (flushState.hasVectors ? "vectors" : "no vectors"));
        message("flushedFiles=" + flushState.flushedFiles);
        message("flushed codecs=" + newSegment.getSegmentCodecs());
      }

      if (mergePolicy.useCompoundFile(segmentInfos, newSegment)) {
        final String cfsFileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        if (infoStream != null) {
          message("flush: create compound file \"" + cfsFileName + "\"");
        }

        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, cfsFileName);
        for(String fileName : flushState.flushedFiles) {
          cfsWriter.addFile(fileName);
        }
        cfsWriter.close();
        deleter.deleteNewFiles(flushState.flushedFiles);

        newSegment.setUseCompoundFile(true);
      }

      if (infoStream != null) {
        message("flush: segment=" + newSegment);
        final double newSegmentSizeNoStore = newSegment.sizeInBytes(false)/1024./1024.;
        final double newSegmentSize = newSegment.sizeInBytes(true)/1024./1024.;
        message("  ramUsed=" + nf.format(startMBUsed) + " MB" +
                " newFlushedSize=" + nf.format(newSegmentSize) + " MB" +
                " (" + nf.format(newSegmentSizeNoStore) + " MB w/o doc stores)" +
                " docs/MB=" + nf.format(numDocs / newSegmentSize) +
                " new/old=" + nf.format(100.0 * newSegmentSizeNoStore / startMBUsed) + "%");
      }

      success = true;
    } finally {
      notifyAll();
      if (!success) {
        if (segment != null) {
          deleter.refresh(segment);
        }
        abort();
      }
    }

    doAfterFlush();

    // Lock order: IW -> DW -> BD
    pushDeletes(newSegment, segmentInfos);

    return newSegment;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631486742/fstmerge_var2_8441778535378352771

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1f4c6_23c62/rev_1f4c6-23c62/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487220/fstmerge_var1_6077720682631393631
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487220/fstmerge_base_5256241431851102834
final Collection<String> getMergedFiles(final SegmentInfo info) throws IOException {
    Set<String> fileSet = new HashSet<String>();

    // Basic files
    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {
      fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
    }

    segmentWriteState.segmentCodecs.files(directory, info, fileSet);
    
    // Fieldable norm files
    int numFIs = fieldInfos.size();
    for (int i = 0; i < numFIs; i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed && !fi.omitNorms) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", IndexFileNames.NORMS_EXTENSION));
        break;
      }
    }

    // Vector files
    if (fieldInfos.hasVectors()) {
      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
      }
    }

    return fileSet;
  }
=======
final Collection<String> getMergedFiles(final SegmentInfo info) throws IOException {
    Set<String> fileSet = new HashSet<String>();

    // Basic files
    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {
      fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
    }

    segmentWriteState.segmentCodecs.files(directory, info, fileSet);

    // Fieldable norm files
    int numFIs = fieldInfos.size();
    for (int i = 0; i < numFIs; i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed && !fi.omitNorms) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", IndexFileNames.NORMS_EXTENSION));
        break;
      }
    }

    // Vector files
    if (fieldInfos.hasVectors()) {
      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
      }
    }

    return fileSet;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487220/fstmerge_var2_1285003099524432423

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1f4c6_23c62/rev_1f4c6-23c62/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
Conflict type: LineBasedMCFd
Conflict body: 
private void mergeNorms() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487286/fstmerge_var1_4339188574323971897
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487286/fstmerge_base_1164764775101270976
    // get needed buffer size by finding the largest segment
    int bufferSize = 0;
    for (IndexReader reader : readers) {
      bufferSize = Math.max(bufferSize, reader.maxDoc());
    }
    
    byte[] normBuffer = null;
=======
    // get needed buffer size by finding the largest segment
    int bufferSize = 0;
    for (IndexReader reader : readers) {
      bufferSize = Math.max(bufferSize, reader.maxDoc());
    }

    byte[] normBuffer = null;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487286/fstmerge_var2_6438485787792135147
    IndexOutput output = null;
    try {
      for (int i = 0, numFieldInfos = fieldInfos.size(); i < numFieldInfos; i++) {
        final FieldInfo fi = fieldInfos.fieldInfo(i);
        if (fi.isIndexed && !fi.omitNorms) {
          if (output == null) {
            output = directory.createOutput(IndexFileNames.segmentFileName(segment, "", IndexFileNames.NORMS_EXTENSION));
            output.writeBytes(NORMS_HEADER,NORMS_HEADER.length);
          }
          for (IndexReader reader : readers) {
            final int maxDoc = reader.maxDoc();
            byte normBuffer[] = reader.norms(fi.name);
            if (normBuffer == null) {
              // Can be null if this segment doesn't have
              // any docs with this field
              normBuffer = new byte[maxDoc];
              Arrays.fill(normBuffer, (byte)0);
            }
            if (!reader.hasDeletions()) {
              //optimized case for segments without deleted docs
              output.writeBytes(normBuffer, maxDoc);
            } else {
              // this segment has deleted docs, so we have to
              // check for every doc if it is deleted or not
              final Bits delDocs = reader.getDeletedDocs();
              for (int k = 0; k < maxDoc; k++) {
                if (!delDocs.get(k)) {
                  output.writeByte(normBuffer[k]);
                }
              }
            }
            checkAbort.work(maxDoc);
          }
        }
      }
    } finally {
      if (output != null) {
        output.close();
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1f4c6_23c62/rev_1f4c6-23c62/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487317/fstmerge_var1_5283736327529046761
@Override
  public void flush(Map<InvertedDocEndConsumerPerThread,Collection<InvertedDocEndConsumerPerField>> threadsAndFields, SegmentWriteState state) throws IOException {

    final Map<FieldInfo,List<NormsWriterPerField>> byField = new HashMap<FieldInfo,List<NormsWriterPerField>>();

    if (!fieldInfos.hasNorms()) {
      return;
    }

    // Typically, each thread will have encountered the same
    // field.  So first we collate by field, ie, all
    // per-thread field instances that correspond to the
    // same FieldInfo
    for (final Map.Entry<InvertedDocEndConsumerPerThread,Collection<InvertedDocEndConsumerPerField>> entry : threadsAndFields.entrySet()) {
      final Collection<InvertedDocEndConsumerPerField> fields = entry.getValue();
      final Iterator<InvertedDocEndConsumerPerField> fieldsIt = fields.iterator();

      while (fieldsIt.hasNext()) {
        final NormsWriterPerField perField = (NormsWriterPerField) fieldsIt.next();

        if (perField.upto > 0) {
          // It has some norms
          List<NormsWriterPerField> l = byField.get(perField.fieldInfo);
          if (l == null) {
            l = new ArrayList<NormsWriterPerField>();
            byField.put(perField.fieldInfo, l);
          }
          l.add(perField);
        } else
          // Remove this field since we haven't seen it
          // since the previous flush
          fieldsIt.remove();
      }
    }

    final String normsFileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.NORMS_EXTENSION);
    IndexOutput normsOut = state.directory.createOutput(normsFileName);

    try {
      normsOut.writeBytes(SegmentMerger.NORMS_HEADER, 0, SegmentMerger.NORMS_HEADER.length);

      final int numField = fieldInfos.size();

      int normCount = 0;

      for(int fieldNumber=0;fieldNumber<numField;fieldNumber++) {

        final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);

        List<NormsWriterPerField> toMerge = byField.get(fieldInfo);
        int upto = 0;
        if (toMerge != null) {

          final int numFields = toMerge.size();

          normCount++;

          final NormsWriterPerField[] fields = new NormsWriterPerField[numFields];
          int[] uptos = new int[numFields];

          for(int j=0;j<numFields;j++)
            fields[j] = toMerge.get(j);

          int numLeft = numFields;
              
          while(numLeft > 0) {

            assert uptos[0] < fields[0].docIDs.length : " uptos[0]=" + uptos[0] + " len=" + (fields[0].docIDs.length);

            int minLoc = 0;
            int minDocID = fields[0].docIDs[uptos[0]];

            for(int j=1;j<numLeft;j++) {
              final int docID = fields[j].docIDs[uptos[j]];
              if (docID < minDocID) {
                minDocID = docID;
                minLoc = j;
              }
            }

            assert minDocID < state.numDocs;

            // Fill hole
            for(;upto<minDocID;upto++)
              normsOut.writeByte((byte) 0);

            normsOut.writeByte(fields[minLoc].norms[uptos[minLoc]]);
            (uptos[minLoc])++;
            upto++;

            if (uptos[minLoc] == fields[minLoc].upto) {
              fields[minLoc].reset();
              if (minLoc != numLeft-1) {
                fields[minLoc] = fields[numLeft-1];
                uptos[minLoc] = uptos[numLeft-1];
              }
              numLeft--;
            }
          }
          
          // Fill final hole with defaultNorm
          for(;upto<state.numDocs;upto++)
            normsOut.writeByte((byte) 0);
        } else if (fieldInfo.isIndexed && !fieldInfo.omitNorms) {
          normCount++;
          // Fill entire field with default norm:
          for(;upto<state.numDocs;upto++)
            normsOut.writeByte((byte) 0);
        }

        assert 4+normCount*state.numDocs == normsOut.getFilePointer() : ".nrm file size mismatch: expected=" + (4+normCount*state.numDocs) + " actual=" + normsOut.getFilePointer();
      }

    } finally {
      normsOut.close();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487317/fstmerge_base_6190689440268816378
@Override
  public void flush(Map<InvertedDocEndConsumerPerThread,Collection<InvertedDocEndConsumerPerField>> threadsAndFields, SegmentWriteState state) throws IOException {

    final Map<FieldInfo,List<NormsWriterPerField>> byField = new HashMap<FieldInfo,List<NormsWriterPerField>>();

    // Typically, each thread will have encountered the same
    // field.  So first we collate by field, ie, all
    // per-thread field instances that correspond to the
    // same FieldInfo
    for (final Map.Entry<InvertedDocEndConsumerPerThread,Collection<InvertedDocEndConsumerPerField>> entry : threadsAndFields.entrySet()) {
      final Collection<InvertedDocEndConsumerPerField> fields = entry.getValue();
      final Iterator<InvertedDocEndConsumerPerField> fieldsIt = fields.iterator();

      while (fieldsIt.hasNext()) {
        final NormsWriterPerField perField = (NormsWriterPerField) fieldsIt.next();

        if (perField.upto > 0) {
          // It has some norms
          List<NormsWriterPerField> l = byField.get(perField.fieldInfo);
          if (l == null) {
            l = new ArrayList<NormsWriterPerField>();
            byField.put(perField.fieldInfo, l);
          }
          l.add(perField);
        } else
          // Remove this field since we haven't seen it
          // since the previous flush
          fieldsIt.remove();
      }
    }

    final String normsFileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.NORMS_EXTENSION);
    state.flushedFiles.add(normsFileName);
    IndexOutput normsOut = state.directory.createOutput(normsFileName);

    try {
      normsOut.writeBytes(SegmentMerger.NORMS_HEADER, 0, SegmentMerger.NORMS_HEADER.length);

      final int numField = fieldInfos.size();

      int normCount = 0;

      for(int fieldNumber=0;fieldNumber<numField;fieldNumber++) {

        final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);

        List<NormsWriterPerField> toMerge = byField.get(fieldInfo);
        int upto = 0;
        if (toMerge != null) {

          final int numFields = toMerge.size();

          normCount++;

          final NormsWriterPerField[] fields = new NormsWriterPerField[numFields];
          int[] uptos = new int[numFields];

          for(int j=0;j<numFields;j++)
            fields[j] = toMerge.get(j);

          int numLeft = numFields;
              
          while(numLeft > 0) {

            assert uptos[0] < fields[0].docIDs.length : " uptos[0]=" + uptos[0] + " len=" + (fields[0].docIDs.length);

            int minLoc = 0;
            int minDocID = fields[0].docIDs[uptos[0]];

            for(int j=1;j<numLeft;j++) {
              final int docID = fields[j].docIDs[uptos[j]];
              if (docID < minDocID) {
                minDocID = docID;
                minLoc = j;
              }
            }

            assert minDocID < state.numDocs;

            // Fill hole
            for(;upto<minDocID;upto++)
              normsOut.writeByte(defaultNorm);

            normsOut.writeByte(fields[minLoc].norms[uptos[minLoc]]);
            (uptos[minLoc])++;
            upto++;

            if (uptos[minLoc] == fields[minLoc].upto) {
              fields[minLoc].reset();
              if (minLoc != numLeft-1) {
                fields[minLoc] = fields[numLeft-1];
                uptos[minLoc] = uptos[numLeft-1];
              }
              numLeft--;
            }
          }
          
          // Fill final hole with defaultNorm
          for(;upto<state.numDocs;upto++)
            normsOut.writeByte(defaultNorm);
        } else if (fieldInfo.isIndexed && !fieldInfo.omitNorms) {
          normCount++;
          // Fill entire field with default norm:
          for(;upto<state.numDocs;upto++)
            normsOut.writeByte(defaultNorm);
        }

        assert 4+normCount*state.numDocs == normsOut.getFilePointer() : ".nrm file size mismatch: expected=" + (4+normCount*state.numDocs) + " actual=" + normsOut.getFilePointer();
      }

    } finally {
      normsOut.close();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487317/fstmerge_var2_3599060979124180708

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1f4c6_23c62/rev_1f4c6-23c62/lucene/src/java/org/apache/lucene/index/NormsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public MergeSpecification findMergesForOptimize(SegmentInfos infos,
      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {

    assert maxNumSegments > 0;
    if (verbose()) {
      message("findMergesForOptimize: maxNumSegs=" + maxNumSegments + " segsToOptimize= "+ segmentsToOptimize);
    }

    // If the segments are already optimized (e.g. there's only 1 segment), or
    // there are <maxNumSegements, all optimized, nothing to do.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487584/fstmerge_var1_3013452720047747556
    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {
      if (verbose()) {
        message("already optimized; skip");
      }
      return null;
    }
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487584/fstmerge_base_3681118766962364168
    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) return null;
    
=======
    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) return null;

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487584/fstmerge_var2_6340219356250734784
    // Find the newest (rightmost) segment that needs to
    // be optimized (other segments may have been flushed
    // since optimize started):
    int last = infos.size();
    while (last > 0) {
      final SegmentInfo info = infos.info(--last);
      if (segmentsToOptimize.contains(info)) {
        last++;
        break;
      }
    }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487584/fstmerge_var1_3013452720047747556
    if (last == 0) {
      if (verbose()) {
        message("last == 0; skip");
      }
      return null;
    }
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487584/fstmerge_base_3681118766962364168
    if (last == 0) return null;
    
=======
    if (last == 0) return null;

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487584/fstmerge_var2_6340219356250734784
    // There is only one segment already, and it is optimized
    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {
      if (verbose()) {
        message("already 1 seg; skip");
      }
      return null;
    }

    // Check if there are any segments above the threshold
    boolean anyTooLarge = false;
    for (int i = 0; i < last; i++) {
      SegmentInfo info = infos.info(i);
      if (size(info) > maxMergeSize || sizeDocs(info) > maxMergeDocs) {
        anyTooLarge = true;
        break;
      }
    }

    if (anyTooLarge) {
      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);
    } else {
      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1f4c6_23c62/rev_1f4c6-23c62/lucene/src/java/org/apache/lucene/index/LogMergePolicy.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487671/fstmerge_var1_8734845945945859516
@Override
  public void flush(Collection<DocConsumerPerThread> threads, SegmentWriteState state) throws IOException {

    Map<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>> childThreadsAndFields = new HashMap<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>>();
    for ( DocConsumerPerThread thread : threads) {
      DocFieldProcessorPerThread perThread = (DocFieldProcessorPerThread) thread;
      childThreadsAndFields.put(perThread.consumer, perThread.fields());
      perThread.trimFields(state);
    }
    fieldsWriter.flush(state);
    consumer.flush(childThreadsAndFields, state);

    // Important to save after asking consumer to flush so
    // consumer can alter the FieldInfo* if necessary.  EG,
    // FreqProxTermsWriter does this with
    // FieldInfo.storePayload.
    final String fileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.FIELD_INFOS_EXTENSION);
    fieldInfos.write(state.directory, fileName);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487671/fstmerge_base_5313975652276798623
@Override
  public void flush(Collection<DocConsumerPerThread> threads, SegmentWriteState state) throws IOException {

    Map<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>> childThreadsAndFields = new HashMap<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>>();
    for ( DocConsumerPerThread thread : threads) {
      DocFieldProcessorPerThread perThread = (DocFieldProcessorPerThread) thread;
      childThreadsAndFields.put(perThread.consumer, perThread.fields());
      perThread.trimFields(state);
    }
    fieldsWriter.flush(state);
    consumer.flush(childThreadsAndFields, state);

    // Important to save after asking consumer to flush so
    // consumer can alter the FieldInfo* if necessary.  EG,
    // FreqProxTermsWriter does this with
    // FieldInfo.storePayload.
    final String fileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.FIELD_INFOS_EXTENSION);
    fieldInfos.write(state.directory, fileName);
    state.flushedFiles.add(fileName);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631487671/fstmerge_var2_5870398643608230792

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1f4c6_23c62/rev_1f4c6-23c62/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631489668/fstmerge_var1_135484617038713017
@Override
  synchronized void flush(Map<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> threadsAndFields, final SegmentWriteState state) throws IOException {
    if (tvx != null) {
      // At least one doc in this run had term vectors enabled
      fill(state.numDocs);
      tvx.close();
      tvf.close();
      tvd.close();
      tvx = tvd = tvf = null;
      assert state.segmentName != null;
      String idxName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.VECTORS_INDEX_EXTENSION);
      if (4 + ((long) state.numDocs) * 16 != state.directory.fileLength(idxName)) {
        throw new RuntimeException("after flush: tvx size mismatch: " + state.numDocs + " docs vs " + state.directory.fileLength(idxName) + " length in bytes of " + idxName + " file exists?=" + state.directory.fileExists(idxName));
      }

      lastDocID = 0;
      state.hasVectors = hasVectors;
      hasVectors = false;
    }

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {
      for (final TermsHashConsumerPerField field : entry.getValue() ) {
        TermVectorsTermsWriterPerField perField = (TermVectorsTermsWriterPerField) field;
        perField.termsHashPerField.reset();
        perField.shrinkHash();
      }

      TermVectorsTermsWriterPerThread perThread = (TermVectorsTermsWriterPerThread) entry.getKey();
      perThread.termsHashPerThread.reset(true);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631489668/fstmerge_base_140288745520713254
@Override
  synchronized void flush(Map<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> threadsAndFields, final SegmentWriteState state) throws IOException {
    if (tvx != null) {
      // At least one doc in this run had term vectors enabled
      fill(state.numDocs);
      tvx.close();
      tvf.close();
      tvd.close();
      tvx = tvd = tvf = null;
      assert state.segmentName != null;
      String idxName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.VECTORS_INDEX_EXTENSION);
      String fldName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.VECTORS_FIELDS_EXTENSION);
      String docName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);

      if (4 + ((long) state.numDocs) * 16 != state.directory.fileLength(idxName)) {
        throw new RuntimeException("after flush: tvx size mismatch: " + state.numDocs + " docs vs " + state.directory.fileLength(idxName) + " length in bytes of " + idxName + " file exists?=" + state.directory.fileExists(idxName));
      }

      state.flushedFiles.add(idxName);
      state.flushedFiles.add(fldName);
      state.flushedFiles.add(docName);

      lastDocID = 0;
      state.hasVectors = hasVectors;
      hasVectors = false;
    }

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {
      for (final TermsHashConsumerPerField field : entry.getValue() ) {
        TermVectorsTermsWriterPerField perField = (TermVectorsTermsWriterPerField) field;
        perField.termsHashPerField.reset();
        perField.shrinkHash();
      }

      TermVectorsTermsWriterPerThread perThread = (TermVectorsTermsWriterPerThread) entry.getKey();
      perThread.termsHashPerThread.reset(true);
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631489668/fstmerge_var2_3946522407591674924

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1f4c6_23c62/rev_1f4c6-23c62/lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void addIndexes(IndexReader... readers) throws CorruptIndexException, IOException {
    ensureOpen();

    try {
      String mergedName = newSegmentName();
      SegmentMerger merger = new SegmentMerger(directory, termIndexInterval,
                                               mergedName, null, codecs, payloadProcessorProvider,
                                               ((FieldInfos) docWriter.getFieldInfos().clone()));

      for (IndexReader reader : readers)      // add new indexes
        merger.add(reader);

      int docCount = merger.merge();                // merge 'em

      SegmentInfo info = new SegmentInfo(mergedName, docCount, directory,
                                         false, merger.fieldInfos().hasProx(), merger.getSegmentCodecs(),
                                         merger.fieldInfos().hasVectors());
      setDiagnostics(info, "addIndexes(IndexReader...)");

      boolean useCompoundFile;
      synchronized(this) { // Guard segmentInfos
        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, info);
      }

      // Now create the compound file if needed
      if (useCompoundFile) {
        merger.createCompoundFile(mergedName + ".cfs", info);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631490023/fstmerge_var1_7854482777778229649
        
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631490023/fstmerge_base_5037894273604458221
        info.setUseCompoundFile(true);
        
=======
        info.setUseCompoundFile(true);

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631490023/fstmerge_var2_2173923622466234470
        // delete new non cfs files directly: they were never
        // registered with IFD
        deleter.deleteNewFiles(info.files());
        info.setUseCompoundFile(true);
      }

      // Register the new segment
      synchronized(this) {
        segmentInfos.add(info);
        checkpoint();
      }
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "addIndexes(IndexReader...)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1f4c6_23c62/rev_1f4c6-23c62/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631511180/fstmerge_var1_5928111337676724645
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631511180/fstmerge_base_4826288559061673909
public SimpleQQParser(String qqNames[], String indexField) {
    this.qqNames = qqNames;
    this.indexField = indexField;
  }
=======
public SimpleQQParser(String qqName, String indexField) {
    this(new String[] { qqName }, indexField);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419631511180/fstmerge_var2_5692499468944603983

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1f4c6_23c62/rev_1f4c6-23c62/lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/utils/SimpleQQParser.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f30af_c9ff2/rev_f30af-c9ff2.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419632360018/fstmerge_var1_2763014389735263413
void appendPostings(FreqProxTermsWriterPerField[] fields,
                      FieldsConsumer consumer)
    throws CorruptIndexException, IOException {

    int numFields = fields.length;

    final BytesRef text = new BytesRef();

    final FreqProxFieldMergeState[] mergeStates = new FreqProxFieldMergeState[numFields];

    final TermsConsumer termsConsumer = consumer.addField(fields[0].fieldInfo);
    final Comparator<BytesRef> termComp = termsConsumer.getComparator();

    for(int i=0;i<numFields;i++) {
      FreqProxFieldMergeState fms = mergeStates[i] = new FreqProxFieldMergeState(fields[i], termComp);

      assert fms.field.fieldInfo == fields[0].fieldInfo;

      // Should always be true
      boolean result = fms.nextTerm();
      assert result;
    }

    FreqProxFieldMergeState[] termStates = new FreqProxFieldMergeState[numFields];

    final boolean currentFieldOmitTermFreqAndPositions = fields[0].fieldInfo.omitTermFreqAndPositions;
    //System.out.println("flush terms field=" + fields[0].fieldInfo.name);

    // TODO: really TermsHashPerField should take over most
    // of this loop, including merge sort of terms from
    // multiple threads and interacting with the
    // TermsConsumer, only calling out to us (passing us the
    // DocsConsumer) to handle delivery of docs/positions
    long sumTotalTermFreq = 0;
    while(numFields > 0) {

      // Get the next term to merge
      termStates[0] = mergeStates[0];
      int numToMerge = 1;

      // TODO: pqueue
      for(int i=1;i<numFields;i++) {
        final int cmp = termComp.compare(mergeStates[i].text, termStates[0].text);
        if (cmp < 0) {
          termStates[0] = mergeStates[i];
          numToMerge = 1;
        } else if (cmp == 0) {
          termStates[numToMerge++] = mergeStates[i];
        }
      }

      // Need shallow copy here because termStates[0].text
      // changes by the time we call finishTerm
      text.bytes = termStates[0].text.bytes;
      text.offset = termStates[0].text.offset;
      text.length = termStates[0].text.length;  

      //System.out.println("  term=" + text.toUnicodeString());
      //System.out.println("  term=" + text.toString());

      final PostingsConsumer postingsConsumer = termsConsumer.startTerm(text);

      // Now termStates has numToMerge FieldMergeStates
      // which all share the same term.  Now we must
      // interleave the docID streams.
      int numDocs = 0;
      long totTF = 0;
      while(numToMerge > 0) {
        
        FreqProxFieldMergeState minState = termStates[0];
        for(int i=1;i<numToMerge;i++) {
          if (termStates[i].docID < minState.docID) {
            minState = termStates[i];
          }
        }

        final int termDocFreq = minState.termFreq;
        numDocs++;

        assert minState.docID < flushedDocCount: "doc=" + minState.docID + " maxDoc=" + flushedDocCount;

        postingsConsumer.startDoc(minState.docID, termDocFreq);

        final ByteSliceReader prox = minState.prox;

        // Carefully copy over the prox + payload info,
        // changing the format to match Lucene's segment
        // format.
        if (!currentFieldOmitTermFreqAndPositions) {
          // omitTermFreqAndPositions == false so we do write positions &
          // payload          
          int position = 0;
          totTF += termDocFreq;
          for(int j=0;j<termDocFreq;j++) {
            final int code = prox.readVInt();
            position += code >> 1;
            //System.out.println("    pos=" + position);

            final int payloadLength;
            final BytesRef thisPayload;

            if ((code & 1) != 0) {
              // This position has a payload
              payloadLength = prox.readVInt();  
              
              if (payload == null) {
                payload = new BytesRef();
                payload.bytes = new byte[payloadLength];
              } else if (payload.bytes.length < payloadLength) {
                payload.grow(payloadLength);
              }

              prox.readBytes(payload.bytes, 0, payloadLength);
              payload.length = payloadLength;
              thisPayload = payload;

            } else {
              payloadLength = 0;
              thisPayload = null;
            }

            postingsConsumer.addPosition(position, thisPayload);
          } //End for

          postingsConsumer.finishDoc();
        }

        if (!minState.nextDoc()) {

          // Remove from termStates
          int upto = 0;
          // TODO: inefficient O(N) where N = number of
          // threads that had seen this term:
          for(int i=0;i<numToMerge;i++) {
            if (termStates[i] != minState) {
              termStates[upto++] = termStates[i];
            }
          }
          numToMerge--;
          assert upto == numToMerge;

          // Advance this state to the next term

          if (!minState.nextTerm()) {
            // OK, no more terms, so remove from mergeStates
            // as well
            upto = 0;
            for(int i=0;i<numFields;i++)
              if (mergeStates[i] != minState)
                mergeStates[upto++] = mergeStates[i];
            numFields--;
            assert upto == numFields;
          }
        }
      }

      assert numDocs > 0;
      termsConsumer.finishTerm(text, new TermStats(numDocs, totTF));
      sumTotalTermFreq += totTF;
    }

    termsConsumer.finish(sumTotalTermFreq);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419632360018/fstmerge_base_756206543902562240
void appendPostings(FreqProxTermsWriterPerField[] fields,
                      FieldsConsumer consumer)
    throws CorruptIndexException, IOException {

    int numFields = fields.length;

    final BytesRef text = new BytesRef();

    final FreqProxFieldMergeState[] mergeStates = new FreqProxFieldMergeState[numFields];

    final TermsConsumer termsConsumer = consumer.addField(fields[0].fieldInfo);
    final Comparator<BytesRef> termComp = termsConsumer.getComparator();

    for(int i=0;i<numFields;i++) {
      FreqProxFieldMergeState fms = mergeStates[i] = new FreqProxFieldMergeState(fields[i], termComp);

      assert fms.field.fieldInfo == fields[0].fieldInfo;

      // Should always be true
      boolean result = fms.nextTerm();
      assert result;
    }

    FreqProxFieldMergeState[] termStates = new FreqProxFieldMergeState[numFields];

    final boolean currentFieldOmitTermFreqAndPositions = fields[0].fieldInfo.omitTermFreqAndPositions;
    //System.out.println("flush terms field=" + fields[0].fieldInfo.name);

    // TODO: really TermsHashPerField should take over most
    // of this loop, including merge sort of terms from
    // multiple threads and interacting with the
    // TermsConsumer, only calling out to us (passing us the
    // DocsConsumer) to handle delivery of docs/positions
    while(numFields > 0) {

      // Get the next term to merge
      termStates[0] = mergeStates[0];
      int numToMerge = 1;

      // TODO: pqueue
      for(int i=1;i<numFields;i++) {
        final int cmp = termComp.compare(mergeStates[i].text, termStates[0].text);
        if (cmp < 0) {
          termStates[0] = mergeStates[i];
          numToMerge = 1;
        } else if (cmp == 0) {
          termStates[numToMerge++] = mergeStates[i];
        }
      }

      // Need shallow copy here because termStates[0].text
      // changes by the time we call finishTerm
      text.bytes = termStates[0].text.bytes;
      text.offset = termStates[0].text.offset;
      text.length = termStates[0].text.length;  

      //System.out.println("  term=" + text.toUnicodeString());
      //System.out.println("  term=" + text.toString());

      final PostingsConsumer postingsConsumer = termsConsumer.startTerm(text);

      // Now termStates has numToMerge FieldMergeStates
      // which all share the same term.  Now we must
      // interleave the docID streams.
      int numDocs = 0;
      while(numToMerge > 0) {
        
        FreqProxFieldMergeState minState = termStates[0];
        for(int i=1;i<numToMerge;i++) {
          if (termStates[i].docID < minState.docID) {
            minState = termStates[i];
          }
        }

        final int termDocFreq = minState.termFreq;
        numDocs++;

        assert minState.docID < flushedDocCount: "doc=" + minState.docID + " maxDoc=" + flushedDocCount;

        postingsConsumer.startDoc(minState.docID, termDocFreq);

        final ByteSliceReader prox = minState.prox;

        // Carefully copy over the prox + payload info,
        // changing the format to match Lucene's segment
        // format.
        if (!currentFieldOmitTermFreqAndPositions) {
          // omitTermFreqAndPositions == false so we do write positions &
          // payload          
          int position = 0;
          for(int j=0;j<termDocFreq;j++) {
            final int code = prox.readVInt();
            position += code >> 1;
            //System.out.println("    pos=" + position);

            final int payloadLength;
            final BytesRef thisPayload;

            if ((code & 1) != 0) {
              // This position has a payload
              payloadLength = prox.readVInt();  
              
              if (payload == null) {
                payload = new BytesRef();
                payload.bytes = new byte[payloadLength];
              } else if (payload.bytes.length < payloadLength) {
                payload.grow(payloadLength);
              }

              prox.readBytes(payload.bytes, 0, payloadLength);
              payload.length = payloadLength;
              thisPayload = payload;

            } else {
              payloadLength = 0;
              thisPayload = null;
            }

            postingsConsumer.addPosition(position, thisPayload);
          } //End for

          postingsConsumer.finishDoc();
        }

        if (!minState.nextDoc()) {

          // Remove from termStates
          int upto = 0;
          // TODO: inefficient O(N) where N = number of
          // threads that had seen this term:
          for(int i=0;i<numToMerge;i++) {
            if (termStates[i] != minState) {
              termStates[upto++] = termStates[i];
            }
          }
          numToMerge--;
          assert upto == numToMerge;

          // Advance this state to the next term

          if (!minState.nextTerm()) {
            // OK, no more terms, so remove from mergeStates
            // as well
            upto = 0;
            for(int i=0;i<numFields;i++)
              if (mergeStates[i] != minState)
                mergeStates[upto++] = mergeStates[i];
            numFields--;
            assert upto == numFields;
          }
        }
      }

      assert numDocs > 0;
      termsConsumer.finishTerm(text, numDocs);
    }

    termsConsumer.finish();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419632360018/fstmerge_var2_8960072804374500583

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f30af_c9ff2/rev_f30af-c9ff2/lucene/src/java/org/apache/lucene/index/FreqProxTermsWriter.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_efc89_474a0/rev_efc89-474a0.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_b2d48_f592c/rev_b2d48-f592c.revisions
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void testNRTThreads() throws Exception {
    String vendor = Constants.JAVA_VENDOR;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634108109/fstmerge_var1_4143279253778643997
    assumeTrue(vendor + " JRE not supported.", 
        vendor.startsWith("Sun") || vendor.startsWith("Apple"));
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634108109/fstmerge_base_6489689787174682747
    assumeTrue(vendor + " JRE not supported.", 
        vendor.startsWith("Sun") || vendor.startsWith("IBM") || vendor.startsWith("Apple"));
    
=======
    assumeTrue(vendor + " JRE not supported.",
        vendor.startsWith("Sun") || vendor.startsWith("IBM") || vendor.startsWith("Apple"));

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634108109/fstmerge_var2_5073759905863360166
    // if we are not the fork
    if (System.getProperty("tests.crashmode") == null) {
      // try up to 10 times to create an index
      for (int i = 0; i < 10; i++) {
        forkTest();
        // if we succeeded in finding an index, we are done.
        if (checkIndexes(tempDir))
          return;
      }
    } else {
      // we are the fork, setup a crashing thread
      final int crashTime = _TestUtil.nextInt(random, 500, 4000);
      Thread t = new Thread() {
        @Override
        public void run() {
          try {
            Thread.sleep(crashTime);
          } catch (InterruptedException e) {}
          crashJRE();
        }
      };
      t.setPriority(Thread.MAX_PRIORITY);
      t.start();
      // run the test until we crash.
      for (int i = 0; i < 1000; i++) {
        super.testNRTThreads();
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_b2d48_f592c/rev_b2d48-f592c/lucene/src/test/org/apache/lucene/index/TestIndexWriterOnJRECrash.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634130165/fstmerge_var1_7304587598550165761
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634130165/fstmerge_base_8683533003002506797
synchronized void setMaxFieldLength(int maxFieldLength) {
    this.maxFieldLength = maxFieldLength;
    for(int i=0;i<threadStates.length;i++) {
      threadStates[i].docState.maxFieldLength = maxFieldLength;
    }
  }
=======
synchronized void setMaxFieldLength(int maxFieldLength) {
    this.maxFieldLength = maxFieldLength;
    pushConfigChange();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634130165/fstmerge_var2_2444913776844243106

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_b2d48_f592c/rev_b2d48-f592c/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634130264/fstmerge_var1_4774823247465968573
@Override
    protected byte[] newBuffer(int size) {
      assert size == PER_DOC_BLOCK_SIZE;
      return perDocAllocator.getByteBlock();
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634130264/fstmerge_base_491005997244096283
protected byte[] newBuffer(int size) {
      assert size == PER_DOC_BLOCK_SIZE;
      return perDocAllocator.getByteBlock();
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634130264/fstmerge_var2_6211593735612453331

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_b2d48_f592c/rev_b2d48-f592c/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634130317/fstmerge_var1_7778249573892052793
synchronized SegmentInfo flush(IndexWriter writer, IndexFileDeleter deleter, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {

    final long startTime = System.currentTimeMillis();

    // We change writer's segmentInfos:
    assert Thread.holdsLock(writer);

    waitIdle();

    if (numDocs == 0) {
      // nothing to do!
      if (infoStream != null) {
        message("flush: no docs; skipping");
      }
      // Lock order: IW -> DW -> BD
      pushDeletes(null, segmentInfos);
      return null;
    }

    if (aborting) {
      if (infoStream != null) {
        message("flush: skip because aborting is set");
      }
      return null;
    }

    boolean success = false;

    SegmentInfo newSegment;

    try {
      assert nextDocID == numDocs;
      assert waitQueue.numWaiting == 0;
      assert waitQueue.waitingBytes == 0;

      if (infoStream != null) {
        message("flush postings as segment " + segment + " numDocs=" + numDocs);
      }

      final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                                                 numDocs, writer.getConfig().getTermIndexInterval(),
                                                                 SegmentCodecs.build(fieldInfos, writer.codecs));

      newSegment = new SegmentInfo(segment, numDocs, directory, false, fieldInfos.hasProx(), flushState.segmentCodecs, false);

      Collection<DocConsumerPerThread> threads = new HashSet<DocConsumerPerThread>();
      for (DocumentsWriterThreadState threadState : threadStates) {
        threads.add(threadState.consumer);
      }

      double startMBUsed = bytesUsed()/1024./1024.;

      consumer.flush(threads, flushState);
      newSegment.setHasVectors(flushState.hasVectors);

      if (infoStream != null) {
        message("new segment has " + (flushState.hasVectors ? "vectors" : "no vectors"));
        message("flushedFiles=" + newSegment.files());
        message("flushed codecs=" + newSegment.getSegmentCodecs());
      }

      if (mergePolicy.useCompoundFile(segmentInfos, newSegment)) {
        final String cfsFileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        if (infoStream != null) {
          message("flush: create compound file \"" + cfsFileName + "\"");
        }

        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, cfsFileName);
        for(String fileName : newSegment.files()) {
          cfsWriter.addFile(fileName);
        }
        cfsWriter.close();
        deleter.deleteNewFiles(newSegment.files());
        newSegment.setUseCompoundFile(true);
      }

      if (infoStream != null) {
        message("flush: segment=" + newSegment);
        final double newSegmentSizeNoStore = newSegment.sizeInBytes(false)/1024./1024.;
        final double newSegmentSize = newSegment.sizeInBytes(true)/1024./1024.;
        message("  ramUsed=" + nf.format(startMBUsed) + " MB" +
                " newFlushedSize=" + nf.format(newSegmentSize) + " MB" +
                " (" + nf.format(newSegmentSizeNoStore) + " MB w/o doc stores)" +
                " docs/MB=" + nf.format(numDocs / newSegmentSize) +
                " new/old=" + nf.format(100.0 * newSegmentSizeNoStore / startMBUsed) + "%");
      }

      success = true;
    } finally {
      notifyAll();
      if (!success) {
        if (segment != null) {
          deleter.refresh(segment);
        }
        abort();
      }
    }

    doAfterFlush();

    // Lock order: IW -> DW -> BD
    pushDeletes(newSegment, segmentInfos);

    if (infoStream != null) {
      message("flush time " + (System.currentTimeMillis()-startTime) + " msec");
    }

    return newSegment;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634130317/fstmerge_base_7253355338546238046
synchronized SegmentInfo flush(IndexWriter writer, IndexFileDeleter deleter, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {

    // We change writer's segmentInfos:
    assert Thread.holdsLock(writer);

    waitIdle();

    if (numDocs == 0) {
      // nothing to do!
      if (infoStream != null) {
        message("flush: no docs; skipping");
      }
      // Lock order: IW -> DW -> BD
      pushDeletes(null, segmentInfos);
      return null;
    }

    if (aborting) {
      if (infoStream != null) {
        message("flush: skip because aborting is set");
      }
      return null;
    }

    boolean success = false;

    SegmentInfo newSegment;

    try {
      assert nextDocID == numDocs;
      assert waitQueue.numWaiting == 0;
      assert waitQueue.waitingBytes == 0;

      if (infoStream != null) {
        message("flush postings as segment " + segment + " numDocs=" + numDocs);
      }

      final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                                                 numDocs, writer.getConfig().getTermIndexInterval(),
                                                                 SegmentCodecs.build(fieldInfos, writer.codecs));

      newSegment = new SegmentInfo(segment, numDocs, directory, false, fieldInfos.hasProx(), flushState.segmentCodecs, false);

      Collection<DocConsumerPerThread> threads = new HashSet<DocConsumerPerThread>();
      for (DocumentsWriterThreadState threadState : threadStates) {
        threads.add(threadState.consumer);
      }

      double startMBUsed = bytesUsed()/1024./1024.;

      consumer.flush(threads, flushState);
      newSegment.setHasVectors(flushState.hasVectors);

      if (infoStream != null) {
        message("new segment has " + (flushState.hasVectors ? "vectors" : "no vectors"));
        message("flushedFiles=" + newSegment.files());
        message("flushed codecs=" + newSegment.getSegmentCodecs());
      }

      if (mergePolicy.useCompoundFile(segmentInfos, newSegment)) {
        final String cfsFileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        if (infoStream != null) {
          message("flush: create compound file \"" + cfsFileName + "\"");
        }

        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, cfsFileName);
        for(String fileName : newSegment.files()) {
          cfsWriter.addFile(fileName);
        }
        cfsWriter.close();
        deleter.deleteNewFiles(newSegment.files());
        newSegment.setUseCompoundFile(true);
      }

      if (infoStream != null) {
        message("flush: segment=" + newSegment);
        final double newSegmentSizeNoStore = newSegment.sizeInBytes(false)/1024./1024.;
        final double newSegmentSize = newSegment.sizeInBytes(true)/1024./1024.;
        message("  ramUsed=" + nf.format(startMBUsed) + " MB" +
                " newFlushedSize=" + nf.format(newSegmentSize) + " MB" +
                " (" + nf.format(newSegmentSizeNoStore) + " MB w/o doc stores)" +
                " docs/MB=" + nf.format(numDocs / newSegmentSize) +
                " new/old=" + nf.format(100.0 * newSegmentSizeNoStore / startMBUsed) + "%");
      }

      success = true;
    } finally {
      notifyAll();
      if (!success) {
        if (segment != null) {
          deleter.refresh(segment);
        }
        abort();
      }
    }

    doAfterFlush();

    // Lock order: IW -> DW -> BD
    pushDeletes(newSegment, segmentInfos);

    return newSegment;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634130317/fstmerge_var2_6664707036292308495

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_b2d48_f592c/rev_b2d48-f592c/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634137519/fstmerge_var1_6970953550821962048
public DocumentsWriterThreadState(DocumentsWriter docWriter) throws IOException {
    this.docWriter = docWriter;
    docState = new DocumentsWriter.DocState();
    docState.infoStream = docWriter.infoStream;
    docState.similarity = docWriter.similarity;
    docState.docWriter = docWriter;
    consumer = docWriter.consumer.addThread(this);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634137519/fstmerge_base_8006332580177556247
public DocumentsWriterThreadState(DocumentsWriter docWriter) throws IOException {
    this.docWriter = docWriter;
    docState = new DocumentsWriter.DocState();
    docState.maxFieldLength = docWriter.maxFieldLength;
    docState.infoStream = docWriter.infoStream;
    docState.similarity = docWriter.similarity;
    docState.docWriter = docWriter;
    consumer = docWriter.consumer.addThread(this);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419634137519/fstmerge_var2_7422601005644490325

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_b2d48_f592c/rev_b2d48-f592c/lucene/src/java/org/apache/lucene/index/DocumentsWriterThreadState.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6a128_03676/rev_6a128-03676.revisions
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testNRTThreads() throws Exception {

    final long t0 = System.currentTimeMillis();

    if (CodecProvider.getDefault().getDefaultFieldCodec().equals("SimpleText")) {
      // no
      CodecProvider.getDefault().setDefaultFieldCodec("Standard");
    }

    final LineFileDocs docs = new LineFileDocs(random);
    final File tempDir = _TestUtil.getTempDir("nrtopenfiles");
    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));
    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());
    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {
      @Override
      public void warm(IndexReader reader) throws IOException {
        if (VERBOSE) {
          System.out.println("TEST: now warm merged reader=" + reader);
        }
        final int maxDoc = reader.maxDoc();
        final Bits delDocs = reader.getDeletedDocs();
        int sum = 0;
        final int inc = Math.max(1, maxDoc/50);
        for(int docID=0;docID<maxDoc;docID += inc) {
          if (delDocs == null || !delDocs.get(docID)) {
            final Document doc = reader.document(docID);
            sum += doc.getFields().size();
          }
        }

        sum += new IndexSearcher(reader).search(new TermQuery(new Term("body", "united")), 10).totalHits;

        if (VERBOSE) {
          System.out.println("TEST: warm visited " + sum + " fields");
        }
      }
      });

    final IndexWriter writer = new IndexWriter(dir, conf);
    if (VERBOSE) {
      writer.setInfoStream(System.out);
    }
    MergeScheduler ms = writer.getConfig().getMergeScheduler();
    if (ms instanceof ConcurrentMergeScheduler) {
      // try to keep max file open count down
      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);
      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);
    }
    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();
    if (lmp.getMergeFactor() > 5) {
      lmp.setMergeFactor(5);
    }

    final int NUM_INDEX_THREADS = 2;
    final int NUM_SEARCH_THREADS = 3;
    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;

    final AtomicBoolean failed = new AtomicBoolean();
    final AtomicInteger addCount = new AtomicInteger();
    final AtomicInteger delCount = new AtomicInteger();

    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());

    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;
    Thread[] threads = new Thread[NUM_INDEX_THREADS];
    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {
      threads[thread] = new Thread() {
          @Override
          public void run() {
            final List<String> toDeleteIDs = new ArrayList<String>();
            while(System.currentTimeMillis() < stopTime && !failed.get()) {
              try {
                Document doc = docs.nextDoc();
                if (doc == null) {
                  break;
                }
                final String addedField;
                if (random.nextBoolean()) {
                  addedField = "extra" + random.nextInt(10);
                  doc.add(new Field(addedField, "a random field", Field.Store.NO, Field.Index.ANALYZED));
                } else {
                  addedField = null;
                }
                if (random.nextBoolean()) {
                  if (VERBOSE) {
                    //System.out.println(Thread.currentThread().getName() + ": add doc id:" + doc.get("id"));
                  }
                  writer.addDocument(doc);
                } else {
                  // we use update but it never replaces a
                  // prior doc
                  if (VERBOSE) {
                    //System.out.println(Thread.currentThread().getName() + ": update doc id:" + doc.get("id"));
                  }
                  writer.updateDocument(new Term("id", doc.get("id")), doc);
                }
                if (random.nextInt(5) == 3) {
                  if (VERBOSE) {
                    //System.out.println(Thread.currentThread().getName() + ": buffer del id:" + doc.get("id"));
                  }
                  toDeleteIDs.add(doc.get("id"));
                }
                if (random.nextInt(50) == 17) {
                  if (VERBOSE) {
                    System.out.println(Thread.currentThread().getName() + ": apply " + toDeleteIDs.size() + " deletes");
                  }
                  for(String id : toDeleteIDs) {
                    writer.deleteDocuments(new Term("id", id));
                  }
                  final int count = delCount.addAndGet(toDeleteIDs.size());
                  if (VERBOSE) {
                    System.out.println(Thread.currentThread().getName() + ": tot " + count + " deletes");
                  }
                  delIDs.addAll(toDeleteIDs);
                  toDeleteIDs.clear();
                }
                addCount.getAndIncrement();
                if (addedField != null) {
                  doc.removeField(addedField);
                }
              } catch (Exception exc) {
                System.out.println(Thread.currentThread().getName() + ": hit exc");
                exc.printStackTrace();
                failed.set(true);
                throw new RuntimeException(exc);
              }
            }
            if (VERBOSE) {
              System.out.println(Thread.currentThread().getName() + ": indexing done");
            }
          }
        };
      threads[thread].setDaemon(true);
      threads[thread].start();
    }

    if (VERBOSE) {
      System.out.println("TEST: DONE start indexing threads [" + (System.currentTimeMillis()-t0) + " ms]");
    }

    // let index build up a bit
    Thread.sleep(100);

    IndexReader r = IndexReader.open(writer);
    boolean any = false;

    // silly starting guess:
    final AtomicInteger totTermCount = new AtomicInteger(100);

    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory("NRT search threads"));

    while(System.currentTimeMillis() < stopTime && !failed.get()) {
      if (random.nextBoolean()) {
        if (VERBOSE) {
          System.out.println("TEST: now reopen r=" + r);
        }
        final IndexReader r2 = r.reopen();
        if (r != r2) {
          r.close();
          r = r2;
        }
      } else {
        if (VERBOSE) {
          System.out.println("TEST: now close reader=" + r);
        }
        r.close();
        writer.commit();
        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();
        if (openDeletedFiles.size() > 0) {
          System.out.println("OBD files: " + openDeletedFiles);
        }
        any |= openDeletedFiles.size() > 0;
        //assertEquals("open but deleted: " + openDeletedFiles, 0, openDeletedFiles.size());
        if (VERBOSE) {
          System.out.println("TEST: now open");
        }
        r = IndexReader.open(writer);
      }
      if (VERBOSE) {
        System.out.println("TEST: got new reader=" + r);
      }
      //System.out.println("numDocs=" + r.numDocs() + "
      //openDelFileCount=" + dir.openDeleteFileCount());

      smokeTestReader(r);

      if (r.numDocs() > 0) {

        final IndexSearcher s = new IndexSearcher(r, es);

        // run search threads
        final long searchStopTime = System.currentTimeMillis() + 500;
        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];
        final AtomicInteger totHits = new AtomicInteger();
        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {
          searchThreads[thread] = new Thread() {
              @Override
                public void run() {
                try {
                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), "body").iterator();
                  int seenTermCount = 0;
                  int shift;
                  int trigger;
                  if (totTermCount.get() == 0) {
                    shift = 0;
                    trigger = 1;
                  } else {
                    shift = random.nextInt(totTermCount.get()/10);
                    trigger = totTermCount.get()/10;
                  }
                  while(System.currentTimeMillis() < searchStopTime) {
                    BytesRef term = termsEnum.next();
                    if (term == null) {
                      if (seenTermCount == 0) {
                        break;
                      }
                      totTermCount.set(seenTermCount);
                      seenTermCount = 0;
                      trigger = totTermCount.get()/10;
                      //System.out.println("trigger " + trigger);
                      shift = random.nextInt(totTermCount.get()/10);
                      termsEnum.seek(new BytesRef(""));
                      continue;
                    }
                    seenTermCount++;
                    // search 10 terms
                    if (trigger == 0) {
                      trigger = 1;
                    }
                    if ((seenTermCount + shift) % trigger == 0) {
                      //if (VERBOSE) {
                      //System.out.println(Thread.currentThread().getName() + " now search body:" + term.utf8ToString());
                      //}
                      totHits.addAndGet(runQuery(s, new TermQuery(new Term("body", term))));
                    }
                  }
                  if (VERBOSE) {
                    System.out.println(Thread.currentThread().getName() + ": search done");
                  }
                } catch (Throwable t) {
                  failed.set(true);
                  t.printStackTrace(System.out);
                  throw new RuntimeException(t);
                }
              }
            };
          searchThreads[thread].setDaemon(true);
          searchThreads[thread].start();
        }

        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {
          searchThreads[thread].join();
        }

        if (VERBOSE) {
          System.out.println("TEST: DONE search: totHits=" + totHits);
        }
      } else {
        Thread.sleep(100);
      }
    }

    es.shutdown();
    es.awaitTermination(1, TimeUnit.SECONDS);

    if (VERBOSE) {
      System.out.println("TEST: all searching done [" + (System.currentTimeMillis()-t0) + " ms]");
    }

    //System.out.println("numDocs=" + r.numDocs() + " openDelFileCount=" + dir.openDeleteFileCount());
    r.close();
    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();
    if (openDeletedFiles.size() > 0) {
      System.out.println("OBD files: " + openDeletedFiles);
    }
    any |= openDeletedFiles.size() > 0;

    assertFalse("saw non-zero open-but-deleted count", any);
    if (VERBOSE) {
      System.out.println("TEST: now join");
    }
    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {
      threads[thread].join();
    }
    if (VERBOSE) {
      System.out.println("TEST: done join [" + (System.currentTimeMillis()-t0) + " ms]; addCount=" + addCount + " delCount=" + delCount);
    }

    final IndexReader r2 = writer.getReader();
    final IndexSearcher s = new IndexSearcher(r2);
    for(String id : delIDs) {
      final TopDocs hits = s.search(new TermQuery(new Term("id", id)), 1);
      if (hits.totalHits != 0) {
        fail("doc id=" + id + " is supposed to be deleted, but got docID=" + hits.scoreDocs[0].doc);
      }
    }
    assertEquals("index=" + writer.segString() + " addCount=" + addCount + " delCount=" + delCount, addCount.get() - delCount.get(), r2.numDocs());
    r2.close();

    writer.commit();
    assertEquals("index=" + writer.segString() + " addCount=" + addCount + " delCount=" + delCount, addCount.get() - delCount.get(), writer.numDocs());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635004544/fstmerge_var1_128012250007827658

    assertFalse(writer.anyNonBulkMerges);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635004544/fstmerge_base_7936482365342653887
      
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635004544/fstmerge_var2_1782788156079696479
    writer.close(false);
    _TestUtil.checkIndex(dir);
    dir.close();
    _TestUtil.rmDir(tempDir);
    docs.close();
    if (VERBOSE) {
      System.out.println("TEST: done [" + (System.currentTimeMillis()-t0) + " ms]");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6a128_03676/rev_6a128-03676/lucene/src/test/org/apache/lucene/index/TestNRTThreads.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635022014/fstmerge_var1_1285012238811513291
public NormsWriterPerField(final DocInverterPerField docInverterPerField, final NormsWriterPerThread perThread, final FieldInfo fieldInfo) {
    this.perThread = perThread;
    this.fieldInfo = fieldInfo;
    docState = perThread.docState;
    fieldState = docInverterPerField.fieldState;
    similarity = docState.similarityProvider.get(fieldInfo.name);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635022014/fstmerge_base_3579002146349145390
public NormsWriterPerField(final DocInverterPerField docInverterPerField, final NormsWriterPerThread perThread, final FieldInfo fieldInfo) {
    this.perThread = perThread;
    this.fieldInfo = fieldInfo;
    docState = perThread.docState;
    fieldState = docInverterPerField.fieldState;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635022014/fstmerge_var2_5584732110143746502

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6a128_03676/rev_6a128-03676/lucene/src/java/org/apache/lucene/index/NormsWriterPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635024155/fstmerge_var1_1391606595150918932
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635024155/fstmerge_base_1647556929844461946
synchronized void setSimilarity(Similarity similarity) {
    this.similarity = similarity;
    for(int i=0;i<threadStates.length;i++) {
      threadStates[i].docState.similarity = similarity;
    }
  }
=======
synchronized void setSimilarity(Similarity similarity) {
    this.similarity = similarity;
    pushConfigChange();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635024155/fstmerge_var2_530691028645122521

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6a128_03676/rev_6a128-03676/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635024248/fstmerge_var1_4322434995160650412
DocumentsWriter(Directory directory, IndexWriter writer, IndexingChain indexingChain, int maxThreadStates, FieldInfos fieldInfos, BufferedDeletes bufferedDeletes) throws IOException {
    this.directory = directory;
    this.writer = writer;
    this.similarityProvider = writer.getConfig().getSimilarityProvider();
    this.maxThreadStates = maxThreadStates;
    this.fieldInfos = fieldInfos;
    this.bufferedDeletes = bufferedDeletes;
    flushControl = writer.flushControl;

    consumer = indexingChain.getChain(this);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635024248/fstmerge_base_8747211175972745485
DocumentsWriter(Directory directory, IndexWriter writer, IndexingChain indexingChain, int maxThreadStates, FieldInfos fieldInfos, BufferedDeletes bufferedDeletes) throws IOException {
    this.directory = directory;
    this.writer = writer;
    this.similarity = writer.getConfig().getSimilarity();
    this.maxThreadStates = maxThreadStates;
    this.fieldInfos = fieldInfos;
    this.bufferedDeletes = bufferedDeletes;
    flushControl = writer.flushControl;

    consumer = indexingChain.getChain(this);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635024248/fstmerge_var2_2386961897600820433

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6a128_03676/rev_6a128-03676/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private int mergeMiddle(MergePolicy.OneMerge merge)
    throws CorruptIndexException, IOException {

    merge.checkAborted(directory);

    final String mergedName = merge.info.name;

    int mergedDocCount = 0;

    SegmentInfos sourceSegments = merge.segments;
    final int numSegments = sourceSegments.size();

    SegmentMerger merger = new SegmentMerger(directory, termIndexInterval, mergedName, merge,
                                             codecs, payloadProcessorProvider,
                                             ((FieldInfos) docWriter.getFieldInfos().clone()));

    if (infoStream != null) {
      message("merging " + merge.segString(directory) + " mergeVectors=" + merger.fieldInfos().hasVectors());
    }

    merge.info.setHasVectors(merger.fieldInfos().hasVectors());
    merge.readers = new SegmentReader[numSegments];
    merge.readersClone = new SegmentReader[numSegments];

    // This is try/finally to make sure merger's readers are
    // closed:
    boolean success = false;
    try {
      int totDocCount = 0;

      for (int i = 0; i < numSegments; i++) {
        final SegmentInfo info = sourceSegments.info(i);

        // Hold onto the "live" reader; we will use this to
        // commit merged deletes
        SegmentReader reader = merge.readers[i] = readerPool.get(info, true,
                                                                 MERGE_READ_BUFFER_SIZE,
                                                                 -config.getReaderTermsIndexDivisor());

        // We clone the segment readers because other
        // deletes may come in while we're merging so we
        // need readers that will not change
        SegmentReader clone = merge.readersClone[i] = (SegmentReader) reader.clone(true);
        merger.add(clone);

        totDocCount += clone.numDocs();
      }

      if (infoStream != null) {
        message("merge: total "+totDocCount+" docs");
      }

      merge.checkAborted(directory);

      // This is where all the work happens:
      mergedDocCount = merge.info.docCount = merger.merge();

      // Record which codec was used to write the segment
      merge.info.setSegmentCodecs(merger.getSegmentCodecs());

      if (infoStream != null) {
        message("merge segmentCodecs=" + merger.getSegmentCodecs());
        message("merge store matchedCount=" + merger.getMatchedSubReaderCount() + " vs " + numSegments);
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635027640/fstmerge_var1_4622527211700621920
      anyNonBulkMerges |= merger.getMatchedSubReaderCount() != numSegments;
      
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635027640/fstmerge_base_6061158583666783210
      
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635027640/fstmerge_var2_967013856600134994
      assert mergedDocCount == totDocCount;

      // Very important to do this before opening the reader
      // because codec must know if prox was written for
      // this segment:
      //System.out.println("merger set hasProx=" + merger.hasProx() + " seg=" + merge.info.name);
      merge.info.setHasProx(merger.fieldInfos().hasProx());

      boolean useCompoundFile;
      synchronized (this) { // Guard segmentInfos
        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);
      }

      if (useCompoundFile) {
        success = false;
        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        try {
          if (infoStream != null) {
            message("create compound file " + compoundFileName);
          }
          merger.createCompoundFile(compoundFileName, merge.info);
          success = true;
        } catch (IOException ioe) {
          synchronized(this) {
            if (merge.isAborted()) {
              // This can happen if rollback or close(false)
              // is called -- fall through to logic below to
              // remove the partially created CFS:
            } else {
              handleMergeException(ioe, merge);
            }
          }
        } catch (Throwable t) {
          handleMergeException(t, merge);
        } finally {
          if (!success) {
            if (infoStream != null) {
              message("hit exception creating compound file during merge");
            }

            synchronized(this) {
              deleter.deleteFile(compoundFileName);
              deleter.deleteNewFiles(merge.info.files());
            }
          }
        }

        success = false;

        synchronized(this) {

          // delete new non cfs files directly: they were never
          // registered with IFD
          deleter.deleteNewFiles(merge.info.files());

          if (merge.isAborted()) {
            if (infoStream != null) {
              message("abort merge after building CFS");
            }
            deleter.deleteFile(compoundFileName);
            return 0;
          }
        }

        merge.info.setUseCompoundFile(true);
      }

      final int termsIndexDivisor;
      final boolean loadDocStores;

      if (poolReaders && mergedSegmentWarmer != null) {
        // Load terms index & doc stores so the segment
        // warmer can run searches, load documents/term
        // vectors
        termsIndexDivisor = config.getReaderTermsIndexDivisor();
        loadDocStores = true;
      } else {
        termsIndexDivisor = -1;
        loadDocStores = false;
      }

      // TODO: in the non-realtime case, we may want to only
      // keep deletes (it's costly to open entire reader
      // when we just need deletes)

      final SegmentReader mergedReader = readerPool.get(merge.info, loadDocStores, BufferedIndexInput.BUFFER_SIZE, termsIndexDivisor);
      try {
        if (poolReaders && mergedSegmentWarmer != null) {
          mergedSegmentWarmer.warm(mergedReader);
        }

        if (!commitMerge(merge, mergedReader)) {
          // commitMerge will return false if this merge was aborted
          return 0;
        }
      } finally {
        synchronized(this) {
          if (readerPool.release(mergedReader)) {
            // Must checkpoint after releasing the
            // mergedReader since it may have written a new
            // deletes file:
            checkpoint();
          }
        }
      }

      success = true;

    } finally {
      // Readers are already closed in commitMerge if we didn't hit
      // an exc:
      if (!success) {
        closeMergeReaders(merge, true);
      }
    }

    return mergedDocCount;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6a128_03676/rev_6a128-03676/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635031404/fstmerge_var1_1832621913478809766
public DocumentsWriterThreadState(DocumentsWriter docWriter) throws IOException {
    this.docWriter = docWriter;
    docState = new DocumentsWriter.DocState();
    docState.infoStream = docWriter.infoStream;
    docState.similarityProvider = docWriter.similarityProvider;
    docState.docWriter = docWriter;
    consumer = docWriter.consumer.addThread(this);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635031404/fstmerge_base_3433095858214286253
public DocumentsWriterThreadState(DocumentsWriter docWriter) throws IOException {
    this.docWriter = docWriter;
    docState = new DocumentsWriter.DocState();
    docState.infoStream = docWriter.infoStream;
    docState.similarity = docWriter.similarity;
    docState.docWriter = docWriter;
    consumer = docWriter.consumer.addThread(this);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635031404/fstmerge_var2_8896255732716068290

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6a128_03676/rev_6a128-03676/lucene/src/java/org/apache/lucene/index/DocumentsWriterThreadState.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a90cb_776df/rev_a90cb-776df.revisions
Conflict type: LineBasedMCFd
Conflict body: 
private void write(final FieldInfos fieldInfos, final Directory dir, final FieldData[] fields, boolean allowPreFlex) throws Throwable {

    final int termIndexInterval = _TestUtil.nextInt(random, 13, 27);
    final SegmentCodecs codecInfo = SegmentCodecs.build(fieldInfos, CodecProvider.getDefault());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635887277/fstmerge_var1_2776704261067652678
    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, 10000, termIndexInterval, codecInfo, null);

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635887277/fstmerge_base_4303148021090473313
    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, 10000, termIndexInterval, codecInfo);

=======
    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, 10000, termIndexInterval, codecInfo, new AtomicLong());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635887277/fstmerge_var2_5587424298174873248
    final FieldsConsumer consumer = state.segmentCodecs.codec().fieldsConsumer(state);
    Arrays.sort(fields);
    for (final FieldData field : fields) {
      if (!allowPreFlex && codecInfo.codecs[field.fieldInfo.codecId] instanceof PreFlexCodec) {
        // code below expects unicode sort order
        continue;
      }
      field.write(consumer);
    }
    consumer.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a90cb_776df/rev_a90cb-776df/lucene/src/test/org/apache/lucene/index/TestCodecs.java
Conflict type: LineBasedMCFd
Conflict body: 
SegmentWriteState(SegmentWriteState state, String codecId) {
    infoStream = state.infoStream;
    directory = state.directory;
    segmentName = state.segmentName;
    fieldInfos = state.fieldInfos;
    numDocs = state.numDocs;
    termIndexInterval = state.termIndexInterval;
    segmentCodecs = state.segmentCodecs;
    flushedFiles = state.flushedFiles;
    this.codecId = codecId;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635908491/fstmerge_var1_6139981782205329866
    segDeletes = state.segDeletes;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635908491/fstmerge_base_6354918037802891087
=======
    bytesUsed = state.bytesUsed;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635908491/fstmerge_var2_3348051836288757830
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a90cb_776df/rev_a90cb-776df/lucene/src/java/org/apache/lucene/index/SegmentWriteState.java
Conflict type: LineBasedMCFd
Conflict body: 
synchronized SegmentInfo flush(IndexWriter writer, IndexFileDeleter deleter, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {

    final long startTime = System.currentTimeMillis();

    // We change writer's segmentInfos:
    assert Thread.holdsLock(writer);

    waitIdle();

    if (numDocs == 0) {
      // nothing to do!
      if (infoStream != null) {
        message("flush: no docs; skipping");
      }
      // Lock order: IW -> DW -> BD
      pushDeletes(null, segmentInfos);
      return null;
    }

    if (aborting) {
      if (infoStream != null) {
        message("flush: skip because aborting is set");
      }
      return null;
    }

    boolean success = false;

    SegmentInfo newSegment;

    try {
      assert nextDocID == numDocs;
      assert waitQueue.numWaiting == 0;
      assert waitQueue.waitingBytes == 0;

      if (infoStream != null) {
        message("flush postings as segment " + segment + " numDocs=" + numDocs);
      }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635908710/fstmerge_var1_1615271902704008610
      final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                                                 numDocs, writer.getConfig().getTermIndexInterval(),
                                                                 SegmentCodecs.build(fieldInfos, writer.codecs),
                                                                 pendingDeletes);
      // Apply delete-by-docID now (delete-byDocID only
      // happens when an exception is hit processing that
      // doc, eg if analyzer has some problem w/ the text):
      if (pendingDeletes.docIDs.size() > 0) {
        flushState.deletedDocs = new BitVector(numDocs);
        for(int delDocID : pendingDeletes.docIDs) {
          flushState.deletedDocs.set(delDocID);
        }
        pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);
        pendingDeletes.docIDs.clear();
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635908710/fstmerge_base_2252803863844664650
      final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                                                 numDocs, writer.getConfig().getTermIndexInterval(),
                                                                 SegmentCodecs.build(fieldInfos, writer.codecs));
=======
      final SegmentWriteState flushState = segWriteState();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635908710/fstmerge_var2_4823881546861228701

      newSegment = new SegmentInfo(segment, numDocs, directory, false, fieldInfos.hasProx(), flushState.segmentCodecs, false);

      Collection<DocConsumerPerThread> threads = new HashSet<DocConsumerPerThread>();
      for (DocumentsWriterThreadState threadState : threadStates) {
        threads.add(threadState.consumer);
      }

      double startMBUsed = bytesUsed()/1024./1024.;

      consumer.flush(threads, flushState);

      newSegment.setHasVectors(flushState.hasVectors);

      if (infoStream != null) {
        message("new segment has " + (flushState.hasVectors ? "vectors" : "no vectors"));
        if (flushState.deletedDocs != null) {
          message("new segment has " + flushState.deletedDocs.count() + " deleted docs");
        }
        message("flushedFiles=" + newSegment.files());
        message("flushed codecs=" + newSegment.getSegmentCodecs());
      }

      if (mergePolicy.useCompoundFile(segmentInfos, newSegment)) {
        final String cfsFileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        if (infoStream != null) {
          message("flush: create compound file \"" + cfsFileName + "\"");
        }

        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, cfsFileName);
        for(String fileName : newSegment.files()) {
          cfsWriter.addFile(fileName);
        }
        cfsWriter.close();
        deleter.deleteNewFiles(newSegment.files());
        newSegment.setUseCompoundFile(true);
      }

      // Must write deleted docs after the CFS so we don't
      // slurp the del file into CFS:
      if (flushState.deletedDocs != null) {
        final int delCount = flushState.deletedDocs.count();
        assert delCount > 0;
        newSegment.setDelCount(delCount);
        newSegment.advanceDelGen();
        final String delFileName = newSegment.getDelFileName();
        boolean success2 = false;
        try {
          flushState.deletedDocs.write(directory, delFileName);
          success2 = true;
        } finally {
          if (!success2) {
            try {
              directory.deleteFile(delFileName);
            } catch (Throwable t) {
              // suppress this so we keep throwing the
              // original exception
            }
          }
        }
      }

      if (infoStream != null) {
        message("flush: segment=" + newSegment);
        final double newSegmentSizeNoStore = newSegment.sizeInBytes(false)/1024./1024.;
        final double newSegmentSize = newSegment.sizeInBytes(true)/1024./1024.;
        message("  ramUsed=" + nf.format(startMBUsed) + " MB" +
                " newFlushedSize=" + nf.format(newSegmentSize) + " MB" +
                " (" + nf.format(newSegmentSizeNoStore) + " MB w/o doc stores)" +
                " docs/MB=" + nf.format(numDocs / newSegmentSize) +
                " new/old=" + nf.format(100.0 * newSegmentSizeNoStore / startMBUsed) + "%");
      }

      success = true;
    } finally {
      notifyAll();
      if (!success) {
        if (segment != null) {
          deleter.refresh(segment);
        }
        abort();
      }
    }

    doAfterFlush();

    // Lock order: IW -> DW -> BD
    pushDeletes(newSegment, segmentInfos);
    if (infoStream != null) {
      message("flush time " + (System.currentTimeMillis()-startTime) + " msec");
    }

    return newSegment;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a90cb_776df/rev_a90cb-776df/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private int mergeFields() throws CorruptIndexException, IOException {

    for (IndexReader reader : readers) {
      if (reader instanceof SegmentReader) {
        SegmentReader segmentReader = (SegmentReader) reader;
        FieldInfos readerFieldInfos = segmentReader.fieldInfos();
        int numReaderFieldInfos = readerFieldInfos.size();
        for (int j = 0; j < numReaderFieldInfos; j++) {
          fieldInfos.add(readerFieldInfos.fieldInfo(j));
        }
      } else {
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION_OFFSET), true, true, true, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION), true, true, false, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_OFFSET), true, false, true, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR), true, false, false, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.OMIT_TERM_FREQ_AND_POSITIONS), false, false, false, false, true);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.STORES_PAYLOADS), false, false, false, true, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.INDEXED), false, false, false, false, false);
        fieldInfos.add(reader.getFieldNames(FieldOption.UNINDEXED), false);
        fieldInfos.add(reader.getFieldNames(FieldOption.DOC_VALUES), false);
      }
    }
    final SegmentCodecs codecInfo = SegmentCodecs.build(fieldInfos, this.codecs);
    fieldInfos.write(directory, segment + ".fnm");

    int docCount = 0;

    setMatchingSegmentReaders();

    final FieldsWriter fieldsWriter = new FieldsWriter(directory, segment, fieldInfos);

    try {
      int idx = 0;
      for (IndexReader reader : readers) {
        final SegmentReader matchingSegmentReader = matchingSegmentReaders[idx++];
        FieldsReader matchingFieldsReader = null;
        if (matchingSegmentReader != null) {
          final FieldsReader fieldsReader = matchingSegmentReader.getFieldsReader();
          if (fieldsReader != null) {
            matchingFieldsReader = fieldsReader;
          }
        }
        if (reader.hasDeletions()) {
          docCount += copyFieldsWithDeletions(fieldsWriter,
                                              reader, matchingFieldsReader);
        } else {
          docCount += copyFieldsNoDeletions(fieldsWriter,
                                            reader, matchingFieldsReader);
        }
      }
    } finally {
      fieldsWriter.close();
    }

    final String fileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.FIELDS_INDEX_EXTENSION);
    final long fdxFileLength = directory.fileLength(fileName);

    if (4+((long) docCount)*8 != fdxFileLength)
      // This is most likely a bug in Sun JRE 1.6.0_04/_05;
      // we detect that the bug has struck, here, and
      // throw an exception to prevent the corruption from
      // entering the index.  See LUCENE-1282 for
      // details.
      throw new RuntimeException("mergeFields produced an invalid result: docCount is " + docCount + " but fdx file size is " + fdxFileLength + " file=" + fileName + " file exists?=" + directory.fileExists(fileName) + "; now aborting this merge to prevent index corruption");

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635909249/fstmerge_var1_8918400095553669161
    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, docCount, termIndexInterval, codecInfo, null);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635909249/fstmerge_base_6989963239179705731
    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, docCount, termIndexInterval, codecInfo);
=======
    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, docCount, termIndexInterval, codecInfo, new AtomicLong(0));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635909249/fstmerge_var2_2126882703286177301
    
    return docCount;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a90cb_776df/rev_a90cb-776df/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635913554/fstmerge_var1_2691795420247082834
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635913554/fstmerge_base_9156249761964807729
@Override
  public TermsConsumer addField(FieldInfo field) throws IOException {
    assert currentField == null || currentField.name.compareTo(field.name) < 0;
    currentField = field;
    TermsIndexWriterBase.FieldWriter fieldIndexWriter = termsIndexWriter.addField(field);
    TermsConsumer terms = new TermsWriter(fieldIndexWriter, field, postingsWriter);
    fields.add(terms);
    return terms;
  }
=======
@Override
  public TermsConsumer addField(FieldInfo field) throws IOException {
    assert currentField == null || currentField.name.compareTo(field.name) < 0 : "current field name " + (currentField == null? null: currentField.name) + " given: " +field.name;
    currentField = field;
    TermsIndexWriterBase.FieldWriter fieldIndexWriter = termsIndexWriter.addField(field);
    TermsConsumer terms = new TermsWriter(fieldIndexWriter, field, postingsWriter);
    fields.add(terms);
    return terms;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635913554/fstmerge_var2_2815312758043648325

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a90cb_776df/rev_a90cb-776df/lucene/src/java/org/apache/lucene/index/codecs/PrefixCodedTermsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635964495/fstmerge_var1_7375774558494119173
@Override
  public void write(byte b[]) throws IOException {
    write(b,0,b.length);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635964495/fstmerge_base_2587873567104895656
public void write(byte b[]) throws IOException {
    write(b,0,b.length);
=======
public void write(byte b) throws IOException {
    if (pos >= buf.length) {
      out.write(buf);
      written += pos;
      pos=0;
    }
    buf[pos++] = b;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419635964495/fstmerge_var2_2324472318204661774
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a90cb_776df/rev_a90cb-776df/solr/src/common/org/apache/solr/common/util/FastOutputStream.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_b8fe6_8bc92/rev_b8fe6-8bc92.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808.revisions
Conflict type: LineBasedMCFd
Conflict body: 
public void testBasic() throws IOException {
    Set<String> fileExtensions = new HashSet<String>();
    fileExtensions.add(IndexFileNames.FIELDS_EXTENSION);
    fileExtensions.add(IndexFileNames.FIELDS_INDEX_EXTENSION);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637687105/fstmerge_var1_656241664793960034
    
    MockDirectoryWrapper primaryDir = new MockDirectoryWrapper(random, new RAMDirectory());
    primaryDir.setCheckIndexOnClose(false); // only part of an index
    MockDirectoryWrapper secondaryDir = new MockDirectoryWrapper(random, new RAMDirectory());
    secondaryDir.setCheckIndexOnClose(false); // only part of an index
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637687105/fstmerge_base_7291863912930047279
    
    Directory primaryDir = new MockDirectoryWrapper(random, new RAMDirectory());
    Directory secondaryDir = new MockDirectoryWrapper(random, new RAMDirectory());
    
=======

    Directory primaryDir = new MockDirectoryWrapper(random, new RAMDirectory());
    Directory secondaryDir = new MockDirectoryWrapper(random, new RAMDirectory());

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637687105/fstmerge_var2_7546370389867462038
    FileSwitchDirectory fsd = new FileSwitchDirectory(fileExtensions, primaryDir, secondaryDir, true);
    IndexWriter writer = new IndexWriter(
        fsd,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
            setMergePolicy(newLogMergePolicy(false))
    );
    TestIndexWriterReader.createIndexNoClose(true, "ram", writer);
    IndexReader reader = IndexReader.open(writer, true);
    assertEquals(100, reader.maxDoc());
    writer.commit();
    // we should see only fdx,fdt files here
    String[] files = primaryDir.listAll();
    assertTrue(files.length > 0);
    for (int x=0; x < files.length; x++) {
      String ext = FileSwitchDirectory.getExtension(files[x]);
      assertTrue(fileExtensions.contains(ext));
    }
    files = secondaryDir.listAll();
    assertTrue(files.length > 0);
    // we should not see fdx,fdt files here
    for (int x=0; x < files.length; x++) {
      String ext = FileSwitchDirectory.getExtension(files[x]);
      assertFalse(fileExtensions.contains(ext));
    }
    reader.close();
    writer.close();

    files = fsd.listAll();
    for(int i=0;i<files.length;i++) {
      assertNotNull(files[i]);
    }
    fsd.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/test/org/apache/lucene/store/TestFileSwitchDirectory.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637687307/fstmerge_var1_2571108401873676304
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637687307/fstmerge_base_2931378386782347021
void maybeThrowIOException() throws IOException {
    if (randomIOExceptionRate > 0.0) {
      int number = Math.abs(randomState.nextInt() % 1000);
      if (number < randomIOExceptionRate*1000) {
        if (LuceneTestCase.VERBOSE) {
          System.out.println(Thread.currentThread().getName() + ": MockDirectoryWrapper: now throw random exception");
          new Throwable().printStackTrace(System.out);
        }
        throw new IOException("a random IOException");
      }
    }
  }
=======
void maybeThrowIOException() throws IOException {
    if (randomIOExceptionRate > 0.0) {
      int number = Math.abs(randomState.nextInt() % 1000);
      if (number < randomIOExceptionRate*1000) {
        throw new IOException("a random IOException");
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637687307/fstmerge_var2_7318957567818061167

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/test/org/apache/lucene/store/MockDirectoryWrapper.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testBinaryFields() throws IOException {
        Directory dir = newDirectory();
        byte[] bin = new byte[]{0, 1, 2, 3, 4, 5, 6, 7, 8, 9};
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637688195/fstmerge_var1_6661433590935908710
        
        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(newInOrderLogMergePolicy()));
        
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637688195/fstmerge_base_2134825668898275404
        
        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
        
=======

        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637688195/fstmerge_var2_1693363789129702303
        for (int i = 0; i < 10; i++) {
          addDoc(writer, "document number " + (i + 1));
          addDocumentWithFields(writer);
          addDocumentWithDifferentFields(writer);
          addDocumentWithTermVectorFields(writer);
        }
        writer.close();
        writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setMergePolicy(newInOrderLogMergePolicy()));
        Document doc = new Document();
        doc.add(new Field("bin1", bin));
        doc.add(new Field("junk", "junk text", Field.Store.NO, Field.Index.ANALYZED));
        writer.addDocument(doc);
        writer.close();
        IndexReader reader = IndexReader.open(dir, false);
        doc = reader.document(reader.maxDoc() - 1);
        Field[] fields = doc.getFields("bin1");
        assertNotNull(fields);
        assertEquals(1, fields.length);
        Field b1 = fields[0];
        assertTrue(b1.isBinary());
        byte[] data1 = b1.getBinaryValue();
        assertEquals(bin.length, b1.getBinaryLength());
        for (int i = 0; i < bin.length; i++) {
          assertEquals(bin[i], data1[i + b1.getBinaryOffset()]);
        }
        Set<String> lazyFields = new HashSet<String>();
        lazyFields.add("bin1");
        FieldSelector sel = new SetBasedFieldSelector(new HashSet<String>(), lazyFields);
        doc = reader.document(reader.maxDoc() - 1, sel);
        Fieldable[] fieldables = doc.getFieldables("bin1");
        assertNotNull(fieldables);
        assertEquals(1, fieldables.length);
        Fieldable fb1 = fieldables[0];
        assertTrue(fb1.isBinary());
        assertEquals(bin.length, fb1.getBinaryLength());
        data1 = fb1.getBinaryValue();
        assertEquals(bin.length, fb1.getBinaryLength());
        for (int i = 0; i < bin.length; i++) {
          assertEquals(bin[i], data1[i + fb1.getBinaryOffset()]);
        }
        reader.close();
        // force optimize


        writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setMergePolicy(newInOrderLogMergePolicy()));
        writer.optimize();
        writer.close();
        reader = IndexReader.open(dir, false);
        doc = reader.document(reader.maxDoc() - 1);
        fields = doc.getFields("bin1");
        assertNotNull(fields);
        assertEquals(1, fields.length);
        b1 = fields[0];
        assertTrue(b1.isBinary());
        data1 = b1.getBinaryValue();
        assertEquals(bin.length, b1.getBinaryLength());
        for (int i = 0; i < bin.length; i++) {
          assertEquals(bin[i], data1[i + b1.getBinaryOffset()]);
        }
        reader.close();
        dir.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir, int maxThreadStates,
                                          boolean doReaderPooling) throws IOException, InterruptedException {
    Map<String,Document> docs = new HashMap<String,Document>();
    for(int iter=0;iter<3;iter++) {
      if (VERBOSE) {
        System.out.println("TEST: iter=" + iter);
      }
      IndexWriter w = new MockIndexWriter(dir, newIndexWriterConfig(
          TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE)
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637688917/fstmerge_var1_2023612809161277897
               .setRAMBufferSizeMB(0.1).setMaxBufferedDocs(maxBufferedDocs).setMaxThreadStates(maxThreadStates)
               .setReaderPooling(doReaderPooling).setMergePolicy(newLogMergePolicy()));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637688917/fstmerge_base_3516019864783272181
               .setRAMBufferSizeMB(0.1).setMaxBufferedDocs(maxBufferedDocs).setMaxThreadStates(maxThreadStates)
               .setReaderPooling(doReaderPooling));
=======
               .setRAMBufferSizeMB(0.1).setMaxBufferedDocs(maxBufferedDocs).setIndexerThreadPool(new ThreadAffinityDocumentsWriterThreadPool(maxThreadStates))
               .setReaderPooling(doReaderPooling));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637688917/fstmerge_var2_8676335584612793704
      w.setInfoStream(VERBOSE ? System.out : null);
      LogMergePolicy lmp = (LogMergePolicy) w.getConfig().getMergePolicy();
      lmp.setUseCompoundFile(false);
      lmp.setMergeFactor(mergeFactor);

      threads = new IndexingThread[nThreads];
      for (int i=0; i<threads.length; i++) {
        IndexingThread th = new IndexingThread();
        th.w = w;
        th.base = 1000000*i;
        th.range = range;
        th.iterations = iterations;
        threads[i] = th;
      }

      for (int i=0; i<threads.length; i++) {
        threads[i].start();
      }
      for (int i=0; i<threads.length; i++) {
        threads[i].join();
      }

      //w.optimize();
      w.close();    

      for (int i=0; i<threads.length; i++) {
        IndexingThread th = threads[i];
        synchronized(th) {
          docs.putAll(th.docs);
        }
      }
    }

    //System.out.println("TEST: checkindex");
    _TestUtil.checkIndex(dir);

    return docs;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/test/org/apache/lucene/index/TestStressIndexing2.java
Conflict type: LineBasedMCFd
Conflict body: 
private void createIndex(int numHits) throws IOException {
        int numDocs = 500;

        Directory directory = new SeekCountingDirectory(new RAMDirectory());
        IndexWriter writer = new IndexWriter(
            directory,
            newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, true, false)).
                setMaxBufferedDocs(10).
                setMergePolicy(newLogMergePolicy(false))
        );
        for (int i = 0; i < numDocs; i++) {
            Document doc = new Document();
            String content;
            if (i % (numDocs / numHits) == 0) {
                // add a document that matches the query "term1 term2"
                content = this.term1 + " " + this.term2;
            } else if (i % 15 == 0) {
                // add a document that only contains term1
                content = this.term1 + " " + this.term1;
            } else {
                // add a document that contains term2 but not term 1
                content = this.term3 + " " + this.term2;
            }

            doc.add(newField(this.field, content, Field.Store.YES, Field.Index.ANALYZED));
            writer.addDocument(doc);
        }

        // make sure the index has only a single segment
        writer.optimize();
        writer.close();

      SegmentReader reader = getOnlySegmentReader(IndexReader.open(directory, false));

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637689174/fstmerge_var1_1202734724879379570
      this.searcher = newSearcher(reader);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637689174/fstmerge_base_7411195140057606669
        this.searcher = new IndexSearcher(reader);        
=======
        this.searcher = new IndexSearcher(reader);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637689174/fstmerge_var2_4763447013470542245
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testEmptyDirRollback() throws Exception {
    // Tests that if IW is created over an empty Directory, some documents are
    // indexed, flushed (but not committed) and then IW rolls back, then no
    // files are left in the Directory.
    Directory dir = newDirectory();
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer())
                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()));
    String[] files = dir.listAll();

    writer.setInfoStream(VERBOSE ? System.out : null);

    // Creating over empty dir should not create any files,
    // or, at most the write.lock file
    final int extraFileCount;
    if (files.length == 1) {
      assertEquals("write.lock", files[0]);
      extraFileCount = 1;
    } else {
      assertEquals(0, files.length);
      extraFileCount = 0;
    }

    Document doc = new Document();
    // create as many files as possible
    doc.add(newField("c", "val", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);
    // Adding just one document does not call flush yet.
    assertEquals("only the stored and term vector files should exist in the directory", 5 + extraFileCount, dir.listAll().length);

    doc = new Document();
    doc.add(newField("c", "val", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);

    // The second document should cause a flush.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637690256/fstmerge_var1_8357505451980894126
    assertTrue("flush should have occurred and files should have been created", dir.listAll().length > 5 + extraFileCount);

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637690256/fstmerge_base_4447047400733899659
    assertTrue("flush should have occurred and files created", dir.listAll().length > 5 + extraFileCount);
   
=======
    assertTrue("flush should have occurred and files created", dir.listAll().length > 5 + extraFileCount);

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637690256/fstmerge_var2_6813565743550610409
    // After rollback, IW should remove all files
    writer.rollback();
    assertEquals("no files should exist in the directory after rollback", 0, dir.listAll().length);

    // Since we rolled-back above, that close should be a no-op
    writer.close();
    assertEquals("expected a no-op close after IW.rollback()", 0, dir.listAll().length);
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637690281/fstmerge_var1_8131672205747530966
public void testIndexingThenDeleting() throws Exception {
    final Random r = random;

    Directory dir = newDirectory();
    FlushCountingIndexWriter w = new FlushCountingIndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, true, false)).setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMaxBufferedDeleteTerms(-1));
    w.setInfoStream(VERBOSE ? System.out : null);
    Document doc = new Document();
    doc.add(newField("field", "go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20", Field.Store.NO, Field.Index.ANALYZED));
    int num = 6 * RANDOM_MULTIPLIER;
    for (int iter = 0; iter < num; iter++) {
      int count = 0;

      final boolean doIndexing = r.nextBoolean();
      if (VERBOSE) {
        System.out.println("TEST: iter doIndexing=" + doIndexing);
      }
      if (doIndexing) {
        // Add docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.addDocument(doc);
          count++;
        }
      } else {
        // Delete docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.deleteDocuments(new Term("foo", ""+count));
          count++;
        }
      }
      assertTrue("flush happened too quickly during " + (doIndexing ? "indexing" : "deleting") + " count=" + count, count > 1500);
    }
    w.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637690281/fstmerge_base_5507304929137159807
public void testIndexingThenDeleting() throws Exception {
    final Random r = random;

    Directory dir = newDirectory();
    FlushCountingIndexWriter w = new FlushCountingIndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, true, false)).setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMaxBufferedDeleteTerms(-1));
    w.setInfoStream(VERBOSE ? System.out : null);
    Document doc = new Document();
    doc.add(newField("field", "go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20", Field.Store.NO, Field.Index.ANALYZED));
    int num = 6 * RANDOM_MULTIPLIER;
    for (int iter = 0; iter < num; iter++) {
      int count = 0;

      final boolean doIndexing = r.nextBoolean();
      if (VERBOSE) {
        System.out.println("TEST: iter doIndexing=" + doIndexing);
      }
      if (doIndexing) {
        // Add docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.addDocument(doc);
          count++;
        }
      } else {
        // Delete docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.deleteDocuments(new Term("foo", ""+count));
          count++;
        }
      }
      assertTrue("flush happened too quickly during " + (doIndexing ? "indexing" : "deleting") + " count=" + count, count > 2500);
    }
    w.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637690281/fstmerge_var2_1636066172479571994

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testDeletes1() throws Exception {
    //IndexWriter.debug2 = System.out;
    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());
    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,
        new MockAnalyzer());
    iwc.setMergeScheduler(new SerialMergeScheduler());
    iwc.setMaxBufferedDocs(5000);
    iwc.setRAMBufferSizeMB(100);
    RangeMergePolicy fsmp = new RangeMergePolicy(false);
    iwc.setMergePolicy(fsmp);
    IndexWriter writer = new IndexWriter(dir, iwc);
    writer.setInfoStream(VERBOSE ? System.out : null);
    for (int x = 0; x < 5; x++) {
      writer.addDocument(TestIndexWriterReader.createDocument(x, "1", 2));
      //System.out.println("numRamDocs(" + x + ")" + writer.numRamDocs());
    }
    //System.out.println("commit1");
    writer.commit();
    assertEquals(1, writer.segmentInfos.size());
    for (int x = 5; x < 10; x++) {
      writer.addDocument(TestIndexWriterReader.createDocument(x, "2", 2));
      //System.out.println("numRamDocs(" + x + ")" + writer.numRamDocs());
    }
    //System.out.println("commit2");
    writer.commit();
    assertEquals(2, writer.segmentInfos.size());

    for (int x = 10; x < 15; x++) {
      writer.addDocument(TestIndexWriterReader.createDocument(x, "3", 2));
      //System.out.println("numRamDocs(" + x + ")" + writer.numRamDocs());
    }

    writer.deleteDocuments(new Term("id", "1"));

    writer.deleteDocuments(new Term("id", "11"));

    // flushing without applying deletes means
    // there will still be deletes in the segment infos
    writer.flush(false, false);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637690974/fstmerge_var1_3825716794484722548
    assertTrue(writer.bufferedDeletesStream.any());
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637690974/fstmerge_base_8985020120838646921
    assertTrue(writer.bufferedDeletes.any());
    
=======
    assertTrue(writer.bufferedDeletes.any());

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637690974/fstmerge_var2_3555762241607708623
    // get reader flushes pending deletes
    // so there should not be anymore
    IndexReader r1 = writer.getReader();
    assertFalse(writer.bufferedDeletesStream.any());
    r1.close();

    // delete id:2 from the first segment
    // merge segments 0 and 1
    // which should apply the delete id:2
    writer.deleteDocuments(new Term("id", "2"));
    writer.flush(false, true);
    fsmp.doMerge = true;
    fsmp.start = 0;
    fsmp.length = 2;
    writer.maybeMerge();

    assertEquals(2, writer.segmentInfos.size());

    // id:2 shouldn't exist anymore because
    // it's been applied in the merge and now it's gone
    IndexReader r2 = writer.getReader();
    int[] id2docs = toDocsArray(new Term("id", "2"), null, r2);
    assertTrue(id2docs == null);
    r2.close();

    /**
    // added docs are in the ram buffer
    for (int x = 15; x < 20; x++) {
      writer.addDocument(TestIndexWriterReader.createDocument(x, "4", 2));
      System.out.println("numRamDocs(" + x + ")" + writer.numRamDocs());
    }
    assertTrue(writer.numRamDocs() > 0);
    // delete from the ram buffer
    writer.deleteDocuments(new Term("id", Integer.toString(13)));

    Term id3 = new Term("id", Integer.toString(3));

    // delete from the 1st segment
    writer.deleteDocuments(id3);

    assertTrue(writer.numRamDocs() > 0);

    //System.out
    //    .println("segdels1:" + writer.docWriter.deletesToString());

    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);

    // we cause a merge to happen
    fsmp.doMerge = true;
    fsmp.start = 0;
    fsmp.length = 2;
    System.out.println("maybeMerge "+writer.segmentInfos);

    SegmentInfo info0 = writer.segmentInfos.get(0);
    SegmentInfo info1 = writer.segmentInfos.get(1);

    writer.maybeMerge();
    System.out.println("maybeMerge after "+writer.segmentInfos);
    // there should be docs in RAM
    assertTrue(writer.numRamDocs() > 0);

    // assert we've merged the 1 and 2 segments
    // and still have a segment leftover == 2
    assertEquals(2, writer.segmentInfos.size());
    assertFalse(segThere(info0, writer.segmentInfos));
    assertFalse(segThere(info1, writer.segmentInfos));

    //System.out.println("segdels2:" + writer.docWriter.deletesToString());

    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);

    IndexReader r = writer.getReader();
    IndexReader r1 = r.getSequentialSubReaders()[0];
    printDelDocs(r1.getDeletedDocs());
    int[] docs = toDocsArray(id3, null, r);
    System.out.println("id3 docs:"+Arrays.toString(docs));
    // there shouldn't be any docs for id:3
    assertTrue(docs == null);
    r.close();

    part2(writer, fsmp);
    **/
    // System.out.println("segdels2:"+writer.docWriter.segmentDeletes.toString());
    //System.out.println("close");
    writer.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java
Conflict type: LineBasedMCFd
Conflict body: 
private SegmentInfo merge(SegmentInfo si1, SegmentInfo si2, String merged, boolean useCompoundFile)
   throws Exception {
      SegmentReader r1 = SegmentReader.get(true, si1, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);
      SegmentReader r2 = SegmentReader.get(true, si2, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);

      SegmentMerger merger = new SegmentMerger(si1.dir, IndexWriterConfig.DEFAULT_TERM_INDEX_INTERVAL, merged, null, CodecProvider.getDefault(), null, new FieldInfos());

      merger.add(r1);
      merger.add(r2);
      merger.merge();
      r1.close();
      r2.close();

      final SegmentInfo info = new SegmentInfo(merged, si1.docCount + si2.docCount, si1.dir,
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637691125/fstmerge_var1_8685206916621232561
                                               false, merger.getSegmentCodecs(),
                                               merger.fieldInfos());
      
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637691125/fstmerge_base_452930539671765514
                                               false, merger.fieldInfos().hasProx(), merger.getSegmentCodecs(),
                                               merger.fieldInfos().hasVectors());
      
=======
                                               false, merger.fieldInfos().hasProx(), merger.getSegmentCodecs(),
                                               merger.fieldInfos().hasVectors());

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637691125/fstmerge_var2_8417674185173444286
      if (useCompoundFile) {
        Collection<String> filesToDelete = merger.createCompoundFile(merged + ".cfs", info);
        info.setUseCompoundFile(true);
        for (final String fileToDelete : filesToDelete)
          si1.dir.deleteFile(fileToDelete);
      }

      return info;
   }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/test/org/apache/lucene/index/TestDoc.java
Conflict type: LineBasedMCFd
Conflict body: 
public SegmentInfo(Directory dir, int format, IndexInput input, CodecProvider codecs) throws IOException {
    this.dir = dir;
    if (format <= DefaultSegmentInfosWriter.FORMAT_3_1) {
      version = input.readString();
    }
    name = input.readString();
    docCount = input.readInt();
    delGen = input.readLong();
    docStoreOffset = input.readInt();
    if (docStoreOffset != -1) {
      docStoreSegment = input.readString();
      docStoreIsCompoundFile = input.readByte() == YES;
    } else {
      docStoreSegment = name;
      docStoreIsCompoundFile = false;
    }

    if (format > DefaultSegmentInfosWriter.FORMAT_4_0) {
      // pre-4.0 indexes write a byte if there is a single norms file
      byte b = input.readByte();
      assert 1 == b;
    }

    int numNormGen = input.readInt();
    if (numNormGen == NO) {
      normGen = null;
    } else {
      normGen = new HashMap<Integer, Long>();
      for(int j=0;j<numNormGen;j++) {
        int fieldNumber = j;
        if (format <= DefaultSegmentInfosWriter.FORMAT_4_0) {
          fieldNumber = input.readInt();
      }

        normGen.put(fieldNumber, input.readLong());
    }
    }
    isCompoundFile = input.readByte() == YES;

    Directory dir0 = dir;
    if (isCompoundFile) {
      dir0 = new CompoundFileReader(dir, IndexFileNames.segmentFileName(name, "", IndexFileNames.COMPOUND_FILE_EXTENSION));
    }

    try {
      fieldInfos = new FieldInfos(dir0, IndexFileNames.segmentFileName(name, "", IndexFileNames.FIELD_INFOS_EXTENSION));
    } finally {
      if (dir != dir0) {
        dir0.close();
      }
    }

    delCount = input.readInt();
    assert delCount <= docCount;

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637708321/fstmerge_var1_2451556680791095733
    hasProx = input.readByte();
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637708321/fstmerge_base_2738855632599309012
    hasProx = input.readByte() == YES;
    
=======
    hasProx = input.readByte() == YES;

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637708321/fstmerge_var2_5015188230951973644
    // System.out.println(Thread.currentThread().getName() + ": si.read hasProx=" + hasProx + " seg=" + name);
    segmentCodecs = new SegmentCodecs(codecs);
    if (format <= DefaultSegmentInfosWriter.FORMAT_4_0) {
      segmentCodecs.read(input);
    } else {
      // codec ID on FieldInfo is 0 so it will simply use the first codec available
      // TODO what todo if preflex is not available in the provider? register it or fail?
      segmentCodecs.codecs = new Codec[] { codecs.lookup("PreFlex")};
    }
    diagnostics = input.readStringStringMap();

    if (format <= DefaultSegmentInfosWriter.FORMAT_HAS_VECTORS) {
      hasVectors = input.readByte();
    } else {
      final String storesSegment;
      final String ext;
      final boolean isCompoundFile;
      if (docStoreOffset != -1) {
        storesSegment = docStoreSegment;
        isCompoundFile = docStoreIsCompoundFile;
        ext = IndexFileNames.COMPOUND_FILE_STORE_EXTENSION;
      } else {
        storesSegment = name;
        isCompoundFile = getUseCompoundFile();
        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;
      }
      final Directory dirToTest;
      if (isCompoundFile) {
        dirToTest = new CompoundFileReader(dir, IndexFileNames.segmentFileName(storesSegment, "", ext));
      } else {
        dirToTest = dir;
      }
      try {
        if (dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, "", IndexFileNames.VECTORS_INDEX_EXTENSION))) {
          hasVectors = YES;
        } else {
          hasVectors = NO;
        }
      } finally {
        if (isCompoundFile) {
          dirToTest.close();
        }
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/SegmentInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637708411/fstmerge_var1_8914787140617826444
void setDocStoreIsCompoundFile(boolean v) {
    docStoreIsCompoundFile = v;
    clearFilesCache();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637708411/fstmerge_base_6628439200576591151
void setDocStoreIsCompoundFile(boolean v) {
    docStoreIsCompoundFile = v;
    clearFiles();
=======
@Deprecated
  public void setDocStoreIsCompoundFile(boolean docStoreIsCompoundFile) {
    this.docStoreIsCompoundFile = docStoreIsCompoundFile;
    clearFiles();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637708411/fstmerge_var2_617409642510201305
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/SegmentInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637708719/fstmerge_var1_5500547592981104851
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637708719/fstmerge_base_553484360122748378
final void addDocument(Document doc) throws IOException {
    indexStream.writeLong(fieldsStream.getFilePointer());

    int storedCount = 0;
    List<Fieldable> fields = doc.getFields();
    for (Fieldable field : fields) {
      if (field.isStored())
          storedCount++;
    }
    fieldsStream.writeVInt(storedCount);



    for (Fieldable field : fields) {
      if (field.isStored())
        writeField(fieldInfos.fieldInfo(field.name()), field);
    }
  }
=======
final void addDocument(Document doc) throws IOException {
    indexStream.writeLong(fieldsStream.getFilePointer());

    int storedCount = 0;
    List<Fieldable> fields = doc.getFields();
    for (Fieldable field : fields) {
      if (field.isStored())
          storedCount++;
    }
    fieldsStream.writeVInt(storedCount);


    for (Fieldable field : fields) {
      if (field.isStored())
        writeField(fieldInfos.fieldNumber(field.name()), field);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637708719/fstmerge_var2_265453922266083515

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/FieldsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637708788/fstmerge_var1_7271762528532381226
@Override
  public void flush(Map<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> threadsAndFields, final SegmentWriteState state) throws IOException {

    // Gather all FieldData's that have postings, across all
    // ThreadStates
    List<FreqProxTermsWriterPerField> allFields = new ArrayList<FreqProxTermsWriterPerField>();
    
    flushedDocCount = state.numDocs;

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {

      Collection<TermsHashConsumerPerField> fields = entry.getValue();


      for (final TermsHashConsumerPerField i : fields) {
        final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) i;
        if (perField.termsHashPerField.bytesHash.size() > 0)
          allFields.add(perField);
      }
    }

    final int numAllFields = allFields.size();

    // Sort by field name
    CollectionUtil.quickSort(allFields);

    final FieldsConsumer consumer = state.segmentCodecs.codec().fieldsConsumer(state);

    /*
    Current writer chain:
      FieldsConsumer
        -> IMPL: FormatPostingsTermsDictWriter
          -> TermsConsumer
            -> IMPL: FormatPostingsTermsDictWriter.TermsWriter
              -> DocsConsumer
                -> IMPL: FormatPostingsDocsWriter
                  -> PositionsConsumer
                    -> IMPL: FormatPostingsPositionsWriter
    */

    int start = 0;
    while(start < numAllFields) {
      final FieldInfo fieldInfo = allFields.get(start).fieldInfo;
      final String fieldName = fieldInfo.name;

      int end = start+1;
      while(end < numAllFields && allFields.get(end).fieldInfo.name.equals(fieldName))
        end++;
      
      FreqProxTermsWriterPerField[] fields = new FreqProxTermsWriterPerField[end-start];
      for(int i=start;i<end;i++) {
        fields[i-start] = allFields.get(i);

        // Aggregate the storePayload as seen by the same
        // field across multiple threads
        fieldInfo.storePayloads |= fields[i-start].hasPayloads;
      }

      // If this field has postings then add them to the
      // segment
      appendPostings(fieldName, state, fields, consumer);

      for(int i=0;i<fields.length;i++) {
        TermsHashPerField perField = fields[i].termsHashPerField;
        int numPostings = perField.bytesHash.size();
        perField.reset();
        perField.shrinkHash(numPostings);
        fields[i].reset();
      }

      start = end;
    }

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {
      FreqProxTermsWriterPerThread perThread = (FreqProxTermsWriterPerThread) entry.getKey();
      perThread.termsHashPerThread.reset(true);
    }
    consumer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637708788/fstmerge_base_6947153889410982554
@Override
  public void flush(Map<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> threadsAndFields, final SegmentWriteState state) throws IOException {

    // Gather all FieldData's that have postings, across all
    // ThreadStates
    List<FreqProxTermsWriterPerField> allFields = new ArrayList<FreqProxTermsWriterPerField>();
    
    flushedDocCount = state.numDocs;

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {

      Collection<TermsHashConsumerPerField> fields = entry.getValue();


      for (final TermsHashConsumerPerField i : fields) {
        final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) i;
        if (perField.termsHashPerField.bytesHash.size() > 0)
          allFields.add(perField);
      }
    }

    final int numAllFields = allFields.size();

    // Sort by field name
    CollectionUtil.quickSort(allFields);

    final FieldsConsumer consumer = state.segmentCodecs.codec().fieldsConsumer(state);

    /*
    Current writer chain:
      FieldsConsumer
        -> IMPL: FormatPostingsTermsDictWriter
          -> TermsConsumer
            -> IMPL: FormatPostingsTermsDictWriter.TermsWriter
              -> DocsConsumer
                -> IMPL: FormatPostingsDocsWriter
                  -> PositionsConsumer
                    -> IMPL: FormatPostingsPositionsWriter
    */

    int start = 0;
    while(start < numAllFields) {
      final FieldInfo fieldInfo = allFields.get(start).fieldInfo;
      final String fieldName = fieldInfo.name;

      int end = start+1;
      while(end < numAllFields && allFields.get(end).fieldInfo.name.equals(fieldName))
        end++;
      
      FreqProxTermsWriterPerField[] fields = new FreqProxTermsWriterPerField[end-start];
      for(int i=start;i<end;i++) {
        fields[i-start] = allFields.get(i);

        // Aggregate the storePayload as seen by the same
        // field across multiple threads
        fieldInfo.storePayloads |= fields[i-start].hasPayloads;
      }

      // If this field has postings then add them to the
      // segment
      appendPostings(fields, consumer);

      for(int i=0;i<fields.length;i++) {
        TermsHashPerField perField = fields[i].termsHashPerField;
        int numPostings = perField.bytesHash.size();
        perField.reset();
        perField.shrinkHash(numPostings);
        fields[i].reset();
      }

      start = end;
    }

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {
      FreqProxTermsWriterPerThread perThread = (FreqProxTermsWriterPerThread) entry.getKey();
      perThread.termsHashPerThread.reset(true);
    }
    consumer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637708788/fstmerge_var2_1952171708330618925

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## private final BufferedDeletes bufferedDeletes; ##FSTMerge## final BufferedDeletes bufferedDeletes;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ private BufferedDeletes pendingDeletes = new BufferedDeletes(false); ##FSTMerge## private SegmentDeletes pendingDeletes = new SegmentDeletes(); ##FSTMerge## SegmentDeletes pendingDeletes;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
boolean updateDocument(final Document doc, final Analyzer analyzer, final Term delTerm)
      throws CorruptIndexException, IOException {
    ensureOpen();

    SegmentInfo newSegment = null;
    SegmentDeletes segmentDeletes = null;

    ThreadState perThread = perThreadPool.getAndLock(Thread.currentThread(), this, doc);
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710862/fstmerge_var1_8500991759072284472
      // This call is not synchronized and does all the
      // work
      final DocWriter perDoc;
      try {
        perDoc = state.consumer.processDocument(fieldInfos);
      } finally {
        docState.clear();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710862/fstmerge_base_2601535691796473908
      // This call is not synchronized and does all the
      // work
      final DocWriter perDoc;
      try {
        perDoc = state.consumer.processDocument();
      } finally {
        docState.clear();
=======
      DocumentsWriterPerThread dwpt = perThread.perThread;
      long perThreadRAMUsedBeforeAdd = dwpt.bytesUsed();
      dwpt.updateDocument(doc, analyzer, delTerm);
      numDocsInRAM.incrementAndGet();

      newSegment = finishAddDocument(dwpt, perThreadRAMUsedBeforeAdd);
      if (newSegment != null) {
        fieldInfos.update(dwpt.getFieldInfos());
        if (dwpt.pendingDeletes.any()) {
          segmentDeletes = dwpt.pendingDeletes;
          dwpt.pendingDeletes = new SegmentDeletes();
        }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710862/fstmerge_var2_7589910688803565315
      }
    } finally {
      perThread.unlock();
    }

    if (segmentDeletes != null) {
      pushDeletes(newSegment, segmentDeletes);
    }

    if (newSegment != null) {
      perThreadPool.clearThreadBindings(perThread);
      indexWriter.addFlushedSegment(newSegment);
      return true;
    }

    // delete term from other DWPTs later, so that this thread
    // doesn't have to lock multiple DWPTs at the same time
    if (delTerm != null) {
      deleteTerm(delTerm, perThread);
    }

    return false;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710935/fstmerge_var1_85808929767590878
private void doAfterFlush() throws IOException {
    // All ThreadStates should be idle when we are called
    assert allThreadsIdle();
    for (DocumentsWriterThreadState threadState : threadStates) {
      threadState.consumer.doAfterFlush();
    }

    threadBindings.clear();
    waitQueue.reset();
    segment = null;
    fieldInfos = fieldInfos.newFieldInfosWithGlobalFieldNumberMap();
    numDocs = 0;
    nextDocID = 0;
    bufferIsFull = false;
    for(int i=0;i<threadStates.length;i++) {
      threadStates[i].doAfterFlush();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710935/fstmerge_base_6916773332075527378
private void doAfterFlush() throws IOException {
    // All ThreadStates should be idle when we are called
    assert allThreadsIdle();
    threadBindings.clear();
    waitQueue.reset();
    segment = null;
    numDocs = 0;
    nextDocID = 0;
    bufferIsFull = false;
    for(int i=0;i<threadStates.length;i++) {
      threadStates[i].doAfterFlush();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710935/fstmerge_var2_5208391360793172875

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710943/fstmerge_var1_4710868853686230710
public BufferedDeletes getPendingDeletes() {
    return pendingDeletes;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710943/fstmerge_base_2561073171689116234
public SegmentDeletes getPendingDeletes() {
    return pendingDeletes;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710943/fstmerge_var2_5225128638905487122

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710948/fstmerge_var1_3808475534784476201
private void pushDeletes(SegmentInfo newSegment, SegmentInfos segmentInfos) {
    // Lock order: DW -> BD
    final long delGen = bufferedDeletesStream.getNextGen();
    if (pendingDeletes.any()) {
      if (segmentInfos.size() > 0 || newSegment != null) {
        final FrozenBufferedDeletes packet = new FrozenBufferedDeletes(pendingDeletes, delGen);
        if (infoStream != null) {
          message("flush: push buffered deletes");
        }
        bufferedDeletesStream.push(packet);
        if (infoStream != null) {
          message("flush: delGen=" + packet.gen);
        }
        if (newSegment != null) {
          newSegment.setBufferedDeletesGen(packet.gen);
        }
      } else {
        if (infoStream != null) {
          message("flush: drop buffered deletes: no segments");
        }
        // We can safely discard these deletes: since
        // there are no segments, the deletions cannot
        // affect anything.
      }
      pendingDeletes.clear();
    } else if (newSegment != null) {
      newSegment.setBufferedDeletesGen(delGen);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710948/fstmerge_base_5938459104977390033
private void pushDeletes(SegmentInfo newSegment, SegmentInfos segmentInfos) {
    // Lock order: DW -> BD
    if (pendingDeletes.any()) {
      if (newSegment != null) {
        if (infoStream != null) {
          message("flush: push buffered deletes to newSegment");
        }
        bufferedDeletes.pushDeletes(pendingDeletes, newSegment);
      } else if (segmentInfos.size() > 0) {
        if (infoStream != null) {
          message("flush: push buffered deletes to previously flushed segment " + segmentInfos.lastElement());
        }
        bufferedDeletes.pushDeletes(pendingDeletes, segmentInfos.lastElement(), true);
      } else {
        if (infoStream != null) {
          message("flush: drop buffered deletes: no segments");
        }
        // We can safely discard these deletes: since
        // there are no segments, the deletions cannot
        // affect anything.
      }
      pendingDeletes = new SegmentDeletes();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710948/fstmerge_var2_3009439280518481000

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710953/fstmerge_var1_5432447857735321654
synchronized SegmentInfo flush(IndexWriter writer, IndexFileDeleter deleter, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {

    final long startTime = System.currentTimeMillis();

    // We change writer's segmentInfos:
    assert Thread.holdsLock(writer);

    waitIdle();

    if (numDocs == 0) {
      // nothing to do!
      if (infoStream != null) {
        message("flush: no docs; skipping");
      }
      // Lock order: IW -> DW -> BD
      pushDeletes(null, segmentInfos);
      return null;
    }

    if (aborting) {
      if (infoStream != null) {
        message("flush: skip because aborting is set");
      }
      return null;
    }

    boolean success = false;

    SegmentInfo newSegment;

    try {
      assert nextDocID == numDocs;
      assert waitQueue.numWaiting == 0;
      assert waitQueue.waitingBytes == 0;

      if (infoStream != null) {
        message("flush postings as segment " + segment + " numDocs=" + numDocs);
      }

      final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                                                 numDocs, writer.getConfig().getTermIndexInterval(),
                                                                 SegmentCodecs.build(fieldInfos, writer.codecs),
                                                                 pendingDeletes);
      // Apply delete-by-docID now (delete-byDocID only
      // happens when an exception is hit processing that
      // doc, eg if analyzer has some problem w/ the text):
      if (pendingDeletes.docIDs.size() > 0) {
        flushState.deletedDocs = new BitVector(numDocs);
        for(int delDocID : pendingDeletes.docIDs) {
          flushState.deletedDocs.set(delDocID);
        }
        pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);
        pendingDeletes.docIDs.clear();
      }

      newSegment = new SegmentInfo(segment, numDocs, directory, false, flushState.segmentCodecs, fieldInfos);

      Collection<DocConsumerPerThread> threads = new HashSet<DocConsumerPerThread>();
      for (DocumentsWriterThreadState threadState : threadStates) {
        threads.add(threadState.consumer);
      }

      double startMBUsed = bytesUsed()/1024./1024.;

      consumer.flush(threads, flushState);

      newSegment.clearFilesCache();

      if (infoStream != null) {
        message("new segment has " + (flushState.hasVectors ? "vectors" : "no vectors"));
        if (flushState.deletedDocs != null) {
          message("new segment has " + flushState.deletedDocs.count() + " deleted docs");
        }
        message("flushedFiles=" + newSegment.files());
        message("flushed codecs=" + newSegment.getSegmentCodecs());
      }

      if (mergePolicy.useCompoundFile(segmentInfos, newSegment)) {
        final String cfsFileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        if (infoStream != null) {
          message("flush: create compound file \"" + cfsFileName + "\"");
        }

        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, cfsFileName);
        for(String fileName : newSegment.files()) {
          cfsWriter.addFile(fileName);
        }
        cfsWriter.close();
        deleter.deleteNewFiles(newSegment.files());
        newSegment.setUseCompoundFile(true);
      }

      // Must write deleted docs after the CFS so we don't
      // slurp the del file into CFS:
      if (flushState.deletedDocs != null) {
        final int delCount = flushState.deletedDocs.count();
        assert delCount > 0;
        newSegment.setDelCount(delCount);
        newSegment.advanceDelGen();
        final String delFileName = newSegment.getDelFileName();
        if (infoStream != null) {
          message("flush: write " + delCount + " deletes to " + delFileName);
        }
        boolean success2 = false;
        try {
          // TODO: in the NRT case it'd be better to hand
          // this del vector over to the
          // shortly-to-be-opened SegmentReader and let it
          // carry the changes; there's no reason to use
          // filesystem as intermediary here.
          flushState.deletedDocs.write(directory, delFileName);
          success2 = true;
        } finally {
          if (!success2) {
            try {
              directory.deleteFile(delFileName);
            } catch (Throwable t) {
              // suppress this so we keep throwing the
              // original exception
            }
          }
        }
      }

      if (infoStream != null) {
        message("flush: segment=" + newSegment);
        final double newSegmentSizeNoStore = newSegment.sizeInBytes(false)/1024./1024.;
        final double newSegmentSize = newSegment.sizeInBytes(true)/1024./1024.;
        message("  ramUsed=" + nf.format(startMBUsed) + " MB" +
                " newFlushedSize=" + nf.format(newSegmentSize) + " MB" +
                " (" + nf.format(newSegmentSizeNoStore) + " MB w/o doc stores)" +
                " docs/MB=" + nf.format(numDocs / newSegmentSize) +
                " new/old=" + nf.format(100.0 * newSegmentSizeNoStore / startMBUsed) + "%");
      }

      success = true;
    } finally {
      notifyAll();
      if (!success) {
        if (segment != null) {
          deleter.refresh(segment);
        }
        abort();
      }
    }

    doAfterFlush();

    // Lock order: IW -> DW -> BD
    pushDeletes(newSegment, segmentInfos);
    if (infoStream != null) {
      message("flush time " + (System.currentTimeMillis()-startTime) + " msec");
    }

    return newSegment;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710953/fstmerge_base_8755832183560886027
synchronized SegmentInfo flush(IndexWriter writer, IndexFileDeleter deleter, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {

    final long startTime = System.currentTimeMillis();

    // We change writer's segmentInfos:
    assert Thread.holdsLock(writer);

    waitIdle();

    if (numDocs == 0) {
      // nothing to do!
      if (infoStream != null) {
        message("flush: no docs; skipping");
      }
      // Lock order: IW -> DW -> BD
      pushDeletes(null, segmentInfos);
      return null;
    }

    if (aborting) {
      if (infoStream != null) {
        message("flush: skip because aborting is set");
      }
      return null;
    }

    boolean success = false;

    SegmentInfo newSegment;

    try {
      assert nextDocID == numDocs;
      assert waitQueue.numWaiting == 0;
      assert waitQueue.waitingBytes == 0;

      if (infoStream != null) {
        message("flush postings as segment " + segment + " numDocs=" + numDocs);
      }

      final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                                                 numDocs, writer.getConfig().getTermIndexInterval(),
                                                                 SegmentCodecs.build(fieldInfos, writer.codecs));

      newSegment = new SegmentInfo(segment, numDocs, directory, false, fieldInfos.hasProx(), flushState.segmentCodecs, false);

      Collection<DocConsumerPerThread> threads = new HashSet<DocConsumerPerThread>();
      for (DocumentsWriterThreadState threadState : threadStates) {
        threads.add(threadState.consumer);
      }

      double startMBUsed = bytesUsed()/1024./1024.;

      consumer.flush(threads, flushState);
      newSegment.setHasVectors(flushState.hasVectors);

      if (infoStream != null) {
        message("new segment has " + (flushState.hasVectors ? "vectors" : "no vectors"));
        message("flushedFiles=" + newSegment.files());
        message("flushed codecs=" + newSegment.getSegmentCodecs());
      }

      if (mergePolicy.useCompoundFile(segmentInfos, newSegment)) {
        final String cfsFileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        if (infoStream != null) {
          message("flush: create compound file \"" + cfsFileName + "\"");
        }

        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, cfsFileName);
        for(String fileName : newSegment.files()) {
          cfsWriter.addFile(fileName);
        }
        cfsWriter.close();
        deleter.deleteNewFiles(newSegment.files());
        newSegment.setUseCompoundFile(true);
      }

      if (infoStream != null) {
        message("flush: segment=" + newSegment);
        final double newSegmentSizeNoStore = newSegment.sizeInBytes(false)/1024./1024.;
        final double newSegmentSize = newSegment.sizeInBytes(true)/1024./1024.;
        message("  ramUsed=" + nf.format(startMBUsed) + " MB" +
                " newFlushedSize=" + nf.format(newSegmentSize) + " MB" +
                " (" + nf.format(newSegmentSizeNoStore) + " MB w/o doc stores)" +
                " docs/MB=" + nf.format(numDocs / newSegmentSize) +
                " new/old=" + nf.format(100.0 * newSegmentSizeNoStore / startMBUsed) + "%");
      }

      success = true;
    } finally {
      notifyAll();
      if (!success) {
        if (segment != null) {
          deleter.refresh(segment);
        }
        abort();
      }
    }

    doAfterFlush();

    // Lock order: IW -> DW -> BD
    pushDeletes(newSegment, segmentInfos);

    if (infoStream != null) {
      message("flush time " + (System.currentTimeMillis()-startTime) + " msec");
    }

    return newSegment;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637710953/fstmerge_var2_4499269065963382251

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711020/fstmerge_var1_9170455099157639657
void balanceRAM() {

    final boolean doBalance;
    final long deletesRAMUsed;

    deletesRAMUsed = bufferedDeletesStream.bytesUsed();

    synchronized(this) {
      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {
        return;
      }
    
      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;
    }

    if (doBalance) {

      if (infoStream != null) {
        message("  RAM: balance allocations: usedMB=" + toMB(bytesUsed()) +
                " vs trigger=" + toMB(ramBufferSize) +
                " deletesMB=" + toMB(deletesRAMUsed) +
                " byteBlockFree=" + toMB(byteBlockAllocator.bytesUsed()) +
                " perDocFree=" + toMB(perDocAllocator.bytesUsed()));
      }

      final long startBytesUsed = bytesUsed() + deletesRAMUsed;

      int iter = 0;

      // We free equally from each pool in 32 KB
      // chunks until we are below our threshold
      // (freeLevel)

      boolean any = true;

      while(bytesUsed()+deletesRAMUsed > freeLevel) {
      
        synchronized(this) {
          if (0 == perDocAllocator.numBufferedBlocks() &&
              0 == byteBlockAllocator.numBufferedBlocks() &&
              0 == freeIntBlocks.size() && !any) {
            // Nothing else to free -- must flush now.
            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;
            if (infoStream != null) {
              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {
                message("    nothing to free; set bufferIsFull");
              } else {
                message("    nothing to free");
              }
            }
            break;
          }

          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {
            byteBlockAllocator.freeBlocks(1);
          }
          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {
            freeIntBlocks.remove(freeIntBlocks.size()-1);
            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);
          }
          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {
            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)
          }
        }

        if ((3 == iter % 4) && any) {
          // Ask consumer to free any recycled state
          any = consumer.freeRAM();
        }

        iter++;
      }

      if (infoStream != null) {
        message("    after free: freedMB=" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + " usedMB=" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711020/fstmerge_base_4294320566337444326
void balanceRAM() {

    final boolean doBalance;
    final long deletesRAMUsed;

    deletesRAMUsed = bufferedDeletes.bytesUsed();

    synchronized(this) {
      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {
        return;
      }
    
      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;
    }

    if (doBalance) {

      if (infoStream != null) {
        message("  RAM: balance allocations: usedMB=" + toMB(bytesUsed()) +
                " vs trigger=" + toMB(ramBufferSize) +
                " deletesMB=" + toMB(deletesRAMUsed) +
                " byteBlockFree=" + toMB(byteBlockAllocator.bytesUsed()) +
                " perDocFree=" + toMB(perDocAllocator.bytesUsed()));
      }

      final long startBytesUsed = bytesUsed() + deletesRAMUsed;

      int iter = 0;

      // We free equally from each pool in 32 KB
      // chunks until we are below our threshold
      // (freeLevel)

      boolean any = true;

      while(bytesUsed()+deletesRAMUsed > freeLevel) {
      
        synchronized(this) {
          if (0 == perDocAllocator.numBufferedBlocks() &&
              0 == byteBlockAllocator.numBufferedBlocks() &&
              0 == freeIntBlocks.size() && !any) {
            // Nothing else to free -- must flush now.
            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;
            if (infoStream != null) {
              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {
                message("    nothing to free; set bufferIsFull");
              } else {
                message("    nothing to free");
              }
            }
            break;
          }

          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {
            byteBlockAllocator.freeBlocks(1);
          }
          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {
            freeIntBlocks.remove(freeIntBlocks.size()-1);
            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);
          }
          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {
            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)
          }
        }

        if ((3 == iter % 4) && any) {
          // Ask consumer to free any recycled state
          any = consumer.freeRAM();
        }

        iter++;
      }

      if (infoStream != null) {
        message("    after free: freedMB=" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + " usedMB=" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));
      }
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711020/fstmerge_var2_6193648844403882306

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private int mergeFields() throws CorruptIndexException, IOException {
    for (IndexReader reader : readers) {
      if (reader instanceof SegmentReader) {
        SegmentReader segmentReader = (SegmentReader) reader;
        FieldInfos readerFieldInfos = segmentReader.fieldInfos();
        for (FieldInfo fi : readerFieldInfos) {
          fieldInfos.add(fi);
        }
      } else {
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION_OFFSET), true, true, true, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION), true, true, false, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_OFFSET), true, false, true, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR), true, false, false, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.OMIT_TERM_FREQ_AND_POSITIONS), false, false, false, false, true);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.STORES_PAYLOADS), false, false, false, true, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.INDEXED), false, false, false, false, false);
        fieldInfos.add(reader.getFieldNames(FieldOption.UNINDEXED), false);
      }
    }
    final SegmentCodecs codecInfo = SegmentCodecs.build(fieldInfos, this.codecs);
    fieldInfos.write(directory, segment + "." + IndexFileNames.FIELD_INFOS_EXTENSION);

    int docCount = 0;

    setMatchingSegmentReaders();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711472/fstmerge_var1_9038695708601710759
    final FieldsWriter fieldsWriter = new FieldsWriter(directory, segment);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711472/fstmerge_base_1730974640287727001
    final FieldsWriter fieldsWriter = new FieldsWriter(directory, segment, fieldInfos);
=======
    // merge field values
    final FieldsWriter fieldsWriter = new FieldsWriter(directory, segment, fieldInfos);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711472/fstmerge_var2_5205540048766093968

    try {
      int idx = 0;
      for (IndexReader reader : readers) {
        final SegmentReader matchingSegmentReader = matchingSegmentReaders[idx++];
        FieldsReader matchingFieldsReader = null;
        if (matchingSegmentReader != null) {
          final FieldsReader fieldsReader = matchingSegmentReader.getFieldsReader();
          if (fieldsReader != null) {
            matchingFieldsReader = fieldsReader;
          }
        }
        if (reader.hasDeletions()) {
          docCount += copyFieldsWithDeletions(fieldsWriter,
                                              reader, matchingFieldsReader);
        } else {
          docCount += copyFieldsNoDeletions(fieldsWriter,
                                            reader, matchingFieldsReader);
        }
      }
    } finally {
      fieldsWriter.close();
    }

    final String fileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.FIELDS_INDEX_EXTENSION);
    final long fdxFileLength = directory.fileLength(fileName);

    if (4+((long) docCount)*8 != fdxFileLength)
      // This is most likely a bug in Sun JRE 1.6.0_04/_05;
      // we detect that the bug has struck, here, and
      // throw an exception to prevent the corruption from
      // entering the index.  See LUCENE-1282 for
      // details.
      throw new RuntimeException("mergeFields produced an invalid result: docCount is " + docCount + " but fdx file size is " + fdxFileLength + " file=" + fileName + " file exists?=" + directory.fileExists(fileName) + "; now aborting this merge to prevent index corruption");

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711472/fstmerge_var1_9038695708601710759
    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, docCount, termIndexInterval, codecInfo, null);
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711472/fstmerge_base_1730974640287727001
    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, docCount, termIndexInterval, codecInfo);
    
=======
    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, docCount, termIndexInterval, codecInfo);

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711472/fstmerge_var2_5205540048766093968
    return docCount;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711539/fstmerge_var1_6033415179696804304
@Override
  public void flush(Map<InvertedDocEndConsumerPerThread,Collection<InvertedDocEndConsumerPerField>> threadsAndFields, SegmentWriteState state) throws IOException {

    final Map<FieldInfo,List<NormsWriterPerField>> byField = new HashMap<FieldInfo,List<NormsWriterPerField>>();

    if (!state.fieldInfos.hasNorms()) {
      return;
    }

    // Typically, each thread will have encountered the same
    // field.  So first we collate by field, ie, all
    // per-thread field instances that correspond to the
    // same FieldInfo
    for (final Map.Entry<InvertedDocEndConsumerPerThread,Collection<InvertedDocEndConsumerPerField>> entry : threadsAndFields.entrySet()) {
      final Collection<InvertedDocEndConsumerPerField> fields = entry.getValue();
      final Iterator<InvertedDocEndConsumerPerField> fieldsIt = fields.iterator();

      while (fieldsIt.hasNext()) {
        final NormsWriterPerField perField = (NormsWriterPerField) fieldsIt.next();

        if (perField.upto > 0) {
          // It has some norms
          List<NormsWriterPerField> l = byField.get(perField.fieldInfo);
          if (l == null) {
            l = new ArrayList<NormsWriterPerField>();
            byField.put(perField.fieldInfo, l);
          }
          l.add(perField);
        } else
          // Remove this field since we haven't seen it
          // since the previous flush
          fieldsIt.remove();
      }
    }

    final String normsFileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.NORMS_EXTENSION);
    IndexOutput normsOut = state.directory.createOutput(normsFileName);

    try {
      normsOut.writeBytes(SegmentMerger.NORMS_HEADER, 0, SegmentMerger.NORMS_HEADER.length);

      int normCount = 0;

      for (FieldInfo fi : state.fieldInfos) {
        List<NormsWriterPerField> toMerge = byField.get(fi);
        int upto = 0;
        if (toMerge != null) {

          final int numFields = toMerge.size();

          normCount++;

          final NormsWriterPerField[] fields = new NormsWriterPerField[numFields];
          int[] uptos = new int[numFields];

          for(int j=0;j<numFields;j++)
            fields[j] = toMerge.get(j);

          int numLeft = numFields;
              
          while(numLeft > 0) {

            assert uptos[0] < fields[0].docIDs.length : " uptos[0]=" + uptos[0] + " len=" + (fields[0].docIDs.length);

            int minLoc = 0;
            int minDocID = fields[0].docIDs[uptos[0]];

            for(int j=1;j<numLeft;j++) {
              final int docID = fields[j].docIDs[uptos[j]];
              if (docID < minDocID) {
                minDocID = docID;
                minLoc = j;
              }
            }

            assert minDocID < state.numDocs;

            // Fill hole
            for(;upto<minDocID;upto++)
              normsOut.writeByte((byte) 0);

            normsOut.writeByte(fields[minLoc].norms[uptos[minLoc]]);
            (uptos[minLoc])++;
            upto++;

            if (uptos[minLoc] == fields[minLoc].upto) {
              fields[minLoc].reset();
              if (minLoc != numLeft-1) {
                fields[minLoc] = fields[numLeft-1];
                uptos[minLoc] = uptos[numLeft-1];
              }
              numLeft--;
            }
          }
          
          // Fill final hole with defaultNorm
          for(;upto<state.numDocs;upto++)
            normsOut.writeByte((byte) 0);
        } else if (fi.isIndexed && !fi.omitNorms) {
          normCount++;
          // Fill entire field with default norm:
          for(;upto<state.numDocs;upto++)
            normsOut.writeByte((byte) 0);
        }

        assert 4+normCount*state.numDocs == normsOut.getFilePointer() : ".nrm file size mismatch: expected=" + (4+normCount*state.numDocs) + " actual=" + normsOut.getFilePointer();
      }

    } finally {
      normsOut.close();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711539/fstmerge_base_8271865827703822792
@Override
  public void flush(Map<InvertedDocEndConsumerPerThread,Collection<InvertedDocEndConsumerPerField>> threadsAndFields, SegmentWriteState state) throws IOException {

    final Map<FieldInfo,List<NormsWriterPerField>> byField = new HashMap<FieldInfo,List<NormsWriterPerField>>();

    if (!fieldInfos.hasNorms()) {
      return;
    }

    // Typically, each thread will have encountered the same
    // field.  So first we collate by field, ie, all
    // per-thread field instances that correspond to the
    // same FieldInfo
    for (final Map.Entry<InvertedDocEndConsumerPerThread,Collection<InvertedDocEndConsumerPerField>> entry : threadsAndFields.entrySet()) {
      final Collection<InvertedDocEndConsumerPerField> fields = entry.getValue();
      final Iterator<InvertedDocEndConsumerPerField> fieldsIt = fields.iterator();

      while (fieldsIt.hasNext()) {
        final NormsWriterPerField perField = (NormsWriterPerField) fieldsIt.next();

        if (perField.upto > 0) {
          // It has some norms
          List<NormsWriterPerField> l = byField.get(perField.fieldInfo);
          if (l == null) {
            l = new ArrayList<NormsWriterPerField>();
            byField.put(perField.fieldInfo, l);
          }
          l.add(perField);
        } else
          // Remove this field since we haven't seen it
          // since the previous flush
          fieldsIt.remove();
      }
    }

    final String normsFileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.NORMS_EXTENSION);
    IndexOutput normsOut = state.directory.createOutput(normsFileName);

    try {
      normsOut.writeBytes(SegmentMerger.NORMS_HEADER, 0, SegmentMerger.NORMS_HEADER.length);

      final int numField = fieldInfos.size();

      int normCount = 0;

      for(int fieldNumber=0;fieldNumber<numField;fieldNumber++) {

        final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);

        List<NormsWriterPerField> toMerge = byField.get(fieldInfo);
        int upto = 0;
        if (toMerge != null) {

          final int numFields = toMerge.size();

          normCount++;

          final NormsWriterPerField[] fields = new NormsWriterPerField[numFields];
          int[] uptos = new int[numFields];

          for(int j=0;j<numFields;j++)
            fields[j] = toMerge.get(j);

          int numLeft = numFields;
              
          while(numLeft > 0) {

            assert uptos[0] < fields[0].docIDs.length : " uptos[0]=" + uptos[0] + " len=" + (fields[0].docIDs.length);

            int minLoc = 0;
            int minDocID = fields[0].docIDs[uptos[0]];

            for(int j=1;j<numLeft;j++) {
              final int docID = fields[j].docIDs[uptos[j]];
              if (docID < minDocID) {
                minDocID = docID;
                minLoc = j;
              }
            }

            assert minDocID < state.numDocs;

            // Fill hole
            for(;upto<minDocID;upto++)
              normsOut.writeByte((byte) 0);

            normsOut.writeByte(fields[minLoc].norms[uptos[minLoc]]);
            (uptos[minLoc])++;
            upto++;

            if (uptos[minLoc] == fields[minLoc].upto) {
              fields[minLoc].reset();
              if (minLoc != numLeft-1) {
                fields[minLoc] = fields[numLeft-1];
                uptos[minLoc] = uptos[numLeft-1];
              }
              numLeft--;
            }
          }
          
          // Fill final hole with defaultNorm
          for(;upto<state.numDocs;upto++)
            normsOut.writeByte((byte) 0);
        } else if (fieldInfo.isIndexed && !fieldInfo.omitNorms) {
          normCount++;
          // Fill entire field with default norm:
          for(;upto<state.numDocs;upto++)
            normsOut.writeByte((byte) 0);
        }

        assert 4+normCount*state.numDocs == normsOut.getFilePointer() : ".nrm file size mismatch: expected=" + (4+normCount*state.numDocs) + " actual=" + normsOut.getFilePointer();
      }

    } finally {
      normsOut.close();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711539/fstmerge_var2_6788147123194967100

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/NormsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public MergeSpecification findMergesForOptimize(SegmentInfos infos,
      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {

    assert maxNumSegments > 0;
    if (verbose()) {
      message("findMergesForOptimize: maxNumSegs=" + maxNumSegments + " segsToOptimize= "+ segmentsToOptimize);
    }

    // If the segments are already optimized (e.g. there's only 1 segment), or
    // there are <maxNumSegements, all optimized, nothing to do.
    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {
      if (verbose()) {
        message("already optimized; skip");
      }
      return null;
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711789/fstmerge_var1_5608030548582833610

    // TODO: handle non-contiguous merge case differently?
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711789/fstmerge_base_525982731951780327
    
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711789/fstmerge_var2_5305051961218997719
    // Find the newest (rightmost) segment that needs to
    // be optimized (other segments may have been flushed
    // since optimize started):
    int last = infos.size();
    while (last > 0) {
      final SegmentInfo info = infos.info(--last);
      if (segmentsToOptimize.contains(info)) {
        last++;
        break;
      }
    }

    if (last == 0) {
      if (verbose()) {
        message("last == 0; skip");
      }
      return null;
    }

    // There is only one segment already, and it is optimized
    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {
      if (verbose()) {
        message("already 1 seg; skip");
      }
      return null;
    }

    // Check if there are any segments above the threshold
    boolean anyTooLarge = false;
    for (int i = 0; i < last; i++) {
      SegmentInfo info = infos.info(i);
      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {
        anyTooLarge = true;
        break;
      }
    }

    if (anyTooLarge) {
      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);
    } else {
      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/LogMergePolicy.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711872/fstmerge_var1_8958009997024269850
public DocFieldProcessor(DocumentsWriter docWriter, DocFieldConsumer consumer) {
    this.docWriter = docWriter;
    this.consumer = consumer;
    fieldsWriter = new StoredFieldsWriter(docWriter);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711872/fstmerge_base_7835180962339180158
public DocFieldProcessor(DocumentsWriter docWriter, DocFieldConsumer consumer) {
    this.docWriter = docWriter;
    this.consumer = consumer;
    fieldInfos = docWriter.getFieldInfos();
    consumer.setFieldInfos(fieldInfos);
    fieldsWriter = new StoredFieldsWriter(docWriter, fieldInfos);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711872/fstmerge_var2_4950998447134418213

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711877/fstmerge_var1_913109203519020785
@Override
  public void flush(Collection<DocConsumerPerThread> threads, SegmentWriteState state) throws IOException {

    Map<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>> childThreadsAndFields = new HashMap<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>>();
    for ( DocConsumerPerThread thread : threads) {
      DocFieldProcessorPerThread perThread = (DocFieldProcessorPerThread) thread;
      childThreadsAndFields.put(perThread.consumer, perThread.fields());
    }
    fieldsWriter.flush(state);
    consumer.flush(childThreadsAndFields, state);

    // Important to save after asking consumer to flush so
    // consumer can alter the FieldInfo* if necessary.  EG,
    // FreqProxTermsWriter does this with
    // FieldInfo.storePayload.
    final String fileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.FIELD_INFOS_EXTENSION);
    state.fieldInfos.write(state.directory, fileName);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711877/fstmerge_base_7268073309880996940
@Override
  public void flush(Collection<DocConsumerPerThread> threads, SegmentWriteState state) throws IOException {

    Map<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>> childThreadsAndFields = new HashMap<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>>();
    for ( DocConsumerPerThread thread : threads) {
      DocFieldProcessorPerThread perThread = (DocFieldProcessorPerThread) thread;
      childThreadsAndFields.put(perThread.consumer, perThread.fields());
      perThread.trimFields(state);
    }
    fieldsWriter.flush(state);
    consumer.flush(childThreadsAndFields, state);

    // Important to save after asking consumer to flush so
    // consumer can alter the FieldInfo* if necessary.  EG,
    // FreqProxTermsWriter does this with
    // FieldInfo.storePayload.
    final String fileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.FIELD_INFOS_EXTENSION);
    fieldInfos.write(state.directory, fileName);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637711877/fstmerge_var2_7209193766424181636

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637712661/fstmerge_var1_6711125455669905944
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637712661/fstmerge_base_9127125852547651783
public synchronized void pushDeletes(SegmentDeletes newDeletes, SegmentInfo info, boolean noLimit) {
    assert newDeletes.any();
    numTerms.addAndGet(newDeletes.numTermDeletes.get());

    if (!noLimit) {
      assert !deletesMap.containsKey(info);
      assert info != null;
      deletesMap.put(info, newDeletes);
      bytesUsed.addAndGet(newDeletes.bytesUsed.get());
    } else {
      final SegmentDeletes deletes = getDeletes(info);
      bytesUsed.addAndGet(-deletes.bytesUsed.get());
      deletes.update(newDeletes, noLimit);
      bytesUsed.addAndGet(deletes.bytesUsed.get());
    }    
    if (infoStream != null) {
      message("push deletes seg=" + info + " dels=" + getDeletes(info));
    }
    assert checkDeleteStats();    
  }
=======
public synchronized void pushDeletes(SegmentDeletes newDeletes, SegmentInfo info, boolean noLimit) {
    assert newDeletes.any();
    numTerms.addAndGet(newDeletes.numTermDeletes.get());

    if (!noLimit) {
      assert !deletesMap.containsKey(info);
      assert info != null;
      deletesMap.put(info, newDeletes);
      bytesUsed.addAndGet(newDeletes.bytesUsed.get());
    } else {
      final SegmentDeletes deletes = getDeletes(info);
      bytesUsed.addAndGet(-deletes.bytesUsed.get());
      deletes.update(newDeletes, noLimit);
      bytesUsed.addAndGet(deletes.bytesUsed.get());
    }
    if (infoStream != null) {
      message("push deletes seg=" + info + " dels=" + getDeletes(info));
    }
    assert checkDeleteStats();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637712661/fstmerge_var2_7680369748405361523

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/BufferedDeletes.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637712690/fstmerge_var1_8517076310476016019
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637712690/fstmerge_base_7266892752972731529
public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {
    if (!any()) {
      return false;
    }
    final long t0 = System.currentTimeMillis();

    if (infoStream != null) {
      message("applyDeletes: applyInfos=" + applyInfos + "; index=" + segmentInfos);
    }

    assert checkDeleteStats();

    assert applyInfos.size() > 0;

    boolean any = false;
    
    final SegmentInfo lastApplyInfo = applyInfos.lastElement();
    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);
    
    final SegmentInfo firstInfo = applyInfos.firstElement();
    final int firstIdx = segmentInfos.indexOf(firstInfo);

    // applyInfos must be a slice of segmentInfos
    assert lastIdx - firstIdx + 1 == applyInfos.size();
    
    // iterate over all segment infos backwards
    // coalesceing deletes along the way 
    // when we're at or below the last of the 
    // segments to apply to, start applying the deletes
    // we traverse up to the first apply infos
    SegmentDeletes coalescedDeletes = null;
    boolean hasDeletes = false;
    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {
      final SegmentInfo info = segmentInfos.info(segIdx);
      final SegmentDeletes deletes = deletesMap.get(info);
      assert deletes == null || deletes.any();

      if (deletes == null && coalescedDeletes == null) {
        continue;
      }

      if (infoStream != null) {
        message("applyDeletes: seg=" + info + " segment's deletes=[" + (deletes == null ? "null" : deletes) + "]; coalesced deletes=[" + (coalescedDeletes == null ? "null" : coalescedDeletes) + "]");
      }

      hasDeletes |= deletes != null;

      if (segIdx <= lastIdx && hasDeletes) {

        final long delCountInc = applyDeletes(readerPool, info, coalescedDeletes, deletes);

        if (delCountInc != 0) {
          any = true;
        }
        if (infoStream != null) {
          message("deletes touched " + delCountInc + " docIDs");
        }
      
        if (deletes != null) {
          // we've applied doc ids, and they're only applied
          // on the current segment
          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);
          deletes.clearDocIDs();
        }
      }
      
      // now coalesce at the max limit
      if (deletes != null) {
        if (coalescedDeletes == null) {
          coalescedDeletes = new SegmentDeletes();
        }
        // TODO: we could make this single pass (coalesce as
        // we apply the deletes
        coalescedDeletes.update(deletes, true);
      }
    }

    // move all deletes to segment just before our merge.
    if (firstIdx > 0) {

      SegmentDeletes mergedDeletes = null;
      // TODO: we could also make this single pass
      for (SegmentInfo info : applyInfos) {
        final SegmentDeletes deletes = deletesMap.get(info);
        if (deletes != null) {
          assert deletes.any();
          if (mergedDeletes == null) {
            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));
            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());
            assert numTerms.get() >= 0;
            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());
            assert bytesUsed.get() >= 0;
          }

          mergedDeletes.update(deletes, true);
        }
      }

      if (mergedDeletes != null) {
        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());
        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());
      }

      if (infoStream != null) {
        if (mergedDeletes != null) {
          message("applyDeletes: merge all deletes into seg=" + segmentInfos.info(firstIdx-1) + ": " + mergedDeletes);
        } else {
          message("applyDeletes: no deletes to merge");
        }
      }
    } else {
      // We drop the deletes in this case, because we've
      // applied them to segment infos starting w/ the first
      // segment.  There are no prior segments so there's no
      // reason to keep them around.  When the applyInfos ==
      // segmentInfos this means all deletes have been
      // removed:
    }
    remove(applyInfos);

    assert checkDeleteStats();
    assert applyInfos != segmentInfos || !any();
    
    if (infoStream != null) {
      message("applyDeletes took " + (System.currentTimeMillis()-t0) + " msec");
    }
    return any;
  }
=======
public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {
    if (!any()) {
      return false;
    }
    final long t0 = System.currentTimeMillis();

    if (infoStream != null) {
      message("applyDeletes: applyInfos=" + applyInfos + "; index=" + segmentInfos);
    }

    assert checkDeleteStats();

    assert applyInfos.size() > 0;

    boolean any = false;

    final SegmentInfo lastApplyInfo = applyInfos.lastElement();
    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);

    final SegmentInfo firstInfo = applyInfos.firstElement();
    final int firstIdx = segmentInfos.indexOf(firstInfo);

    // applyInfos must be a slice of segmentInfos
    assert lastIdx - firstIdx + 1 == applyInfos.size();

    // iterate over all segment infos backwards
    // coalesceing deletes along the way
    // when we're at or below the last of the
    // segments to apply to, start applying the deletes
    // we traverse up to the first apply infos
    SegmentDeletes coalescedDeletes = null;
    boolean hasDeletes = false;
    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {
      final SegmentInfo info = segmentInfos.info(segIdx);
      final SegmentDeletes deletes = deletesMap.get(info);
      assert deletes == null || deletes.any();

      if (deletes == null && coalescedDeletes == null) {
        continue;
      }

      if (infoStream != null) {
        message("applyDeletes: seg=" + info + " segment's deletes=[" + (deletes == null ? "null" : deletes) + "]; coalesced deletes=[" + (coalescedDeletes == null ? "null" : coalescedDeletes) + "]");
      }

      hasDeletes |= deletes != null;

      if (segIdx <= lastIdx && hasDeletes) {

        final long delCountInc = applyDeletes(readerPool, info, coalescedDeletes, deletes);

        if (delCountInc != 0) {
          any = true;
        }
        if (infoStream != null) {
          message("deletes touched " + delCountInc + " docIDs");
        }

        if (deletes != null) {
          // we've applied doc ids, and they're only applied
          // on the current segment
          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);
          deletes.clearDocIDs();
        }
      }

      // now coalesce at the max limit
      if (deletes != null) {
        if (coalescedDeletes == null) {
          coalescedDeletes = new SegmentDeletes();
        }
        // TODO: we could make this single pass (coalesce as
        // we apply the deletes
        coalescedDeletes.update(deletes, true);
      }
    }

    // move all deletes to segment just before our merge.
    if (firstIdx > 0) {

      SegmentDeletes mergedDeletes = null;
      // TODO: we could also make this single pass
      for (SegmentInfo info : applyInfos) {
        final SegmentDeletes deletes = deletesMap.get(info);
        if (deletes != null) {
          assert deletes.any();
          if (mergedDeletes == null) {
            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));
            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());
            assert numTerms.get() >= 0;
            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());
            assert bytesUsed.get() >= 0;
          }

          mergedDeletes.update(deletes, true);
        }
      }

      if (mergedDeletes != null) {
        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());
        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());
      }

      if (infoStream != null) {
        if (mergedDeletes != null) {
          message("applyDeletes: merge all deletes into seg=" + segmentInfos.info(firstIdx-1) + ": " + mergedDeletes);
        } else {
          message("applyDeletes: no deletes to merge");
        }
      }
    } else {
      // We drop the deletes in this case, because we've
      // applied them to segment infos starting w/ the first
      // segment.  There are no prior segments so there's no
      // reason to keep them around.  When the applyInfos ==
      // segmentInfos this means all deletes have been
      // removed:
    }
    remove(applyInfos);

    assert checkDeleteStats();
    assert applyInfos != segmentInfos || !any();

    if (infoStream != null) {
      message("applyDeletes took " + (System.currentTimeMillis()-t0) + " msec");
    }
    return any;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637712690/fstmerge_var2_5894454303301364202

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/BufferedDeletes.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637712697/fstmerge_var1_2292470747567892841
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637712697/fstmerge_base_7761455449246283815
private synchronized long applyDeletes(IndexWriter.ReaderPool readerPool,
                                            SegmentInfo info, 
                                            SegmentDeletes coalescedDeletes,
                                            SegmentDeletes segmentDeletes) throws IOException {    
    assert readerPool.infoIsLive(info);
    
    assert coalescedDeletes == null || coalescedDeletes.docIDs.size() == 0;
    
    long delCount = 0;

    // Lock order: IW -> BD -> RP
    SegmentReader reader = readerPool.get(info, false);
    try {
      if (coalescedDeletes != null) {
        delCount += applyDeletes(coalescedDeletes, reader);
      }
      if (segmentDeletes != null) {
        delCount += applyDeletes(segmentDeletes, reader);
      }
    } finally {
      readerPool.release(reader);
    }
    return delCount;
  }
=======
private synchronized long applyDeletes(IndexWriter.ReaderPool readerPool,
                                            SegmentInfo info,
                                            SegmentDeletes coalescedDeletes,
                                            SegmentDeletes segmentDeletes) throws IOException {
    assert readerPool.infoIsLive(info);

    assert coalescedDeletes == null || coalescedDeletes.docIDs.size() == 0;

    long delCount = 0;

    // Lock order: IW -> BD -> RP
    SegmentReader reader = readerPool.get(info, false);
    try {
      if (coalescedDeletes != null) {
        delCount += applyDeletes(coalescedDeletes, reader);
      }
      if (segmentDeletes != null) {
        delCount += applyDeletes(segmentDeletes, reader);
      }
    } finally {
      readerPool.release(reader);
    }
    return delCount;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637712697/fstmerge_var2_6948518553412084981

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/BufferedDeletes.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637712702/fstmerge_var1_1268195115772111300
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637712702/fstmerge_base_4211786185399468523
private synchronized long applyDeletes(SegmentDeletes deletes, SegmentReader reader) throws IOException {

    long delCount = 0;

    assert checkDeleteTerm(null);
    
    if (deletes.terms.size() > 0) {
      Fields fields = reader.fields();
      if (fields == null) {
        // This reader has no postings
        return 0;
      }

      TermsEnum termsEnum = null;
        
      String currentField = null;
      DocsEnum docs = null;
        
      for (Entry<Term,Integer> entry: deletes.terms.entrySet()) {
        Term term = entry.getKey();
        // Since we visit terms sorted, we gain performance
        // by re-using the same TermsEnum and seeking only
        // forwards
        if (term.field() != currentField) {
          assert currentField == null || currentField.compareTo(term.field()) < 0;
          currentField = term.field();
          Terms terms = fields.terms(currentField);
          if (terms != null) {
            termsEnum = terms.iterator();
          } else {
            termsEnum = null;
          }
        }
          
        if (termsEnum == null) {
          continue;
        }
        assert checkDeleteTerm(term);
          
        if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {
          DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);
            
          if (docsEnum != null) {
            docs = docsEnum;
            final int limit = entry.getValue();
            while (true) {
              final int docID = docs.nextDoc();
              if (docID == DocsEnum.NO_MORE_DOCS || docID >= limit) {
                break;
              }
              reader.deleteDocument(docID);
              // TODO: we could/should change
              // reader.deleteDocument to return boolean
              // true if it did in fact delete, because here
              // we could be deleting an already-deleted doc
              // which makes this an upper bound:
              delCount++;
            }
          }
        }
      }
    }

    // Delete by docID
    for (Integer docIdInt : deletes.docIDs) {
      int docID = docIdInt.intValue();
      reader.deleteDocument(docID);
      delCount++;
    }

    // Delete by query
    if (deletes.queries.size() > 0) {
      IndexSearcher searcher = new IndexSearcher(reader);
      assert searcher.getTopReaderContext().isAtomic;
      final AtomicReaderContext readerContext = (AtomicReaderContext) searcher.getTopReaderContext();
      try {
        for (Entry<Query, Integer> entry : deletes.queries.entrySet()) {
          Query query = entry.getKey();
          int limit = entry.getValue().intValue();
          Weight weight = query.weight(searcher);
          Scorer scorer = weight.scorer(readerContext, Weight.ScorerContext.def());
          if (scorer != null) {
            while(true)  {
              int doc = scorer.nextDoc();
              if (doc >= limit)
                break;

              reader.deleteDocument(doc);
              // TODO: we could/should change
              // reader.deleteDocument to return boolean
              // true if it did in fact delete, because here
              // we could be deleting an already-deleted doc
              // which makes this an upper bound:
              delCount++;
            }
          }
        }
      } finally {
        searcher.close();
      }
    }

    return delCount;
  }
=======
private synchronized long applyDeletes(SegmentDeletes deletes, SegmentReader reader) throws IOException {

    long delCount = 0;

    assert checkDeleteTerm(null);

    if (deletes.terms.size() > 0) {
      Fields fields = reader.fields();
      if (fields == null) {
        // This reader has no postings
        return 0;
      }

      TermsEnum termsEnum = null;

      String currentField = null;
      DocsEnum docs = null;

      for (Entry<Term,Integer> entry: deletes.terms.entrySet()) {
        Term term = entry.getKey();
        // Since we visit terms sorted, we gain performance
        // by re-using the same TermsEnum and seeking only
        // forwards
        if (term.field() != currentField) {
          assert currentField == null || currentField.compareTo(term.field()) < 0;
          currentField = term.field();
          Terms terms = fields.terms(currentField);
          if (terms != null) {
            termsEnum = terms.iterator();
          } else {
            termsEnum = null;
          }
        }

        if (termsEnum == null) {
          continue;
        }
        assert checkDeleteTerm(term);

        if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {
          DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);

          if (docsEnum != null) {
            docs = docsEnum;
            final int limit = entry.getValue();
            while (true) {
              final int docID = docs.nextDoc();
              if (docID == DocsEnum.NO_MORE_DOCS || docID >= limit) {
                break;
              }
              reader.deleteDocument(docID);
              // TODO: we could/should change
              // reader.deleteDocument to return boolean
              // true if it did in fact delete, because here
              // we could be deleting an already-deleted doc
              // which makes this an upper bound:
              delCount++;
            }
          }
        }
      }
    }

    // Delete by docID
    for (Integer docIdInt : deletes.docIDs) {
      int docID = docIdInt.intValue();
      reader.deleteDocument(docID);
      delCount++;
    }

    // Delete by query
    if (deletes.queries.size() > 0) {
      IndexSearcher searcher = new IndexSearcher(reader);
      assert searcher.getTopReaderContext().isAtomic;
      final AtomicReaderContext readerContext = (AtomicReaderContext) searcher.getTopReaderContext();
      try {
        for (Entry<Query, Integer> entry : deletes.queries.entrySet()) {
          Query query = entry.getKey();
          int limit = entry.getValue().intValue();
          Weight weight = query.weight(searcher);
          Scorer scorer = weight.scorer(readerContext, Weight.ScorerContext.def());
          if (scorer != null) {
            while(true)  {
              int doc = scorer.nextDoc();
              if (doc >= limit)
                break;

              reader.deleteDocument(doc);
              // TODO: we could/should change
              // reader.deleteDocument to return boolean
              // true if it did in fact delete, because here
              // we could be deleting an already-deleted doc
              // which makes this an upper bound:
              delCount++;
            }
          }
        }
      } finally {
        searcher.close();
      }
    }

    return delCount;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637712702/fstmerge_var2_2440380287686354386

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/BufferedDeletes.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637713267/fstmerge_var1_6401200478700983252
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637713267/fstmerge_base_7884459622620712585
private FieldInfo addInternal(String name, boolean isIndexed,
                                boolean storeTermVector, boolean storePositionWithTermVector, 
                                boolean storeOffsetWithTermVector, boolean omitNorms, boolean storePayloads, boolean omitTermFreqAndPositions) {
    name = StringHelper.intern(name);
    FieldInfo fi = new FieldInfo(name, isIndexed, byNumber.size(), storeTermVector, storePositionWithTermVector,
                                 storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
    byNumber.add(fi);
    byName.put(name, fi);
    return fi;
  }
=======
private FieldInfo addInternal(String name, boolean isIndexed,
                                boolean storeTermVector, boolean storePositionWithTermVector,
                                boolean storeOffsetWithTermVector, boolean omitNorms, boolean storePayloads, boolean omitTermFreqAndPositions) {
    name = StringHelper.intern(name);
    FieldInfo fi = new FieldInfo(name, isIndexed, byNumber.size(), storeTermVector, storePositionWithTermVector,
                                 storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
    byNumber.add(fi);
    byName.put(name, fi);
    return fi;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637713267/fstmerge_var2_642086566529519217

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/FieldInfos.java
Conflict type: LineBasedMCFd
Conflict body: 
public IndexWriter(Directory d, IndexWriterConfig conf)
      throws CorruptIndexException, LockObtainFailedException, IOException {
    config = (IndexWriterConfig) conf.clone();
    directory = d;
    analyzer = conf.getAnalyzer();
    infoStream = defaultInfoStream;
    termIndexInterval = conf.getTermIndexInterval();
    mergePolicy = conf.getMergePolicy();
    mergePolicy.setIndexWriter(this);
    mergeScheduler = conf.getMergeScheduler();
    mergedSegmentWarmer = conf.getMergedSegmentWarmer();
    codecs = conf.getCodecProvider();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637713902/fstmerge_var1_5709413618623143480
    
    bufferedDeletesStream = new BufferedDeletesStream(messageID);
    bufferedDeletesStream.setInfoStream(infoStream);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637713902/fstmerge_base_7907195303962277948
    
    bufferedDeletes = new BufferedDeletes(messageID);
    bufferedDeletes.setInfoStream(infoStream);
=======

    bufferedDeletes = new BufferedDeletes(messageID);
    bufferedDeletes.setInfoStream(infoStream);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637713902/fstmerge_var2_6108853828293859691
    poolReaders = conf.getReaderPooling();

    OpenMode mode = conf.getOpenMode();
    boolean create;
    if (mode == OpenMode.CREATE) {
      create = true;
    } else if (mode == OpenMode.APPEND) {
      create = false;
    } else {
      // CREATE_OR_APPEND - create only if an index does not exist
      create = !IndexReader.indexExists(directory);
    }

    writeLock = directory.makeLock(WRITE_LOCK_NAME);

    if (!writeLock.obtain(conf.getWriteLockTimeout())) // obtain write lock
      throw new LockObtainFailedException("Index locked for write: " + writeLock);

    boolean success = false;

    // If index is too old, reading the segments will throw
    // IndexFormatTooOldException.
    segmentInfos = new SegmentInfos(codecs);
    try {
      if (create) {
        // Try to read first.  This is to allow create
        // against an index that's currently open for
        // searching.  In this case we write the next
        // segments_N file with no segments:
        try {
          segmentInfos.read(directory, codecs);
          segmentInfos.clear();
        } catch (IOException e) {
          // Likely this means it's a fresh directory
        }

        // Record that we have a change (zero out all
        // segments) pending:
        changeCount++;
        segmentInfos.changed();
      } else {
        segmentInfos.read(directory, codecs);

        IndexCommit commit = conf.getIndexCommit();
        if (commit != null) {
          // Swap out all segments, but, keep metadata in
          // SegmentInfos, like version & generation, to
          // preserve write-once.  This is important if
          // readers are open against the future commit
          // points.
          if (commit.getDirectory() != directory)
            throw new IllegalArgumentException("IndexCommit's directory doesn't match my directory");
          SegmentInfos oldInfos = new SegmentInfos(codecs);
          oldInfos.read(directory, commit.getSegmentsFileName(), codecs);
          segmentInfos.replace(oldInfos);
          changeCount++;
          segmentInfos.changed();
          if (infoStream != null)
            message("init: loaded commit \"" + commit.getSegmentsFileName() + "\"");
        }
      }

      setRollbackSegmentInfos(segmentInfos);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637713902/fstmerge_var1_5709413618623143480
      // start with previous field numbers, but new FieldInfos
      fieldInfos = getCurrentFieldInfos();
      docWriter = new DocumentsWriter(directory, this, conf.getIndexingChain(), conf.getMaxThreadStates(),
          fieldInfos.newFieldInfosWithGlobalFieldNumberMap(), bufferedDeletesStream);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637713902/fstmerge_base_7907195303962277948
      docWriter = new DocumentsWriter(directory, this, conf.getIndexingChain(), conf.getMaxThreadStates(), getCurrentFieldInfos(), bufferedDeletes);
=======
      docWriter = new DocumentsWriter(directory, this, conf.getIndexingChain(), conf.getIndexerThreadPool(), getCurrentFieldInfos(), bufferedDeletes);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637713902/fstmerge_var2_6108853828293859691
      docWriter.setInfoStream(infoStream);

      // Default deleter (for backwards compatibility) is
      // KeepOnlyLastCommitDeleter:
      deleter = new IndexFileDeleter(directory,
                                     conf.getIndexDeletionPolicy(),
                                     segmentInfos, infoStream, codecs);

      if (deleter.startingCommitDeleted) {
        // Deletion policy deleted the "head" commit point.
        // We have to mark ourself as changed so that if we
        // are closed w/o any further changes we write a new
        // segments_N file.
        changeCount++;
        segmentInfos.changed();
      }

      docWriter.setRAMBufferSizeMB(conf.getRAMBufferSizeMB());
      docWriter.setMaxBufferedDocs(conf.getMaxBufferedDocs());
      pushMaxBufferedDocs();

      if (infoStream != null) {
        message("init: create=" + create);
        messageState();
      }

      success = true;

    } finally {
      if (!success) {
        if (infoStream != null) {
          message("init: hit exception on init; releasing write lock");
        }
        try {
          writeLock.release();
        } catch (Throwable t) {
          // don't mask the original exception
        }
        writeLock = null;
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private void rollbackInternal() throws IOException {

    boolean success = false;

    if (infoStream != null ) {
      message("rollback");
    }

    try {
      synchronized(this) {
        finishMerges(false);
        stopMerges = true;
      }

      if (infoStream != null ) {
        message("rollback: done finish merges");
      }

      // Must pre-close these two, in case they increment
      // changeCount so that we can then set it to false
      // before calling closeInternal
      mergePolicy.close();
      mergeScheduler.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714142/fstmerge_var1_7690489509828852236
      bufferedDeletesStream.clear();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714142/fstmerge_base_5312271869861372672
      bufferedDeletes.clear();
=======
      synchronized(this) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714142/fstmerge_var2_2356791532883771010

        bufferedDeletes.clear();

        if (pendingCommit != null) {
          pendingCommit.rollbackCommit(directory);
          deleter.decRef(pendingCommit);
          pendingCommit = null;
          notifyAll();
        }

        // Keep the same segmentInfos instance but replace all
        // of its SegmentInfo instances.  This is so the next
        // attempt to commit using this instance of IndexWriter
        // will always write to a new generation ("write
        // once").
        segmentInfos.clear();
        segmentInfos.addAll(rollbackSegmentInfos);

        docWriter.abort();

        assert testPoint("rollback before checkpoint");

        // Ask deleter to locate unreferenced files & remove
        // them:
        deleter.checkpoint(segmentInfos, false);
        deleter.refresh();
      }

      // Don't bother saving any changes in our segmentInfos
      readerPool.clear(null);

      lastCommitChangeCount = changeCount;

      success = true;
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "rollbackInternal");
    } finally {
      synchronized(this) {
        if (!success) {
          closing = false;
          notifyAll();
          if (infoStream != null)
            message("hit exception during rollback");
        }
      }
    }

    closeInternal(false);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void addIndexes(IndexReader... readers) throws CorruptIndexException, IOException {
    ensureOpen();

    try {
      String mergedName = newSegmentName();
      SegmentMerger merger = new SegmentMerger(directory, termIndexInterval,
                                               mergedName, null, codecs, payloadProcessorProvider,
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714180/fstmerge_var1_4315677909680487310
                                               fieldInfos.newFieldInfosWithGlobalFieldNumberMap());
      
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714180/fstmerge_base_3515495171304666863
                                               ((FieldInfos) docWriter.getFieldInfos().clone()));
      
=======
                                               ((FieldInfos) docWriter.getFieldInfos().clone()));

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714180/fstmerge_var2_8280681212026993469
      for (IndexReader reader : readers)      // add new indexes
        merger.add(reader);

      int docCount = merger.merge();                // merge 'em

      SegmentInfo info = new SegmentInfo(mergedName, docCount, directory,
                                         false, merger.getSegmentCodecs(),
                                         merger.fieldInfos());
      setDiagnostics(info, "addIndexes(IndexReader...)");

      boolean useCompoundFile;
      synchronized(this) { // Guard segmentInfos
        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, info);
      }

      // Now create the compound file if needed
      if (useCompoundFile) {
        merger.createCompoundFile(mergedName + ".cfs", info);

        // delete new non cfs files directly: they were never
        // registered with IFD
        deleter.deleteNewFiles(info.files());
        info.setUseCompoundFile(true);
      }

      // Register the new segment
      synchronized(this) {
        segmentInfos.add(info);
        checkpoint();
      }
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "addIndexes(IndexReader...)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private boolean doFlush(boolean applyAllDeletes) throws CorruptIndexException, IOException {
    if (hitOOM) {
      throw new IllegalStateException("this writer hit an OutOfMemoryError; cannot flush");
    }

    doBeforeFlush();

    assert testPoint("startDoFlush");

    // We may be flushing because it was triggered by doc
    // count, del count, ram usage (in which case flush
    // pending is already set), or we may be flushing
    // due to external event eg getReader or commit is
    // called (in which case we now set it, and this will
    // pause all threads):
    flushControl.setFlushPendingNoWait("explicit flush");

    boolean success = false;

    try {

      if (infoStream != null) {
        message("  start flush: applyAllDeletes=" + applyAllDeletes);
        message("  index before flush " + segString());
      }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714226/fstmerge_var1_1597623054870756191
      if (!applyAllDeletes) {
        // If deletes alone are consuming > 1/2 our RAM
        // buffer, force them all to apply now. This is to
        // prevent too-frequent flushing of a long tail of
        // tiny segments:
        if (flushControl.getFlushDeletes() ||
            (config.getRAMBufferSizeMB() != IndexWriterConfig.DISABLE_AUTO_FLUSH &&
             bufferedDeletesStream.bytesUsed() > (1024*1024*config.getRAMBufferSizeMB()/2))) {
          applyAllDeletes = true;
          if (infoStream != null) {
            message("force apply deletes bytesUsed=" + bufferedDeletesStream.bytesUsed() + " vs ramBuffer=" + (1024*1024*config.getRAMBufferSizeMB()));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714226/fstmerge_base_495501493604572315
      if (!applyAllDeletes) {
        // If deletes alone are consuming > 1/2 our RAM
        // buffer, force them all to apply now. This is to
        // prevent too-frequent flushing of a long tail of
        // tiny segments:
        if (flushControl.getFlushDeletes() ||
            (config.getRAMBufferSizeMB() != IndexWriterConfig.DISABLE_AUTO_FLUSH &&
             bufferedDeletes.bytesUsed() > (1024*1024*config.getRAMBufferSizeMB()/2))) {
          applyAllDeletes = true;
          if (infoStream != null) {
            message("force apply deletes bytesUsed=" + bufferedDeletes.bytesUsed() + " vs ramBuffer=" + (1024*1024*config.getRAMBufferSizeMB()));
=======
      boolean maybeMerge = docWriter.flushAllThreads(applyAllDeletes);

      synchronized(this) {
        if (!applyAllDeletes) {
          // If deletes alone are consuming > 1/2 our RAM
          // buffer, force them all to apply now. This is to
          // prevent too-frequent flushing of a long tail of
          // tiny segments:
          if (flushControl.getFlushDeletes() ||
              (config.getRAMBufferSizeMB() != IndexWriterConfig.DISABLE_AUTO_FLUSH &&
               bufferedDeletes.bytesUsed() > (1024*1024*config.getRAMBufferSizeMB()/2))) {
            applyAllDeletes = true;
            if (infoStream != null) {
              message("force apply deletes bytesUsed=" + bufferedDeletes.bytesUsed() + " vs ramBuffer=" + (1024*1024*config.getRAMBufferSizeMB()));
            }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714226/fstmerge_var2_2604793013435493552
          }
        }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714226/fstmerge_var1_1597623054870756191
      if (applyAllDeletes) {
        if (infoStream != null) {
          message("apply all deletes during flush");
        }
        flushDeletesCount.incrementAndGet();
        final BufferedDeletesStream.ApplyDeletesResult result = bufferedDeletesStream.applyDeletes(readerPool, segmentInfos);
        if (result.anyDeletes) {
          checkpoint();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714226/fstmerge_base_495501493604572315
      if (applyAllDeletes) {
        if (infoStream != null) {
          message("apply all deletes during flush");
        }
        flushDeletesCount.incrementAndGet();
        if (bufferedDeletes.applyDeletes(readerPool, segmentInfos, segmentInfos)) {
          checkpoint();
=======
        if (applyAllDeletes) {
          if (infoStream != null) {
            message("apply all deletes during flush");
          }
          flushDeletesCount.incrementAndGet();
          if (bufferedDeletes.applyDeletes(readerPool, segmentInfos, segmentInfos)) {
            checkpoint();
          }
          flushControl.clearDeletes();
        } else if (infoStream != null) {
          message("don't apply deletes now delTermCount=" + bufferedDeletes.numTerms() + " bytesUsed=" + bufferedDeletes.bytesUsed());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714226/fstmerge_var2_2604793013435493552
        }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714226/fstmerge_var1_1597623054870756191
        if (!keepFullyDeletedSegments && result.allDeleted != null) {
          if (infoStream != null) {
            message("drop 100% deleted segments: " + result.allDeleted);
          }
          for(SegmentInfo info : result.allDeleted) {
            // If a merge has already registered for this
            // segment, we leave it in the readerPool; the
            // merge will skip merging it and will then drop
            // it once it's done:
            if (!mergingSegments.contains(info)) {
              segmentInfos.remove(info);
              if (readerPool != null) {
                readerPool.drop(info);
              }
            }
          }
          checkpoint();
        }
        bufferedDeletesStream.prune(segmentInfos);
        assert !bufferedDeletesStream.any();
        flushControl.clearDeletes();
      } else if (infoStream != null) {
        message("don't apply deletes now delTermCount=" + bufferedDeletesStream.numTerms() + " bytesUsed=" + bufferedDeletesStream.bytesUsed());
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714226/fstmerge_base_495501493604572315
        flushControl.clearDeletes();
      } else if (infoStream != null) {
        message("don't apply deletes now delTermCount=" + bufferedDeletes.numTerms() + " bytesUsed=" + bufferedDeletes.bytesUsed());
      }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714226/fstmerge_var2_2604793013435493552

        doAfterFlush();
        flushCount.incrementAndGet();

        success = true;

        return maybeMerge;

      }
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "doFlush");
      // never hit
      return false;
    } finally {
      flushControl.clearFlushPending();
      if (!success && infoStream != null)
        message("hit exception during flush");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public final long ramSizeInBytes() {
    ensureOpen();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714232/fstmerge_var1_8792172240478481062
    return docWriter.bytesUsed() + bufferedDeletesStream.bytesUsed();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714232/fstmerge_base_7742604978927248175
    return docWriter.bytesUsed() + bufferedDeletes.bytesUsed();
=======
    // nocommit
    //return docWriter.bytesUsed() + bufferedDeletes.bytesUsed();
    return 0;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714232/fstmerge_var2_1659135691498285189
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714242/fstmerge_var1_2413219246872966825
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714242/fstmerge_base_14641164259518433
private int ensureContiguousMerge(MergePolicy.OneMerge merge) {

    int first = segmentInfos.indexOf(merge.segments.info(0));
    if (first == -1)
      throw new MergePolicy.MergeException("could not find segment " + merge.segments.info(0).name + " in current index " + segString(), directory);

    final int numSegments = segmentInfos.size();
    
    final int numSegmentsToMerge = merge.segments.size();
    for(int i=0;i<numSegmentsToMerge;i++) {
      final SegmentInfo info = merge.segments.info(i);

      if (first + i >= numSegments || !segmentInfos.info(first+i).equals(info)) {
        if (segmentInfos.indexOf(info) == -1)
          throw new MergePolicy.MergeException("MergePolicy selected a segment (" + info.name + ") that is not in the current index " + segString(), directory);
        else
          throw new MergePolicy.MergeException("MergePolicy selected non-contiguous segments to merge (" + merge.segString(directory) + " vs " + segString() + "), which IndexWriter (currently) cannot handle",
                                               directory);
      }
    }

    return first;
  }
=======
private int ensureContiguousMerge(MergePolicy.OneMerge merge) {

    int first = segmentInfos.indexOf(merge.segments.info(0));
    if (first == -1)
      throw new MergePolicy.MergeException("could not find segment " + merge.segments.info(0).name + " in current index " + segString(), directory);

    final int numSegments = segmentInfos.size();

    final int numSegmentsToMerge = merge.segments.size();
    for(int i=0;i<numSegmentsToMerge;i++) {
      final SegmentInfo info = merge.segments.info(i);

      if (first + i >= numSegments || !segmentInfos.info(first+i).equals(info)) {
        if (segmentInfos.indexOf(info) == -1)
          throw new MergePolicy.MergeException("MergePolicy selected a segment (" + info.name + ") that is not in the current index " + segString(), directory);
        else
          throw new MergePolicy.MergeException("MergePolicy selected non-contiguous segments to merge (" + merge.segString(directory) + " vs " + segString() + "), which IndexWriter (currently) cannot handle",
                                               directory);
      }
    }

    return first;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714242/fstmerge_var2_8249722226694675079

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {

    assert testPoint("startCommitMerge");

    if (hitOOM) {
      throw new IllegalStateException("this writer hit an OutOfMemoryError; cannot complete merge");
    }

    if (infoStream != null)
      message("commitMerge: " + merge.segString(directory) + " index=" + segString());

    assert merge.registerDone;

    // If merge was explicitly aborted, or, if rollback() or
    // rollbackTransaction() had been called since our merge
    // started (which results in an unqualified
    // deleter.refresh() call that will remove any index
    // file that current segments does not reference), we
    // abort this merge
    if (merge.isAborted()) {
      if (infoStream != null)
        message("commitMerge: skipping merge " + merge.segString(directory) + ": it was aborted");
      return false;
    }

    commitMergedDeletes(merge, mergedReader);

    // If the doc store we are using has been closed and
    // is in now compound format (but wasn't when we
    // started), then we will switch to the compound
    // format as well:

    assert !segmentInfos.contains(merge.info);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714252/fstmerge_var1_7349235735885742606

    final boolean allDeleted = mergedReader.numDocs() == 0;

    if (infoStream != null && allDeleted) {
      message("merged segment " + merge.info + " is 100% deleted" +  (keepFullyDeletedSegments ? "" : "; skipping insert"));
    }

    final Set mergedAway = new HashSet<SegmentInfo>(merge.segments);
    int segIdx = 0;
    int newSegIdx = 0;
    boolean inserted = false;
    final int curSegCount = segmentInfos.size();
    while(segIdx < curSegCount) {
      final SegmentInfo info = segmentInfos.info(segIdx++);
      if (mergedAway.contains(info)) {
        if (!inserted && (!allDeleted || keepFullyDeletedSegments)) {
          segmentInfos.set(segIdx-1, merge.info);
          inserted = true;
          newSegIdx++;
        }
      } else {
        segmentInfos.set(newSegIdx++, info);
      }
    }

    // Either we found place to insert segment, or, we did
    // not, but only because all segments we merged became
    // deleted while we are merging, in which case it should
    // be the case that the new segment is also all deleted:
    if (!inserted) {
      assert allDeleted;
      if (keepFullyDeletedSegments) {
        segmentInfos.add(0, merge.info);
      } else {
        readerPool.drop(merge.info);
      }
    }

    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();

    if (infoStream != null) {
      message("after commit: " + segString());
    }

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714252/fstmerge_base_3954199948023665438
    segmentInfos.add(start, merge.info);
    
=======
    segmentInfos.add(start, merge.info);

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714252/fstmerge_var2_4900508001058794897
    closeMergeReaders(merge, false);

    // Must note the change to segmentInfos so any commits
    // in-flight don't lose it:
    checkpoint();

    // If the merged segments had pending changes, clear
    // them so that they don't bother writing them to
    // disk, updating SegmentInfo, etc.:
    readerPool.clear(merge.segments);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714252/fstmerge_var1_7349235735885742606
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714252/fstmerge_base_3954199948023665438
    
    // remove pending deletes of the segments 
    // that were merged, moving them onto the segment just
    // before the merged segment
    // Lock order: IW -> BD
    bufferedDeletes.commitMerge(merge);

=======

    // remove pending deletes of the segments
    // that were merged, moving them onto the segment just
    // before the merged segment
    // Lock order: IW -> BD
    bufferedDeletes.commitMerge(merge);

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714252/fstmerge_var2_4900508001058794897
    if (merge.optimize) {
      // cascade the optimize:
      segmentsToOptimize.add(merge.info);
    }
    
    return true;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714300/fstmerge_var1_3528163231021218071
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714300/fstmerge_base_1055196523427215299
private synchronized void setMergeDocStoreIsCompoundFile(MergePolicy.OneMerge merge) {
    final String mergeDocStoreSegment = merge.info.getDocStoreSegment(); 
    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {
      final int size = segmentInfos.size();
      for(int i=0;i<size;i++) {
        final SegmentInfo info = segmentInfos.info(i);
        final String docStoreSegment = info.getDocStoreSegment();
        if (docStoreSegment != null &&
            docStoreSegment.equals(mergeDocStoreSegment) && 
            info.getDocStoreIsCompoundFile()) {
          merge.info.setDocStoreIsCompoundFile(true);
          break;
        }
      }
    }
  }
=======
private synchronized void setMergeDocStoreIsCompoundFile(MergePolicy.OneMerge merge) {
    final String mergeDocStoreSegment = merge.info.getDocStoreSegment();
    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {
      final int size = segmentInfos.size();
      for(int i=0;i<size;i++) {
        final SegmentInfo info = segmentInfos.info(i);
        final String docStoreSegment = info.getDocStoreSegment();
        if (docStoreSegment != null &&
            docStoreSegment.equals(mergeDocStoreSegment) &&
            info.getDocStoreIsCompoundFile()) {
          merge.info.setDocStoreIsCompoundFile(true);
          break;
        }
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714300/fstmerge_var2_9054352188230521917

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private int mergeMiddle(MergePolicy.OneMerge merge)
    throws CorruptIndexException, IOException {

    merge.checkAborted(directory);

    final String mergedName = merge.info.name;

    int mergedDocCount = 0;

    SegmentInfos sourceSegments = merge.segments;

    SegmentMerger merger = new SegmentMerger(directory, termIndexInterval, mergedName, merge,
                                             codecs, payloadProcessorProvider,
                                             merge.info.getFieldInfos());

    if (infoStream != null) {
      message("merging " + merge.segString(directory) + " mergeVectors=" + merger.fieldInfos().hasVectors());
    }

    merge.readers = new ArrayList<SegmentReader>();
    merge.readerClones = new ArrayList<SegmentReader>();

    merge.info.clearFilesCache();


    // This is try/finally to make sure merger's readers are
    // closed:
    boolean success = false;
    try {
      int totDocCount = 0;
      int segUpto = 0;
      while(segUpto < sourceSegments.size()) {

        final SegmentInfo info = sourceSegments.info(segUpto);

        // Hold onto the "live" reader; we will use this to
        // commit merged deletes
        final SegmentReader reader = readerPool.get(info, true,
                                                    MERGE_READ_BUFFER_SIZE,
                                                    -config.getReaderTermsIndexDivisor());
        merge.readers.add(reader);

        // We clone the segment readers because other
        // deletes may come in while we're merging so we
        // need readers that will not change
        final SegmentReader clone = (SegmentReader) reader.clone(true);
        merge.readerClones.add(clone);

        if (reader.numDocs() > 0) {
          merger.add(clone);
        }
        totDocCount += clone.numDocs();
        segUpto++;
      }

      if (infoStream != null) {
        message("merge: total " + totDocCount + " docs");
      }

      merge.checkAborted(directory);

      // This is where all the work happens:
      mergedDocCount = merge.info.docCount = merger.merge();

      // Record which codec was used to write the segment
      merge.info.setSegmentCodecs(merger.getSegmentCodecs());

      if (infoStream != null) {
        message("merge segmentCodecs=" + merger.getSegmentCodecs());
        message("merge store matchedCount=" + merger.getMatchedSubReaderCount() + " vs " + merge.readers.size());
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714343/fstmerge_var1_505861423122105074
      anyNonBulkMerges |= merger.getMatchedSubReaderCount() != merge.readers.size();
      
      assert mergedDocCount == totDocCount: "mergedDocCount=" + mergedDocCount + " vs " + totDocCount;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714343/fstmerge_base_320639947867472663
      anyNonBulkMerges |= merger.getMatchedSubReaderCount() != numSegments;
      
      assert mergedDocCount == totDocCount;
=======
      anyNonBulkMerges |= merger.getMatchedSubReaderCount() != numSegments;

      assert mergedDocCount == totDocCount;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714343/fstmerge_var2_6917390202151065618

      // Very important to do this before opening the reader
      // because codec must know if prox was written for
      // this segment:
      //System.out.println("merger set hasProx=" + merger.hasProx() + " seg=" + merge.info.name);
      merge.info.clearFilesCache();

      boolean useCompoundFile;
      synchronized (this) { // Guard segmentInfos
        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);
      }

      if (useCompoundFile) {
        success = false;
        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        try {
          if (infoStream != null) {
            message("create compound file " + compoundFileName);
          }
          merger.createCompoundFile(compoundFileName, merge.info);
          success = true;
        } catch (IOException ioe) {
          synchronized(this) {
            if (merge.isAborted()) {
              // This can happen if rollback or close(false)
              // is called -- fall through to logic below to
              // remove the partially created CFS:
            } else {
              handleMergeException(ioe, merge);
            }
          }
        } catch (Throwable t) {
          handleMergeException(t, merge);
        } finally {
          if (!success) {
            if (infoStream != null) {
              message("hit exception creating compound file during merge");
            }

            synchronized(this) {
              deleter.deleteFile(compoundFileName);
              deleter.deleteNewFiles(merge.info.files());
            }
          }
        }

        success = false;

        synchronized(this) {

          // delete new non cfs files directly: they were never
          // registered with IFD
          deleter.deleteNewFiles(merge.info.files());

          if (merge.isAborted()) {
            if (infoStream != null) {
              message("abort merge after building CFS");
            }
            deleter.deleteFile(compoundFileName);
            return 0;
          }
        }

        merge.info.setUseCompoundFile(true);
      }

      final int termsIndexDivisor;
      final boolean loadDocStores;

      if (poolReaders && mergedSegmentWarmer != null) {
        // Load terms index & doc stores so the segment
        // warmer can run searches, load documents/term
        // vectors
        termsIndexDivisor = config.getReaderTermsIndexDivisor();
        loadDocStores = true;
      } else {
        termsIndexDivisor = -1;
        loadDocStores = false;
      }

      // TODO: in the non-realtime case, we may want to only
      // keep deletes (it's costly to open entire reader
      // when we just need deletes)

      final SegmentReader mergedReader = readerPool.get(merge.info, loadDocStores, BufferedIndexInput.BUFFER_SIZE, termsIndexDivisor);
      try {
        if (poolReaders && mergedSegmentWarmer != null) {
          mergedSegmentWarmer.warm(mergedReader);
        }

        if (!commitMerge(merge, mergedReader)) {
          // commitMerge will return false if this merge was aborted
          return 0;
        }
      } finally {
        synchronized(this) {
          if (readerPool.release(mergedReader)) {
            // Must checkpoint after releasing the
            // mergedReader since it may have written a new
            // deletes file:
            checkpoint();
          }
        }
      }

      success = true;

    } finally {
      // Readers are already closed in commitMerge if we didn't hit
      // an exc:
      if (!success) {
        closeMergeReaders(merge, true);
      }
    }

    return mergedDocCount;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private void startCommit(Map<String,String> commitUserData) throws IOException {

    assert testPoint("startStartCommit");
    assert pendingCommit == null;

    if (hitOOM) {
      throw new IllegalStateException("this writer hit an OutOfMemoryError; cannot commit");
    }

    try {

      if (infoStream != null)
        message("startCommit(): start");

      final SegmentInfos toSync;
      final long myChangeCount;

      synchronized(this) {

        assert lastCommitChangeCount <= changeCount;
        myChangeCount = changeCount;

        if (changeCount == lastCommitChangeCount) {
          if (infoStream != null)
            message("  skip startCommit(): no changes pending");
          return;
        }

        // First, we clone & incref the segmentInfos we intend
        // to sync, then, without locking, we sync() all files
        // referenced by toSync, in the background.

        if (infoStream != null)
          message("startCommit index=" + segString(segmentInfos) + " changeCount=" + changeCount);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714406/fstmerge_var1_25045627658768690
        readerPool.commit(segmentInfos);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714406/fstmerge_base_330193750802702771
        readerPool.commit();
        
=======
        readerPool.commit();

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714406/fstmerge_var2_3616628799811048489
        toSync = (SegmentInfos) segmentInfos.clone();

        assert filesExist(toSync);

        if (commitUserData != null)
          toSync.setUserData(commitUserData);

        // This protects the segmentInfos we are now going
        // to commit.  This is important in case, eg, while
        // we are trying to sync all referenced files, a
        // merge completes which would otherwise have
        // removed the files we are now syncing.
        deleter.incRef(toSync, false);
      }

      assert testPoint("midStartCommit");

      try {
        // This call can take a long time -- 10s of seconds
        // or more.  We do it without sync:
        directory.sync(toSync.files(directory, false));

        assert testPoint("midStartCommit2");

        synchronized(this) {

          assert pendingCommit == null;

          assert segmentInfos.getGeneration() == toSync.getGeneration();

          // Exception here means nothing is prepared
          // (this method unwinds everything it did on
          // an exception)
          toSync.prepareCommit(directory);

          pendingCommit = toSync;
          pendingCommitChangeCount = myChangeCount;
        }

        if (infoStream != null)
          message("done all syncs");

        assert testPoint("midStartCommitSuccess");

      } finally {
        synchronized(this) {

          // Have our master segmentInfos record the
          // generations we just prepared.  We do this
          // on error or success so we don't
          // double-write a segments_N file.
          segmentInfos.updateGeneration(toSync);

          if (pendingCommit == null) {
            if (infoStream != null) {
              message("hit exception committing segments file");
            }

            deleter.decRef(toSync);
          }
        }
      }
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "startCommit");
    }
    assert testPoint("finishStartCommit");
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public synchronized boolean flushByRAMUsage(String reason) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714497/fstmerge_var1_6614078477762967671
      final double ramBufferSizeMB = config.getRAMBufferSizeMB();
      if (ramBufferSizeMB != IndexWriterConfig.DISABLE_AUTO_FLUSH) {
        final long limit = (long) (ramBufferSizeMB*1024*1024);
        long used = bufferedDeletesStream.bytesUsed() + docWriter.bytesUsed();
        if (used >= limit) {
          
          // DocumentsWriter may be able to free up some
          // RAM:
          // Lock order: FC -> DW
          docWriter.balanceRAM();

          used = bufferedDeletesStream.bytesUsed() + docWriter.bytesUsed();
          if (used >= limit) {
            return setFlushPending("ram full: " + reason, false);
          }
        }
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714497/fstmerge_base_6523938242208201591
      final double ramBufferSizeMB = config.getRAMBufferSizeMB();
      if (ramBufferSizeMB != IndexWriterConfig.DISABLE_AUTO_FLUSH) {
        final long limit = (long) (ramBufferSizeMB*1024*1024);
        long used = bufferedDeletes.bytesUsed() + docWriter.bytesUsed();
        if (used >= limit) {
          
          // DocumentsWriter may be able to free up some
          // RAM:
          // Lock order: FC -> DW
          docWriter.balanceRAM();

          used = bufferedDeletes.bytesUsed() + docWriter.bytesUsed();
          if (used >= limit) {
            return setFlushPending("ram full: " + reason, false);
          }
        }
      }
=======
      // nocommit
//      final double ramBufferSizeMB = config.getRAMBufferSizeMB();
//      if (ramBufferSizeMB != IndexWriterConfig.DISABLE_AUTO_FLUSH) {
//        final long limit = (long) (ramBufferSizeMB*1024*1024);
//        long used = bufferedDeletes.bytesUsed() + docWriter.bytesUsed();
//        if (used >= limit) {
//
//          // DocumentsWriter may be able to free up some
//          // RAM:
//          // Lock order: FC -> DW
//          docWriter.balanceRAM();
//
//          used = bufferedDeletes.bytesUsed() + docWriter.bytesUsed();
//          if (used >= limit) {
//            return setFlushPending("ram full: " + reason, false);
//          }
//        }
//      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637714497/fstmerge_var2_6952720856627013023
      return false;
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637717963/fstmerge_var1_7315684340348048785
public DocFieldProcessorPerThread(DocumentsWriterThreadState threadState, DocFieldProcessor docFieldProcessor) throws IOException {
    this.docState = threadState.docState;
    this.docFieldProcessor = docFieldProcessor;
    this.consumer = docFieldProcessor.consumer.addThread(this);
    fieldsWriter = docFieldProcessor.fieldsWriter.addThread(docState);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637717963/fstmerge_base_7001087730611845664
public DocFieldProcessorPerThread(DocumentsWriterThreadState threadState, DocFieldProcessor docFieldProcessor) throws IOException {
    this.docState = threadState.docState;
    this.docFieldProcessor = docFieldProcessor;
    this.fieldInfos = docFieldProcessor.fieldInfos;
    this.consumer = docFieldProcessor.consumer.addThread(this);
    fieldsWriter = docFieldProcessor.fieldsWriter.addThread(docState);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637717963/fstmerge_var2_1314552851022068514

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637717968/fstmerge_var1_1952814761706175808
@Override
  public void abort() {
    for(int i=0;i<fieldHash.length;i++) {
      DocFieldProcessorPerField field = fieldHash[i];
      while(field != null) {
        final DocFieldProcessorPerField next = field.next;
        field.abort();
        field = next;
      }
    }
    doAfterFlush();
    fieldsWriter.abort();
    consumer.abort();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637717968/fstmerge_base_3765784629325598553
@Override
  public void abort() {
    for(int i=0;i<fieldHash.length;i++) {
      DocFieldProcessorPerField field = fieldHash[i];
      while(field != null) {
        final DocFieldProcessorPerField next = field.next;
        field.abort();
        field = next;
      }
    }
    fieldsWriter.abort();
    consumer.abort();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637717968/fstmerge_var2_7797152436886199662

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637718165/fstmerge_var1_6859191388904128058
public StoredFieldsWriterPerThread(DocumentsWriter.DocState docState, StoredFieldsWriter storedFieldsWriter) throws IOException {
    this.storedFieldsWriter = storedFieldsWriter;
    this.docState = docState;
    localFieldsWriter = new FieldsWriter((IndexOutput) null, (IndexOutput) null);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637718165/fstmerge_base_7939916680737240760
public StoredFieldsWriterPerThread(DocumentsWriter.DocState docState, StoredFieldsWriter storedFieldsWriter) throws IOException {
    this.storedFieldsWriter = storedFieldsWriter;
    this.docState = docState;
    localFieldsWriter = new FieldsWriter((IndexOutput) null, (IndexOutput) null, storedFieldsWriter.fieldInfos);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637718165/fstmerge_var2_5689208712327866210

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/lucene/src/java/org/apache/lucene/index/StoredFieldsWriterPerThread.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637766166/fstmerge_var1_5930044393342970879
@Override
  public void write(byte b[]) throws IOException {
    write(b,0,b.length);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637766166/fstmerge_base_5276284038448015141
public void write(byte b[]) throws IOException {
    write(b,0,b.length);
=======
public void write(byte b) throws IOException {
    if (pos >= buf.length) {
      out.write(buf);
      written += pos;
      pos=0;
    }
    buf[pos++] = b;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419637766166/fstmerge_var2_1642247717277503560
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_268bd_64808/rev_268bd-64808/solr/src/common/org/apache/solr/common/util/FastOutputStream.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_10dce_7f044/rev_10dce-7f044.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419638618915/fstmerge_var1_2720172185055134643
@Override
  public void flush(Collection<DocConsumerPerThread> threads, SegmentWriteState state) throws IOException {

    Map<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>> childThreadsAndFields = new HashMap<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>>();
    for ( DocConsumerPerThread thread : threads) {
      DocFieldProcessorPerThread perThread = (DocFieldProcessorPerThread) thread;
      childThreadsAndFields.put(perThread.consumer, perThread.fields());
    }
    fieldsWriter.flush(state);
    consumer.flush(childThreadsAndFields, state);

    // Important to save after asking consumer to flush so
    // consumer can alter the FieldInfo* if necessary.  EG,
    // FreqProxTermsWriter does this with
    // FieldInfo.storePayload.
    final String fileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.FIELD_INFOS_EXTENSION);

    // If this segment only has docs that hit non-aborting exceptions,
    // then no term vectors files will have been written; therefore we
    // need to update the fieldInfos and clear the term vectors bits
    if (!state.hasVectors) {
      state.fieldInfos.clearVectors();
    }
    state.fieldInfos.write(state.directory, fileName);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419638618915/fstmerge_base_2607853143600387883
@Override
  public void flush(Collection<DocConsumerPerThread> threads, SegmentWriteState state) throws IOException {

    Map<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>> childThreadsAndFields = new HashMap<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>>();
    for ( DocConsumerPerThread thread : threads) {
      DocFieldProcessorPerThread perThread = (DocFieldProcessorPerThread) thread;
      childThreadsAndFields.put(perThread.consumer, perThread.fields());
    }
    fieldsWriter.flush(state);
    consumer.flush(childThreadsAndFields, state);

    // Important to save after asking consumer to flush so
    // consumer can alter the FieldInfo* if necessary.  EG,
    // FreqProxTermsWriter does this with
    // FieldInfo.storePayload.
    final String fileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.FIELD_INFOS_EXTENSION);
    state.fieldInfos.write(state.directory, fileName);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419638618915/fstmerge_var2_5325329710856512014

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_10dce_7f044/rev_10dce-7f044/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0e54b_6b0ef/rev_0e54b-6b0ef.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17290_114f1/rev_17290-114f1.revisions
Conflict type: LineBasedMCFd
Conflict body: 
private void write(final FieldInfos fieldInfos, final Directory dir, final FieldData[] fields, boolean allowPreFlex) throws Throwable {

    final int termIndexInterval = _TestUtil.nextInt(random, 13, 27);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640417200/fstmerge_var1_7623205235295067218
    final SegmentCodecs codecInfo =  fieldInfos.buildSegmentCodecs(false);
    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, 10000, termIndexInterval, codecInfo, null);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640417200/fstmerge_base_172593623545295058
    final SegmentCodecs codecInfo = SegmentCodecs.build(fieldInfos, CodecProvider.getDefault());
    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, 10000, termIndexInterval, codecInfo, null);
=======
    final SegmentCodecs codecInfo = SegmentCodecs.build(fieldInfos, CodecProvider.getDefault());
    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, 10000, termIndexInterval, codecInfo, null, new AtomicLong(0));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640417200/fstmerge_var2_4368299975617474851

    final FieldsConsumer consumer = state.segmentCodecs.codec().fieldsConsumer(state);
    Arrays.sort(fields);
    for (final FieldData field : fields) {
      assertTrue(field.fieldInfo.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID);
      if (!allowPreFlex && codecInfo.codecs[field.fieldInfo.getCodecId()] instanceof PreFlexCodec) {
        // code below expects unicode sort order
        continue;
      }
      field.write(consumer);
    }
    consumer.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17290_114f1/rev_17290-114f1/lucene/src/test/org/apache/lucene/index/TestCodecs.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640435263/fstmerge_var1_819274001865733292
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640435263/fstmerge_base_1770085183799643283
@Override
  public DocumentsWriter.DocWriter processDocument() throws IOException {

    consumer.startDocument();
    fieldsWriter.startDocument();

    final Document doc = docState.doc;

    assert docFieldProcessor.docWriter.writer.testPoint("DocumentsWriter.ThreadState.init start");

    fieldCount = 0;
    
    final int thisFieldGen = fieldGen++;

    final List<Fieldable> docFields = doc.getFields();
    final int numDocFields = docFields.size();

    // Absorb any new fields first seen in this document.
    // Also absorb any changes to fields we had already
    // seen before (eg suddenly turning on norms or
    // vectors, etc.):

    for(int i=0;i<numDocFields;i++) {
      Fieldable field = docFields.get(i);
      final String fieldName = field.name();

      // Make sure we have a PerField allocated
      final int hashPos = fieldName.hashCode() & hashMask;
      DocFieldProcessorPerField fp = fieldHash[hashPos];
      while(fp != null && !fp.fieldInfo.name.equals(fieldName))
        fp = fp.next;

      if (fp == null) {

        // TODO FI: we need to genericize the "flags" that a
        // field holds, and, how these flags are merged; it
        // needs to be more "pluggable" such that if I want
        // to have a new "thing" my Fields can do, I can
        // easily add it
        FieldInfo fi = fieldInfos.add(fieldName, field.isIndexed(), field.isTermVectorStored(),
                                      field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                                      field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
        fp = new DocFieldProcessorPerField(this, fi);
        fp.next = fieldHash[hashPos];
        fieldHash[hashPos] = fp;
        totalFieldCount++;

        if (totalFieldCount >= fieldHash.length/2)
          rehash();
      } else
        fp.fieldInfo.update(field.isIndexed(), field.isTermVectorStored(),
                            field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                            field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());

      if (thisFieldGen != fp.lastGen) {

        // First time we're seeing this field for this doc
        fp.fieldCount = 0;

        if (fieldCount == fields.length) {
          final int newSize = fields.length*2;
          DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];
          System.arraycopy(fields, 0, newArray, 0, fieldCount);
          fields = newArray;
        }

        fields[fieldCount++] = fp;
        fp.lastGen = thisFieldGen;
      }

      if (fp.fieldCount == fp.fields.length) {
        Fieldable[] newArray = new Fieldable[fp.fields.length*2];
        System.arraycopy(fp.fields, 0, newArray, 0, fp.fieldCount);
        fp.fields = newArray;
      }

      fp.fields[fp.fieldCount++] = field;
      if (field.isStored()) {
        fieldsWriter.addField(field, fp.fieldInfo);
      }
    }

    // If we are writing vectors then we must visit
    // fields in sorted order so they are written in
    // sorted order.  TODO: we actually only need to
    // sort the subset of fields that have vectors
    // enabled; we could save [small amount of] CPU
    // here.
    ArrayUtil.quickSort(fields, 0, fieldCount, fieldsComp);

    for(int i=0;i<fieldCount;i++)
      fields[i].consumer.processFields(fields[i].fields, fields[i].fieldCount);

    if (docState.maxTermPrefix != null && docState.infoStream != null) {
      docState.infoStream.println("WARNING: document contains at least one immense term (whose UTF8 encoding is longer than the max length " + DocumentsWriter.MAX_TERM_LENGTH_UTF8 + "), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '" + docState.maxTermPrefix + "...'"); 
      docState.maxTermPrefix = null;
    }

    final DocumentsWriter.DocWriter one = fieldsWriter.finishDocument();
    final DocumentsWriter.DocWriter two = consumer.finishDocument();
    if (one == null) {
      return two;
    } else if (two == null) {
      return one;
    } else {
      PerDoc both = getPerDoc();
      both.docID = docState.docID;
      assert one.docID == docState.docID;
      assert two.docID == docState.docID;
      both.one = one;
      both.two = two;
      return both;
    }
  }
=======
@Override
  public DocumentsWriter.DocWriter processDocument() throws IOException {

    consumer.startDocument();
    fieldsWriter.startDocument();

    final Document doc = docState.doc;

    assert docFieldProcessor.docWriter.writer.testPoint("DocumentsWriter.ThreadState.init start");

    fieldCount = 0;
    
    final int thisFieldGen = fieldGen++;

    final List<Fieldable> docFields = doc.getFields();
    final int numDocFields = docFields.size();

    // Absorb any new fields first seen in this document.
    // Also absorb any changes to fields we had already
    // seen before (eg suddenly turning on norms or
    // vectors, etc.):

    for(int i=0;i<numDocFields;i++) {
      Fieldable field = docFields.get(i);
      final String fieldName = field.name();

      // Make sure we have a PerField allocated
      final int hashPos = fieldName.hashCode() & hashMask;
      DocFieldProcessorPerField fp = fieldHash[hashPos];
      while(fp != null && !fp.fieldInfo.name.equals(fieldName))
        fp = fp.next;

      if (fp == null) {

        // TODO FI: we need to genericize the "flags" that a
        // field holds, and, how these flags are merged; it
        // needs to be more "pluggable" such that if I want
        // to have a new "thing" my Fields can do, I can
        // easily add it
        FieldInfo fi = fieldInfos.add(fieldName, field.isIndexed(), field.isTermVectorStored(),
                                      field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                                      field.getOmitNorms(), false, field.getOmitTermFreqAndPositions(), field.docValuesType());
        fp = new DocFieldProcessorPerField(this, fi);
        fp.next = fieldHash[hashPos];
        fieldHash[hashPos] = fp;
        totalFieldCount++;

        if (totalFieldCount >= fieldHash.length/2)
          rehash();
      } else
        fp.fieldInfo.update(field.isIndexed(), field.isTermVectorStored(),
                            field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                            field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());

      if (thisFieldGen != fp.lastGen) {

        // First time we're seeing this field for this doc
        fp.fieldCount = 0;

        if (fieldCount == fields.length) {
          final int newSize = fields.length*2;
          DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];
          System.arraycopy(fields, 0, newArray, 0, fieldCount);
          fields = newArray;
        }

        fields[fieldCount++] = fp;
        fp.lastGen = thisFieldGen;
      }

      if (fp.fieldCount == fp.fields.length) {
        Fieldable[] newArray = new Fieldable[fp.fields.length*2];
        System.arraycopy(fp.fields, 0, newArray, 0, fp.fieldCount);
        fp.fields = newArray;
      }

      fp.fields[fp.fieldCount++] = field;
      if (field.isStored()) {
        fieldsWriter.addField(field, fp.fieldInfo);
      }
    }

    // If we are writing vectors then we must visit
    // fields in sorted order so they are written in
    // sorted order.  TODO: we actually only need to
    // sort the subset of fields that have vectors
    // enabled; we could save [small amount of] CPU
    // here.
    ArrayUtil.quickSort(fields, 0, fieldCount, fieldsComp);
   

    for(int i=0;i<fieldCount;i++) {
      final DocFieldProcessorPerField perField = fields[i];
      final Fieldable fieldable = perField.fields[0];
      perField.consumer.processFields(perField.fields, perField.fieldCount);
      final PerDocFieldValues docValues = fieldable.getDocValues();
      if (docValues == null) {
        continue;
      }
      final DocValuesConsumer consumer = docFieldProcessor.docValuesConsumer(docState.docWriter.directory,
              docState.docWriter.segment, fieldable.name(), docValues, perField.fieldInfo);
      consumer.add(docState.docID, docValues);
    }
    if (docState.maxTermPrefix != null && docState.infoStream != null) {
      docState.infoStream.println("WARNING: document contains at least one immense term (whose UTF8 encoding is longer than the max length " + DocumentsWriter.MAX_TERM_LENGTH_UTF8 + "), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '" + docState.maxTermPrefix + "...'"); 
      docState.maxTermPrefix = null;
    }

    final DocumentsWriter.DocWriter one = fieldsWriter.finishDocument();
    final DocumentsWriter.DocWriter two = consumer.finishDocument();
    if (one == null) {
      return two;
    } else if (two == null) {
      return one;
    } else {
      PerDoc both = getPerDoc();
      both.docID = docState.docID;
      assert one.docID == docState.docID;
      assert two.docID == docState.docID;
      both.one = one;
      both.two = two;
      return both;
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640435263/fstmerge_var2_4284564070509550362

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17290_114f1/rev_17290-114f1/lucene/src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640435585/fstmerge_var1_1098002373632750428
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640435585/fstmerge_base_7696537045465562473
static SegmentCodecs build(FieldInfos infos, CodecProvider provider) {
    final int size = infos.size();
    final Map<Codec, Integer> codecRegistry = new IdentityHashMap<Codec, Integer>();
    final ArrayList<Codec> codecs = new ArrayList<Codec>();

    for (int i = 0; i < size; i++) {
      final FieldInfo info = infos.fieldInfo(i);
      if (info.isIndexed) {
        final Codec fieldCodec = provider.lookup(provider
            .getFieldCodec(info.name));
        Integer ord = codecRegistry.get(fieldCodec);
        if (ord == null) {
          ord = Integer.valueOf(codecs.size());
          codecRegistry.put(fieldCodec, ord);
          codecs.add(fieldCodec);
        }
        info.codecId = ord.intValue();
      }
    }
    return new SegmentCodecs(provider, codecs.toArray(Codec.EMPTY));

  }
=======
static SegmentCodecs build(FieldInfos infos, CodecProvider provider) {
    final int size = infos.size();
    final Map<Codec, Integer> codecRegistry = new IdentityHashMap<Codec, Integer>();
    final ArrayList<Codec> codecs = new ArrayList<Codec>();

    for (int i = 0; i < size; i++) {
      final FieldInfo info = infos.fieldInfo(i);
      if (info.isIndexed || info.hasDocValues()) {
        final Codec fieldCodec = provider.lookup(provider
            .getFieldCodec(info.name));
        Integer ord = codecRegistry.get(fieldCodec);
        if (ord == null) {
          ord = Integer.valueOf(codecs.size());
          codecRegistry.put(fieldCodec, ord);
          codecs.add(fieldCodec);
        }
        info.codecId = ord.intValue();
      }
    }
    return new SegmentCodecs(provider, codecs.toArray(Codec.EMPTY));
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640435585/fstmerge_var2_1326930000608971173

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17290_114f1/rev_17290-114f1/lucene/src/java/org/apache/lucene/index/SegmentCodecs.java
Conflict type: LineBasedMCFd
Conflict body: 
public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,
        int readBufferSize, int indexDivisor) throws IOException {

      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();
      boolean success = false;
      try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640435651/fstmerge_var1_957739175439401508
        for (FieldInfo fi : fieldInfos) {
          if (fi.isIndexed) { // TODO this does not work for non-indexed fields
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640435651/fstmerge_base_4683284900030955384
        for (int i = 0; i < fieldCount; i++) {
          FieldInfo fi = fieldInfos.fieldInfo(i);
          if (fi.isIndexed) { // TODO this does not work for non-indexed fields
=======
        for (int i = 0; i < fieldCount; i++) {
          FieldInfo fi = fieldInfos.fieldInfo(i);
          if (fi.isIndexed || fi.hasDocValues()) { // TODO this does not work for non-indexed fields
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640435651/fstmerge_var2_618152398998161710
            fields.add(fi.name);
            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;
            Codec codec = segmentCodecs.codecs[fi.getCodecId()];
            if (!producers.containsKey(codec)) {
              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,
                                                                             si, fieldInfos, readBufferSize, indexDivisor, ""+fi.getCodecId())));
            }
            codecs.put(fi.name, producers.get(codec));
          }
        }
        success = true;
      } finally {
        if (!success) {
          // If we hit exception (eg, IOE because writer was
          // committing, or, for any other reason) we must
          // go back and close all FieldsProducers we opened:
          for(FieldsProducer fp : producers.values()) {
            try {
              fp.close();
            } catch (Throwable t) {
              // Suppress all exceptions here so we continue
              // to throw the original one
            }
          }
        }
      }
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17290_114f1/rev_17290-114f1/lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.java
Conflict type: LineBasedMCFd
Conflict body: 
synchronized SegmentInfo flush(IndexWriter writer, IndexFileDeleter deleter, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {

    final long startTime = System.currentTimeMillis();

    // We change writer's segmentInfos:
    assert Thread.holdsLock(writer);

    waitIdle();

    if (numDocs == 0) {
      // nothing to do!
      if (infoStream != null) {
        message("flush: no docs; skipping");
      }
      // Lock order: IW -> DW -> BD
      pushDeletes(null, segmentInfos);
      return null;
    }

    if (aborting) {
      if (infoStream != null) {
        message("flush: skip because aborting is set");
      }
      return null;
    }

    boolean success = false;

    SegmentInfo newSegment;

    try {
      assert nextDocID == numDocs;
      assert waitQueue.numWaiting == 0;
      assert waitQueue.waitingBytes == 0;

      if (infoStream != null) {
        message("flush postings as segment " + segment + " numDocs=" + numDocs);
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640437826/fstmerge_var1_4862028722483031311
      
      final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                                                 numDocs, writer.getConfig().getTermIndexInterval(),
                                                                 fieldInfos.buildSegmentCodecs(true),
                                                                 pendingDeletes);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640437826/fstmerge_base_6954573597114763422

      final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                                                 numDocs, writer.getConfig().getTermIndexInterval(),
                                                                 SegmentCodecs.build(fieldInfos, writer.codecs),
                                                                 pendingDeletes);
=======

      final SegmentWriteState flushState = segWriteState();

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640437826/fstmerge_var2_4008761590122298006
      // Apply delete-by-docID now (delete-byDocID only
      // happens when an exception is hit processing that
      // doc, eg if analyzer has some problem w/ the text):
      if (pendingDeletes.docIDs.size() > 0) {
        flushState.deletedDocs = new BitVector(numDocs);
        for(int delDocID : pendingDeletes.docIDs) {
          flushState.deletedDocs.set(delDocID);
        }
        pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);
        pendingDeletes.docIDs.clear();
      }

      newSegment = new SegmentInfo(segment, numDocs, directory, false, fieldInfos.hasProx(), flushState.segmentCodecs, false, fieldInfos);

      Collection<DocConsumerPerThread> threads = new HashSet<DocConsumerPerThread>();
      for (DocumentsWriterThreadState threadState : threadStates) {
        threads.add(threadState.consumer);
      }

      double startMBUsed = bytesUsed()/1024./1024.;

      consumer.flush(threads, flushState);

      newSegment.setHasVectors(flushState.hasVectors);

      if (infoStream != null) {
        message("new segment has " + (flushState.hasVectors ? "vectors" : "no vectors"));
        if (flushState.deletedDocs != null) {
          message("new segment has " + flushState.deletedDocs.count() + " deleted docs");
        }
        message("flushedFiles=" + newSegment.files());
        message("flushed codecs=" + newSegment.getSegmentCodecs());
      }

      if (mergePolicy.useCompoundFile(segmentInfos, newSegment)) {
        final String cfsFileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        if (infoStream != null) {
          message("flush: create compound file \"" + cfsFileName + "\"");
        }

        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, cfsFileName);
        for(String fileName : newSegment.files()) {
          cfsWriter.addFile(fileName);
        }
        cfsWriter.close();
        deleter.deleteNewFiles(newSegment.files());
        newSegment.setUseCompoundFile(true);
      }

      // Must write deleted docs after the CFS so we don't
      // slurp the del file into CFS:
      if (flushState.deletedDocs != null) {
        final int delCount = flushState.deletedDocs.count();
        assert delCount > 0;
        newSegment.setDelCount(delCount);
        newSegment.advanceDelGen();
        final String delFileName = newSegment.getDelFileName();
        if (infoStream != null) {
          message("flush: write " + delCount + " deletes to " + delFileName);
        }
        boolean success2 = false;
        try {
          // TODO: in the NRT case it'd be better to hand
          // this del vector over to the
          // shortly-to-be-opened SegmentReader and let it
          // carry the changes; there's no reason to use
          // filesystem as intermediary here.
          flushState.deletedDocs.write(directory, delFileName);
          success2 = true;
        } finally {
          if (!success2) {
            try {
              directory.deleteFile(delFileName);
            } catch (Throwable t) {
              // suppress this so we keep throwing the
              // original exception
            }
          }
        }
      }

      if (infoStream != null) {
        message("flush: segment=" + newSegment);
        final double newSegmentSizeNoStore = newSegment.sizeInBytes(false)/1024./1024.;
        final double newSegmentSize = newSegment.sizeInBytes(true)/1024./1024.;
        message("  ramUsed=" + nf.format(startMBUsed) + " MB" +
                " newFlushedSize=" + nf.format(newSegmentSize) + " MB" +
                " (" + nf.format(newSegmentSizeNoStore) + " MB w/o doc stores)" +
                " docs/MB=" + nf.format(numDocs / newSegmentSize) +
                " new/old=" + nf.format(100.0 * newSegmentSizeNoStore / startMBUsed) + "%");
      }

      success = true;
    } finally {
      notifyAll();
      if (!success) {
        if (segment != null) {
          deleter.refresh(segment);
        }
        abort();
      }
    }

    doAfterFlush();

    // Lock order: IW -> DW -> BD
    pushDeletes(newSegment, segmentInfos);
    if (infoStream != null) {
      message("flush time " + (System.currentTimeMillis()-startTime) + " msec");
    }

    return newSegment;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17290_114f1/rev_17290-114f1/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private int mergeFields() throws CorruptIndexException, IOException {

    for (IndexReader reader : readers) {
      if (reader instanceof SegmentReader) {
        SegmentReader segmentReader = (SegmentReader) reader;
        FieldInfos readerFieldInfos = segmentReader.fieldInfos();
        for (FieldInfo fi : readerFieldInfos) {
          fieldInfos.add(fi);
        }
      } else {
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION_OFFSET), true, true, true, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION), true, true, false, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_OFFSET), true, false, true, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR), true, false, false, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.OMIT_TERM_FREQ_AND_POSITIONS), false, false, false, false, true);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.STORES_PAYLOADS), false, false, false, true, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.INDEXED), false, false, false, false, false);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640438384/fstmerge_var1_1156822626847344838
        fieldInfos.addOrUpdate(reader.getFieldNames(FieldOption.UNINDEXED), false);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640438384/fstmerge_base_8197375160980463428
        fieldInfos.add(reader.getFieldNames(FieldOption.UNINDEXED), false);
=======
        fieldInfos.add(reader.getFieldNames(FieldOption.UNINDEXED), false);
        fieldInfos.add(reader.getFieldNames(FieldOption.DOC_VALUES), false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640438384/fstmerge_var2_1836928155744317412
      }
    }
    final SegmentCodecs codecInfo = fieldInfos.buildSegmentCodecs(false);
    fieldInfos.write(directory, segment + "." + IndexFileNames.FIELD_INFOS_EXTENSION);

    int docCount = 0;

    setMatchingSegmentReaders();

    final FieldsWriter fieldsWriter = new FieldsWriter(directory, segment);

    try {
      int idx = 0;
      for (IndexReader reader : readers) {
        final SegmentReader matchingSegmentReader = matchingSegmentReaders[idx++];
        FieldsReader matchingFieldsReader = null;
        if (matchingSegmentReader != null) {
          final FieldsReader fieldsReader = matchingSegmentReader.getFieldsReader();
          if (fieldsReader != null) {
            matchingFieldsReader = fieldsReader;
          }
        }
        if (reader.hasDeletions()) {
          docCount += copyFieldsWithDeletions(fieldsWriter,
                                              reader, matchingFieldsReader);
        } else {
          docCount += copyFieldsNoDeletions(fieldsWriter,
                                            reader, matchingFieldsReader);
        }
      }
    } finally {
      fieldsWriter.close();
    }

    final String fileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.FIELDS_INDEX_EXTENSION);
    final long fdxFileLength = directory.fileLength(fileName);

    if (4+((long) docCount)*8 != fdxFileLength)
      // This is most likely a bug in Sun JRE 1.6.0_04/_05;
      // we detect that the bug has struck, here, and
      // throw an exception to prevent the corruption from
      // entering the index.  See LUCENE-1282 for
      // details.
      throw new RuntimeException("mergeFields produced an invalid result: docCount is " + docCount + " but fdx file size is " + fdxFileLength + " file=" + fileName + " file exists?=" + directory.fileExists(fileName) + "; now aborting this merge to prevent index corruption");

    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, docCount, termIndexInterval, codecInfo, null, new AtomicLong(0));
    
    return docCount;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17290_114f1/rev_17290-114f1/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640440378/fstmerge_var1_123367352587409279
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640440378/fstmerge_base_6865202163672653326
synchronized public void add(Document doc) {
    List<Fieldable> fields = doc.getFields();
    for (Fieldable field : fields) {
      add(field.name(), field.isIndexed(), field.isTermVectorStored(), field.isStorePositionWithTermVector(),
              field.isStoreOffsetWithTermVector(), field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
    }
  }
=======
synchronized public void add(Document doc) {
    List<Fieldable> fields = doc.getFields();
    for (Fieldable field : fields) {
      add(field.name(), field.isIndexed(), field.isTermVectorStored(), field.isStorePositionWithTermVector(),
              field.isStoreOffsetWithTermVector(), field.getOmitNorms(), false, field.getOmitTermFreqAndPositions(), field.docValuesType()); 
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640440378/fstmerge_var2_4107752125408566882

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17290_114f1/rev_17290-114f1/lucene/src/java/org/apache/lucene/index/FieldInfos.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640440409/fstmerge_var1_1197026443410204452
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640440409/fstmerge_base_4513637553838157364
synchronized public void add(String name, boolean isIndexed, boolean storeTermVector,
                  boolean storePositionWithTermVector, boolean storeOffsetWithTermVector, boolean omitNorms) {
    add(name, isIndexed, storeTermVector, storePositionWithTermVector,
        storeOffsetWithTermVector, omitNorms, false, false);
  }
=======
synchronized public void add(String name, boolean isIndexed, boolean storeTermVector,
                  boolean storePositionWithTermVector, boolean storeOffsetWithTermVector, boolean omitNorms) {
    add(name, isIndexed, storeTermVector, storePositionWithTermVector,
        storeOffsetWithTermVector, omitNorms, false, false, null);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640440409/fstmerge_var2_8535727589078722150

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17290_114f1/rev_17290-114f1/lucene/src/java/org/apache/lucene/index/FieldInfos.java
Conflict type: LineBasedMCFd
Conflict body: 
private void read(IndexInput input, String fileName) throws IOException {
    format = input.readVInt();

    if (format > FORMAT_MINIMUM) {
      throw new IndexFormatTooOldException(fileName, format, FORMAT_MINIMUM, FORMAT_CURRENT);
    }
    if (format < FORMAT_CURRENT) {
      throw new IndexFormatTooNewException(fileName, format, FORMAT_MINIMUM, FORMAT_CURRENT);
    }

    final int size = input.readVInt(); //read in the size

    for (int i = 0; i < size; i++) {
      String name = StringHelper.intern(input.readString());
      // if this is a previous format codec 0 will be preflex!
      final int fieldNumber = format <= FORMAT_PER_FIELD_CODEC? input.readInt():i;
      final int codecId = format <= FORMAT_PER_FIELD_CODEC? input.readInt():0;
      byte bits = input.readByte();
      boolean isIndexed = (bits & IS_INDEXED) != 0;
      boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;
      boolean storePositionsWithTermVector = (bits & STORE_POSITIONS_WITH_TERMVECTOR) != 0;
      boolean storeOffsetWithTermVector = (bits & STORE_OFFSET_WITH_TERMVECTOR) != 0;
      boolean omitNorms = (bits & OMIT_NORMS) != 0;
      boolean storePayloads = (bits & STORE_PAYLOADS) != 0;
      boolean omitTermFreqAndPositions = (bits & OMIT_TERM_FREQ_AND_POSITIONS) != 0;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640440457/fstmerge_var1_4291103957790959323
      final FieldInfo addInternal = addInternal(name, fieldNumber, isIndexed, storeTermVector, storePositionsWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
      addInternal.setCodecId(codecId);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640440457/fstmerge_base_4329621602300847551
      final FieldInfo addInternal = addInternal(name, isIndexed, storeTermVector, storePositionsWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
      addInternal.codecId = codecId;
=======
      Type docValuesType = null;
      if (format <= FORMAT_INDEX_VALUES) {
        final byte b = input.readByte();
        switch(b) {
        case 0:
          docValuesType = null;
          break;
        case 1:
          docValuesType = Type.INTS;
          break;
        case 2:
          docValuesType = Type.FLOAT_32;
          break;
        case 3:
          docValuesType = Type.FLOAT_64;
          break;
        case 4:
          docValuesType = Type.BYTES_FIXED_STRAIGHT;
          break;
        case 5:
          docValuesType = Type.BYTES_FIXED_DEREF;
          break;
        case 6:
          docValuesType = Type.BYTES_FIXED_SORTED;
          break;
        case 7:
          docValuesType = Type.BYTES_VAR_STRAIGHT;
          break;
        case 8:
          docValuesType = Type.BYTES_VAR_DEREF;
          break;
        case 9:
          docValuesType = Type.BYTES_VAR_SORTED;
          break;
        default:
          throw new IllegalStateException("unhandled indexValues type " + b);
        }
      }
      final FieldInfo fi = addInternal(name, isIndexed, storeTermVector, storePositionsWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions, docValuesType);

      fi.codecId = codecId;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419640440457/fstmerge_var2_8930574316284650468
    }

    if (input.getFilePointer() != input.length()) {
      throw new CorruptIndexException("did not read all bytes from file \"" + fileName + "\": read " + input.getFilePointer() + " vs size " + input.length());
    }    
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17290_114f1/rev_17290-114f1/lucene/src/java/org/apache/lucene/index/FieldInfos.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641338740/fstmerge_var1_4744495775029887307
public void testIndexingThenDeleting() throws Exception {
    final Random r = random;

    Directory dir = newDirectory();
    FlushCountingIndexWriter w = new FlushCountingIndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, true, false)).setRAMBufferSizeMB(1.0).setMaxBufferedDocs(-1).setMaxBufferedDeleteTerms(-1));
    w.setInfoStream(VERBOSE ? System.out : null);
    Document doc = new Document();
    doc.add(newField("field", "go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20", Field.Store.NO, Field.Index.ANALYZED));
    int num = 6 * RANDOM_MULTIPLIER;
    for (int iter = 0; iter < num; iter++) {
      int count = 0;

      final boolean doIndexing = r.nextBoolean();
      if (VERBOSE) {
        System.out.println("TEST: iter doIndexing=" + doIndexing);
      }
      if (doIndexing) {
        // Add docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.addDocument(doc);
          count++;
        }
      } else {
        // Delete docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.deleteDocuments(new Term("foo", ""+count));
          count++;
        }
      }
      assertTrue("flush happened too quickly during " + (doIndexing ? "indexing" : "deleting") + " count=" + count, count > 3000);
    }
    w.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641338740/fstmerge_base_7960090832670097825
public void testIndexingThenDeleting() throws Exception {
    final Random r = random;

    Directory dir = newDirectory();
    FlushCountingIndexWriter w = new FlushCountingIndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, true, false)).setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMaxBufferedDeleteTerms(-1));
    w.setInfoStream(VERBOSE ? System.out : null);
    Document doc = new Document();
    doc.add(newField("field", "go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20", Field.Store.NO, Field.Index.ANALYZED));
    int num = 6 * RANDOM_MULTIPLIER;
    for (int iter = 0; iter < num; iter++) {
      int count = 0;

      final boolean doIndexing = r.nextBoolean();
      if (VERBOSE) {
        System.out.println("TEST: iter doIndexing=" + doIndexing);
      }
      if (doIndexing) {
        // Add docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.addDocument(doc);
          count++;
        }
      } else {
        // Delete docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.deleteDocuments(new Term("foo", ""+count));
          count++;
        }
      }
      assertTrue("flush happened too quickly during " + (doIndexing ? "indexing" : "deleting") + " count=" + count, count > 1500);
    }
    w.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641338740/fstmerge_var2_573988962142847643

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private SegmentInfo merge(SegmentInfo si1, SegmentInfo si2, String merged, boolean useCompoundFile)
   throws Exception {
      SegmentReader r1 = SegmentReader.get(true, si1, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);
      SegmentReader r2 = SegmentReader.get(true, si2, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);

      SegmentMerger merger = new SegmentMerger(si1.dir, IndexWriterConfig.DEFAULT_TERM_INDEX_INTERVAL, merged, null, CodecProvider.getDefault(), null, new FieldInfos());

      merger.add(r1);
      merger.add(r2);
      merger.merge();
      r1.close();
      r2.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641339613/fstmerge_var1_4185927400101587229
      final FieldInfos fieldInfos =  merger.fieldInfos();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641339613/fstmerge_base_3468890669817629213
      
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641339613/fstmerge_var2_2770009126418588237
      final SegmentInfo info = new SegmentInfo(merged, si1.docCount + si2.docCount, si1.dir,
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641339613/fstmerge_var1_4185927400101587229
                                               false, fieldInfos.hasProx(), merger.getSegmentCodecs(),
                                               fieldInfos.hasVectors(), fieldInfos);
      
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641339613/fstmerge_base_3468890669817629213
                                               false, merger.getSegmentCodecs(),
                                               merger.fieldInfos());
      
=======
                                               false, merger.getSegmentCodecs(),
                                               merger.fieldInfos());

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641339613/fstmerge_var2_2770009126418588237
      if (useCompoundFile) {
        Collection<String> filesToDelete = merger.createCompoundFile(merged + ".cfs", info);
        info.setUseCompoundFile(true);
        for (final String fileToDelete : filesToDelete)
          si1.dir.deleteFile(fileToDelete);
      }

      return info;
   }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/test/org/apache/lucene/index/TestDoc.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testNonCFSLeftovers() throws Exception {
    Directory[] dirs = new Directory[2];
    for (int i = 0; i < dirs.length; i++) {
      dirs[i] = new RAMDirectory();
      IndexWriter w = new IndexWriter(dirs[i], new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
      Document d = new Document();
      d.add(new Field("c", "v", Store.YES, Index.ANALYZED, TermVector.YES));
      w.addDocument(d);
      w.close();
    }

    IndexReader[] readers = new IndexReader[] { IndexReader.open(dirs[0]), IndexReader.open(dirs[1]) };

    Directory dir = new RAMDirectory();
    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());
    LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
    lmp.setNoCFSRatio(1.0); // Force creation of CFS
    IndexWriter w3 = new IndexWriter(dir, conf);
    w3.addIndexes(readers);
    w3.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641340670/fstmerge_var1_3975563327640224460
    // we should now see segments_X, segments.gen,_Y.cfs, _Z.fnx
    assertEquals("Only one compound segment should exist", 4, dir.listAll().length);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641340670/fstmerge_base_7943735485676575875
    
    assertEquals("Only one compound segment should exist", 3, dir.listAll().length);
=======

    assertEquals("Only one compound segment should exist", 3, dir.listAll().length);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641340670/fstmerge_var2_4894824576905131355
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
Conflict type: LineBasedMCFd
Conflict body: 
public SegmentInfo(Directory dir, int format, IndexInput input, CodecProvider codecs) throws IOException {
    this.dir = dir;
    if (format <= DefaultSegmentInfosWriter.FORMAT_3_1) {
      version = input.readString();
    }
    name = input.readString();
    docCount = input.readInt();
    delGen = input.readLong();
    docStoreOffset = input.readInt();
    if (docStoreOffset != -1) {
      docStoreSegment = input.readString();
      docStoreIsCompoundFile = input.readByte() == YES;
    } else {
      docStoreSegment = name;
      docStoreIsCompoundFile = false;
    }

    if (format > DefaultSegmentInfosWriter.FORMAT_4_0) {
      // pre-4.0 indexes write a byte if there is a single norms file
      byte b = input.readByte();
      assert 1 == b;
    }

    int numNormGen = input.readInt();
    if (numNormGen == NO) {
      normGen = null;
    } else {
      normGen = new HashMap<Integer, Long>();
      for(int j=0;j<numNormGen;j++) {
        int fieldNumber = j;
        if (format <= DefaultSegmentInfosWriter.FORMAT_4_0) {
          fieldNumber = input.readInt();
        }

        normGen.put(fieldNumber, input.readLong());
      }
    }
    isCompoundFile = input.readByte() == YES;

    delCount = input.readInt();
    assert delCount <= docCount;

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641356870/fstmerge_var1_8639613480479252185
    hasProx = input.readByte() == YES;
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641356870/fstmerge_base_4341080975297082837
    hasProx = input.readByte();
    
=======
    hasProx = input.readByte();

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641356870/fstmerge_var2_1020599861051588055
    // System.out.println(Thread.currentThread().getName() + ": si.read hasProx=" + hasProx + " seg=" + name);
    if (format <= DefaultSegmentInfosWriter.FORMAT_4_0) {
      segmentCodecs = new SegmentCodecs(codecs, input);
    } else {
      // codec ID on FieldInfo is 0 so it will simply use the first codec available
      // TODO what todo if preflex is not available in the provider? register it or fail?
      segmentCodecs = new SegmentCodecs(codecs, new Codec[] { codecs.lookup("PreFlex")});
    }
    diagnostics = input.readStringStringMap();

    if (format <= DefaultSegmentInfosWriter.FORMAT_HAS_VECTORS) {
      hasVectors = input.readByte() == 1;
    } else {
      final String storesSegment;
      final String ext;
      final boolean isCompoundFile;
      if (docStoreOffset != -1) {
        storesSegment = docStoreSegment;
        isCompoundFile = docStoreIsCompoundFile;
        ext = IndexFileNames.COMPOUND_FILE_STORE_EXTENSION;
      } else {
        storesSegment = name;
        isCompoundFile = getUseCompoundFile();
        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;
      }
      final Directory dirToTest;
      if (isCompoundFile) {
        dirToTest = new CompoundFileReader(dir, IndexFileNames.segmentFileName(storesSegment, "", ext));
      } else {
        dirToTest = dir;
      }
      try {
        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, "", IndexFileNames.VECTORS_INDEX_EXTENSION));
      } finally {
        if (isCompoundFile) {
          dirToTest.close();
        }
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/SegmentInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ private volatile int maxThreadStates; ##FSTMerge## private int maxThreadStates; ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/IndexWriterConfig.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359393/fstmerge_var1_8125248475368347497
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359393/fstmerge_base_8961748359002486743
synchronized void setSimilarityProvider(SimilarityProvider similarity) {
    this.similarityProvider = similarity;
    for(int i=0;i<threadStates.length;i++) {
      threadStates[i].docState.similarityProvider = similarity;
    }
  }
=======
synchronized void setSimilarityProvider(SimilarityProvider similarityProvider) {
    this.similarityProvider = similarityProvider;
    pushConfigChange();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359393/fstmerge_var2_3963479997803974842

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359398/fstmerge_var1_2731967628650432452
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359398/fstmerge_base_8614318500077089742
synchronized void setRAMBufferSizeMB(double mb) {
    if (mb == IndexWriterConfig.DISABLE_AUTO_FLUSH) {
      ramBufferSize = IndexWriterConfig.DISABLE_AUTO_FLUSH;
      waitQueuePauseBytes = 4*1024*1024;
      waitQueueResumeBytes = 2*1024*1024;
    } else {
      ramBufferSize = (long) (mb*1024*1024);
      waitQueuePauseBytes = (long) (ramBufferSize*0.1);
      waitQueueResumeBytes = (long) (ramBufferSize*0.05);
      freeLevel = (long) (0.95 * ramBufferSize);
    }
  }
=======
synchronized void setRAMBufferSizeMB(double mb) {
    if (mb == IndexWriterConfig.DISABLE_AUTO_FLUSH) {
      ramBufferSize = IndexWriterConfig.DISABLE_AUTO_FLUSH;
    } else {
      ramBufferSize = (long) (mb*1024*1024);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359398/fstmerge_var2_8519570457022294897

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359514/fstmerge_var1_4584399898122297257
private void doAfterFlush() throws IOException {
    // All ThreadStates should be idle when we are called
    assert allThreadsIdle();
    for (DocumentsWriterThreadState threadState : threadStates) {
      threadState.consumer.doAfterFlush();
    }

    threadBindings.clear();
    waitQueue.reset();
    segment = null;
    fieldInfos = new FieldInfos(fieldInfos);
    numDocs = 0;
    nextDocID = 0;
    bufferIsFull = false;
    for(int i=0;i<threadStates.length;i++) {
      threadStates[i].doAfterFlush();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359514/fstmerge_base_4184632921958169320
private void doAfterFlush() throws IOException {
    // All ThreadStates should be idle when we are called
    assert allThreadsIdle();
    for (DocumentsWriterThreadState threadState : threadStates) {
      threadState.consumer.doAfterFlush();
    }

    threadBindings.clear();
    waitQueue.reset();
    segment = null;
    fieldInfos = fieldInfos.newFieldInfosWithGlobalFieldNumberMap();
    numDocs = 0;
    nextDocID = 0;
    bufferIsFull = false;
    for(int i=0;i<threadStates.length;i++) {
      threadStates[i].doAfterFlush();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359514/fstmerge_var2_640563637622474036

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359527/fstmerge_var1_5802220526827242163
private void pushDeletes(SegmentInfo newSegment, SegmentInfos segmentInfos) {
    // Lock order: DW -> BD
    final long delGen = bufferedDeletesStream.getNextGen();
    if (pendingDeletes.any()) {
      if (segmentInfos.size() > 0 || newSegment != null) {
        final FrozenBufferedDeletes packet = new FrozenBufferedDeletes(pendingDeletes, delGen);
        if (infoStream != null) {
          message("flush: push buffered deletes startSize=" + pendingDeletes.bytesUsed.get() + " frozenSize=" + packet.bytesUsed);
        }
        bufferedDeletesStream.push(packet);
        if (infoStream != null) {
          message("flush: delGen=" + packet.gen);
        }
        if (newSegment != null) {
          newSegment.setBufferedDeletesGen(packet.gen);
        }
      } else {
        if (infoStream != null) {
          message("flush: drop buffered deletes: no segments");
        }
        // We can safely discard these deletes: since
        // there are no segments, the deletions cannot
        // affect anything.
      }
      pendingDeletes.clear();
    } else if (newSegment != null) {
      newSegment.setBufferedDeletesGen(delGen);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359527/fstmerge_base_2192075226750031776
private void pushDeletes(SegmentInfo newSegment, SegmentInfos segmentInfos) {
    // Lock order: DW -> BD
    final long delGen = bufferedDeletesStream.getNextGen();
    if (pendingDeletes.any()) {
      if (segmentInfos.size() > 0 || newSegment != null) {
        final FrozenBufferedDeletes packet = new FrozenBufferedDeletes(pendingDeletes, delGen);
        if (infoStream != null) {
          message("flush: push buffered deletes");
        }
        bufferedDeletesStream.push(packet);
        if (infoStream != null) {
          message("flush: delGen=" + packet.gen);
        }
        if (newSegment != null) {
          newSegment.setBufferedDeletesGen(packet.gen);
        }
      } else {
        if (infoStream != null) {
          message("flush: drop buffered deletes: no segments");
        }
        // We can safely discard these deletes: since
        // there are no segments, the deletions cannot
        // affect anything.
      }
      pendingDeletes.clear();
    } else if (newSegment != null) {
      newSegment.setBufferedDeletesGen(delGen);
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359527/fstmerge_var2_4125041430589050220

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359532/fstmerge_var1_4858559040916320499
synchronized SegmentInfo flush(IndexWriter writer, IndexFileDeleter deleter, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {

    final long startTime = System.currentTimeMillis();

    // We change writer's segmentInfos:
    assert Thread.holdsLock(writer);

    waitIdle();

    if (numDocs == 0) {
      // nothing to do!
      if (infoStream != null) {
        message("flush: no docs; skipping");
      }
      // Lock order: IW -> DW -> BD
      pushDeletes(null, segmentInfos);
      return null;
    }

    if (aborting) {
      if (infoStream != null) {
        message("flush: skip because aborting is set");
      }
      return null;
    }

    boolean success = false;

    SegmentInfo newSegment;

    try {
      assert nextDocID == numDocs;
      assert waitQueue.numWaiting == 0;
      assert waitQueue.waitingBytes == 0;

      if (infoStream != null) {
        message("flush postings as segment " + segment + " numDocs=" + numDocs);
      }
      
      final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                                                 numDocs, writer.getConfig().getTermIndexInterval(),
                                                                 fieldInfos.buildSegmentCodecs(true),
                                                                 pendingDeletes);
      // Apply delete-by-docID now (delete-byDocID only
      // happens when an exception is hit processing that
      // doc, eg if analyzer has some problem w/ the text):
      if (pendingDeletes.docIDs.size() > 0) {
        flushState.deletedDocs = new BitVector(numDocs);
        for(int delDocID : pendingDeletes.docIDs) {
          flushState.deletedDocs.set(delDocID);
        }
        pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);
        pendingDeletes.docIDs.clear();
      }

      newSegment = new SegmentInfo(segment, numDocs, directory, false, fieldInfos.hasProx(), flushState.segmentCodecs, false, fieldInfos);

      Collection<DocConsumerPerThread> threads = new HashSet<DocConsumerPerThread>();
      for (DocumentsWriterThreadState threadState : threadStates) {
        threads.add(threadState.consumer);
      }

      double startMBUsed = bytesUsed()/1024./1024.;

      consumer.flush(threads, flushState);

      newSegment.setHasVectors(flushState.hasVectors);

      if (infoStream != null) {
        message("new segment has " + (flushState.hasVectors ? "vectors" : "no vectors"));
        if (flushState.deletedDocs != null) {
          message("new segment has " + flushState.deletedDocs.count() + " deleted docs");
        }
        message("flushedFiles=" + newSegment.files());
        message("flushed codecs=" + newSegment.getSegmentCodecs());
      }

      if (mergePolicy.useCompoundFile(segmentInfos, newSegment)) {
        final String cfsFileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        if (infoStream != null) {
          message("flush: create compound file \"" + cfsFileName + "\"");
        }

        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, cfsFileName);
        for(String fileName : newSegment.files()) {
          cfsWriter.addFile(fileName);
        }
        cfsWriter.close();
        deleter.deleteNewFiles(newSegment.files());
        newSegment.setUseCompoundFile(true);
      }

      // Must write deleted docs after the CFS so we don't
      // slurp the del file into CFS:
      if (flushState.deletedDocs != null) {
        final int delCount = flushState.deletedDocs.count();
        assert delCount > 0;
        newSegment.setDelCount(delCount);
        newSegment.advanceDelGen();
        final String delFileName = newSegment.getDelFileName();
        if (infoStream != null) {
          message("flush: write " + delCount + " deletes to " + delFileName);
        }
        boolean success2 = false;
        try {
          // TODO: in the NRT case it'd be better to hand
          // this del vector over to the
          // shortly-to-be-opened SegmentReader and let it
          // carry the changes; there's no reason to use
          // filesystem as intermediary here.
          flushState.deletedDocs.write(directory, delFileName);
          success2 = true;
        } finally {
          if (!success2) {
            try {
              directory.deleteFile(delFileName);
            } catch (Throwable t) {
              // suppress this so we keep throwing the
              // original exception
            }
          }
        }
      }

      if (infoStream != null) {
        message("flush: segment=" + newSegment);
        final double newSegmentSizeNoStore = newSegment.sizeInBytes(false)/1024./1024.;
        final double newSegmentSize = newSegment.sizeInBytes(true)/1024./1024.;
        message("  ramUsed=" + nf.format(startMBUsed) + " MB" +
                " newFlushedSize=" + nf.format(newSegmentSize) + " MB" +
                " (" + nf.format(newSegmentSizeNoStore) + " MB w/o doc stores)" +
                " docs/MB=" + nf.format(numDocs / newSegmentSize) +
                " new/old=" + nf.format(100.0 * newSegmentSizeNoStore / startMBUsed) + "%");
      }

      success = true;
    } finally {
      notifyAll();
      if (!success) {
        if (segment != null) {
          deleter.refresh(segment);
        }
        abort();
      }
    }

    doAfterFlush();

    // Lock order: IW -> DW -> BD
    pushDeletes(newSegment, segmentInfos);
    if (infoStream != null) {
      message("flush time " + (System.currentTimeMillis()-startTime) + " msec");
    }

    return newSegment;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359532/fstmerge_base_2260690585296757945
synchronized SegmentInfo flush(IndexWriter writer, IndexFileDeleter deleter, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {

    final long startTime = System.currentTimeMillis();

    // We change writer's segmentInfos:
    assert Thread.holdsLock(writer);

    waitIdle();

    if (numDocs == 0) {
      // nothing to do!
      if (infoStream != null) {
        message("flush: no docs; skipping");
      }
      // Lock order: IW -> DW -> BD
      pushDeletes(null, segmentInfos);
      return null;
    }

    if (aborting) {
      if (infoStream != null) {
        message("flush: skip because aborting is set");
      }
      return null;
    }

    boolean success = false;

    SegmentInfo newSegment;

    try {
      assert nextDocID == numDocs;
      assert waitQueue.numWaiting == 0;
      assert waitQueue.waitingBytes == 0;

      if (infoStream != null) {
        message("flush postings as segment " + segment + " numDocs=" + numDocs);
      }

      final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                                                 numDocs, writer.getConfig().getTermIndexInterval(),
                                                                 SegmentCodecs.build(fieldInfos, writer.codecs),
                                                                 pendingDeletes);
      // Apply delete-by-docID now (delete-byDocID only
      // happens when an exception is hit processing that
      // doc, eg if analyzer has some problem w/ the text):
      if (pendingDeletes.docIDs.size() > 0) {
        flushState.deletedDocs = new BitVector(numDocs);
        for(int delDocID : pendingDeletes.docIDs) {
          flushState.deletedDocs.set(delDocID);
        }
        pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);
        pendingDeletes.docIDs.clear();
      }

      newSegment = new SegmentInfo(segment, numDocs, directory, false, flushState.segmentCodecs, fieldInfos);

      Collection<DocConsumerPerThread> threads = new HashSet<DocConsumerPerThread>();
      for (DocumentsWriterThreadState threadState : threadStates) {
        threads.add(threadState.consumer);
      }

      double startMBUsed = bytesUsed()/1024./1024.;

      consumer.flush(threads, flushState);

      newSegment.clearFilesCache();

      if (infoStream != null) {
        message("new segment has " + (flushState.hasVectors ? "vectors" : "no vectors"));
        if (flushState.deletedDocs != null) {
          message("new segment has " + flushState.deletedDocs.count() + " deleted docs");
        }
        message("flushedFiles=" + newSegment.files());
        message("flushed codecs=" + newSegment.getSegmentCodecs());
      }

      if (mergePolicy.useCompoundFile(segmentInfos, newSegment)) {
        final String cfsFileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        if (infoStream != null) {
          message("flush: create compound file \"" + cfsFileName + "\"");
        }

        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, cfsFileName);
        for(String fileName : newSegment.files()) {
          cfsWriter.addFile(fileName);
        }
        cfsWriter.close();
        deleter.deleteNewFiles(newSegment.files());
        newSegment.setUseCompoundFile(true);
      }

      // Must write deleted docs after the CFS so we don't
      // slurp the del file into CFS:
      if (flushState.deletedDocs != null) {
        final int delCount = flushState.deletedDocs.count();
        assert delCount > 0;
        newSegment.setDelCount(delCount);
        newSegment.advanceDelGen();
        final String delFileName = newSegment.getDelFileName();
        if (infoStream != null) {
          message("flush: write " + delCount + " deletes to " + delFileName);
        }
        boolean success2 = false;
        try {
          // TODO: in the NRT case it'd be better to hand
          // this del vector over to the
          // shortly-to-be-opened SegmentReader and let it
          // carry the changes; there's no reason to use
          // filesystem as intermediary here.
          flushState.deletedDocs.write(directory, delFileName);
          success2 = true;
        } finally {
          if (!success2) {
            try {
              directory.deleteFile(delFileName);
            } catch (Throwable t) {
              // suppress this so we keep throwing the
              // original exception
            }
          }
        }
      }

      if (infoStream != null) {
        message("flush: segment=" + newSegment);
        final double newSegmentSizeNoStore = newSegment.sizeInBytes(false)/1024./1024.;
        final double newSegmentSize = newSegment.sizeInBytes(true)/1024./1024.;
        message("  ramUsed=" + nf.format(startMBUsed) + " MB" +
                " newFlushedSize=" + nf.format(newSegmentSize) + " MB" +
                " (" + nf.format(newSegmentSizeNoStore) + " MB w/o doc stores)" +
                " docs/MB=" + nf.format(numDocs / newSegmentSize) +
                " new/old=" + nf.format(100.0 * newSegmentSizeNoStore / startMBUsed) + "%");
      }

      success = true;
    } finally {
      notifyAll();
      if (!success) {
        if (segment != null) {
          deleter.refresh(segment);
        }
        abort();
      }
    }

    doAfterFlush();

    // Lock order: IW -> DW -> BD
    pushDeletes(newSegment, segmentInfos);
    if (infoStream != null) {
      message("flush time " + (System.currentTimeMillis()-startTime) + " msec");
    }

    return newSegment;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359532/fstmerge_var2_5599300801236842688

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359600/fstmerge_var1_2843462282332539203
void balanceRAM() {

    final boolean doBalance;
    final long deletesRAMUsed;

    deletesRAMUsed = bufferedDeletesStream.bytesUsed();

    final long ramBufferSize;
    final double mb = config.getRAMBufferSizeMB();
    if (mb == IndexWriterConfig.DISABLE_AUTO_FLUSH) {
      ramBufferSize = IndexWriterConfig.DISABLE_AUTO_FLUSH;
    } else {
      ramBufferSize = (long) (mb*1024*1024);
    }

    synchronized(this) {
      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {
        return;
      }
    
      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;
    }

    if (doBalance) {

      if (infoStream != null) {
        message("  RAM: balance allocations: usedMB=" + toMB(bytesUsed()) +
                " vs trigger=" + toMB(ramBufferSize) +
                " deletesMB=" + toMB(deletesRAMUsed) +
                " byteBlockFree=" + toMB(byteBlockAllocator.bytesUsed()) +
                " perDocFree=" + toMB(perDocAllocator.bytesUsed()));
      }

      final long startBytesUsed = bytesUsed() + deletesRAMUsed;

      int iter = 0;

      // We free equally from each pool in 32 KB
      // chunks until we are below our threshold
      // (freeLevel)

      boolean any = true;

      final long freeLevel = (long) (0.95 * ramBufferSize);

      while(bytesUsed()+deletesRAMUsed > freeLevel) {
      
        synchronized(this) {
          if (0 == perDocAllocator.numBufferedBlocks() &&
              0 == byteBlockAllocator.numBufferedBlocks() &&
              0 == freeIntBlocks.size() && !any) {
            // Nothing else to free -- must flush now.
            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;
            if (infoStream != null) {
              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {
                message("    nothing to free; set bufferIsFull");
              } else {
                message("    nothing to free");
              }
            }
            break;
          }

          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {
            byteBlockAllocator.freeBlocks(1);
          }
          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {
            freeIntBlocks.remove(freeIntBlocks.size()-1);
            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);
          }
          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {
            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)
          }
        }

        if ((3 == iter % 4) && any) {
          // Ask consumer to free any recycled state
          any = consumer.freeRAM();
        }

        iter++;
      }

      if (infoStream != null) {
        message("    after free: freedMB=" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + " usedMB=" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359600/fstmerge_base_5802215378284338442
void balanceRAM() {

    final boolean doBalance;
    final long deletesRAMUsed;

    deletesRAMUsed = bufferedDeletesStream.bytesUsed();

    synchronized(this) {
      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {
        return;
      }
    
      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;
    }

    if (doBalance) {

      if (infoStream != null) {
        message("  RAM: balance allocations: usedMB=" + toMB(bytesUsed()) +
                " vs trigger=" + toMB(ramBufferSize) +
                " deletesMB=" + toMB(deletesRAMUsed) +
                " byteBlockFree=" + toMB(byteBlockAllocator.bytesUsed()) +
                " perDocFree=" + toMB(perDocAllocator.bytesUsed()));
      }

      final long startBytesUsed = bytesUsed() + deletesRAMUsed;

      int iter = 0;

      // We free equally from each pool in 32 KB
      // chunks until we are below our threshold
      // (freeLevel)

      boolean any = true;

      while(bytesUsed()+deletesRAMUsed > freeLevel) {
      
        synchronized(this) {
          if (0 == perDocAllocator.numBufferedBlocks() &&
              0 == byteBlockAllocator.numBufferedBlocks() &&
              0 == freeIntBlocks.size() && !any) {
            // Nothing else to free -- must flush now.
            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;
            if (infoStream != null) {
              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {
                message("    nothing to free; set bufferIsFull");
              } else {
                message("    nothing to free");
              }
            }
            break;
          }

          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {
            byteBlockAllocator.freeBlocks(1);
          }
          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {
            freeIntBlocks.remove(freeIntBlocks.size()-1);
            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);
          }
          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {
            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)
          }
        }

        if ((3 == iter % 4) && any) {
          // Ask consumer to free any recycled state
          any = consumer.freeRAM();
        }

        iter++;
      }

      if (infoStream != null) {
        message("    after free: freedMB=" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + " usedMB=" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));
      }
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359600/fstmerge_var2_3429140807155894529

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359614/fstmerge_var1_8687626974788439508
synchronized boolean doResume() {
      final double mb = config.getRAMBufferSizeMB();
      final long waitQueueResumeBytes;
      if (mb == IndexWriterConfig.DISABLE_AUTO_FLUSH) {
        waitQueueResumeBytes = 2*1024*1024;
      } else {
        waitQueueResumeBytes = (long) (mb*1024*1024*0.05);
      }
      return waitingBytes <= waitQueueResumeBytes;
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359614/fstmerge_base_2488102397800946550
synchronized boolean doResume() {
      return waitingBytes <= waitQueueResumeBytes;
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359614/fstmerge_var2_3388802170614221490

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359619/fstmerge_var1_1068015894967588146
synchronized boolean doPause() {
      final double mb = config.getRAMBufferSizeMB();
      final long waitQueuePauseBytes;
      if (mb == IndexWriterConfig.DISABLE_AUTO_FLUSH) {
        waitQueuePauseBytes = 4*1024*1024;
      } else {
        waitQueuePauseBytes = (long) (mb*1024*1024*0.1);
      }
      return waitingBytes > waitQueuePauseBytes;
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359619/fstmerge_base_3438701583718783292
synchronized boolean doPause() {
      return waitingBytes > waitQueuePauseBytes;
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641359619/fstmerge_var2_7681360235735038153

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641360100/fstmerge_var1_5653940633393758169
@Override
  public void flush(Map<InvertedDocEndConsumerPerThread,Collection<InvertedDocEndConsumerPerField>> threadsAndFields, SegmentWriteState state) throws IOException {

    final Map<FieldInfo,List<NormsWriterPerField>> byField = new HashMap<FieldInfo,List<NormsWriterPerField>>();

    if (!state.fieldInfos.hasNorms()) {
      return;
    }

    // Typically, each thread will have encountered the same
    // field.  So first we collate by field, ie, all
    // per-thread field instances that correspond to the
    // same FieldInfo
    for (final Map.Entry<InvertedDocEndConsumerPerThread,Collection<InvertedDocEndConsumerPerField>> entry : threadsAndFields.entrySet()) {
      final Collection<InvertedDocEndConsumerPerField> fields = entry.getValue();
      final Iterator<InvertedDocEndConsumerPerField> fieldsIt = fields.iterator();

      while (fieldsIt.hasNext()) {
        final NormsWriterPerField perField = (NormsWriterPerField) fieldsIt.next();

        if (perField.upto > 0) {
          // It has some norms
          List<NormsWriterPerField> l = byField.get(perField.fieldInfo);
          if (l == null) {
            l = new ArrayList<NormsWriterPerField>();
            byField.put(perField.fieldInfo, l);
          }
          l.add(perField);
        } else
          // Remove this field since we haven't seen it
          // since the previous flush
          fieldsIt.remove();
      }
    }

    final String normsFileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.NORMS_EXTENSION);
    IndexOutput normsOut = state.directory.createOutput(normsFileName);

    try {
      normsOut.writeBytes(SegmentMerger.NORMS_HEADER, 0, SegmentMerger.NORMS_HEADER.length);

      int normCount = 0;

      for (FieldInfo fi : state.fieldInfos) {
        final List<NormsWriterPerField> toMerge = byField.get(fi);
        int upto = 0;
        if (toMerge != null) {

          final int numFields = toMerge.size();

          normCount++;

          final NormsWriterPerField[] fields = new NormsWriterPerField[numFields];
          int[] uptos = new int[numFields];

          for(int j=0;j<numFields;j++)
            fields[j] = toMerge.get(j);

          int numLeft = numFields;
              
          while(numLeft > 0) {

            assert uptos[0] < fields[0].docIDs.length : " uptos[0]=" + uptos[0] + " len=" + (fields[0].docIDs.length);

            int minLoc = 0;
            int minDocID = fields[0].docIDs[uptos[0]];

            for(int j=1;j<numLeft;j++) {
              final int docID = fields[j].docIDs[uptos[j]];
              if (docID < minDocID) {
                minDocID = docID;
                minLoc = j;
              }
            }

            assert minDocID < state.numDocs;

            // Fill hole
            for(;upto<minDocID;upto++)
              normsOut.writeByte((byte) 0);

            normsOut.writeByte(fields[minLoc].norms[uptos[minLoc]]);
            (uptos[minLoc])++;
            upto++;

            if (uptos[minLoc] == fields[minLoc].upto) {
              fields[minLoc].reset();
              if (minLoc != numLeft-1) {
                fields[minLoc] = fields[numLeft-1];
                uptos[minLoc] = uptos[numLeft-1];
              }
              numLeft--;
            }
          }
          
          // Fill final hole with defaultNorm
          for(;upto<state.numDocs;upto++)
            normsOut.writeByte((byte) 0);
        } else if (fi.isIndexed && !fi.omitNorms) {
          normCount++;
          // Fill entire field with default norm:
          for(;upto<state.numDocs;upto++)
            normsOut.writeByte((byte) 0);
        }

        assert 4+normCount*state.numDocs == normsOut.getFilePointer() : ".nrm file size mismatch: expected=" + (4+normCount*state.numDocs) + " actual=" + normsOut.getFilePointer();
      }

    } finally {
      normsOut.close();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641360100/fstmerge_base_707838985222499307
@Override
  public void flush(Map<InvertedDocEndConsumerPerThread,Collection<InvertedDocEndConsumerPerField>> threadsAndFields, SegmentWriteState state) throws IOException {

    final Map<FieldInfo,List<NormsWriterPerField>> byField = new HashMap<FieldInfo,List<NormsWriterPerField>>();

    if (!state.fieldInfos.hasNorms()) {
      return;
    }

    // Typically, each thread will have encountered the same
    // field.  So first we collate by field, ie, all
    // per-thread field instances that correspond to the
    // same FieldInfo
    for (final Map.Entry<InvertedDocEndConsumerPerThread,Collection<InvertedDocEndConsumerPerField>> entry : threadsAndFields.entrySet()) {
      final Collection<InvertedDocEndConsumerPerField> fields = entry.getValue();
      final Iterator<InvertedDocEndConsumerPerField> fieldsIt = fields.iterator();

      while (fieldsIt.hasNext()) {
        final NormsWriterPerField perField = (NormsWriterPerField) fieldsIt.next();

        if (perField.upto > 0) {
          // It has some norms
          List<NormsWriterPerField> l = byField.get(perField.fieldInfo);
          if (l == null) {
            l = new ArrayList<NormsWriterPerField>();
            byField.put(perField.fieldInfo, l);
          }
          l.add(perField);
        } else
          // Remove this field since we haven't seen it
          // since the previous flush
          fieldsIt.remove();
      }
    }

    final String normsFileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.NORMS_EXTENSION);
    IndexOutput normsOut = state.directory.createOutput(normsFileName);

    try {
      normsOut.writeBytes(SegmentMerger.NORMS_HEADER, 0, SegmentMerger.NORMS_HEADER.length);

      int normCount = 0;

      for (FieldInfo fi : state.fieldInfos) {
        List<NormsWriterPerField> toMerge = byField.get(fi);
        int upto = 0;
        if (toMerge != null) {

          final int numFields = toMerge.size();

          normCount++;

          final NormsWriterPerField[] fields = new NormsWriterPerField[numFields];
          int[] uptos = new int[numFields];

          for(int j=0;j<numFields;j++)
            fields[j] = toMerge.get(j);

          int numLeft = numFields;
              
          while(numLeft > 0) {

            assert uptos[0] < fields[0].docIDs.length : " uptos[0]=" + uptos[0] + " len=" + (fields[0].docIDs.length);

            int minLoc = 0;
            int minDocID = fields[0].docIDs[uptos[0]];

            for(int j=1;j<numLeft;j++) {
              final int docID = fields[j].docIDs[uptos[j]];
              if (docID < minDocID) {
                minDocID = docID;
                minLoc = j;
              }
            }

            assert minDocID < state.numDocs;

            // Fill hole
            for(;upto<minDocID;upto++)
              normsOut.writeByte((byte) 0);

            normsOut.writeByte(fields[minLoc].norms[uptos[minLoc]]);
            (uptos[minLoc])++;
            upto++;

            if (uptos[minLoc] == fields[minLoc].upto) {
              fields[minLoc].reset();
              if (minLoc != numLeft-1) {
                fields[minLoc] = fields[numLeft-1];
                uptos[minLoc] = uptos[numLeft-1];
              }
              numLeft--;
            }
          }
          
          // Fill final hole with defaultNorm
          for(;upto<state.numDocs;upto++)
            normsOut.writeByte((byte) 0);
        } else if (fi.isIndexed && !fi.omitNorms) {
          normCount++;
          // Fill entire field with default norm:
          for(;upto<state.numDocs;upto++)
            normsOut.writeByte((byte) 0);
        }

        assert 4+normCount*state.numDocs == normsOut.getFilePointer() : ".nrm file size mismatch: expected=" + (4+normCount*state.numDocs) + " actual=" + normsOut.getFilePointer();
      }

    } finally {
      normsOut.close();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641360100/fstmerge_var2_2834273573307541233

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/NormsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641360601/fstmerge_var1_5332749768348238972
@Override
  public void flush(Collection<DocConsumerPerThread> threads, SegmentWriteState state) throws IOException {

    Map<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>> childThreadsAndFields = new HashMap<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>>();
    for ( DocConsumerPerThread thread : threads) {
      DocFieldProcessorPerThread perThread = (DocFieldProcessorPerThread) thread;
      childThreadsAndFields.put(perThread.consumer, perThread.fields());
    }
    fieldsWriter.flush(state);
    consumer.flush(childThreadsAndFields, state);

    // Important to save after asking consumer to flush so
    // consumer can alter the FieldInfo* if necessary.  EG,
    // FreqProxTermsWriter does this with
    // FieldInfo.storePayload.
    final String fileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.FIELD_INFOS_EXTENSION);
    state.fieldInfos.write(state.directory, fileName);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641360601/fstmerge_base_5097589628002876431
@Override
  public void flush(Collection<DocConsumerPerThread> threads, SegmentWriteState state) throws IOException {

    Map<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>> childThreadsAndFields = new HashMap<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>>();
    for ( DocConsumerPerThread thread : threads) {
      DocFieldProcessorPerThread perThread = (DocFieldProcessorPerThread) thread;
      childThreadsAndFields.put(perThread.consumer, perThread.fields());
    }
    fieldsWriter.flush(state);
    consumer.flush(childThreadsAndFields, state);

    // Important to save after asking consumer to flush so
    // consumer can alter the FieldInfo* if necessary.  EG,
    // FreqProxTermsWriter does this with
    // FieldInfo.storePayload.
    final String fileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.FIELD_INFOS_EXTENSION);

    // If this segment only has docs that hit non-aborting exceptions,
    // then no term vectors files will have been written; therefore we
    // need to update the fieldInfos and clear the term vectors bits
    if (!state.hasVectors) {
      state.fieldInfos.clearVectors();
    }
    state.fieldInfos.write(state.directory, fileName);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641360601/fstmerge_var2_8136539849392660680

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641361340/fstmerge_var1_1138060348667200051
public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {
    this.perThread = perThread;
    intPool = perThread.intPool;
    bytePool = perThread.bytePool;
    termBytePool = perThread.termBytePool;
    docState = perThread.docState;
    bytesUsed =  perThread.termsHash.trackAllocations?perThread.termsHash.docWriter.bytesUsed:new AtomicLong();

    fieldState = docInverterPerField.fieldState;
    this.consumer = perThread.consumer.addField(this, fieldInfo);
    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);
    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts); 
    streamCount = consumer.getStreamCount();
    numPostingInt = 2*streamCount;
    this.fieldInfo = fieldInfo;
    if (nextPerThread != null)
      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);
    else
      nextPerField = null;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641361340/fstmerge_base_6082905407088839250
public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {
    this.perThread = perThread;
    intPool = perThread.intPool;
    bytePool = perThread.bytePool;
    termBytePool = perThread.termBytePool;
    docState = perThread.docState;
    bytesUsed =  perThread.termsHash.trackAllocations?perThread.termsHash.docWriter.bytesUsed:new AtomicLong();

    fieldState = docInverterPerField.fieldState;
    this.consumer = perThread.consumer.addField(this, fieldInfo);
    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);
    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts); 
    streamCount = consumer.getStreamCount();
    numPostingInt = 2*streamCount;
    termBytesRef = perThread.termBytesRef;
    this.fieldInfo = fieldInfo;
    if (nextPerThread != null)
      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);
    else
      nextPerField = null;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641361340/fstmerge_var2_4956028573839698373

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/TermsHashPerField.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641362020/fstmerge_var1_7619374254768672611
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641362020/fstmerge_base_7474720329331583173
synchronized public void addIndexed(Collection<String> names, boolean storeTermVectors, boolean storePositionWithTermVector, 
                         boolean storeOffsetWithTermVector) {
    for (String name : names) {
      add(name, true, storeTermVectors, storePositionWithTermVector, storeOffsetWithTermVector);
    }
  }
=======
synchronized public void addIndexed(Collection<String> names, boolean storeTermVectors, boolean storePositionWithTermVector,
                         boolean storeOffsetWithTermVector) {
    for (String name : names) {
      add(name, true, storeTermVectors, storePositionWithTermVector, storeOffsetWithTermVector);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641362020/fstmerge_var2_6458361087599157512

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/FieldInfos.java
Conflict type: LineBasedMCFd
Conflict body: 
public IndexWriter(Directory d, IndexWriterConfig conf)
      throws CorruptIndexException, LockObtainFailedException, IOException {
    config = (IndexWriterConfig) conf.clone();
    directory = d;
    analyzer = conf.getAnalyzer();
    infoStream = defaultInfoStream;
    mergePolicy = conf.getMergePolicy();
    mergePolicy.setIndexWriter(this);
    mergeScheduler = conf.getMergeScheduler();
    codecs = conf.getCodecProvider();

    bufferedDeletesStream = new BufferedDeletesStream(messageID);
    bufferedDeletesStream.setInfoStream(infoStream);
    poolReaders = conf.getReaderPooling();

    OpenMode mode = conf.getOpenMode();
    boolean create;
    if (mode == OpenMode.CREATE) {
      create = true;
    } else if (mode == OpenMode.APPEND) {
      create = false;
    } else {
      // CREATE_OR_APPEND - create only if an index does not exist
      create = !IndexReader.indexExists(directory);
    }

    writeLock = directory.makeLock(WRITE_LOCK_NAME);

    if (!writeLock.obtain(conf.getWriteLockTimeout())) // obtain write lock
      throw new LockObtainFailedException("Index locked for write: " + writeLock);

    boolean success = false;

    // If index is too old, reading the segments will throw
    // IndexFormatTooOldException.
    segmentInfos = new SegmentInfos(codecs);
    try {
      if (create) {
        // Try to read first.  This is to allow create
        // against an index that's currently open for
        // searching.  In this case we write the next
        // segments_N file with no segments:
        try {
          segmentInfos.read(directory, codecs);
          segmentInfos.clear();
        } catch (IOException e) {
          // Likely this means it's a fresh directory
        }

        // Record that we have a change (zero out all
        // segments) pending:
        changeCount++;
        segmentInfos.changed();
      } else {
        segmentInfos.read(directory, codecs);

        IndexCommit commit = conf.getIndexCommit();
        if (commit != null) {
          // Swap out all segments, but, keep metadata in
          // SegmentInfos, like version & generation, to
          // preserve write-once.  This is important if
          // readers are open against the future commit
          // points.
          if (commit.getDirectory() != directory)
            throw new IllegalArgumentException("IndexCommit's directory doesn't match my directory");
          SegmentInfos oldInfos = new SegmentInfos(codecs);
          oldInfos.read(directory, commit.getSegmentsFileName(), codecs);
          segmentInfos.replace(oldInfos);
          changeCount++;
          segmentInfos.changed();
          if (infoStream != null)
            message("init: loaded commit \"" + commit.getSegmentsFileName() + "\"");
        }
      }

      setRollbackSegmentInfos(segmentInfos);

      // start with previous field numbers, but new FieldInfos
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641362824/fstmerge_var1_8290592036750866130
      globalFieldNumberMap = segmentInfos.getOrLoadGlobalFieldNumberMap(directory);
      docWriter = new DocumentsWriter(config, directory, this, conf.getIndexingChain(),
          globalFieldNumberMap.newFieldInfos(SegmentCodecsBuilder.create(codecs)), bufferedDeletesStream);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641362824/fstmerge_base_9212645754509720199
      fieldInfos = getCurrentFieldInfos();
      docWriter = new DocumentsWriter(directory, this, conf.getIndexingChain(), conf.getMaxThreadStates(),
          fieldInfos.newFieldInfosWithGlobalFieldNumberMap(), bufferedDeletesStream);
=======
      fieldInfos = getCurrentFieldInfos();
      docWriter = new DocumentsWriter(directory, this, conf.getIndexingChain(), conf.getIndexerThreadPool(),
          fieldInfos.newFieldInfosWithGlobalFieldNumberMap(), bufferedDeletesStream);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641362824/fstmerge_var2_6314836640716264152
      docWriter.setInfoStream(infoStream);

      // Default deleter (for backwards compatibility) is
      // KeepOnlyLastCommitDeleter:
      deleter = new IndexFileDeleter(directory,
                                     conf.getIndexDeletionPolicy(),
                                     segmentInfos, infoStream, codecs);

      if (deleter.startingCommitDeleted) {
        // Deletion policy deleted the "head" commit point.
        // We have to mark ourself as changed so that if we
        // are closed w/o any further changes we write a new
        // segments_N file.
        changeCount++;
        segmentInfos.changed();
      }

      if (infoStream != null) {
        message("init: create=" + create);
        messageState();
      }

      success = true;

    } finally {
      if (!success) {
        if (infoStream != null) {
          message("init: hit exception on init; releasing write lock");
        }
        try {
          writeLock.release();
        } catch (Throwable t) {
          // don't mask the original exception
        }
        writeLock = null;
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641362833/fstmerge_var1_3820019729489213265
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641362833/fstmerge_base_3282435582894719331
private FieldInfos getCurrentFieldInfos() throws IOException {
    final FieldInfos fieldInfos;
    if (segmentInfos.size() > 0) {
        fieldInfos = new FieldInfos();
        for(SegmentInfo info : segmentInfos) {
          final FieldInfos segFieldInfos = getFieldInfos(info);
        for (FieldInfo fi : segFieldInfos) {
          fieldInfos.add(fi);
          }
        }
      } else {
      fieldInfos = new FieldInfos();
    }
    return fieldInfos;
  }
=======
private FieldInfos getCurrentFieldInfos() throws IOException {
    final FieldInfos fieldInfos;
    if (segmentInfos.size() > 0) {
        fieldInfos = new FieldInfos();
        for(SegmentInfo info : segmentInfos) {
          final FieldInfos segFieldInfos = getFieldInfos(info);
          for (FieldInfo fi : segFieldInfos) {
            fieldInfos.add(fi);
          }
        }
      } else {
      fieldInfos = new FieldInfos();
    }
    return fieldInfos;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641362833/fstmerge_var2_6705011923221597294

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void addIndexes(IndexReader... readers) throws CorruptIndexException, IOException {
    ensureOpen();

    try {
      if (infoStream != null)
        message("flush at addIndexes(IndexReader...)");
      flush(false, true);

      String mergedName = newSegmentName();
      SegmentMerger merger = new SegmentMerger(directory, config.getTermIndexInterval(),
                                               mergedName, null, codecs, payloadProcessorProvider,
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641363034/fstmerge_var1_7924778002442048497
                                               globalFieldNumberMap.newFieldInfos(SegmentCodecsBuilder.create(codecs)));
      
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641363034/fstmerge_base_5986257573778578519
                                               fieldInfos.newFieldInfosWithGlobalFieldNumberMap());
      
=======
                                               fieldInfos.newFieldInfosWithGlobalFieldNumberMap());

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641363034/fstmerge_var2_7585498830587584626
      for (IndexReader reader : readers)      // add new indexes
        merger.add(reader);

      int docCount = merger.merge();                // merge 'em
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641363034/fstmerge_var1_7924778002442048497
      final FieldInfos fieldInfos = merger.fieldInfos();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641363034/fstmerge_base_5986257573778578519
      
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641363034/fstmerge_var2_7585498830587584626
      SegmentInfo info = new SegmentInfo(mergedName, docCount, directory,
                                         false, fieldInfos.hasProx(), merger.getSegmentCodecs(),
                                         fieldInfos.hasVectors(),
                                         fieldInfos);
      setDiagnostics(info, "addIndexes(IndexReader...)");

      boolean useCompoundFile;
      synchronized(this) { // Guard segmentInfos
        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, info);
      }

      // Now create the compound file if needed
      if (useCompoundFile) {
        merger.createCompoundFile(mergedName + ".cfs", info);

        // delete new non cfs files directly: they were never
        // registered with IFD
        deleter.deleteNewFiles(info.files());
        info.setUseCompoundFile(true);
      }

      // Register the new segment
      synchronized(this) {
        segmentInfos.add(info);
        checkpoint();
      }
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "addIndexes(IndexReader...)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private int mergeMiddle(MergePolicy.OneMerge merge)
    throws CorruptIndexException, IOException {

    merge.checkAborted(directory);

    final String mergedName = merge.info.name;

    int mergedDocCount = 0;

    SegmentInfos sourceSegments = merge.segments;

    SegmentMerger merger = new SegmentMerger(directory, config.getTermIndexInterval(), mergedName, merge,
                                             codecs, payloadProcessorProvider,
                                             merge.info.getFieldInfos());

    if (infoStream != null) {
      message("merging " + merge.segString(directory) + " mergeVectors=" + merger.fieldInfos().hasVectors());
    }

    merge.readers = new ArrayList<SegmentReader>();
    merge.readerClones = new ArrayList<SegmentReader>();

    // This is try/finally to make sure merger's readers are
    // closed:
    boolean success = false;
    try {
      int totDocCount = 0;
      int segUpto = 0;
      while(segUpto < sourceSegments.size()) {

        final SegmentInfo info = sourceSegments.info(segUpto);

        // Hold onto the "live" reader; we will use this to
        // commit merged deletes
        final SegmentReader reader = readerPool.get(info, true,
                                                    MERGE_READ_BUFFER_SIZE,
                                                    -config.getReaderTermsIndexDivisor());
        merge.readers.add(reader);

        // We clone the segment readers because other
        // deletes may come in while we're merging so we
        // need readers that will not change
        final SegmentReader clone = (SegmentReader) reader.clone(true);
        merge.readerClones.add(clone);

        if (clone.numDocs() > 0) {
          merger.add(clone);
          totDocCount += clone.numDocs();
        }
        segUpto++;
      }

      if (infoStream != null) {
        message("merge: total " + totDocCount + " docs");
      }

      merge.checkAborted(directory);

      // This is where all the work happens:
      mergedDocCount = merge.info.docCount = merger.merge();

      // Record which codec was used to write the segment
      merge.info.setSegmentCodecs(merger.getSegmentCodecs());
      // Record if we have merged vectors
      merge.info.setHasVectors(merger.fieldInfos().hasVectors());

      if (infoStream != null) {
        message("merge segmentCodecs=" + merger.getSegmentCodecs());
        message("merge store matchedCount=" + merger.getMatchedSubReaderCount() + " vs " + merge.readers.size());
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641363216/fstmerge_var1_2481879307266951059
      anyNonBulkMerges |= merger.getAnyNonBulkMerges();
      
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641363216/fstmerge_base_5417320214580310282
      anyNonBulkMerges |= merger.getMatchedSubReaderCount() != merge.readers.size();
      
=======
      anyNonBulkMerges |= merger.getMatchedSubReaderCount() != merge.readers.size();

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641363216/fstmerge_var2_1452353272634895268
      assert mergedDocCount == totDocCount: "mergedDocCount=" + mergedDocCount + " vs " + totDocCount;

      // Very important to do this before opening the reader
      // because codec must know if prox was written for
      // this segment:
      //System.out.println("merger set hasProx=" + merger.hasProx() + " seg=" + merge.info.name);
      merge.info.setHasProx(merger.fieldInfos().hasProx());

      boolean useCompoundFile;
      synchronized (this) { // Guard segmentInfos
        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);
      }

      if (useCompoundFile) {
        success = false;
        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        try {
          if (infoStream != null) {
            message("create compound file " + compoundFileName);
          }
          merger.createCompoundFile(compoundFileName, merge.info);
          success = true;
        } catch (IOException ioe) {
          synchronized(this) {
            if (merge.isAborted()) {
              // This can happen if rollback or close(false)
              // is called -- fall through to logic below to
              // remove the partially created CFS:
            } else {
              handleMergeException(ioe, merge);
            }
          }
        } catch (Throwable t) {
          handleMergeException(t, merge);
        } finally {
          if (!success) {
            if (infoStream != null) {
              message("hit exception creating compound file during merge");
            }

            synchronized(this) {
              deleter.deleteFile(compoundFileName);
              deleter.deleteNewFiles(merge.info.files());
            }
          }
        }

        success = false;

        synchronized(this) {

          // delete new non cfs files directly: they were never
          // registered with IFD
          deleter.deleteNewFiles(merge.info.files());

          if (merge.isAborted()) {
            if (infoStream != null) {
              message("abort merge after building CFS");
            }
            deleter.deleteFile(compoundFileName);
            return 0;
          }
        }

        merge.info.setUseCompoundFile(true);
      }

      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();

      final int termsIndexDivisor;
      final boolean loadDocStores;

      if (mergedSegmentWarmer != null) {
        // Load terms index & doc stores so the segment
        // warmer can run searches, load documents/term
        // vectors
        termsIndexDivisor = config.getReaderTermsIndexDivisor();
        loadDocStores = true;
      } else {
        termsIndexDivisor = -1;
        loadDocStores = false;
      }

      // TODO: in the non-realtime case, we may want to only
      // keep deletes (it's costly to open entire reader
      // when we just need deletes)

      final SegmentReader mergedReader = readerPool.get(merge.info, loadDocStores, BufferedIndexInput.BUFFER_SIZE, termsIndexDivisor);
      try {
        if (poolReaders && mergedSegmentWarmer != null) {
          mergedSegmentWarmer.warm(mergedReader);
        }

        if (!commitMerge(merge, mergedReader)) {
          // commitMerge will return false if this merge was aborted
          return 0;
        }
      } finally {
        synchronized(this) {
          if (readerPool.release(mergedReader)) {
            // Must checkpoint after releasing the
            // mergedReader since it may have written a new
            // deletes file:
            checkpoint();
          }
        }
      }

      success = true;

    } finally {
      // Readers are already closed in commitMerge if we didn't hit
      // an exc:
      if (!success) {
        closeMergeReaders(merge, true);
      }
    }

    return mergedDocCount;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641366866/fstmerge_var1_836940159674951705
@Override
  public DocumentsWriter.DocWriter processDocument(FieldInfos fieldInfos) throws IOException {

    consumer.startDocument();
    fieldsWriter.startDocument();

    final Document doc = docState.doc;

    assert docFieldProcessor.docWriter.writer.testPoint("DocumentsWriter.ThreadState.init start");

    fieldCount = 0;
    
    final int thisFieldGen = fieldGen++;

    final List<Fieldable> docFields = doc.getFields();
    final int numDocFields = docFields.size();

    // Absorb any new fields first seen in this document.
    // Also absorb any changes to fields we had already
    // seen before (eg suddenly turning on norms or
    // vectors, etc.):

    for(int i=0;i<numDocFields;i++) {
      Fieldable field = docFields.get(i);
      final String fieldName = field.name();

      // Make sure we have a PerField allocated
      final int hashPos = fieldName.hashCode() & hashMask;
      DocFieldProcessorPerField fp = fieldHash[hashPos];
      while(fp != null && !fp.fieldInfo.name.equals(fieldName))
        fp = fp.next;

      if (fp == null) {

        // TODO FI: we need to genericize the "flags" that a
        // field holds, and, how these flags are merged; it
        // needs to be more "pluggable" such that if I want
        // to have a new "thing" my Fields can do, I can
        // easily add it
        FieldInfo fi = fieldInfos.addOrUpdate(fieldName, field.isIndexed(), field.isTermVectorStored(),
                                      field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                                      field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
        fp = new DocFieldProcessorPerField(this, fi);
        fp.next = fieldHash[hashPos];
        fieldHash[hashPos] = fp;
        totalFieldCount++;

        if (totalFieldCount >= fieldHash.length/2)
          rehash();
      } else {
        fieldInfos.addOrUpdate(fp.fieldInfo.name, field.isIndexed(), field.isTermVectorStored(),
                            field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                            field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
      }
      if (thisFieldGen != fp.lastGen) {

        // First time we're seeing this field for this doc
        fp.fieldCount = 0;

        if (fieldCount == fields.length) {
          final int newSize = fields.length*2;
          DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];
          System.arraycopy(fields, 0, newArray, 0, fieldCount);
          fields = newArray;
        }

        fields[fieldCount++] = fp;
        fp.lastGen = thisFieldGen;
      }

      if (fp.fieldCount == fp.fields.length) {
        Fieldable[] newArray = new Fieldable[fp.fields.length*2];
        System.arraycopy(fp.fields, 0, newArray, 0, fp.fieldCount);
        fp.fields = newArray;
      }

      fp.fields[fp.fieldCount++] = field;
      if (field.isStored()) {
        fieldsWriter.addField(field, fp.fieldInfo);
      }
    }

    // If we are writing vectors then we must visit
    // fields in sorted order so they are written in
    // sorted order.  TODO: we actually only need to
    // sort the subset of fields that have vectors
    // enabled; we could save [small amount of] CPU
    // here.
    ArrayUtil.quickSort(fields, 0, fieldCount, fieldsComp);

    for(int i=0;i<fieldCount;i++)
      fields[i].consumer.processFields(fields[i].fields, fields[i].fieldCount);

    if (docState.maxTermPrefix != null && docState.infoStream != null) {
      docState.infoStream.println("WARNING: document contains at least one immense term (whose UTF8 encoding is longer than the max length " + DocumentsWriter.MAX_TERM_LENGTH_UTF8 + "), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '" + docState.maxTermPrefix + "...'"); 
      docState.maxTermPrefix = null;
    }

    final DocumentsWriter.DocWriter one = fieldsWriter.finishDocument();
    final DocumentsWriter.DocWriter two = consumer.finishDocument();
    if (one == null) {
      return two;
    } else if (two == null) {
      return one;
    } else {
      PerDoc both = getPerDoc();
      both.docID = docState.docID;
      assert one.docID == docState.docID;
      assert two.docID == docState.docID;
      both.one = one;
      both.two = two;
      return both;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641366866/fstmerge_base_6179274249576179020
@Override
  public DocumentsWriter.DocWriter processDocument(FieldInfos fieldInfos) throws IOException {

    consumer.startDocument();
    fieldsWriter.startDocument();

    final Document doc = docState.doc;

    assert docFieldProcessor.docWriter.writer.testPoint("DocumentsWriter.ThreadState.init start");

    fieldCount = 0;
    
    final int thisFieldGen = fieldGen++;

    final List<Fieldable> docFields = doc.getFields();
    final int numDocFields = docFields.size();

    // Absorb any new fields first seen in this document.
    // Also absorb any changes to fields we had already
    // seen before (eg suddenly turning on norms or
    // vectors, etc.):

    for(int i=0;i<numDocFields;i++) {
      Fieldable field = docFields.get(i);
      final String fieldName = field.name();

      // Make sure we have a PerField allocated
      final int hashPos = fieldName.hashCode() & hashMask;
      DocFieldProcessorPerField fp = fieldHash[hashPos];
      while(fp != null && !fp.fieldInfo.name.equals(fieldName))
        fp = fp.next;

      if (fp == null) {

        // TODO FI: we need to genericize the "flags" that a
        // field holds, and, how these flags are merged; it
        // needs to be more "pluggable" such that if I want
        // to have a new "thing" my Fields can do, I can
        // easily add it
        FieldInfo fi = fieldInfos.add(fieldName, field.isIndexed(), field.isTermVectorStored(),
                                      field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                                      field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
        fp = new DocFieldProcessorPerField(this, fi);
        fp.next = fieldHash[hashPos];
        fieldHash[hashPos] = fp;
        totalFieldCount++;

        if (totalFieldCount >= fieldHash.length/2)
          rehash();
      } else
        fp.fieldInfo.update(field.isIndexed(), field.isTermVectorStored(),
                            field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                            field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());

      if (thisFieldGen != fp.lastGen) {

        // First time we're seeing this field for this doc
        fp.fieldCount = 0;

        if (fieldCount == fields.length) {
          final int newSize = fields.length*2;
          DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];
          System.arraycopy(fields, 0, newArray, 0, fieldCount);
          fields = newArray;
        }

        fields[fieldCount++] = fp;
        fp.lastGen = thisFieldGen;
      }

      if (fp.fieldCount == fp.fields.length) {
        Fieldable[] newArray = new Fieldable[fp.fields.length*2];
        System.arraycopy(fp.fields, 0, newArray, 0, fp.fieldCount);
        fp.fields = newArray;
      }

      fp.fields[fp.fieldCount++] = field;
      if (field.isStored()) {
        fieldsWriter.addField(field, fp.fieldInfo);
      }
    }

    // If we are writing vectors then we must visit
    // fields in sorted order so they are written in
    // sorted order.  TODO: we actually only need to
    // sort the subset of fields that have vectors
    // enabled; we could save [small amount of] CPU
    // here.
    ArrayUtil.quickSort(fields, 0, fieldCount, fieldsComp);

    for(int i=0;i<fieldCount;i++)
      fields[i].consumer.processFields(fields[i].fields, fields[i].fieldCount);

    if (docState.maxTermPrefix != null && docState.infoStream != null) {
      docState.infoStream.println("WARNING: document contains at least one immense term (whose UTF8 encoding is longer than the max length " + DocumentsWriter.MAX_TERM_LENGTH_UTF8 + "), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '" + docState.maxTermPrefix + "...'"); 
      docState.maxTermPrefix = null;
    }

    final DocumentsWriter.DocWriter one = fieldsWriter.finishDocument();
    final DocumentsWriter.DocWriter two = consumer.finishDocument();
    if (one == null) {
      return two;
    } else if (two == null) {
      return one;
    } else {
      PerDoc both = getPerDoc();
      both.docID = docState.docID;
      assert one.docID == docState.docID;
      assert two.docID == docState.docID;
      both.one = one;
      both.two = two;
      return both;
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641366866/fstmerge_var2_758993284699674163

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641369219/fstmerge_var1_1048160171935837337
public IndexReader getReader(boolean applyDeletions) throws IOException {
    getReaderCalled = true;
    if (r.nextInt(4) == 2) {
      doRandomOptimize();
    }
    // If we are writing with PreFlexRW, force a full
    // IndexReader.open so terms are sorted in codepoint
    // order during searching:
    if (!applyDeletions || !w.codecs.getDefaultFieldCodec().equals("PreFlex") && r.nextBoolean()) {
      if (LuceneTestCase.VERBOSE) {
        System.out.println("RIW.getReader: use NRT reader");
      }
      return w.getReader(applyDeletions);
    } else {
      if (LuceneTestCase.VERBOSE) {
        System.out.println("RIW.getReader: open new reader");
      }
      w.commit();
      return IndexReader.open(w.getDirectory(), new KeepOnlyLastCommitDeletionPolicy(), r.nextBoolean(), _TestUtil.nextInt(r, 1, 10));
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641369219/fstmerge_base_2146969358278847403
public IndexReader getReader(boolean applyDeletions) throws IOException {
    getReaderCalled = true;
    if (r.nextInt(4) == 2)
      w.optimize();
    // If we are writing with PreFlexRW, force a full
    // IndexReader.open so terms are sorted in codepoint
    // order during searching:
    if (!applyDeletions || !w.codecs.getDefaultFieldCodec().equals("PreFlex") && r.nextBoolean()) {
      if (LuceneTestCase.VERBOSE) {
        System.out.println("RIW.getReader: use NRT reader");
      }
      return w.getReader(applyDeletions);
    } else {
      if (LuceneTestCase.VERBOSE) {
        System.out.println("RIW.getReader: open new reader");
      }
      w.commit();
      return IndexReader.open(w.getDirectory(), new KeepOnlyLastCommitDeletionPolicy(), r.nextBoolean(), _TestUtil.nextInt(r, 1, 10));
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419641369219/fstmerge_var2_8893824368522205615

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65e50_27632/rev_65e50-27632/lucene/src/test-framework/org/apache/lucene/index/RandomIndexWriter.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_bdb0e_c228e/rev_bdb0e-c228e.revisions
Conflict type: LineBasedMCFd
Conflict body: 
public void testBinaryFields() throws IOException {
        Directory dir = newDirectory();
        byte[] bin = new byte[]{0, 1, 2, 3, 4, 5, 6, 7, 8, 9};
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642269092/fstmerge_var1_2128625361627612256
        
        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(newLogMergePolicy()));
        
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642269092/fstmerge_base_6333892860146141788
        
        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(newInOrderLogMergePolicy()));
        
=======

        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(newInOrderLogMergePolicy()));

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642269092/fstmerge_var2_1051071356934542201
        for (int i = 0; i < 10; i++) {
          addDoc(writer, "document number " + (i + 1));
          addDocumentWithFields(writer);
          addDocumentWithDifferentFields(writer);
          addDocumentWithTermVectorFields(writer);
        }
        writer.close();
        writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setMergePolicy(newLogMergePolicy()));
        Document doc = new Document();
        doc.add(new Field("bin1", bin));
        doc.add(new Field("junk", "junk text", Field.Store.NO, Field.Index.ANALYZED));
        writer.addDocument(doc);
        writer.close();
        IndexReader reader = IndexReader.open(dir, false);
        doc = reader.document(reader.maxDoc() - 1);
        Field[] fields = doc.getFields("bin1");
        assertNotNull(fields);
        assertEquals(1, fields.length);
        Field b1 = fields[0];
        assertTrue(b1.isBinary());
        byte[] data1 = b1.getBinaryValue();
        assertEquals(bin.length, b1.getBinaryLength());
        for (int i = 0; i < bin.length; i++) {
          assertEquals(bin[i], data1[i + b1.getBinaryOffset()]);
        }
        Set<String> lazyFields = new HashSet<String>();
        lazyFields.add("bin1");
        FieldSelector sel = new SetBasedFieldSelector(new HashSet<String>(), lazyFields);
        doc = reader.document(reader.maxDoc() - 1, sel);
        Fieldable[] fieldables = doc.getFieldables("bin1");
        assertNotNull(fieldables);
        assertEquals(1, fieldables.length);
        Fieldable fb1 = fieldables[0];
        assertTrue(fb1.isBinary());
        assertEquals(bin.length, fb1.getBinaryLength());
        data1 = fb1.getBinaryValue();
        assertEquals(bin.length, fb1.getBinaryLength());
        for (int i = 0; i < bin.length; i++) {
          assertEquals(bin[i], data1[i + fb1.getBinaryOffset()]);
        }
        reader.close();
        // force optimize


        writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setMergePolicy(newLogMergePolicy()));
        writer.optimize();
        writer.close();
        reader = IndexReader.open(dir, false);
        doc = reader.document(reader.maxDoc() - 1);
        fields = doc.getFields("bin1");
        assertNotNull(fields);
        assertEquals(1, fields.length);
        b1 = fields[0];
        assertTrue(b1.isBinary());
        data1 = b1.getBinaryValue();
        assertEquals(bin.length, b1.getBinaryLength());
        for (int i = 0; i < bin.length; i++) {
          assertEquals(bin[i], data1[i + b1.getBinaryOffset()]);
        }
        reader.close();
        dir.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_bdb0e_c228e/rev_bdb0e-c228e/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testDefaults() throws Exception {
    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());
    assertEquals(MockAnalyzer.class, conf.getAnalyzer().getClass());
    assertNull(conf.getIndexCommit());
    assertEquals(KeepOnlyLastCommitDeletionPolicy.class, conf.getIndexDeletionPolicy().getClass());
    assertEquals(ConcurrentMergeScheduler.class, conf.getMergeScheduler().getClass());
    assertEquals(OpenMode.CREATE_OR_APPEND, conf.getOpenMode());
    // we don't need to assert this, it should be unspecified
    assertTrue(IndexSearcher.getDefaultSimilarityProvider() == conf.getSimilarityProvider());
    assertEquals(IndexWriterConfig.DEFAULT_TERM_INDEX_INTERVAL, conf.getTermIndexInterval());
    assertEquals(IndexWriterConfig.getDefaultWriteLockTimeout(), conf.getWriteLockTimeout());
    assertEquals(IndexWriterConfig.WRITE_LOCK_TIMEOUT, IndexWriterConfig.getDefaultWriteLockTimeout());
    assertEquals(IndexWriterConfig.DEFAULT_MAX_BUFFERED_DELETE_TERMS, conf.getMaxBufferedDeleteTerms());
    assertEquals(IndexWriterConfig.DEFAULT_RAM_BUFFER_SIZE_MB, conf.getRAMBufferSizeMB(), 0.0);
    assertEquals(IndexWriterConfig.DEFAULT_MAX_BUFFERED_DOCS, conf.getMaxBufferedDocs());
    assertEquals(IndexWriterConfig.DEFAULT_READER_POOLING, conf.getReaderPooling());
    assertTrue(DocumentsWriterPerThread.defaultIndexingChain == conf.getIndexingChain());
    assertNull(conf.getMergedSegmentWarmer());
    assertEquals(IndexWriterConfig.DEFAULT_MAX_THREAD_STATES, conf.getMaxThreadStates());
    assertEquals(IndexWriterConfig.DEFAULT_READER_TERMS_INDEX_DIVISOR, conf.getReaderTermsIndexDivisor());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642272401/fstmerge_var1_2090979555419932190
    assertEquals(TieredMergePolicy.class, conf.getMergePolicy().getClass());
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642272401/fstmerge_base_6583675615004337571
    assertEquals(LogByteSizeMergePolicy.class, conf.getMergePolicy().getClass());
    
=======
    assertEquals(LogByteSizeMergePolicy.class, conf.getMergePolicy().getClass());
    assertEquals(ThreadAffinityDocumentsWriterThreadPool.class, conf.getIndexerThreadPool().getClass());
    assertNull(conf.getFlushPolicy());
    assertEquals(IndexWriterConfig.DEFAULT_RAM_PER_THREAD_HARD_LIMIT_MB, conf.getRAMPerThreadHardLimitMB());



>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642272401/fstmerge_var2_5129043953804359340
    // Sanity check - validate that all getters are covered.
    Set<String> getters = new HashSet<String>();
    getters.add("getAnalyzer");
    getters.add("getIndexCommit");
    getters.add("getIndexDeletionPolicy");
    getters.add("getMaxFieldLength");
    getters.add("getMergeScheduler");
    getters.add("getOpenMode");
    getters.add("getSimilarityProvider");
    getters.add("getTermIndexInterval");
    getters.add("getWriteLockTimeout");
    getters.add("getDefaultWriteLockTimeout");
    getters.add("getMaxBufferedDeleteTerms");
    getters.add("getRAMBufferSizeMB");
    getters.add("getMaxBufferedDocs");
    getters.add("getIndexingChain");
    getters.add("getMergedSegmentWarmer");
    getters.add("getCodecProvider");
    getters.add("getMergePolicy");
    getters.add("getMaxThreadStates");
    getters.add("getReaderPooling");
    getters.add("getIndexerThreadPool");
    getters.add("getReaderTermsIndexDivisor");
    getters.add("getFlushPolicy");
    getters.add("getRAMPerThreadHardLimitMB");
    
    for (Method m : IndexWriterConfig.class.getDeclaredMethods()) {
      if (m.getDeclaringClass() == IndexWriterConfig.class && m.getName().startsWith("get")) {
        assertTrue("method " + m.getName() + " is not tested for defaults", getters.contains(m.getName()));
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_bdb0e_c228e/rev_bdb0e-c228e/lucene/src/test/org/apache/lucene/index/TestIndexWriterConfig.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testRollingUpdates() throws Exception {
    final Directory dir = newDirectory();

    final LineFileDocs docs = new LineFileDocs(random);

    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    final int SIZE = 200 * RANDOM_MULTIPLIER;
    int id = 0;
    IndexReader r = null;
    final int numUpdates = (int) (SIZE * (2+random.nextDouble()));
    for(int docIter=0;docIter<numUpdates;docIter++) {
      final Document doc = docs.nextDoc();
      final String myID = ""+id;
      if (id == SIZE-1) {
        id = 0;
      } else {
        id++;
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642272597/fstmerge_var1_3205963826371282318
      doc.getField("docid").setValue(myID);
      w.updateDocument(new Term("docid", myID), doc);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642272597/fstmerge_base_6639289941845621795
      doc.getField("id").setValue(myID);
      w.updateDocument(new Term("id", myID), doc);
=======
      doc.getField("id").setValue(myID);
      int mode = docIter % 3;
      switch (mode) {
        case 0: {
          w.deleteDocuments(new Term("id", myID));
          w.addDocument(doc);
          break;
        }
        case 1: {
          w.deleteDocuments(new TermQuery(new Term("id", myID)));
          w.addDocument(doc);
          break;
        }
        default : w.updateDocument(new Term("id", myID), doc);
      }

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642272597/fstmerge_var2_6503487894485320457

      if (docIter >= SIZE && random.nextInt(50) == 17) {
        if (r != null) {
          r.close();
        }
        final boolean applyDeletions = random.nextBoolean();
        r = w.getReader(applyDeletions);
        assertTrue("applyDeletions=" + applyDeletions + " r.numDocs()=" + r.numDocs() + " vs SIZE=" + SIZE, !applyDeletions || r.numDocs() == SIZE);
      }
    }

    if (r != null) {
      r.close();
    }

    w.commit();
    assertEquals(SIZE, w.numDocs());

    w.close();
    docs.close();
    
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_bdb0e_c228e/rev_bdb0e-c228e/lucene/src/test/org/apache/lucene/index/TestRollingUpdates.java
Conflict type: LineBasedMCFd
Conflict body: 
public IndexWriterConfig(Version matchVersion, Analyzer analyzer) {
    this.matchVersion = matchVersion;
    this.analyzer = analyzer;
    delPolicy = new KeepOnlyLastCommitDeletionPolicy();
    commit = null;
    openMode = OpenMode.CREATE_OR_APPEND;
    similarityProvider = IndexSearcher.getDefaultSimilarityProvider();
    termIndexInterval = DEFAULT_TERM_INDEX_INTERVAL; // TODO: this should be private to the codec, not settable here
    mergeScheduler = new ConcurrentMergeScheduler();
    writeLockTimeout = WRITE_LOCK_TIMEOUT;
    maxBufferedDeleteTerms = DEFAULT_MAX_BUFFERED_DELETE_TERMS;
    ramBufferSizeMB = DEFAULT_RAM_BUFFER_SIZE_MB;
    maxBufferedDocs = DEFAULT_MAX_BUFFERED_DOCS;
    indexingChain = DocumentsWriterPerThread.defaultIndexingChain;
    mergedSegmentWarmer = null;
    codecProvider = CodecProvider.getDefault();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642291134/fstmerge_var1_3672630830792390887
    mergePolicy = new TieredMergePolicy();
    maxThreadStates = DEFAULT_MAX_THREAD_STATES;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642291134/fstmerge_base_1000484265122548793
    mergePolicy = new LogByteSizeMergePolicy();
    maxThreadStates = DEFAULT_MAX_THREAD_STATES;
=======
    mergePolicy = new LogByteSizeMergePolicy();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642291134/fstmerge_var2_1634864193403581318
    readerPooling = DEFAULT_READER_POOLING;
    indexerThreadPool = new ThreadAffinityDocumentsWriterThreadPool(DEFAULT_MAX_THREAD_STATES);
    readerTermsIndexDivisor = DEFAULT_READER_TERMS_INDEX_DIVISOR;
    perThreadHardLimitMB = DEFAULT_RAM_PER_THREAD_HARD_LIMIT_MB;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_bdb0e_c228e/rev_bdb0e-c228e/lucene/src/java/org/apache/lucene/index/IndexWriterConfig.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public MergeSpecification findMergesForOptimize(SegmentInfos infos,
      int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {

    assert maxNumSegments > 0;
    if (verbose()) {
      message("findMergesForOptimize: maxNumSegs=" + maxNumSegments + " segsToOptimize= "+ segmentsToOptimize);
    }

    // If the segments are already optimized (e.g. there's only 1 segment), or
    // there are <maxNumSegements, all optimized, nothing to do.
    if (isOptimized(infos, maxNumSegments, segmentsToOptimize)) {
      if (verbose()) {
        message("already optimized; skip");
      }
      return null;
    }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642293238/fstmerge_var1_8542547342829815879
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642293238/fstmerge_base_8541350714789790955
    // TODO: handle non-contiguous merge case differently?
    
=======
    // TODO: handle non-contiguous merge case differently?

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419642293238/fstmerge_var2_7919546528113065757
    // Find the newest (rightmost) segment that needs to
    // be optimized (other segments may have been flushed
    // since optimize started):
    int last = infos.size();
    while (last > 0) {
      final SegmentInfo info = infos.info(--last);
      if (segmentsToOptimize.contains(info)) {
        last++;
        break;
      }
    }

    if (last == 0) {
      if (verbose()) {
        message("last == 0; skip");
      }
      return null;
    }

    // There is only one segment already, and it is optimized
    if (maxNumSegments == 1 && last == 1 && isOptimized(infos.info(0))) {
      if (verbose()) {
        message("already 1 seg; skip");
      }
      return null;
    }

    // Check if there are any segments above the threshold
    boolean anyTooLarge = false;
    for (int i = 0; i < last; i++) {
      SegmentInfo info = infos.info(i);
      if (size(info) > maxMergeSizeForOptimize || sizeDocs(info) > maxMergeDocs) {
        anyTooLarge = true;
        break;
      }
    }

    if (anyTooLarge) {
      return findMergesForOptimizeSizeLimit(infos, maxNumSegments, last);
    } else {
      return findMergesForOptimizeMaxNumSegments(infos, maxNumSegments, last);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_bdb0e_c228e/rev_bdb0e-c228e/lucene/src/java/org/apache/lucene/index/LogMergePolicy.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a.revisions
Conflict type: LineBasedMCFd
Conflict body: 
public void testIsCurrent() throws Exception {
      Directory d = newDirectory();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195634/fstmerge_var1_1546923928710141095
      IndexWriter writer = new IndexWriter(d, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer(random)));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195634/fstmerge_base_5410330393946792810
      IndexWriter writer = new IndexWriter(d, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
      IndexWriter writer = new IndexWriter(d, newIndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195634/fstmerge_var2_7555308061826388173
      addDocumentWithFields(writer);
      writer.close();
      // set up reader:
      IndexReader reader = IndexReader.open(d, false);
      assertTrue(reader.isCurrent());
      // modify index by adding another document:
      writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
          new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));
      addDocumentWithFields(writer);
      writer.close();
      assertFalse(reader.isCurrent());
      // re-create index:
      writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
          new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE));
      addDocumentWithFields(writer);
      writer.close();
      assertFalse(reader.isCurrent());
      reader.close();
      d.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testBinaryFields() throws IOException {
        Directory dir = newDirectory();
        byte[] bin = new byte[]{0, 1, 2, 3, 4, 5, 6, 7, 8, 9};
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195646/fstmerge_var1_7544199831851500240
        
        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
        
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195646/fstmerge_base_27771679761224483
        
        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(newLogMergePolicy()));
        
=======

        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(newLogMergePolicy()));

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195646/fstmerge_var2_6220056245990974585
        for (int i = 0; i < 10; i++) {
          addDoc(writer, "document number " + (i + 1));
          addDocumentWithFields(writer);
          addDocumentWithDifferentFields(writer);
          addDocumentWithTermVectorFields(writer);
        }
        writer.close();
        writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND).setMergePolicy(newLogMergePolicy()));
        Document doc = new Document();
        doc.add(new Field("bin1", bin));
        doc.add(new Field("junk", "junk text", Field.Store.NO, Field.Index.ANALYZED));
        writer.addDocument(doc);
        writer.close();
        IndexReader reader = IndexReader.open(dir, false);
        doc = reader.document(reader.maxDoc() - 1);
        Field[] fields = doc.getFields("bin1");
        assertNotNull(fields);
        assertEquals(1, fields.length);
        Field b1 = fields[0];
        assertTrue(b1.isBinary());
        byte[] data1 = b1.getBinaryValue();
        assertEquals(bin.length, b1.getBinaryLength());
        for (int i = 0; i < bin.length; i++) {
          assertEquals(bin[i], data1[i + b1.getBinaryOffset()]);
        }
        Set<String> lazyFields = new HashSet<String>();
        lazyFields.add("bin1");
        FieldSelector sel = new SetBasedFieldSelector(new HashSet<String>(), lazyFields);
        doc = reader.document(reader.maxDoc() - 1, sel);
        Fieldable[] fieldables = doc.getFieldables("bin1");
        assertNotNull(fieldables);
        assertEquals(1, fieldables.length);
        Fieldable fb1 = fieldables[0];
        assertTrue(fb1.isBinary());
        assertEquals(bin.length, fb1.getBinaryLength());
        data1 = fb1.getBinaryValue();
        assertEquals(bin.length, fb1.getBinaryLength());
        for (int i = 0; i < bin.length; i++) {
          assertEquals(bin[i], data1[i + fb1.getBinaryOffset()]);
        }
        reader.close();
        // force optimize


        writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND).setMergePolicy(newLogMergePolicy()));
        writer.optimize();
        writer.close();
        reader = IndexReader.open(dir, false);
        doc = reader.document(reader.maxDoc() - 1);
        fields = doc.getFields("bin1");
        assertNotNull(fields);
        assertEquals(1, fields.length);
        b1 = fields[0];
        assertTrue(b1.isBinary());
        data1 = b1.getBinaryValue();
        assertEquals(bin.length, b1.getBinaryLength());
        for (int i = 0; i < bin.length; i++) {
          assertEquals(bin[i], data1[i + b1.getBinaryOffset()]);
        }
        reader.close();
        dir.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testDocsOutOfOrderJIRA140() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195720/fstmerge_var1_1656313549353736723
      Directory dir = newDirectory();      
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195720/fstmerge_base_8723417582665306675
      Directory dir = newDirectory();      
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
      Directory dir = newDirectory();
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195720/fstmerge_var2_7906041111418994889
      for(int i=0;i<11;i++) {
        addDoc(writer, "aaa");
      }
      writer.close();
      IndexReader reader = IndexReader.open(dir, false);

      // Try to delete an invalid docId, yet, within range
      // of the final bits of the BitVector:

      boolean gotException = false;
      try {
        reader.deleteDocument(11);
      } catch (ArrayIndexOutOfBoundsException e) {
        gotException = true;
      }
      reader.close();

      writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));

      // We must add more docs to get a new segment written
      for(int i=0;i<11;i++) {
        addDoc(writer, "aaa");
      }

      // Without the fix for LUCENE-140 this call will
      // [incorrectly] hit a "docs out of order"
      // IllegalStateException because above out-of-bounds
      // deleteDocument corrupted the index:
      writer.optimize();
      writer.close();
      if (!gotException) {
        fail("delete of out-of-bounds doc number failed to hit exception");
      }
      dir.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testExceptionReleaseWriteLockJIRA768() throws IOException {

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195724/fstmerge_var1_6685885567317090264
      Directory dir = newDirectory();      
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195724/fstmerge_base_2087602708618441057
      Directory dir = newDirectory();      
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
      Directory dir = newDirectory();
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195724/fstmerge_var2_581135816133462281
      addDoc(writer, "aaa");
      writer.close();

      IndexReader reader = IndexReader.open(dir, false);
      try {
        reader.deleteDocument(1);
        fail("did not hit exception when deleting an invalid doc number");
      } catch (ArrayIndexOutOfBoundsException e) {
        // expected
      }
      reader.close();
      if (IndexWriter.isLocked(dir)) {
        fail("write lock is still held after close");
      }

      reader = IndexReader.open(dir, false);
      Similarity sim = new DefaultSimilarity();
      try {
        reader.setNorm(1, "content", sim.encodeNormValue(2.0f));
        fail("did not hit exception when calling setNorm on an invalid doc number");
      } catch (ArrayIndexOutOfBoundsException e) {
        // expected
      }
      reader.close();
      if (IndexWriter.isLocked(dir)) {
        fail("write lock is still held after close");
      }
      dir.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testPrepareCommitIsCurrent() throws Throwable {
    Directory dir = newDirectory();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195813/fstmerge_var1_8283808167144663062
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer(random)));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195813/fstmerge_base_4714736551760172707
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643195813/fstmerge_var2_6986222789717196618
    writer.commit();
    Document doc = new Document();
    writer.addDocument(doc);
    IndexReader r = IndexReader.open(dir, true);
    assertTrue(r.isCurrent());
    writer.addDocument(doc);
    writer.prepareCommit();
    assertTrue(r.isCurrent());
    IndexReader r2 = r.reopen();
    assertTrue(r == r2);
    writer.commit();
    assertFalse(r.isCurrent());
    writer.close();
    r.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir, int maxThreadStates,
                                          boolean doReaderPooling) throws IOException, InterruptedException {
    Map<String,Document> docs = new HashMap<String,Document>();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643196388/fstmerge_var1_8769664069972214399
    IndexWriter w = new MockIndexWriter(dir, newIndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE)
             .setRAMBufferSizeMB(0.1).setMaxBufferedDocs(maxBufferedDocs).setMaxThreadStates(maxThreadStates)
             .setReaderPooling(doReaderPooling).setMergePolicy(newLogMergePolicy()));
    w.setInfoStream(VERBOSE ? System.out : null);
    LogMergePolicy lmp = (LogMergePolicy) w.getConfig().getMergePolicy();
    lmp.setUseCompoundFile(false);
    lmp.setMergeFactor(mergeFactor);

    threads = new IndexingThread[nThreads];
    for (int i=0; i<threads.length; i++) {
      IndexingThread th = new IndexingThread();
      th.w = w;
      th.base = 1000000*i;
      th.range = range;
      th.iterations = iterations;
      threads[i] = th;
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643196388/fstmerge_base_3652021477769383939
    for(int iter=0;iter<3;iter++) {
      if (VERBOSE) {
        System.out.println("TEST: iter=" + iter);
      }
      IndexWriter w = new MockIndexWriter(dir, newIndexWriterConfig(
          TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE)
               .setRAMBufferSizeMB(0.1).setMaxBufferedDocs(maxBufferedDocs).setMaxThreadStates(maxThreadStates)
               .setReaderPooling(doReaderPooling).setMergePolicy(newLogMergePolicy()));
      w.setInfoStream(VERBOSE ? System.out : null);
      LogMergePolicy lmp = (LogMergePolicy) w.getConfig().getMergePolicy();
      lmp.setUseCompoundFile(false);
      lmp.setMergeFactor(mergeFactor);

      threads = new IndexingThread[nThreads];
      for (int i=0; i<threads.length; i++) {
        IndexingThread th = new IndexingThread();
        th.w = w;
        th.base = 1000000*i;
        th.range = range;
        th.iterations = iterations;
        threads[i] = th;
      }
=======
    IndexWriter w = new MockIndexWriter(dir, newIndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE)
             .setRAMBufferSizeMB(0.1).setMaxBufferedDocs(maxBufferedDocs).setIndexerThreadPool(new ThreadAffinityDocumentsWriterThreadPool(maxThreadStates))
             .setReaderPooling(doReaderPooling).setMergePolicy(newLogMergePolicy()));
    w.setInfoStream(VERBOSE ? System.out : null);
    LogMergePolicy lmp = (LogMergePolicy) w.getConfig().getMergePolicy();
    lmp.setUseCompoundFile(false);
    lmp.setMergeFactor(mergeFactor);

    threads = new IndexingThread[nThreads];
    for (int i=0; i<threads.length; i++) {
      IndexingThread th = new IndexingThread();
      th.w = w;
      th.base = 1000000*i;
      th.range = range;
      th.iterations = iterations;
      threads[i] = th;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643196388/fstmerge_var2_5880877190551018279

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643196388/fstmerge_base_3652021477769383939
      for (int i=0; i<threads.length; i++) {
        threads[i].start();
      }
      for (int i=0; i<threads.length; i++) {
        threads[i].join();
      }
=======
    for (int i=0; i<threads.length; i++) {
      threads[i].start();
    }
    for (int i=0; i<threads.length; i++) {
      threads[i].join();
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643196388/fstmerge_var2_5880877190551018279

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643196388/fstmerge_base_3652021477769383939
      //w.optimize();
      w.close();    
=======
    //w.optimize();
    w.close();    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643196388/fstmerge_var2_5880877190551018279

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643196388/fstmerge_base_3652021477769383939
      for (int i=0; i<threads.length; i++) {
        IndexingThread th = threads[i];
        synchronized(th) {
          docs.putAll(th.docs);
        }
=======
    for (int i=0; i<threads.length; i++) {
      IndexingThread th = threads[i];
      synchronized(th) {
        docs.putAll(th.docs);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643196388/fstmerge_var2_5880877190551018279
      }
    }

    //System.out.println("TEST: checkindex");
    _TestUtil.checkIndex(dir);

    return docs;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestStressIndexing2.java
Conflict type: LineBasedMCFd
Conflict body: 
private void createIndex(int numHits) throws IOException {
        int numDocs = 500;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643196682/fstmerge_var1_4247794678970112359
        
        final Analyzer analyzer = new Analyzer() {
          @Override
          public TokenStream tokenStream(String fieldName, Reader reader) {
            return new MockTokenizer(reader, MockTokenizer.WHITESPACE, true);
          }
        };
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643196682/fstmerge_base_6413645370101410203
        
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643196682/fstmerge_var2_8526466890074428052
        Directory directory = new SeekCountingDirectory(new RAMDirectory());
        // note: test explicitly disables payloads
        IndexWriter writer = new IndexWriter(
            directory,
            newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer).
                setMaxBufferedDocs(10).
                setMergePolicy(newLogMergePolicy(false))
        );
        for (int i = 0; i < numDocs; i++) {
            Document doc = new Document();
            String content;
            if (i % (numDocs / numHits) == 0) {
                // add a document that matches the query "term1 term2"
                content = this.term1 + " " + this.term2;
            } else if (i % 15 == 0) {
                // add a document that only contains term1
                content = this.term1 + " " + this.term1;
            } else {
                // add a document that contains term2 but not term 1
                content = this.term3 + " " + this.term2;
            }

            doc.add(newField(this.field, content, Field.Store.YES, Field.Index.ANALYZED));
            writer.addDocument(doc);
        }

        // make sure the index has only a single segment
        writer.optimize();
        writer.close();

      SegmentReader reader = getOnlySegmentReader(IndexReader.open(directory, false));

      this.searcher = newSearcher(reader);
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testCommitOnClose() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197358/fstmerge_var1_9102443340656774360
        Directory dir = newDirectory();      
        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197358/fstmerge_base_6071869984479369123
        Directory dir = newDirectory();      
        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
        Directory dir = newDirectory();
        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197358/fstmerge_var2_7875579149150916506
        for (int i = 0; i < 14; i++) {
          addDoc(writer);
        }
        writer.close();

        Term searchTerm = new Term("content", "aaa");
        IndexSearcher searcher = new IndexSearcher(dir, false);
        ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
        assertEquals("first number of hits", 14, hits.length);
        searcher.close();

        IndexReader reader = IndexReader.open(dir, true);

        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));
        for(int i=0;i<3;i++) {
          for(int j=0;j<11;j++) {
            addDoc(writer);
          }
          searcher = new IndexSearcher(dir, false);
          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
          assertEquals("reader incorrectly sees changes from writer", 14, hits.length);
          searcher.close();
          assertTrue("reader should have still been current", reader.isCurrent());
        }

        // Now, close the writer:
        writer.close();
        assertFalse("reader should not be current now", reader.isCurrent());

        searcher = new IndexSearcher(dir, false);
        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
        assertEquals("reader did not see changes after writer was closed", 47, hits.length);
        searcher.close();
        reader.close();
        dir.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testCommitOnCloseAbort() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197362/fstmerge_var1_6722496507980322265
      MockDirectoryWrapper dir = newDirectory();      
      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(10));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197362/fstmerge_base_8696426980372007851
      MockDirectoryWrapper dir = newDirectory();      
      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
=======
      MockDirectoryWrapper dir = newDirectory();
      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197362/fstmerge_var2_5491235968147784290
      for (int i = 0; i < 14; i++) {
        addDoc(writer);
      }
      writer.close();

      Term searchTerm = new Term("content", "aaa");
      IndexSearcher searcher = new IndexSearcher(dir, false);
      ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
      assertEquals("first number of hits", 14, hits.length);
      searcher.close();

      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))
        .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(10));
      for(int j=0;j<17;j++) {
        addDoc(writer);
      }
      // Delete all docs:
      writer.deleteDocuments(searchTerm);

      searcher = new IndexSearcher(dir, false);
      hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
      assertEquals("reader incorrectly sees changes from writer", 14, hits.length);
      searcher.close();

      // Now, close the writer:
      writer.rollback();

      assertNoUnreferencedFiles(dir, "unreferenced files remain after rollback()");

      searcher = new IndexSearcher(dir, false);
      hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
      assertEquals("saw changes after writer.abort", 14, hits.length);
      searcher.close();

      // Now make sure we can re-open the index, add docs,
      // and all is good:
      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))
        .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(10));

      // On abort, writer in fact may write to the same
      // segments_N file:
      dir.setPreventDoubleWrite(false);

      for(int i=0;i<12;i++) {
        for(int j=0;j<17;j++) {
          addDoc(writer);
        }
        searcher = new IndexSearcher(dir, false);
        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
        assertEquals("reader incorrectly sees changes from writer", 14, hits.length);
        searcher.close();
      }

      writer.close();
      searcher = new IndexSearcher(dir, false);
      hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
      assertEquals("didn't see changes after close", 218, hits.length);
      searcher.close();

      dir.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testCommitOnCloseDiskUsage() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197367/fstmerge_var1_1381797535010370044
      MockDirectoryWrapper dir = newDirectory();
      Analyzer analyzer;
      if (random.nextBoolean()) {
        // no payloads
       analyzer = new Analyzer() {
          @Override
          public TokenStream tokenStream(String fieldName, Reader reader) {
            return new MockTokenizer(reader, MockTokenizer.WHITESPACE, true);
          }
        };
      } else {
        // fixed length payloads
        final int length = random.nextInt(200);
        analyzer = new Analyzer() {
          @Override
          public TokenStream tokenStream(String fieldName, Reader reader) {
            return new MockFixedLengthPayloadFilter(random,
                new MockTokenizer(reader, MockTokenizer.WHITESPACE, true),
                length);
          }
        };
      }
      
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197367/fstmerge_base_3932554210122877393
      MockDirectoryWrapper dir = newDirectory();      
=======
      MockDirectoryWrapper dir = newDirectory();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197367/fstmerge_var2_5179736305233873391
      IndexWriter writer  = new IndexWriter(
          dir,
          newIndexWriterConfig( TEST_VERSION_CURRENT, analyzer).
              setMaxBufferedDocs(10).
              setReaderPooling(false).
              setMergePolicy(newLogMergePolicy(10))
      );
      for(int j=0;j<30;j++) {
        addDocWithIndex(writer, j);
      }
      writer.close();
      dir.resetMaxUsedSizeInBytes();

      dir.setTrackDiskUsage(true);
      long startDiskUsage = dir.getMaxUsedSizeInBytes();
      writer = new IndexWriter(
          dir,
          newIndexWriterConfig( TEST_VERSION_CURRENT, analyzer)
              .setOpenMode(OpenMode.APPEND).
              setMaxBufferedDocs(10).
              setMergeScheduler(new SerialMergeScheduler()).
              setReaderPooling(false).
              setMergePolicy(newLogMergePolicy(10))

      );
      for(int j=0;j<1470;j++) {
        addDocWithIndex(writer, j);
      }
      long midDiskUsage = dir.getMaxUsedSizeInBytes();
      dir.resetMaxUsedSizeInBytes();
      writer.optimize();
      writer.close();

      IndexReader.open(dir, true).close();

      long endDiskUsage = dir.getMaxUsedSizeInBytes();

      // Ending index is 50X as large as starting index; due
      // to 3X disk usage normally we allow 150X max
      // transient usage.  If something is wrong w/ deleter
      // and it doesn't delete intermediate segments then it
      // will exceed this 150X:
      // System.out.println("start " + startDiskUsage + "; mid " + midDiskUsage + ";end " + endDiskUsage);
      assertTrue("writer used too much space while adding documents: mid=" + midDiskUsage + " start=" + startDiskUsage + " end=" + endDiskUsage + " max=" + (startDiskUsage*150),
                 midDiskUsage < 150*startDiskUsage);
      assertTrue("writer used too much space after close: endDiskUsage=" + endDiskUsage + " startDiskUsage=" + startDiskUsage + " max=" + (startDiskUsage*150),
                 endDiskUsage < 150*startDiskUsage);
      dir.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testIndexNoDocuments() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197377/fstmerge_var1_5344232791293522395
      MockDirectoryWrapper dir = newDirectory();      
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197377/fstmerge_base_5857558857225562772
      MockDirectoryWrapper dir = newDirectory();      
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
      MockDirectoryWrapper dir = newDirectory();
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197377/fstmerge_var2_812955028500383756
      writer.commit();
      writer.close();

      IndexReader reader = IndexReader.open(dir, true);
      assertEquals(0, reader.maxDoc());
      assertEquals(0, reader.numDocs());
      reader.close();

      writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));
      writer.commit();
      writer.close();

      reader = IndexReader.open(dir, true);
      assertEquals(0, reader.maxDoc());
      assertEquals(0, reader.numDocs());
      reader.close();
      dir.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testManyFields() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197382/fstmerge_var1_7059333175615058976
      MockDirectoryWrapper dir = newDirectory();      
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(10));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197382/fstmerge_base_5678215744022733950
      MockDirectoryWrapper dir = newDirectory();      
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
=======
      MockDirectoryWrapper dir = newDirectory();
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197382/fstmerge_var2_9024384781806614640
      for(int j=0;j<100;j++) {
        Document doc = new Document();
        doc.add(newField("a"+j, "aaa" + j, Field.Store.YES, Field.Index.ANALYZED));
        doc.add(newField("b"+j, "aaa" + j, Field.Store.YES, Field.Index.ANALYZED));
        doc.add(newField("c"+j, "aaa" + j, Field.Store.YES, Field.Index.ANALYZED));
        doc.add(newField("d"+j, "aaa", Field.Store.YES, Field.Index.ANALYZED));
        doc.add(newField("e"+j, "aaa", Field.Store.YES, Field.Index.ANALYZED));
        doc.add(newField("f"+j, "aaa", Field.Store.YES, Field.Index.ANALYZED));
        writer.addDocument(doc);
      }
      writer.close();

      IndexReader reader = IndexReader.open(dir, true);
      assertEquals(100, reader.maxDoc());
      assertEquals(100, reader.numDocs());
      for(int j=0;j<100;j++) {
        assertEquals(1, reader.docFreq(new Term("a"+j, "aaa"+j)));
        assertEquals(1, reader.docFreq(new Term("b"+j, "aaa"+j)));
        assertEquals(1, reader.docFreq(new Term("c"+j, "aaa"+j)));
        assertEquals(1, reader.docFreq(new Term("d"+j, "aaa")));
        assertEquals(1, reader.docFreq(new Term("e"+j, "aaa")));
        assertEquals(1, reader.docFreq(new Term("f"+j, "aaa")));
      }
      reader.close();
      dir.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testDiverseDocs() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197400/fstmerge_var1_4852030483202874101
      MockDirectoryWrapper dir = newDirectory();      
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197400/fstmerge_base_1539705110644433544
      MockDirectoryWrapper dir = newDirectory();      
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));
=======
      MockDirectoryWrapper dir = newDirectory();
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197400/fstmerge_var2_4507967329179425723
      for(int i=0;i<3;i++) {
        // First, docs where every term is unique (heavy on
        // Posting instances)
        for(int j=0;j<100;j++) {
          Document doc = new Document();
          for(int k=0;k<100;k++) {
            doc.add(newField("field", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));
          }
          writer.addDocument(doc);
        }

        // Next, many single term docs where only one term
        // occurs (heavy on byte blocks)
        for(int j=0;j<100;j++) {
          Document doc = new Document();
          doc.add(newField("field", "aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa", Field.Store.YES, Field.Index.ANALYZED));
          writer.addDocument(doc);
        }

        // Next, many single term docs where only one term
        // occurs but the terms are very long (heavy on
        // char[] arrays)
        for(int j=0;j<100;j++) {
          StringBuilder b = new StringBuilder();
          String x = Integer.toString(j) + ".";
          for(int k=0;k<1000;k++)
            b.append(x);
          String longTerm = b.toString();

          Document doc = new Document();
          doc.add(newField("field", longTerm, Field.Store.YES, Field.Index.ANALYZED));
          writer.addDocument(doc);
        }
      }
      writer.close();

      IndexSearcher searcher = new IndexSearcher(dir, false);
      ScoreDoc[] hits = searcher.search(new TermQuery(new Term("field", "aaa")), null, 1000).scoreDocs;
      assertEquals(300, hits.length);
      searcher.close();

      dir.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testEnablingNorms() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197405/fstmerge_var1_5836496516786075149
      MockDirectoryWrapper dir = newDirectory();      
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(10));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197405/fstmerge_base_6013811532626793114
      MockDirectoryWrapper dir = newDirectory();      
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
=======
      MockDirectoryWrapper dir = newDirectory();
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197405/fstmerge_var2_1372216177069169289
      // Enable norms for only 1 doc, pre flush
      for(int j=0;j<10;j++) {
        Document doc = new Document();
        Field f = newField("field", "aaa", Field.Store.YES, Field.Index.ANALYZED);
        if (j != 8) {
          f.setOmitNorms(true);
        }
        doc.add(f);
        writer.addDocument(doc);
      }
      writer.close();

      Term searchTerm = new Term("field", "aaa");

      IndexSearcher searcher = new IndexSearcher(dir, false);
      ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
      assertEquals(10, hits.length);
      searcher.close();

      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))
        .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(10));
      // Enable norms for only 1 doc, post flush
      for(int j=0;j<27;j++) {
        Document doc = new Document();
        Field f = newField("field", "aaa", Field.Store.YES, Field.Index.ANALYZED);
        if (j != 26) {
          f.setOmitNorms(true);
        }
        doc.add(f);
        writer.addDocument(doc);
      }
      writer.close();
      searcher = new IndexSearcher(dir, false);
      hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
      assertEquals(27, hits.length);
      searcher.close();

      IndexReader reader = IndexReader.open(dir, true);
      reader.close();

      dir.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testBadSegment() throws IOException {
    Directory dir = newDirectory();
    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197432/fstmerge_var1_8754802506619524229
        TEST_VERSION_CURRENT, new MockAnalyzer(random)));
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197432/fstmerge_base_881915940333741381
        TEST_VERSION_CURRENT, new MockAnalyzer()));
    
=======
        TEST_VERSION_CURRENT, new MockAnalyzer()));

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197432/fstmerge_var2_6606001292522462905
    Document document = new Document();
    document.add(newField("tvtest", "", Store.NO, Index.ANALYZED, TermVector.YES));
    iw.addDocument(document);
    iw.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testExpungeDeletes() throws IOException {
    Directory dir = newDirectory();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197472/fstmerge_var1_577196933724823685
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer(random))
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197472/fstmerge_base_6684708280399781220
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer())
=======
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer())
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197472/fstmerge_var2_8369824937284527647
        .setMaxBufferedDocs(2).setRAMBufferSizeMB(
                                                  IndexWriterConfig.DISABLE_AUTO_FLUSH));
    writer.setInfoStream(VERBOSE ? System.out : null);
    Document document = new Document();

    document = new Document();
    Field storedField = newField("stored", "stored", Field.Store.YES,
                                  Field.Index.NO);
    document.add(storedField);
    Field termVectorField = newField("termVector", "termVector",
                                      Field.Store.NO, Field.Index.NOT_ANALYZED,
                                      Field.TermVector.WITH_POSITIONS_OFFSETS);
    document.add(termVectorField);
    for(int i=0;i<10;i++)
      writer.addDocument(document);
    writer.close();

    IndexReader ir = IndexReader.open(dir, false);
    assertEquals(10, ir.maxDoc());
    assertEquals(10, ir.numDocs());
    ir.deleteDocument(0);
    ir.deleteDocument(7);
    assertEquals(8, ir.numDocs());
    ir.close();

    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
    assertEquals(8, writer.numDocs());
    assertEquals(10, writer.maxDoc());
    writer.expungeDeletes();
    assertEquals(8, writer.numDocs());
    writer.close();
    ir = IndexReader.open(dir, true);
    assertEquals(8, ir.maxDoc());
    assertEquals(8, ir.numDocs());
    ir.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testCommitUserData() throws IOException {
    Directory dir = newDirectory();
    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2));
    for(int j=0;j<17;j++)
      addDoc(w);
    w.close();

    assertEquals(0, IndexReader.getCommitUserData(dir).size());

    IndexReader r = IndexReader.open(dir, true);
    // commit(Map) never called for this index
    assertEquals(0, r.getCommitUserData().size());
    r.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197568/fstmerge_var1_4523022246744925031
      
    w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197568/fstmerge_base_1723803187105643418
      
    w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
=======

    w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197568/fstmerge_var2_7963910594535164698
    for(int j=0;j<17;j++)
      addDoc(w);
    Map<String,String> data = new HashMap<String,String>();
    data.put("label", "test1");
    w.commit(data);
    w.close();

    assertEquals("test1", IndexReader.getCommitUserData(dir).get("label"));

    r = IndexReader.open(dir, true);
    assertEquals("test1", r.getCommitUserData().get("label"));
    r.close();

    w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));
    w.optimize();
    w.close();

    assertEquals("test1", IndexReader.getCommitUserData(dir).get("label"));

    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public void run() {
      // LUCENE-2239: won't work with NIOFS/MMAP
      Directory dir = new MockDirectoryWrapper(random, new RAMDirectory());
      IndexWriter w = null;
      while(!finish) {
        try {

          while(true) {
            if (w != null) {
              w.close();
            }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197585/fstmerge_var1_7986197218267489813
            IndexWriterConfig conf = newIndexWriterConfig( 
                                                          TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197585/fstmerge_base_4736090592879769076
            IndexWriterConfig conf = newIndexWriterConfig( 
                                                          TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2);
=======
            IndexWriterConfig conf = newIndexWriterConfig(
                                                          TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197585/fstmerge_var2_436668525788941570
            w = new IndexWriter(dir, conf);

            Document doc = new Document();
            doc.add(newField("field", "some text contents", Field.Store.YES, Field.Index.ANALYZED));
            for(int i=0;i<100;i++) {
              w.addDocument(doc);
              if (i%10 == 0) {
                w.commit();
              }
            }
            w.close();
            _TestUtil.checkIndex(dir);
            IndexReader.open(dir, true).close();

            // Strangely, if we interrupt a thread before
            // all classes are loaded, the class loader
            // seems to do scary things with the interrupt
            // status.  In java 1.5, it'll throw an
            // incorrect ClassNotFoundException.  In java
            // 1.6, it'll silently clear the interrupt.
            // So, on first iteration through here we
            // don't open ourselves up for interrupts
            // until we've done the above loop.
            allowInterrupt = true;
          }
        } catch (ThreadInterruptedException re) {
          Throwable e = re.getCause();
          assertTrue(e instanceof InterruptedException);
          if (finish) {
            break;
          }
        } catch (Throwable t) {
          System.out.println("FAILED; unexpected exception");
          t.printStackTrace(System.out);
          failed = true;
          break;
        }
      }

      if (!failed) {
        // clear interrupt state:
        Thread.interrupted();
        try {
          w.rollback();
        } catch (IOException ioe) {
          throw new RuntimeException(ioe);
        }

        try {
          _TestUtil.checkIndex(dir);
        } catch (Exception e) {
          failed = true;
          System.out.println("CheckIndex FAILED: unexpected exception");
          e.printStackTrace(System.out);
        }
        try {
          IndexReader r = IndexReader.open(dir, true);
          //System.out.println("doc count=" + r.numDocs());
          r.close();
        } catch (Exception e) {
          failed = true;
          System.out.println("IndexReader.open FAILED: unexpected exception");
          e.printStackTrace(System.out);
        }
      }
      try {
        dir.close();
      } catch (IOException e) {
        throw new RuntimeException(e);
      }
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testNoDocsIndex() throws Throwable {
    Directory dir = newDirectory();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197606/fstmerge_var1_7820705809920667287
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer(random)));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197606/fstmerge_base_8157296764623641552
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer()));
=======
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197606/fstmerge_var2_3470571404417738841
    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);
    writer.setInfoStream(new PrintStream(bos));
    writer.addDocument(new Document());
    writer.close();

    _TestUtil.checkIndex(dir);
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testCommitThreadSafety() throws Throwable {
    final int NUM_THREADS = 5;
    final double RUN_SEC = 0.5;
    final Directory dir = newDirectory();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197611/fstmerge_var1_7184014359430873470
    final RandomIndexWriter w = new RandomIndexWriter(random, dir, newIndexWriterConfig( 
                                                                                        TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197611/fstmerge_base_8445329170796124825
    final RandomIndexWriter w = new RandomIndexWriter(random, dir, newIndexWriterConfig( 
                                                                                        TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(newLogMergePolicy()));
=======
    final RandomIndexWriter w = new RandomIndexWriter(random, dir, newIndexWriterConfig(
                                                                                        TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(newLogMergePolicy()));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197611/fstmerge_var2_6736795025497389792
    _TestUtil.reduceOpenFiles(w.w);
    w.commit();
    final AtomicBoolean failed = new AtomicBoolean();
    Thread[] threads = new Thread[NUM_THREADS];
    final long endTime = System.currentTimeMillis()+((long) (RUN_SEC*1000));
    for(int i=0;i<NUM_THREADS;i++) {
      final int finalI = i;
      threads[i] = new Thread() {
          @Override
          public void run() {
            try {
              final Document doc = new Document();
              IndexReader r = IndexReader.open(dir);
              Field f = newField("f", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
              doc.add(f);
              int count = 0;
              do {
                if (failed.get()) break;
                for(int j=0;j<10;j++) {
                  final String s = finalI + "_" + String.valueOf(count++);
                  f.setValue(s);
                  w.addDocument(doc);
                  w.commit();
                  IndexReader r2 = r.reopen();
                  assertTrue(r2 != r);
                  r.close();
                  r = r2;
                  assertEquals("term=f:" + s + "; r=" + r, 1, r.docFreq(new Term("f", s)));
                }
              } while(System.currentTimeMillis() < endTime);
              r.close();
            } catch (Throwable t) {
              failed.set(true);
              throw new RuntimeException(t);
            }
          }
        };
      threads[i].start();
    }
    for(int i=0;i<NUM_THREADS;i++) {
      threads[i].join();
    }
    assertFalse(failed.get());
    w.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testDeleteUnsedFiles2() throws Exception {
    // Validates that iw.deleteUnusedFiles() also deletes unused index commits
    // in case a deletion policy which holds onto commits is used.
    Directory dir = newDirectory();
    SnapshotDeletionPolicy sdp = new SnapshotDeletionPolicy(new KeepOnlyLastCommitDeletionPolicy());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197660/fstmerge_var1_5045680515834292126
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer(random))
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197660/fstmerge_base_6189569667511069560
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer())
=======
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer())
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197660/fstmerge_var2_7655370425764952939
        .setIndexDeletionPolicy(sdp));

    // First commit
    Document doc = new Document();
    doc.add(newField("c", "val", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);
    writer.commit();
    assertEquals(1, IndexReader.listCommits(dir).size());

    // Keep that commit
    sdp.snapshot("id");

    // Second commit - now KeepOnlyLastCommit cannot delete the prev commit.
    doc = new Document();
    doc.add(newField("c", "val", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);
    writer.commit();
    assertEquals(2, IndexReader.listCommits(dir).size());

    // Should delete the unreferenced commit
    sdp.release("id");
    writer.deleteUnusedFiles();
    assertEquals(1, IndexReader.listCommits(dir).size());

    writer.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testEmptyDirRollback() throws Exception {
    // Tests that if IW is created over an empty Directory, some documents are
    // indexed, flushed (but not committed) and then IW rolls back, then no
    // files are left in the Directory.
    Directory dir = newDirectory();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197681/fstmerge_var1_5702522198210968214
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer(random))
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197681/fstmerge_base_646613500544708962
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer())
=======
    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer())
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197681/fstmerge_var2_6697381051803497980
                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()));
    String[] files = dir.listAll();

    writer.setInfoStream(VERBOSE ? System.out : null);

    // Creating over empty dir should not create any files,
    // or, at most the write.lock file
    final int extraFileCount;
    if (files.length == 1) {
      assertEquals("write.lock", files[0]);
      extraFileCount = 1;
    } else {
      assertEquals(0, files.length);
      extraFileCount = 0;
    }

    Document doc = new Document();
    // create as many files as possible
    doc.add(newField("c", "val", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);
    // Adding just one document does not call flush yet.
    assertEquals("only the stored and term vector files should exist in the directory", 5 + extraFileCount, dir.listAll().length);

    doc = new Document();
    doc.add(newField("c", "val", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);

    // The second document should cause a flush.
    assertTrue("flush should have occurred and files should have been created", dir.listAll().length > 5 + extraFileCount);

    // After rollback, IW should remove all files
    writer.rollback();
    assertEquals("no files should exist in the directory after rollback", 0, dir.listAll().length);

    // Since we rolled-back above, that close should be a no-op
    writer.close();
    assertEquals("expected a no-op close after IW.rollback()", 0, dir.listAll().length);
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testNoSegmentFile() throws IOException {
    Directory dir = newDirectory();
    dir.setLockFactory(NoLockFactory.getNoLockFactory());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197686/fstmerge_var1_5737120050906798034
    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2));
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197686/fstmerge_base_4409893056562457485
    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
    
=======
    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197686/fstmerge_var2_3521130755410962455
    Document doc = new Document();
    doc.add(newField("c", "val", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
    w.addDocument(doc);
    w.addDocument(doc);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197686/fstmerge_var1_5737120050906798034
    IndexWriter w2 = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2)
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197686/fstmerge_base_4409893056562457485
    IndexWriter w2 = new IndexWriter(dir, newIndexWriterConfig( 
        TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2)
=======
    IndexWriter w2 = new IndexWriter(dir, newIndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2)
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197686/fstmerge_var2_3521130755410962455
        .setOpenMode(OpenMode.CREATE));

    w2.close();
    // If we don't do that, the test fails on Windows
    w.rollback();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197724/fstmerge_var1_2285612953274903147
public void testIndexingThenDeleting() throws Exception {
    final Random r = random;

    Directory dir = newDirectory();
    // note this test explicitly disables payloads
    final Analyzer analyzer = new Analyzer() {
      @Override
      public TokenStream tokenStream(String fieldName, Reader reader) {
        return new MockTokenizer(reader, MockTokenizer.WHITESPACE, true);
      }
    };
    FlushCountingIndexWriter w = new FlushCountingIndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, analyzer).setRAMBufferSizeMB(1.0).setMaxBufferedDocs(-1).setMaxBufferedDeleteTerms(-1));
    w.setInfoStream(VERBOSE ? System.out : null);
    Document doc = new Document();
    doc.add(newField("field", "go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20", Field.Store.NO, Field.Index.ANALYZED));
    int num = TEST_NIGHTLY ? 6 * RANDOM_MULTIPLIER : 3 * RANDOM_MULTIPLIER;
    for (int iter = 0; iter < num; iter++) {
      int count = 0;

      final boolean doIndexing = r.nextBoolean();
      if (VERBOSE) {
        System.out.println("TEST: iter doIndexing=" + doIndexing);
      }
      if (doIndexing) {
        // Add docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.addDocument(doc);
          count++;
        }
      } else {
        // Delete docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.deleteDocuments(new Term("foo", ""+count));
          count++;
        }
      }
      assertTrue("flush happened too quickly during " + (doIndexing ? "indexing" : "deleting") + " count=" + count, count > 3000);
    }
    w.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197724/fstmerge_base_6074413481696547417
public void testIndexingThenDeleting() throws Exception {
    final Random r = random;

    Directory dir = newDirectory();
    FlushCountingIndexWriter w = new FlushCountingIndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, true, false)).setRAMBufferSizeMB(1.0).setMaxBufferedDocs(-1).setMaxBufferedDeleteTerms(-1));
    w.setInfoStream(VERBOSE ? System.out : null);
    Document doc = new Document();
    doc.add(newField("field", "go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20", Field.Store.NO, Field.Index.ANALYZED));
    int num = 6 * RANDOM_MULTIPLIER;
    for (int iter = 0; iter < num; iter++) {
      int count = 0;

      final boolean doIndexing = r.nextBoolean();
      if (VERBOSE) {
        System.out.println("TEST: iter doIndexing=" + doIndexing);
      }
      if (doIndexing) {
        // Add docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.addDocument(doc);
          count++;
        }
      } else {
        // Delete docs until a flush is triggered
        final int startFlushCount = w.flushCount;
        while(w.flushCount == startFlushCount) {
          w.deleteDocuments(new Term("foo", ""+count));
          count++;
        }
      }
      assertTrue("flush happened too quickly during " + (doIndexing ? "indexing" : "deleting") + " count=" + count, count > 3000);
    }
    w.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643197724/fstmerge_var2_4124195927619696597

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testInvalidValues() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643198939/fstmerge_var1_919213683604415632
    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643198939/fstmerge_base_2524057683111119221
    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());
    
=======
    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643198939/fstmerge_var2_7343050811719615443
    // Test IndexDeletionPolicy
    assertEquals(KeepOnlyLastCommitDeletionPolicy.class, conf.getIndexDeletionPolicy().getClass());
    conf.setIndexDeletionPolicy(new SnapshotDeletionPolicy(null));
    assertEquals(SnapshotDeletionPolicy.class, conf.getIndexDeletionPolicy().getClass());
    conf.setIndexDeletionPolicy(null);
    assertEquals(KeepOnlyLastCommitDeletionPolicy.class, conf.getIndexDeletionPolicy().getClass());

    // Test MergeScheduler
    assertEquals(ConcurrentMergeScheduler.class, conf.getMergeScheduler().getClass());
    conf.setMergeScheduler(new SerialMergeScheduler());
    assertEquals(SerialMergeScheduler.class, conf.getMergeScheduler().getClass());
    conf.setMergeScheduler(null);
    assertEquals(ConcurrentMergeScheduler.class, conf.getMergeScheduler().getClass());

    // Test Similarity: 
    // we shouldnt assert what the default is, just that its not null.
    assertTrue(IndexSearcher.getDefaultSimilarityProvider() == conf.getSimilarityProvider());
    conf.setSimilarityProvider(new MySimilarityProvider());
    assertEquals(MySimilarityProvider.class, conf.getSimilarityProvider().getClass());
    conf.setSimilarityProvider(null);
    assertTrue(IndexSearcher.getDefaultSimilarityProvider() == conf.getSimilarityProvider());

    // Test IndexingChain
    assertTrue(DocumentsWriterPerThread.defaultIndexingChain == conf.getIndexingChain());
    conf.setIndexingChain(new MyIndexingChain());
    assertEquals(MyIndexingChain.class, conf.getIndexingChain().getClass());
    conf.setIndexingChain(null);
    assertTrue(DocumentsWriterPerThread.defaultIndexingChain == conf.getIndexingChain());

    try {
      conf.setMaxBufferedDeleteTerms(0);
      fail("should not have succeeded to set maxBufferedDeleteTerms to 0");
    } catch (IllegalArgumentException e) {
      // this is expected
    }

    try {
      conf.setMaxBufferedDocs(1);
      fail("should not have succeeded to set maxBufferedDocs to 1");
    } catch (IllegalArgumentException e) {
      // this is expected
    }

    try {
      // Disable both MAX_BUF_DOCS and RAM_SIZE_MB
      conf.setMaxBufferedDocs(4);
      conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);
      conf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);
      fail("should not have succeeded to disable maxBufferedDocs when ramBufferSizeMB is disabled as well");
    } catch (IllegalArgumentException e) {
      // this is expected
    }

    conf.setRAMBufferSizeMB(IndexWriterConfig.DEFAULT_RAM_BUFFER_SIZE_MB);
    conf.setMaxBufferedDocs(IndexWriterConfig.DEFAULT_MAX_BUFFERED_DOCS);
    try {
      conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);
      fail("should not have succeeded to disable ramBufferSizeMB when maxBufferedDocs is disabled as well");
    } catch (IllegalArgumentException e) {
      // this is expected
    }

    // Test setReaderTermsIndexDivisor
    try {
      conf.setReaderTermsIndexDivisor(0);
      fail("should not have succeeded to set termsIndexDivisor to 0");
    } catch (IllegalArgumentException e) {
      // this is expected
    }
    
    // Setting to -1 is ok
    conf.setReaderTermsIndexDivisor(-1);
    try {
      conf.setReaderTermsIndexDivisor(-2);
      fail("should not have succeeded to set termsIndexDivisor to < -1");
    } catch (IllegalArgumentException e) {
      // this is expected
    }
    
    try {
      conf.setRAMPerThreadHardLimitMB(2048);
      fail("should not have succeeded to set RAMPerThreadHardLimitMB to >= 2048");
    } catch (IllegalArgumentException e) {
      // this is expected
    }
    
    try {
      conf.setRAMPerThreadHardLimitMB(0);
      fail("should not have succeeded to set RAMPerThreadHardLimitMB to 0");
    } catch (IllegalArgumentException e) {
      // this is expected
    }
    
    assertEquals(IndexWriterConfig.DEFAULT_MAX_THREAD_STATES, conf.getMaxThreadStates());
    conf.setIndexerThreadPool(new ThreadAffinityDocumentsWriterThreadPool(5));
    assertEquals(5, conf.getMaxThreadStates());
    conf.setIndexerThreadPool(new ThreadAffinityDocumentsWriterThreadPool(0));
    assertEquals(IndexWriterConfig.DEFAULT_MAX_THREAD_STATES, conf.getMaxThreadStates());

    // Test MergePolicy
    assertEquals(TieredMergePolicy.class, conf.getMergePolicy().getClass());
    conf.setMergePolicy(new LogDocMergePolicy());
    assertEquals(LogDocMergePolicy.class, conf.getMergePolicy().getClass());
    conf.setMergePolicy(null);
    assertEquals(LogByteSizeMergePolicy.class, conf.getMergePolicy().getClass());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test/org/apache/lucene/index/TestIndexWriterConfig.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643227634/fstmerge_var1_7289370318476240759
public void updateDocument(Term t, Document doc) throws IOException {
    w.updateDocument(t, doc);
    maybeCommit();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643227634/fstmerge_base_1189775810254629787
public void updateDocument(Term t, Document doc) throws IOException {
    w.updateDocument(t, doc);
    if (docCount++ == flushAt) {
      if (LuceneTestCase.VERBOSE) {
        System.out.println("RIW.updateDocument: now doing a commit");
      }
      w.commit();
      flushAt += _TestUtil.nextInt(r, 10, 1000);
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419643227634/fstmerge_var2_5247166170548681115

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4d8d5_6c29a/rev_4d8d5-6c29a/lucene/src/test-framework/org/apache/lucene/index/RandomIndexWriter.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_317e9_cf72b/rev_317e9-cf72b.revisions
Conflict type: LineBasedMCFd
Conflict body: 
private void doTestOperationsOnDiskFull(boolean updates) throws IOException {

    Term searchTerm = new Term("content", "aaa");
    int START_COUNT = 157;
    int END_COUNT = 144;

    // First build up a starting index:
    MockDirectoryWrapper startDir = newDirectory();
    // TODO: find the resource leak that only occurs sometimes here.
    startDir.setNoDeleteOpenFile(false);
    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));
    for (int i = 0; i < 157; i++) {
      Document d = new Document();
      d.add(newField("id", Integer.toString(i), Field.Store.YES,
                      Field.Index.NOT_ANALYZED));
      d.add(newField("content", "aaa " + i, Field.Store.NO,
                      Field.Index.ANALYZED));
      writer.addDocument(d);
    }
    writer.close();

    long diskUsage = startDir.sizeInBytes();
    long diskFree = diskUsage + 10;

    IOException err = null;

    boolean done = false;

    // Iterate w/ ever increasing free disk space:
    while (!done) {
      if (VERBOSE) {
        System.out.println("TEST: cycle");
      }
      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));
      dir.setPreventDoubleWrite(false);
      IndexWriter modifier = new IndexWriter(dir,
                                             newIndexWriterConfig(
                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false))
                                             .setMaxBufferedDocs(1000)
                                             .setMaxBufferedDeleteTerms(1000)
                                             .setMergeScheduler(new ConcurrentMergeScheduler()));
      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();
      modifier.setInfoStream(VERBOSE ? System.out : null);

      // For each disk size, first try to commit against
      // dir that will hit random IOExceptions & disk
      // full; after, give it infinite disk space & turn
      // off random IOExceptions & retry w/ same reader:
      boolean success = false;

      for (int x = 0; x < 2; x++) {
        if (VERBOSE) {
          System.out.println("TEST: x=" + x);
        }

        double rate = 0.1;
        double diskRatio = ((double)diskFree) / diskUsage;
        long thisDiskFree;
        String testName;

        if (0 == x) {
          thisDiskFree = diskFree;
          if (diskRatio >= 2.0) {
            rate /= 2;
          }
          if (diskRatio >= 4.0) {
            rate /= 2;
          }
          if (diskRatio >= 6.0) {
            rate = 0.0;
          }
          if (VERBOSE) {
            System.out.println("\ncycle: " + diskFree + " bytes");
          }
          testName = "disk full during reader.close() @ " + thisDiskFree
            + " bytes";
        } else {
          thisDiskFree = 0;
          rate = 0.0;
          if (VERBOSE) {
            System.out.println("\ncycle: same writer: unlimited disk space");
          }
          testName = "reader re-use after disk full";
        }

        dir.setMaxSizeInBytes(thisDiskFree);
        dir.setRandomIOExceptionRate(rate);

        try {
          if (0 == x) {
            int docId = 12;
            for (int i = 0; i < 13; i++) {
              if (updates) {
                Document d = new Document();
                d.add(newField("id", Integer.toString(i), Field.Store.YES,
                                Field.Index.NOT_ANALYZED));
                d.add(newField("content", "bbb " + i, Field.Store.NO,
                                Field.Index.ANALYZED));
                modifier.updateDocument(new Term("id", Integer.toString(docId)), d);
              } else { // deletes
                modifier.deleteDocuments(new Term("id", Integer.toString(docId)));
                // modifier.setNorm(docId, "contents", (float)2.0);
              }
              docId += 12;
            }
          }
          modifier.close();
          success = true;
          if (0 == x) {
            done = true;
          }
        }
        catch (IOException e) {
          if (VERBOSE) {
            System.out.println("  hit IOException: " + e);
            e.printStackTrace(System.out);
          }
          err = e;
          if (1 == x) {
            e.printStackTrace();
            fail(testName + " hit IOException after disk space was freed up");
          }
        }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419644124089/fstmerge_var1_4374746037244000297
        // prevent throwing a random exception here!!
        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();
        dir.setRandomIOExceptionRate(0.0);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419644124089/fstmerge_base_7591190890344882789

=======
        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();
        final long maxSizeInBytes = dir.getMaxSizeInBytes();
        dir.setRandomIOExceptionRate(0.0);
        dir.setMaxSizeInBytes(0);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419644124089/fstmerge_var2_1400703836416072349
        if (!success) {
          // Must force the close else the writer can have
          // open files which cause exc in MockRAMDir.close
         
          modifier.rollback();
        }

        // If the close() succeeded, make sure there are
        // no unreferenced files.
        if (success) {
          _TestUtil.checkIndex(dir);
          TestIndexWriter.assertNoUnreferencedFiles(dir, "after writer.close");
        }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419644124089/fstmerge_var1_4374746037244000297
        dir.setRandomIOExceptionRate(randomIOExceptionRate);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419644124089/fstmerge_base_7591190890344882789
=======
        dir.setRandomIOExceptionRate(randomIOExceptionRate);
        dir.setMaxSizeInBytes(maxSizeInBytes);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419644124089/fstmerge_var2_1400703836416072349

        // Finally, verify index is not corrupt, and, if
        // we succeeded, we see all docs changed, and if
        // we failed, we see either all docs or no docs
        // changed (transactional semantics):
        IndexReader newReader = null;
        try {
          newReader = IndexReader.open(dir, true);
        }
        catch (IOException e) {
          e.printStackTrace();
          fail(testName
               + ":exception when creating IndexReader after disk full during close: "
               + e);
        }

        IndexSearcher searcher = newSearcher(newReader);
        ScoreDoc[] hits = null;
        try {
          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
        }
        catch (IOException e) {
          e.printStackTrace();
          fail(testName + ": exception when searching: " + e);
        }
        int result2 = hits.length;
        if (success) {
          if (x == 0 && result2 != END_COUNT) {
            fail(testName
                 + ": method did not throw exception but hits.length for search on term 'aaa' is "
                 + result2 + " instead of expected " + END_COUNT);
          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {
            // It's possible that the first exception was
            // "recoverable" wrt pending deletes, in which
            // case the pending deletes are retained and
            // then re-flushing (with plenty of disk
            // space) will succeed in flushing the
            // deletes:
            fail(testName
                 + ": method did not throw exception but hits.length for search on term 'aaa' is "
                 + result2 + " instead of expected " + START_COUNT + " or " + END_COUNT);
          }
        } else {
          // On hitting exception we still may have added
          // all docs:
          if (result2 != START_COUNT && result2 != END_COUNT) {
            err.printStackTrace();
            fail(testName
                 + ": method did throw exception but hits.length for search on term 'aaa' is "
                 + result2 + " instead of expected " + START_COUNT + " or " + END_COUNT);
          }
        }
        searcher.close();
        newReader.close();
        if (result2 == END_COUNT) {
          break;
        }
      }
      dir.close();
      modifier.close();

      // Try again with 10 more bytes of free space:
      diskFree += 10;
    }
    startDir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_317e9_cf72b/rev_317e9-cf72b/lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419644145096/fstmerge_var1_7787850015310195153
@Override
  public void flush(Map<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> threadsAndFields, final SegmentWriteState state) throws IOException {

    // Gather all FieldData's that have postings, across all
    // ThreadStates
    List<FreqProxTermsWriterPerField> allFields = new ArrayList<FreqProxTermsWriterPerField>();
    
    flushedDocCount = state.numDocs;

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {

      Collection<TermsHashConsumerPerField> fields = entry.getValue();


      for (final TermsHashConsumerPerField i : fields) {
        final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) i;
        if (perField.termsHashPerField.bytesHash.size() > 0)
          allFields.add(perField);
      }
    }

    final int numAllFields = allFields.size();

    // Sort by field name
    CollectionUtil.quickSort(allFields);

    final FieldsConsumer consumer = state.segmentCodecs.codec().fieldsConsumer(state);

    /*
    Current writer chain:
      FieldsConsumer
        -> IMPL: FormatPostingsTermsDictWriter
          -> TermsConsumer
            -> IMPL: FormatPostingsTermsDictWriter.TermsWriter
              -> DocsConsumer
                -> IMPL: FormatPostingsDocsWriter
                  -> PositionsConsumer
                    -> IMPL: FormatPostingsPositionsWriter
    */

    int start = 0;
    while(start < numAllFields) {
      final FieldInfo fieldInfo = allFields.get(start).fieldInfo;
      final String fieldName = fieldInfo.name;

      int end = start+1;
      while(end < numAllFields && allFields.get(end).fieldInfo.name.equals(fieldName))
        end++;
      
      FreqProxTermsWriterPerField[] fields = new FreqProxTermsWriterPerField[end-start];
      for(int i=start;i<end;i++) {
        fields[i-start] = allFields.get(i);

        // Aggregate the storePayload as seen by the same
        // field across multiple threads
        if (!fieldInfo.omitTermFreqAndPositions) {
          fieldInfo.storePayloads |= fields[i-start].hasPayloads;
        }
      }

      // If this field has postings then add them to the
      // segment
      appendPostings(fieldName, state, fields, consumer);

      for(int i=0;i<fields.length;i++) {
        TermsHashPerField perField = fields[i].termsHashPerField;
        int numPostings = perField.bytesHash.size();
        perField.reset();
        perField.shrinkHash(numPostings);
        fields[i].reset();
      }

      start = end;
    }

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {
      FreqProxTermsWriterPerThread perThread = (FreqProxTermsWriterPerThread) entry.getKey();
      perThread.termsHashPerThread.reset(true);
    }
    consumer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419644145096/fstmerge_base_4589900255263776065
@Override
  public void flush(Map<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> threadsAndFields, final SegmentWriteState state) throws IOException {

    // Gather all FieldData's that have postings, across all
    // ThreadStates
    List<FreqProxTermsWriterPerField> allFields = new ArrayList<FreqProxTermsWriterPerField>();
    
    flushedDocCount = state.numDocs;

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {

      Collection<TermsHashConsumerPerField> fields = entry.getValue();


      for (final TermsHashConsumerPerField i : fields) {
        final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) i;
        if (perField.termsHashPerField.bytesHash.size() > 0)
          allFields.add(perField);
      }
    }

    final int numAllFields = allFields.size();

    // Sort by field name
    CollectionUtil.quickSort(allFields);

    final FieldsConsumer consumer = state.segmentCodecs.codec().fieldsConsumer(state);

    /*
    Current writer chain:
      FieldsConsumer
        -> IMPL: FormatPostingsTermsDictWriter
          -> TermsConsumer
            -> IMPL: FormatPostingsTermsDictWriter.TermsWriter
              -> DocsConsumer
                -> IMPL: FormatPostingsDocsWriter
                  -> PositionsConsumer
                    -> IMPL: FormatPostingsPositionsWriter
    */

    int start = 0;
    while(start < numAllFields) {
      final FieldInfo fieldInfo = allFields.get(start).fieldInfo;
      final String fieldName = fieldInfo.name;

      int end = start+1;
      while(end < numAllFields && allFields.get(end).fieldInfo.name.equals(fieldName))
        end++;
      
      FreqProxTermsWriterPerField[] fields = new FreqProxTermsWriterPerField[end-start];
      for(int i=start;i<end;i++) {
        fields[i-start] = allFields.get(i);

        // Aggregate the storePayload as seen by the same
        // field across multiple threads
        fieldInfo.storePayloads |= fields[i-start].hasPayloads;
      }

      // If this field has postings then add them to the
      // segment
      appendPostings(fieldName, state, fields, consumer);

      for(int i=0;i<fields.length;i++) {
        TermsHashPerField perField = fields[i].termsHashPerField;
        int numPostings = perField.bytesHash.size();
        perField.reset();
        perField.shrinkHash(numPostings);
        fields[i].reset();
      }

      start = end;
    }

    for (Map.Entry<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> entry : threadsAndFields.entrySet()) {
      FreqProxTermsWriterPerThread perThread = (FreqProxTermsWriterPerThread) entry.getKey();
      perThread.termsHashPerThread.reset(true);
    }
    consumer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419644145096/fstmerge_var2_6344115374719937081

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_317e9_cf72b/rev_317e9-cf72b/lucene/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419644154375/fstmerge_var1_3181358876663256579
@Override
  public DocumentsWriter.DocWriter processDocument(FieldInfos fieldInfos) throws IOException {

    consumer.startDocument();
    fieldsWriter.startDocument();

    final Document doc = docState.doc;

    assert docFieldProcessor.docWriter.writer.testPoint("DocumentsWriter.ThreadState.init start");

    fieldCount = 0;
    
    final int thisFieldGen = fieldGen++;

    final List<Fieldable> docFields = doc.getFields();
    final int numDocFields = docFields.size();

    // Absorb any new fields first seen in this document.
    // Also absorb any changes to fields we had already
    // seen before (eg suddenly turning on norms or
    // vectors, etc.):

    for(int i=0;i<numDocFields;i++) {
      Fieldable field = docFields.get(i);
      final String fieldName = field.name();

      // Make sure we have a PerField allocated
      final int hashPos = fieldName.hashCode() & hashMask;
      DocFieldProcessorPerField fp = fieldHash[hashPos];
      while(fp != null && !fp.fieldInfo.name.equals(fieldName))
        fp = fp.next;

      if (fp == null) {

        // TODO FI: we need to genericize the "flags" that a
        // field holds, and, how these flags are merged; it
        // needs to be more "pluggable" such that if I want
        // to have a new "thing" my Fields can do, I can
        // easily add it
        FieldInfo fi = fieldInfos.addOrUpdate(fieldName, field.isIndexed(), field.isTermVectorStored(),
                                      field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                                      field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
        fp = new DocFieldProcessorPerField(this, fi);
        fp.next = fieldHash[hashPos];
        fieldHash[hashPos] = fp;
        totalFieldCount++;

        if (totalFieldCount >= fieldHash.length/2)
          rehash();
      } else {
        fieldInfos.addOrUpdate(fp.fieldInfo.name, field.isIndexed(), field.isTermVectorStored(),
                               field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                               field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
      }
      if (thisFieldGen != fp.lastGen) {

        // First time we're seeing this field for this doc
        fp.fieldCount = 0;

        if (fieldCount == fields.length) {
          final int newSize = fields.length*2;
          DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];
          System.arraycopy(fields, 0, newArray, 0, fieldCount);
          fields = newArray;
        }

        fields[fieldCount++] = fp;
        fp.lastGen = thisFieldGen;
      }

      if (fp.fieldCount == fp.fields.length) {
        Fieldable[] newArray = new Fieldable[fp.fields.length*2];
        System.arraycopy(fp.fields, 0, newArray, 0, fp.fieldCount);
        fp.fields = newArray;
      }

      fp.fields[fp.fieldCount++] = field;
      if (field.isStored()) {
        fieldsWriter.addField(field, fp.fieldInfo);
      }
    }

    // If we are writing vectors then we must visit
    // fields in sorted order so they are written in
    // sorted order.  TODO: we actually only need to
    // sort the subset of fields that have vectors
    // enabled; we could save [small amount of] CPU
    // here.
    ArrayUtil.quickSort(fields, 0, fieldCount, fieldsComp);

    for(int i=0;i<fieldCount;i++)
      fields[i].consumer.processFields(fields[i].fields, fields[i].fieldCount);

    if (docState.maxTermPrefix != null && docState.infoStream != null) {
      docState.infoStream.println("WARNING: document contains at least one immense term (whose UTF8 encoding is longer than the max length " + DocumentsWriter.MAX_TERM_LENGTH_UTF8 + "), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '" + docState.maxTermPrefix + "...'"); 
      docState.maxTermPrefix = null;
    }

    final DocumentsWriter.DocWriter one = fieldsWriter.finishDocument();
    final DocumentsWriter.DocWriter two = consumer.finishDocument();
    if (one == null) {
      return two;
    } else if (two == null) {
      return one;
    } else {
      PerDoc both = getPerDoc();
      both.docID = docState.docID;
      assert one.docID == docState.docID;
      assert two.docID == docState.docID;
      both.one = one;
      both.two = two;
      return both;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419644154375/fstmerge_base_211592022474717630
@Override
  public DocumentsWriter.DocWriter processDocument(FieldInfos fieldInfos) throws IOException {

    consumer.startDocument();
    fieldsWriter.startDocument();

    final Document doc = docState.doc;

    assert docFieldProcessor.docWriter.writer.testPoint("DocumentsWriter.ThreadState.init start");

    fieldCount = 0;
    
    final int thisFieldGen = fieldGen++;

    final List<Fieldable> docFields = doc.getFields();
    final int numDocFields = docFields.size();

    // Absorb any new fields first seen in this document.
    // Also absorb any changes to fields we had already
    // seen before (eg suddenly turning on norms or
    // vectors, etc.):

    for(int i=0;i<numDocFields;i++) {
      Fieldable field = docFields.get(i);
      final String fieldName = field.name();

      // Make sure we have a PerField allocated
      final int hashPos = fieldName.hashCode() & hashMask;
      DocFieldProcessorPerField fp = fieldHash[hashPos];
      while(fp != null && !fp.fieldInfo.name.equals(fieldName))
        fp = fp.next;

      if (fp == null) {

        // TODO FI: we need to genericize the "flags" that a
        // field holds, and, how these flags are merged; it
        // needs to be more "pluggable" such that if I want
        // to have a new "thing" my Fields can do, I can
        // easily add it
        FieldInfo fi = fieldInfos.addOrUpdate(fieldName, field.isIndexed(), field.isTermVectorStored(),
                                      field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                                      field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
        fp = new DocFieldProcessorPerField(this, fi);
        fp.next = fieldHash[hashPos];
        fieldHash[hashPos] = fp;
        totalFieldCount++;

        if (totalFieldCount >= fieldHash.length/2)
          rehash();
      } else {
        fieldInfos.addOrUpdate(fp.fieldInfo.name, field.isIndexed(), field.isTermVectorStored(),
                            field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                            field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
      }
      if (thisFieldGen != fp.lastGen) {

        // First time we're seeing this field for this doc
        fp.fieldCount = 0;

        if (fieldCount == fields.length) {
          final int newSize = fields.length*2;
          DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];
          System.arraycopy(fields, 0, newArray, 0, fieldCount);
          fields = newArray;
        }

        fields[fieldCount++] = fp;
        fp.lastGen = thisFieldGen;
      }

      if (fp.fieldCount == fp.fields.length) {
        Fieldable[] newArray = new Fieldable[fp.fields.length*2];
        System.arraycopy(fp.fields, 0, newArray, 0, fp.fieldCount);
        fp.fields = newArray;
      }

      fp.fields[fp.fieldCount++] = field;
      if (field.isStored()) {
        fieldsWriter.addField(field, fp.fieldInfo);
      }
    }

    // If we are writing vectors then we must visit
    // fields in sorted order so they are written in
    // sorted order.  TODO: we actually only need to
    // sort the subset of fields that have vectors
    // enabled; we could save [small amount of] CPU
    // here.
    ArrayUtil.quickSort(fields, 0, fieldCount, fieldsComp);

    for(int i=0;i<fieldCount;i++)
      fields[i].consumer.processFields(fields[i].fields, fields[i].fieldCount);

    if (docState.maxTermPrefix != null && docState.infoStream != null) {
      docState.infoStream.println("WARNING: document contains at least one immense term (whose UTF8 encoding is longer than the max length " + DocumentsWriter.MAX_TERM_LENGTH_UTF8 + "), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '" + docState.maxTermPrefix + "...'"); 
      docState.maxTermPrefix = null;
    }

    final DocumentsWriter.DocWriter one = fieldsWriter.finishDocument();
    final DocumentsWriter.DocWriter two = consumer.finishDocument();
    if (one == null) {
      return two;
    } else if (two == null) {
      return one;
    } else {
      PerDoc both = getPerDoc();
      both.docID = docState.docID;
      assert one.docID == docState.docID;
      assert two.docID == docState.docID;
      both.one = one;
      both.two = two;
      return both;
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419644154375/fstmerge_var2_4973803103275012359

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_317e9_cf72b/rev_317e9-cf72b/lucene/src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_57f85_e4571/rev_57f85-e4571.revisions
Conflict type: LineBasedMCFd
Conflict body: 
public static void unzip(File zipName, File destDir) throws IOException {

    ZipFile zipFile = new ZipFile(zipName);

    Enumeration<? extends ZipEntry> entries = zipFile.entries();

    rmDir(destDir);

    destDir.mkdir();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419645093096/fstmerge_var1_6469628176215672817
    LuceneTestCase.tempDirs.add(destDir.getAbsolutePath());
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419645093096/fstmerge_base_2619514804632032677
    
=======

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419645093096/fstmerge_var2_408175949751493461
    while (entries.hasMoreElements()) {
      ZipEntry entry = entries.nextElement();

      InputStream in = zipFile.getInputStream(entry);
      File targetFile = new File(destDir, entry.getName());
      if (entry.isDirectory()) {
        // allow unzipping with directory structure
        targetFile.mkdirs();
      } else {
        if (targetFile.getParentFile()!=null) {
          // be on the safe side: do not rely on that directories are always extracted
          // before their children (although this makes sense, but is it guaranteed?)
          targetFile.getParentFile().mkdirs();
        }
        OutputStream out = new BufferedOutputStream(new FileOutputStream(targetFile));

        byte[] buffer = new byte[8192];
        int len;
        while((len = in.read(buffer)) >= 0) {
          out.write(buffer, 0, len);
        }

        in.close();
        out.close();
      }
    }

    zipFile.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_57f85_e4571/rev_57f85-e4571/lucene/src/test-framework/org/apache/lucene/util/_TestUtil.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a082b_ccacb/rev_a082b-ccacb.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47833_6707b/rev_47833-6707b.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_feff3_a6300/rev_feff3-a6300.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6a6b1_f245a/rev_6a6b1-f245a.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0cda5_fb88d/rev_0cda5-fb88d.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_9089e_4efd1/rev_9089e-4efd1.revisions
Conflict type: LineBasedMCFd
Conflict body: 
public void testEnforceDeletions() throws Exception {
    Directory dir = newDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(
        random,
        dir,
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random)).
            setMergeScheduler(new SerialMergeScheduler()).
            // asserts below requires no unexpected merges:
            setMergePolicy(newLogMergePolicy(10))
    );

    // NOTE: cannot use writer.getReader because RIW (on
    // flipping a coin) may give us a newly opened reader,
    // but we use .reopen on this reader below and expect to
    // (must) get an NRT reader:
    IndexReader reader = IndexReader.open(writer.w, true);
    // same reason we don't wrap?
    IndexSearcher searcher = newSearcher(reader, false);

    // add a doc, refresh the reader, and check that its there
    Document doc = new Document();
    doc.add(newField("id", "1", Field.Store.YES, Field.Index.NOT_ANALYZED));
    writer.addDocument(doc);

    reader = refreshReader(reader);
    searcher.close();
    searcher = newSearcher(reader, false);

    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);
    assertEquals("Should find a hit...", 1, docs.totalHits);

    final SpanFilter startFilter = new SpanQueryFilter(new SpanTermQuery(new Term("id", "1")));

    // ignore deletions
    CachingSpanFilter filter = new CachingSpanFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);

    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);
    assertEquals("[query + filter] Should find a hit...", 1, docs.totalHits);
    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);
    docs = searcher.search(constantScore, 1);
    assertEquals("[just filter] Should find a hit...", 1, docs.totalHits);

    // now delete the doc, refresh the reader, and see that
    // it's not there
    _TestUtil.keepFullyDeletedSegments(writer.w);
    writer.deleteDocuments(new Term("id", "1"));

    reader = refreshReader(reader);
    searcher.close();
    searcher = newSearcher(reader, false);

    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);
    assertEquals("[query + filter] Should *not* find a hit...", 0, docs.totalHits);

    docs = searcher.search(constantScore, 1);
    assertEquals("[just filter] Should find a hit...", 1, docs.totalHits);


    // force cache to regenerate:
    filter = new CachingSpanFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);

    writer.addDocument(doc);
    reader = refreshReader(reader);
    searcher.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419650704740/fstmerge_var1_2116859199020000219
    searcher = newSearcher(reader);

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419650704740/fstmerge_base_5619017253685112606
    searcher = newSearcher(reader);
        
=======
    searcher = newSearcher(reader, false);
        
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419650704740/fstmerge_var2_3323547713087919801
    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);
    assertEquals("[query + filter] Should find a hit...", 1, docs.totalHits);

    constantScore = new ConstantScoreQuery(filter);
    docs = searcher.search(constantScore, 1);
    assertEquals("[just filter] Should find a hit...", 1, docs.totalHits);

    // NOTE: important to hold ref here so GC doesn't clear
    // the cache entry!  Else the assert below may sometimes
    // fail:
    IndexReader oldReader = reader;

    // make sure we get a cache hit when we reopen readers
    // that had no new deletions
    reader = refreshReader(reader);
    assertTrue(reader != oldReader);
    searcher.close();
    searcher = newSearcher(reader, false);
    int missCount = filter.missCount;
    docs = searcher.search(constantScore, 1);
    assertEquals("[just filter] Should find a hit...", 1, docs.totalHits);
    assertEquals(missCount, filter.missCount);

    // now delete the doc, refresh the reader, and see that it's not there
    writer.deleteDocuments(new Term("id", "1"));

    reader = refreshReader(reader);
    searcher.close();
    searcher = newSearcher(reader, false);

    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);
    assertEquals("[query + filter] Should *not* find a hit...", 0, docs.totalHits);

    docs = searcher.search(constantScore, 1);
    assertEquals("[just filter] Should *not* find a hit...", 0, docs.totalHits);

    // NOTE: silliness to make sure JRE does not optimize
    // away our holding onto oldReader to prevent
    // CachingWrapperFilter's WeakHashMap from dropping the
    // entry:
    assertTrue(oldReader != null);

    searcher.close();
    writer.close();
    reader.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_9089e_4efd1/rev_9089e-4efd1/lucene/src/test/org/apache/lucene/search/TestCachingSpanFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void deleteDocuments(Term... terms) throws CorruptIndexException, IOException {
    ensureOpen();
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419650735435/fstmerge_var1_2939308871195206734
      docWriter.deleteTerms(term);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419650735435/fstmerge_base_906255311990336947
      if (docWriter.deleteTerm(term, false)) {
        flush(true, false);
      }
=======
      if (docWriter.deleteTerms(terms)) {
        flush(true, false);
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419650735435/fstmerge_var2_1368368401689352261
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Term..)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_9089e_4efd1/rev_9089e-4efd1/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void deleteDocuments(Query... queries) throws CorruptIndexException, IOException {
    ensureOpen();
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419650735445/fstmerge_var1_1106264523450660638
      docWriter.deleteQueries(query);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419650735445/fstmerge_base_7742809167541681553
      if (docWriter.deleteQuery(query)) {
        flush(true, false);
      }
=======
      if (docWriter.deleteQueries(queries)) {
        flush(true, false);
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419650735445/fstmerge_var2_4467387651113413879
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Query..)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_9089e_4efd1/rev_9089e-4efd1/lucene/src/java/org/apache/lucene/index/IndexWriter.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0c32e_3e3bb/rev_0c32e-3e3bb.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651657464/fstmerge_var1_6589519767602289176
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651657464/fstmerge_base_7507277472804699652
@Override
    DocConsumer getChain(DocumentsWriter documentsWriter) {
      return null;
    }
=======
@Override
    public DocConsumer getChain(DocumentsWriter documentsWriter) {
      return null;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651657464/fstmerge_var2_3944787568279891618

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0c32e_3e3bb/rev_0c32e-3e3bb/lucene/src/test/org/apache/lucene/index/TestIndexWriterConfig.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651674544/fstmerge_var1_8851199293549991198
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651674544/fstmerge_base_2670810877653635862
@Override
  public DocumentsWriter.DocWriter processDocument(FieldInfos fieldInfos) throws IOException {

    consumer.startDocument();
    fieldsWriter.startDocument();

    final Document doc = docState.doc;

    assert docFieldProcessor.docWriter.writer.testPoint("DocumentsWriter.ThreadState.init start");

    fieldCount = 0;
    
    final int thisFieldGen = fieldGen++;

    final List<Fieldable> docFields = doc.getFields();
    final int numDocFields = docFields.size();

    // Absorb any new fields first seen in this document.
    // Also absorb any changes to fields we had already
    // seen before (eg suddenly turning on norms or
    // vectors, etc.):

    for(int i=0;i<numDocFields;i++) {
      Fieldable field = docFields.get(i);
      final String fieldName = field.name();

      // Make sure we have a PerField allocated
      final int hashPos = fieldName.hashCode() & hashMask;
      DocFieldProcessorPerField fp = fieldHash[hashPos];
      while(fp != null && !fp.fieldInfo.name.equals(fieldName))
        fp = fp.next;

      if (fp == null) {

        // TODO FI: we need to genericize the "flags" that a
        // field holds, and, how these flags are merged; it
        // needs to be more "pluggable" such that if I want
        // to have a new "thing" my Fields can do, I can
        // easily add it
        FieldInfo fi = fieldInfos.addOrUpdate(fieldName, field.isIndexed(), field.isTermVectorStored(),
                                      field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                                      field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
        fp = new DocFieldProcessorPerField(this, fi);
        fp.next = fieldHash[hashPos];
        fieldHash[hashPos] = fp;
        totalFieldCount++;

        if (totalFieldCount >= fieldHash.length/2)
          rehash();
      } else {
        fieldInfos.addOrUpdate(fp.fieldInfo.name, field.isIndexed(), field.isTermVectorStored(),
                            field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                            field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
      }
      if (thisFieldGen != fp.lastGen) {

        // First time we're seeing this field for this doc
        fp.fieldCount = 0;

        if (fieldCount == fields.length) {
          final int newSize = fields.length*2;
          DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];
          System.arraycopy(fields, 0, newArray, 0, fieldCount);
          fields = newArray;
        }

        fields[fieldCount++] = fp;
        fp.lastGen = thisFieldGen;
      }

      if (fp.fieldCount == fp.fields.length) {
        Fieldable[] newArray = new Fieldable[fp.fields.length*2];
        System.arraycopy(fp.fields, 0, newArray, 0, fp.fieldCount);
        fp.fields = newArray;
      }

      fp.fields[fp.fieldCount++] = field;
      if (field.isStored()) {
        fieldsWriter.addField(field, fp.fieldInfo);
      }
    }

    // If we are writing vectors then we must visit
    // fields in sorted order so they are written in
    // sorted order.  TODO: we actually only need to
    // sort the subset of fields that have vectors
    // enabled; we could save [small amount of] CPU
    // here.
    ArrayUtil.quickSort(fields, 0, fieldCount, fieldsComp);

    for(int i=0;i<fieldCount;i++)
      fields[i].consumer.processFields(fields[i].fields, fields[i].fieldCount);

    if (docState.maxTermPrefix != null && docState.infoStream != null) {
      docState.infoStream.println("WARNING: document contains at least one immense term (whose UTF8 encoding is longer than the max length " + DocumentsWriter.MAX_TERM_LENGTH_UTF8 + "), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '" + docState.maxTermPrefix + "...'"); 
      docState.maxTermPrefix = null;
    }

    final DocumentsWriter.DocWriter one = fieldsWriter.finishDocument();
    final DocumentsWriter.DocWriter two = consumer.finishDocument();
    if (one == null) {
      return two;
    } else if (two == null) {
      return one;
    } else {
      PerDoc both = getPerDoc();
      both.docID = docState.docID;
      assert one.docID == docState.docID;
      assert two.docID == docState.docID;
      both.one = one;
      both.two = two;
      return both;
    }
  }
=======
@Override
  public DocumentsWriter.DocWriter processDocument(FieldInfos fieldInfos) throws IOException {

    consumer.startDocument();
    fieldsWriter.startDocument();

    final Document doc = docState.doc;

    assert docFieldProcessor.docWriter.writer.testPoint("DocumentsWriter.ThreadState.init start");

    fieldCount = 0;
    
    final int thisFieldGen = fieldGen++;

    final List<Fieldable> docFields = doc.getFields();
    final int numDocFields = docFields.size();

    // Absorb any new fields first seen in this document.
    // Also absorb any changes to fields we had already
    // seen before (eg suddenly turning on norms or
    // vectors, etc.):

    for(int i=0;i<numDocFields;i++) {
      Fieldable field = docFields.get(i);
      final String fieldName = field.name();

      // Make sure we have a PerField allocated
      final int hashPos = fieldName.hashCode() & hashMask;
      DocFieldProcessorPerField fp = fieldHash[hashPos];
      while(fp != null && !fp.fieldInfo.name.equals(fieldName))
        fp = fp.next;

      if (fp == null) {

        // TODO FI: we need to genericize the "flags" that a
        // field holds, and, how these flags are merged; it
        // needs to be more "pluggable" such that if I want
        // to have a new "thing" my Fields can do, I can
        // easily add it
        FieldInfo fi = fieldInfos.addOrUpdate(fieldName, field.isIndexed(), field.isTermVectorStored(),
                                      field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                                      field.getOmitNorms(), false, field.getOmitTermFreqAndPositions(), field.docValuesType());
        fp = new DocFieldProcessorPerField(this, fi);
        fp.next = fieldHash[hashPos];
        fieldHash[hashPos] = fp;
        totalFieldCount++;

        if (totalFieldCount >= fieldHash.length/2)
          rehash();
      } else {
        fieldInfos.addOrUpdate(fp.fieldInfo.name, field.isIndexed(), field.isTermVectorStored(),
                            field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
                            field.getOmitNorms(), false, field.getOmitTermFreqAndPositions(), field.docValuesType());
      }
      if (thisFieldGen != fp.lastGen) {

        // First time we're seeing this field for this doc
        fp.fieldCount = 0;

        if (fieldCount == fields.length) {
          final int newSize = fields.length*2;
          DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];
          System.arraycopy(fields, 0, newArray, 0, fieldCount);
          fields = newArray;
        }

        fields[fieldCount++] = fp;
        fp.lastGen = thisFieldGen;
      }

      if (fp.fieldCount == fp.fields.length) {
        Fieldable[] newArray = new Fieldable[fp.fields.length*2];
        System.arraycopy(fp.fields, 0, newArray, 0, fp.fieldCount);
        fp.fields = newArray;
      }

      fp.fields[fp.fieldCount++] = field;
      if (field.isStored()) {
        fieldsWriter.addField(field, fp.fieldInfo);
      }
    }

    // If we are writing vectors then we must visit
    // fields in sorted order so they are written in
    // sorted order.  TODO: we actually only need to
    // sort the subset of fields that have vectors
    // enabled; we could save [small amount of] CPU
    // here.
    ArrayUtil.quickSort(fields, 0, fieldCount, fieldsComp);
   

    for(int i=0;i<fieldCount;i++) {
      final DocFieldProcessorPerField perField = fields[i];
      final Fieldable fieldable = perField.fields[0];
      perField.consumer.processFields(perField.fields, perField.fieldCount);
      final PerDocFieldValues docValues = fieldable.getDocValues();
      if (docValues == null) {
        continue;
      }
      final DocValuesConsumer consumer = docFieldProcessor.docValuesConsumer(docState.docWriter.directory,
              docState.docWriter.segment, fieldable.name(), docValues, perField.fieldInfo);
      consumer.add(docState.docID, docValues);
    }
    if (docState.maxTermPrefix != null && docState.infoStream != null) {
      docState.infoStream.println("WARNING: document contains at least one immense term (whose UTF8 encoding is longer than the max length " + DocumentsWriter.MAX_TERM_LENGTH_UTF8 + "), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '" + docState.maxTermPrefix + "...'"); 
      docState.maxTermPrefix = null;
    }

    final DocumentsWriter.DocWriter one = fieldsWriter.finishDocument();
    final DocumentsWriter.DocWriter two = consumer.finishDocument();
    if (one == null) {
      return two;
    } else if (two == null) {
      return one;
    } else {
      PerDoc both = getPerDoc();
      both.docID = docState.docID;
      assert one.docID == docState.docID;
      assert two.docID == docState.docID;
      both.one = one;
      both.two = two;
      return both;
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651674544/fstmerge_var2_8729302314628346075

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0c32e_3e3bb/rev_0c32e-3e3bb/lucene/src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651674802/fstmerge_var1_4904079810914210121
FieldInfo(String na, boolean tk, int nu, boolean storeTermVector, 
            boolean storePositionWithTermVector,  boolean storeOffsetWithTermVector, 
            boolean omitNorms, boolean storePayloads, boolean omitTermFreqAndPositions) {
    name = na;
    isIndexed = tk;
    number = nu;
    if (isIndexed) {
      this.storeTermVector = storeTermVector;
      this.storeOffsetWithTermVector = storeOffsetWithTermVector;
      this.storePositionWithTermVector = storePositionWithTermVector;
      this.storePayloads = storePayloads;
      this.omitNorms = omitNorms;
      this.omitTermFreqAndPositions = omitTermFreqAndPositions;
    } else { // for non-indexed fields, leave defaults
      this.storeTermVector = false;
      this.storeOffsetWithTermVector = false;
      this.storePositionWithTermVector = false;
      this.storePayloads = false;
      this.omitNorms = false;
      this.omitTermFreqAndPositions = false;
    }
    assert !omitTermFreqAndPositions || !storePayloads;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651674802/fstmerge_base_5489867185590737882
FieldInfo(String na, boolean tk, int nu, boolean storeTermVector, 
            boolean storePositionWithTermVector,  boolean storeOffsetWithTermVector, 
            boolean omitNorms, boolean storePayloads, boolean omitTermFreqAndPositions) {
    name = na;
    isIndexed = tk;
    number = nu;
    if (isIndexed) {
      this.storeTermVector = storeTermVector;
      this.storeOffsetWithTermVector = storeOffsetWithTermVector;
      this.storePositionWithTermVector = storePositionWithTermVector;
      this.storePayloads = storePayloads;
      this.omitNorms = omitNorms;
      this.omitTermFreqAndPositions = omitTermFreqAndPositions;
    } else { // for non-indexed fields, leave defaults
      this.storeTermVector = false;
      this.storeOffsetWithTermVector = false;
      this.storePositionWithTermVector = false;
      this.storePayloads = false;
      this.omitNorms = false;
      this.omitTermFreqAndPositions = false;
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651674802/fstmerge_var2_2028799219357424450

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0c32e_3e3bb/rev_0c32e-3e3bb/lucene/src/java/org/apache/lucene/index/FieldInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651677120/fstmerge_var1_7074773638996860408
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651677120/fstmerge_base_5243582602234914148
synchronized SegmentInfo flush(IndexWriter writer, IndexFileDeleter deleter, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {

    final long startTime = System.currentTimeMillis();

    // We change writer's segmentInfos:
    assert Thread.holdsLock(writer);

    waitIdle();

    if (numDocs == 0) {
      // nothing to do!
      if (infoStream != null) {
        message("flush: no docs; skipping");
      }
      // Lock order: IW -> DW -> BD
      pushDeletes(null, segmentInfos);
      return null;
    }

    if (aborting) {
      if (infoStream != null) {
        message("flush: skip because aborting is set");
      }
      return null;
    }

    boolean success = false;

    SegmentInfo newSegment;

    try {
      assert nextDocID == numDocs;
      assert waitQueue.numWaiting == 0;
      assert waitQueue.waitingBytes == 0;

      if (infoStream != null) {
        message("flush postings as segment " + segment + " numDocs=" + numDocs);
      }
      
      final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,
                                                                 numDocs, writer.getConfig().getTermIndexInterval(),
                                                                 fieldInfos.buildSegmentCodecs(true),
                                                                 pendingDeletes);
      // Apply delete-by-docID now (delete-byDocID only
      // happens when an exception is hit processing that
      // doc, eg if analyzer has some problem w/ the text):
      if (pendingDeletes.docIDs.size() > 0) {
        flushState.deletedDocs = new BitVector(numDocs);
        for(int delDocID : pendingDeletes.docIDs) {
          flushState.deletedDocs.set(delDocID);
        }
        pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);
        pendingDeletes.docIDs.clear();
      }

      newSegment = new SegmentInfo(segment, numDocs, directory, false, fieldInfos.hasProx(), flushState.segmentCodecs, false, fieldInfos);

      Collection<DocConsumerPerThread> threads = new HashSet<DocConsumerPerThread>();
      for (DocumentsWriterThreadState threadState : threadStates) {
        threads.add(threadState.consumer);
      }

      double startMBUsed = bytesUsed()/1024./1024.;

      consumer.flush(threads, flushState);

      newSegment.setHasVectors(flushState.hasVectors);

      if (infoStream != null) {
        message("new segment has " + (flushState.hasVectors ? "vectors" : "no vectors"));
        if (flushState.deletedDocs != null) {
          message("new segment has " + flushState.deletedDocs.count() + " deleted docs");
        }
        message("flushedFiles=" + newSegment.files());
        message("flushed codecs=" + newSegment.getSegmentCodecs());
      }

      if (mergePolicy.useCompoundFile(segmentInfos, newSegment)) {
        final String cfsFileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        if (infoStream != null) {
          message("flush: create compound file \"" + cfsFileName + "\"");
        }

        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, cfsFileName);
        for(String fileName : newSegment.files()) {
          cfsWriter.addFile(fileName);
        }
        cfsWriter.close();
        deleter.deleteNewFiles(newSegment.files());
        newSegment.setUseCompoundFile(true);
      }

      // Must write deleted docs after the CFS so we don't
      // slurp the del file into CFS:
      if (flushState.deletedDocs != null) {
        final int delCount = flushState.deletedDocs.count();
        assert delCount > 0;
        newSegment.setDelCount(delCount);
        newSegment.advanceDelGen();
        final String delFileName = newSegment.getDelFileName();
        if (infoStream != null) {
          message("flush: write " + delCount + " deletes to " + delFileName);
        }
        boolean success2 = false;
        try {
          // TODO: in the NRT case it'd be better to hand
          // this del vector over to the
          // shortly-to-be-opened SegmentReader and let it
          // carry the changes; there's no reason to use
          // filesystem as intermediary here.
          flushState.deletedDocs.write(directory, delFileName);
          success2 = true;
        } finally {
          if (!success2) {
            try {
              directory.deleteFile(delFileName);
            } catch (Throwable t) {
              // suppress this so we keep throwing the
              // original exception
            }
          }
        }
      }

      if (infoStream != null) {
        message("flush: segment=" + newSegment);
        final double newSegmentSizeNoStore = newSegment.sizeInBytes(false)/1024./1024.;
        final double newSegmentSize = newSegment.sizeInBytes(true)/1024./1024.;
        message("  ramUsed=" + nf.format(startMBUsed) + " MB" +
                " newFlushedSize=" + nf.format(newSegmentSize) + " MB" +
                " (" + nf.format(newSegmentSizeNoStore) + " MB w/o doc stores)" +
                " docs/MB=" + nf.format(numDocs / newSegmentSize) +
                " new/old=" + nf.format(100.0 * newSegmentSizeNoStore / startMBUsed) + "%");
      }

      success = true;
    } finally {
      notifyAll();
      if (!success) {
        if (segment != null) {
          deleter.refresh(segment);
        }
        abort();
      }
    }

    doAfterFlush();

    // Lock order: IW -> DW -> BD
    pushDeletes(newSegment, segmentInfos);
    if (infoStream != null) {
      message("flush time " + (System.currentTimeMillis()-startTime) + " msec");
    }

    return newSegment;
  }
=======
synchronized SegmentInfo flush(IndexWriter writer, IndexFileDeleter deleter, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {

    final long startTime = System.currentTimeMillis();

    // We change writer's segmentInfos:
    assert Thread.holdsLock(writer);

    waitIdle();

    if (numDocs == 0) {
      // nothing to do!
      if (infoStream != null) {
        message("flush: no docs; skipping");
      }
      // Lock order: IW -> DW -> BD
      pushDeletes(null, segmentInfos);
      return null;
    }

    if (aborting) {
      if (infoStream != null) {
        message("flush: skip because aborting is set");
      }
      return null;
    }

    boolean success = false;

    SegmentInfo newSegment;

    try {
      assert nextDocID == numDocs;
      assert waitQueue.numWaiting == 0;
      assert waitQueue.waitingBytes == 0;

      if (infoStream != null) {
        message("flush postings as segment " + segment + " numDocs=" + numDocs);
      }
      
      final SegmentWriteState flushState = segWriteState(true);
      // Apply delete-by-docID now (delete-byDocID only
      // happens when an exception is hit processing that
      // doc, eg if analyzer has some problem w/ the text):
      if (pendingDeletes.docIDs.size() > 0) {
        flushState.deletedDocs = new BitVector(numDocs);
        for(int delDocID : pendingDeletes.docIDs) {
          flushState.deletedDocs.set(delDocID);
        }
        pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);
        pendingDeletes.docIDs.clear();
      }

      newSegment = new SegmentInfo(segment, numDocs, directory, false, fieldInfos.hasProx(), flushState.segmentCodecs, false, fieldInfos);

      Collection<DocConsumerPerThread> threads = new HashSet<DocConsumerPerThread>();
      for (DocumentsWriterThreadState threadState : threadStates) {
        threads.add(threadState.consumer);
      }

      double startMBUsed = bytesUsed()/1024./1024.;

      consumer.flush(threads, flushState);

      newSegment.setHasVectors(flushState.hasVectors);

      if (infoStream != null) {
        message("new segment has " + (flushState.hasVectors ? "vectors" : "no vectors"));
        if (flushState.deletedDocs != null) {
          message("new segment has " + flushState.deletedDocs.count() + " deleted docs");
        }
        message("flushedFiles=" + newSegment.files());
        message("flushed codecs=" + newSegment.getSegmentCodecs());
      }

      if (mergePolicy.useCompoundFile(segmentInfos, newSegment)) {
        final String cfsFileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        if (infoStream != null) {
          message("flush: create compound file \"" + cfsFileName + "\"");
        }

        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, cfsFileName);
        for(String fileName : newSegment.files()) {
          cfsWriter.addFile(fileName);
        }
        cfsWriter.close();
        deleter.deleteNewFiles(newSegment.files());
        newSegment.setUseCompoundFile(true);
      }

      // Must write deleted docs after the CFS so we don't
      // slurp the del file into CFS:
      if (flushState.deletedDocs != null) {
        final int delCount = flushState.deletedDocs.count();
        assert delCount > 0;
        newSegment.setDelCount(delCount);
        newSegment.advanceDelGen();
        final String delFileName = newSegment.getDelFileName();
        if (infoStream != null) {
          message("flush: write " + delCount + " deletes to " + delFileName);
        }
        boolean success2 = false;
        try {
          // TODO: in the NRT case it'd be better to hand
          // this del vector over to the
          // shortly-to-be-opened SegmentReader and let it
          // carry the changes; there's no reason to use
          // filesystem as intermediary here.
          flushState.deletedDocs.write(directory, delFileName);
          success2 = true;
        } finally {
          if (!success2) {
            try {
              directory.deleteFile(delFileName);
            } catch (Throwable t) {
              // suppress this so we keep throwing the
              // original exception
            }
          }
        }
      }

      if (infoStream != null) {
        message("flush: segment=" + newSegment);
        final double newSegmentSizeNoStore = newSegment.sizeInBytes(false)/1024./1024.;
        final double newSegmentSize = newSegment.sizeInBytes(true)/1024./1024.;
        message("  ramUsed=" + nf.format(startMBUsed) + " MB" +
                " newFlushedSize=" + nf.format(newSegmentSize) + " MB" +
                " (" + nf.format(newSegmentSizeNoStore) + " MB w/o doc stores)" +
                " docs/MB=" + nf.format(numDocs / newSegmentSize) +
                " new/old=" + nf.format(100.0 * newSegmentSizeNoStore / startMBUsed) + "%");
      }

      success = true;
    } finally {
      notifyAll();
      if (!success) {
        if (segment != null) {
          deleter.refresh(segment);
        }
        abort();
      }
    }

    doAfterFlush();

    // Lock order: IW -> DW -> BD
    pushDeletes(newSegment, segmentInfos);
    if (infoStream != null) {
      message("flush time " + (System.currentTimeMillis()-startTime) + " msec");
    }

    return newSegment;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651677120/fstmerge_var2_8504917400131264167

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0c32e_3e3bb/rev_0c32e-3e3bb/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
private int mergeFields() throws CorruptIndexException, IOException {
    for (IndexReader reader : readers) {
      if (reader instanceof SegmentReader) {
        SegmentReader segmentReader = (SegmentReader) reader;
        FieldInfos readerFieldInfos = segmentReader.fieldInfos();
        for (FieldInfo fi : readerFieldInfos) {
          fieldInfos.add(fi);
        }
      } else {
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION_OFFSET), true, true, true, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION), true, true, false, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_OFFSET), true, false, true, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR), true, false, false, false, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.OMIT_TERM_FREQ_AND_POSITIONS), false, false, false, false, true);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.STORES_PAYLOADS), false, false, false, true, false);
        addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.INDEXED), false, false, false, false, false);
        fieldInfos.addOrUpdate(reader.getFieldNames(FieldOption.UNINDEXED), false);
        fieldInfos.addOrUpdate(reader.getFieldNames(FieldOption.DOC_VALUES), false);
      }
    }
    final SegmentCodecs codecInfo = fieldInfos.buildSegmentCodecs(false);
    fieldInfos.write(directory, segment + "." + IndexFileNames.FIELD_INFOS_EXTENSION);

    int docCount = 0;

    setMatchingSegmentReaders();

    final FieldsWriter fieldsWriter = new FieldsWriter(directory, segment);

    try {
      int idx = 0;
      for (IndexReader reader : readers) {
        final SegmentReader matchingSegmentReader = matchingSegmentReaders[idx++];
        FieldsReader matchingFieldsReader = null;
        if (matchingSegmentReader != null) {
          final FieldsReader fieldsReader = matchingSegmentReader.getFieldsReader();
          if (fieldsReader != null) {
            matchingFieldsReader = fieldsReader;
          }
        }
        if (reader.hasDeletions()) {
          docCount += copyFieldsWithDeletions(fieldsWriter,
                                              reader, matchingFieldsReader);
        } else {
          docCount += copyFieldsNoDeletions(fieldsWriter,
                                            reader, matchingFieldsReader);
        }
      }
    } finally {
      fieldsWriter.close();
    }

    final String fileName = IndexFileNames.segmentFileName(segment, "", IndexFileNames.FIELDS_INDEX_EXTENSION);
    final long fdxFileLength = directory.fileLength(fileName);

    if (4+((long) docCount)*8 != fdxFileLength)
      // This is most likely a bug in Sun JRE 1.6.0_04/_05;
      // we detect that the bug has struck, here, and
      // throw an exception to prevent the corruption from
      // entering the index.  See LUCENE-1282 for
      // details.
      throw new RuntimeException("mergeFields produced an invalid result: docCount is " + docCount + " but fdx file size is " + fdxFileLength + " file=" + fileName + " file exists?=" + directory.fileExists(fileName) + "; now aborting this merge to prevent index corruption");

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651677620/fstmerge_var1_7627652915889166129
    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, docCount, termIndexInterval, codecInfo, null);

||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651677620/fstmerge_base_2516519769557409277
    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, docCount, termIndexInterval, codecInfo, null);
    
=======
    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, docCount, termIndexInterval, codecInfo, null, new AtomicLong(0));
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651677620/fstmerge_var2_692294224574314030
    return docCount;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0c32e_3e3bb/rev_0c32e-3e3bb/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651678256/fstmerge_var1_4563878559815758414
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651678256/fstmerge_base_744671598027159455
@Override
  public void flush(Collection<DocConsumerPerThread> threads, SegmentWriteState state) throws IOException {

    Map<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>> childThreadsAndFields = new HashMap<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>>();
    for ( DocConsumerPerThread thread : threads) {
      DocFieldProcessorPerThread perThread = (DocFieldProcessorPerThread) thread;
      childThreadsAndFields.put(perThread.consumer, perThread.fields());
    }
    fieldsWriter.flush(state);
    consumer.flush(childThreadsAndFields, state);

    // Important to save after asking consumer to flush so
    // consumer can alter the FieldInfo* if necessary.  EG,
    // FreqProxTermsWriter does this with
    // FieldInfo.storePayload.
    final String fileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.FIELD_INFOS_EXTENSION);
    state.fieldInfos.write(state.directory, fileName);
  }
=======
@Override
  public void flush(Collection<DocConsumerPerThread> threads, SegmentWriteState state) throws IOException {

    Map<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>> childThreadsAndFields = new HashMap<DocFieldConsumerPerThread, Collection<DocFieldConsumerPerField>>();
    for ( DocConsumerPerThread thread : threads) {
      DocFieldProcessorPerThread perThread = (DocFieldProcessorPerThread) thread;
      childThreadsAndFields.put(perThread.consumer, perThread.fields());
    }
    fieldsWriter.flush(state);
    consumer.flush(childThreadsAndFields, state);

    for(DocValuesConsumer p : docValues.values()) {
      if (p != null) {
        p.finish(state.numDocs);
      }
    }
    docValues.clear();
    if(fieldsConsumer != null) {
      fieldsConsumer.close(); // TODO remove this once docvalues are fully supported by codecs
      docValuesConsumerState = null;
      fieldsConsumer = null;
    }

    // Important to save after asking consumer to flush so
    // consumer can alter the FieldInfo* if necessary.  EG,
    // FreqProxTermsWriter does this with
    // FieldInfo.storePayload.
    final String fileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.FIELD_INFOS_EXTENSION);
    state.fieldInfos.write(state.directory, fileName);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651678256/fstmerge_var2_5245718493240980616

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0c32e_3e3bb/rev_0c32e-3e3bb/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
private void read(IndexInput input, String fileName) throws IOException {
    format = input.readVInt();

    if (format > FORMAT_MINIMUM) {
      throw new IndexFormatTooOldException(fileName, format, FORMAT_MINIMUM, FORMAT_CURRENT);
    }
    if (format < FORMAT_CURRENT) {
      throw new IndexFormatTooNewException(fileName, format, FORMAT_MINIMUM, FORMAT_CURRENT);
    }

    final int size = input.readVInt(); //read in the size

    for (int i = 0; i < size; i++) {
      String name = StringHelper.intern(input.readString());
      // if this is a previous format codec 0 will be preflex!
      final int fieldNumber = format <= FORMAT_PER_FIELD_CODEC? input.readInt():i;
      final int codecId = format <= FORMAT_PER_FIELD_CODEC? input.readInt():0;
      byte bits = input.readByte();
      boolean isIndexed = (bits & IS_INDEXED) != 0;
      boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;
      boolean storePositionsWithTermVector = (bits & STORE_POSITIONS_WITH_TERMVECTOR) != 0;
      boolean storeOffsetWithTermVector = (bits & STORE_OFFSET_WITH_TERMVECTOR) != 0;
      boolean omitNorms = (bits & OMIT_NORMS) != 0;
      boolean storePayloads = (bits & STORE_PAYLOADS) != 0;
      boolean omitTermFreqAndPositions = (bits & OMIT_TERM_FREQ_AND_POSITIONS) != 0;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651679918/fstmerge_var1_249584897372099265

      // LUCENE-3027: past indices were able to write
      // storePayloads=true when omitTFAP is also true,
      // which is invalid.  We correct that, here:
      if (omitTermFreqAndPositions) {
        storePayloads = false;
      }

      final FieldInfo addInternal = addInternal(name, fieldNumber, isIndexed, storeTermVector, storePositionsWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651679918/fstmerge_base_3421514037764776875
      final FieldInfo addInternal = addInternal(name, fieldNumber, isIndexed, storeTermVector, storePositionsWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
=======
      Type docValuesType = null;
      if (format <= FORMAT_INDEX_VALUES) {
        final byte b = input.readByte();
        switch(b) {
        case 0:
          docValuesType = null;
          break;
        case 1:
          docValuesType = Type.INTS;
          break;
        case 2:
          docValuesType = Type.FLOAT_32;
          break;
        case 3:
          docValuesType = Type.FLOAT_64;
          break;
        case 4:
          docValuesType = Type.BYTES_FIXED_STRAIGHT;
          break;
        case 5:
          docValuesType = Type.BYTES_FIXED_DEREF;
          break;
        case 6:
          docValuesType = Type.BYTES_FIXED_SORTED;
          break;
        case 7:
          docValuesType = Type.BYTES_VAR_STRAIGHT;
          break;
        case 8:
          docValuesType = Type.BYTES_VAR_DEREF;
          break;
        case 9:
          docValuesType = Type.BYTES_VAR_SORTED;
          break;
        default:
          throw new IllegalStateException("unhandled indexValues type " + b);
        }
      }
      final FieldInfo addInternal = addInternal(name, fieldNumber, isIndexed, storeTermVector, storePositionsWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions, docValuesType);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651679918/fstmerge_var2_3320364274526520759
      addInternal.setCodecId(codecId);
    }

    if (input.getFilePointer() != input.length()) {
      throw new CorruptIndexException("did not read all bytes from file \"" + fileName + "\": read " + input.getFilePointer() + " vs size " + input.length());
    }    
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0c32e_3e3bb/rev_0c32e-3e3bb/lucene/src/java/org/apache/lucene/index/FieldInfos.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651679928/fstmerge_var1_5451184206535363851
synchronized private FieldInfo addOrUpdateInternal(String name, int preferredFieldNumber, boolean isIndexed,
                                                     boolean storeTermVector, boolean storePositionWithTermVector, boolean storeOffsetWithTermVector,
                                                     boolean omitNorms, boolean storePayloads, boolean omitTermFreqAndPositions) {
    if (globalFieldNumbers == null) {
      throw new IllegalStateException("FieldInfos are read-only, create a new instance with a global field map to make modifications to FieldInfos");
    }
    assert segmentCodecsBuilder != null : "SegmentCodecsBuilder is set to null but FieldInfos is not read-only";
    FieldInfo fi = fieldInfo(name);
    if (fi == null) {
      final int fieldNumber = nextFieldNumber(name, preferredFieldNumber);
      fi = addInternal(name, fieldNumber, isIndexed, storeTermVector, storePositionWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
    } else {
      fi.update(isIndexed, storeTermVector, storePositionWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
    }
    if (fi.isIndexed && fi.getCodecId() == FieldInfo.UNASSIGNED_CODEC_ID) {
      segmentCodecsBuilder.tryAddAndSet(fi);
    }
    return fi;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651679928/fstmerge_base_7751820094791694332
synchronized private FieldInfo addOrUpdateInternal(String name, int preferredFieldNumber, boolean isIndexed,
      boolean storeTermVector, boolean storePositionWithTermVector, boolean storeOffsetWithTermVector,
      boolean omitNorms, boolean storePayloads, boolean omitTermFreqAndPositions) {
    if (globalFieldNumbers == null) {
      throw new IllegalStateException("FieldInfos are read-only, create a new instance with a global field map to make modifications to FieldInfos");
    }
    assert segmentCodecsBuilder != null : "SegmentCodecsBuilder is set to null but FieldInfos is not read-only";
    FieldInfo fi = fieldInfo(name);
    if (fi == null) {
      final int fieldNumber = nextFieldNumber(name, preferredFieldNumber);
      fi = addInternal(name, fieldNumber, isIndexed, storeTermVector, storePositionWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
    } else {
      fi.update(isIndexed, storeTermVector, storePositionWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
    }
    if (fi.isIndexed && fi.getCodecId() == FieldInfo.UNASSIGNED_CODEC_ID) {
      segmentCodecsBuilder.tryAddAndSet(fi);
    }
    return fi;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651679928/fstmerge_var2_6212991686412001435

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0c32e_3e3bb/rev_0c32e-3e3bb/lucene/src/java/org/apache/lucene/index/FieldInfos.java
Conflict type: LineBasedMCFd
Conflict body: 
public void deleteDocuments(Term... terms) throws CorruptIndexException, IOException {
    ensureOpen();
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651680865/fstmerge_var1_4292533962333724674
      docWriter.deleteTerms(term);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651680865/fstmerge_base_2109807025096007393
      if (docWriter.deleteTerm(term, false)) {
        flush(true, false);
      }
=======
      if (docWriter.deleteTerms(terms)) {
        flush(true, false);
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651680865/fstmerge_var2_7696639843701211464
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Term..)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0c32e_3e3bb/rev_0c32e-3e3bb/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void deleteDocuments(Query... queries) throws CorruptIndexException, IOException {
    ensureOpen();
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651680875/fstmerge_var1_4493221768706736487
      docWriter.deleteQueries(query);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651680875/fstmerge_base_4807937362245414914
      if (docWriter.deleteQuery(query)) {
        flush(true, false);
      }
=======
      if (docWriter.deleteQueries(queries)) {
        flush(true, false);
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651680875/fstmerge_var2_4402394193862054840
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Query..)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0c32e_3e3bb/rev_0c32e-3e3bb/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651682518/fstmerge_var1_6569654370588899729
public VariableGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, int indexDivisor, String codecId)
    throws IOException {

    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, VariableGapTermsIndexWriter.TERMS_INDEX_EXTENSION));
    this.segment = segment;
    boolean success = false;

    try {
      
      readHeader(in);
      this.indexDivisor = indexDivisor;

      seekDir(in, dirOffset);

      // Read directory
      final int numFields = in.readVInt();

      for(int i=0;i<numFields;i++) {
        final int field = in.readVInt();
        final long indexStart = in.readVLong();
        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
        fields.put(fieldInfo, new FieldIndexData(fieldInfo, indexStart));
      }
      success = true;
    } finally {
      if (indexDivisor > 0) {
        in.close();
        in = null;
        if (success) {
          indexLoaded = true;
        }
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651682518/fstmerge_base_5869688023881328067
public VariableGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, int indexDivisor, String codecId)
    throws IOException {

    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, VariableGapTermsIndexWriter.TERMS_INDEX_EXTENSION));
    
    boolean success = false;

    try {
      
      readHeader(in);
      this.indexDivisor = indexDivisor;

      seekDir(in, dirOffset);

      // Read directory
      final int numFields = in.readVInt();

      for(int i=0;i<numFields;i++) {
        final int field = in.readVInt();
        final long indexStart = in.readVLong();
        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
        fields.put(fieldInfo, new FieldIndexData(fieldInfo, indexStart));
      }
      success = true;
    } finally {
      if (indexDivisor > 0) {
        in.close();
        in = null;
        if (success) {
          indexLoaded = true;
        }
      }
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651682518/fstmerge_var2_7975779915431970977

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0c32e_3e3bb/rev_0c32e-3e3bb/lucene/src/java/org/apache/lucene/index/codecs/VariableGapTermsIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
public SepPostingsWriterImpl(SegmentWriteState state, IntStreamFactory factory) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651683030/fstmerge_var1_3403851828697579264
    this(state, factory, DEFAULT_SKIP_INTERVAL);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651683030/fstmerge_base_7945581089876967055
    super();

    final String docFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, DOC_EXTENSION);
    docOut = factory.createOutput(state.directory, docFileName);
    docIndex = docOut.index();

    if (state.fieldInfos.hasProx()) {
      final String frqFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, FREQ_EXTENSION);
      freqOut = factory.createOutput(state.directory, frqFileName);
      freqIndex = freqOut.index();

      final String posFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, POS_EXTENSION);
      posOut = factory.createOutput(state.directory, posFileName);
      posIndex = posOut.index();

      // TODO: -- only if at least one field stores payloads?
      final String payloadFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, PAYLOAD_EXTENSION);
      payloadOut = state.directory.createOutput(payloadFileName);

    } else {
      freqOut = null;
      freqIndex = null;
      posOut = null;
      posIndex = null;
      payloadOut = null;
    }

    final String skipFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, SKIP_EXTENSION);
    skipOut = state.directory.createOutput(skipFileName);

    totalNumDocs = state.numDocs;

    skipListWriter = new SepSkipListWriter(skipInterval,
                                           maxSkipLevels,
                                           state.numDocs,
                                           freqOut, docOut,
                                           posOut, payloadOut);
=======
    super();
    final String codecIdAsString = state.codecIdAsString();
    final String docFileName = IndexFileNames.segmentFileName(state.segmentName, codecIdAsString, DOC_EXTENSION);
    docOut = factory.createOutput(state.directory, docFileName);
    docIndex = docOut.index();

    if (state.fieldInfos.hasProx()) {
      final String frqFileName = IndexFileNames.segmentFileName(state.segmentName, codecIdAsString, FREQ_EXTENSION);
      freqOut = factory.createOutput(state.directory, frqFileName);
      freqIndex = freqOut.index();

      final String posFileName = IndexFileNames.segmentFileName(state.segmentName, codecIdAsString, POS_EXTENSION);
      posOut = factory.createOutput(state.directory, posFileName);
      posIndex = posOut.index();

      // TODO: -- only if at least one field stores payloads?
      final String payloadFileName = IndexFileNames.segmentFileName(state.segmentName, codecIdAsString, PAYLOAD_EXTENSION);
      payloadOut = state.directory.createOutput(payloadFileName);

    } else {
      freqOut = null;
      freqIndex = null;
      posOut = null;
      posIndex = null;
      payloadOut = null;
    }

    final String skipFileName = IndexFileNames.segmentFileName(state.segmentName, codecIdAsString, SKIP_EXTENSION);
    skipOut = state.directory.createOutput(skipFileName);

    totalNumDocs = state.numDocs;

    skipListWriter = new SepSkipListWriter(skipInterval,
                                           maxSkipLevels,
                                           state.numDocs,
                                           freqOut, docOut,
                                           posOut, payloadOut);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651683030/fstmerge_var2_5656060453289559605
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0c32e_3e3bb/rev_0c32e-3e3bb/lucene/src/java/org/apache/lucene/index/codecs/sep/SepPostingsWriterImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
public StandardPostingsWriter(SegmentWriteState state) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651683494/fstmerge_var1_2956351062391676336
    this(state, DEFAULT_SKIP_INTERVAL);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651683494/fstmerge_base_3027992563213926311
    super();
    //this.segment = state.segmentName;
    String fileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, StandardCodec.FREQ_EXTENSION);
    freqOut = state.directory.createOutput(fileName);

    if (state.fieldInfos.hasProx()) {
      // At least one field does not omit TF, so create the
      // prox file
      fileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, StandardCodec.PROX_EXTENSION);
      proxOut = state.directory.createOutput(fileName);
    } else {
      // Every field omits TF so we will write no prox file
      proxOut = null;
    }

    totalNumDocs = state.numDocs;

    skipListWriter = new DefaultSkipListWriter(skipInterval,
                                               maxSkipLevels,
                                               state.numDocs,
                                               freqOut,
                                               proxOut);
=======
    super();
    //this.segment = state.segmentName;
    String fileName = IndexFileNames.segmentFileName(state.segmentName, state.codecIdAsString(), StandardCodec.FREQ_EXTENSION);
    freqOut = state.directory.createOutput(fileName);

    if (state.fieldInfos.hasProx()) {
      // At least one field does not omit TF, so create the
      // prox file
      fileName = IndexFileNames.segmentFileName(state.segmentName, state.codecIdAsString(), StandardCodec.PROX_EXTENSION);
      proxOut = state.directory.createOutput(fileName);
    } else {
      // Every field omits TF so we will write no prox file
      proxOut = null;
    }

    totalNumDocs = state.numDocs;

    skipListWriter = new DefaultSkipListWriter(skipInterval,
                                               maxSkipLevels,
                                               state.numDocs,
                                               freqOut,
                                               proxOut);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419651683494/fstmerge_var2_4081895345769960943
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_0c32e_3e3bb/rev_0c32e-3e3bb/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardPostingsWriter.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_641a5_cb8a4/rev_641a5-cb8a4.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f7f69_95cf8/rev_f7f69-95cf8.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653574833/fstmerge_var1_2804894524775174638
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653574833/fstmerge_base_2951210798625174739
SegmentMerger(Directory dir, int termIndexInterval, String name, MergePolicy.OneMerge merge, CodecProvider codecs, PayloadProcessorProvider payloadProcessorProvider, FieldInfos fieldInfos) {
    this.payloadProcessorProvider = payloadProcessorProvider;
    directory = dir;
    this.codecs = codecs;
    segment = name;
    this.fieldInfos = fieldInfos;
    if (merge != null) {
      checkAbort = new MergeState.CheckAbort(merge, directory);
    } else {
      checkAbort = new MergeState.CheckAbort(null, null) {
        @Override
        public void work(double units) throws MergeAbortedException {
          // do nothing
        }
      };
    }
    this.termIndexInterval = termIndexInterval;
  }
=======
SegmentMerger(Directory dir, int termIndexInterval, String name, MergePolicy.OneMerge merge, CodecProvider codecs, PayloadProcessorProvider payloadProcessorProvider, FieldInfos fieldInfos) {
    this.payloadProcessorProvider = payloadProcessorProvider;
    directory = dir;
    segment = name;
    this.fieldInfos = fieldInfos;
    if (merge != null) {
      checkAbort = new MergeState.CheckAbort(merge, directory);
    } else {
      checkAbort = new MergeState.CheckAbort(null, null) {
        @Override
        public void work(double units) throws MergeAbortedException {
          // do nothing
        }
      };
    }
    this.termIndexInterval = termIndexInterval;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653574833/fstmerge_var2_687531161715086639

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f7f69_95cf8/rev_f7f69-95cf8/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
Conflict type: LineBasedMCFd
Conflict body: 
private void read(IndexInput input, String fileName) throws IOException {
    format = input.readVInt();

    if (format > FORMAT_MINIMUM) {
      throw new IndexFormatTooOldException(fileName, format, FORMAT_MINIMUM, FORMAT_CURRENT);
    }
    if (format < FORMAT_CURRENT) {
      throw new IndexFormatTooNewException(fileName, format, FORMAT_MINIMUM, FORMAT_CURRENT);
    }

    final int size = input.readVInt(); //read in the size

    for (int i = 0; i < size; i++) {
      String name = StringHelper.intern(input.readString());
      // if this is a previous format codec 0 will be preflex!
      final int fieldNumber = format <= FORMAT_PER_FIELD_CODEC? input.readInt():i;
      final int codecId = format <= FORMAT_PER_FIELD_CODEC? input.readInt():0;
      byte bits = input.readByte();
      boolean isIndexed = (bits & IS_INDEXED) != 0;
      boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;
      boolean storePositionsWithTermVector = (bits & STORE_POSITIONS_WITH_TERMVECTOR) != 0;
      boolean storeOffsetWithTermVector = (bits & STORE_OFFSET_WITH_TERMVECTOR) != 0;
      boolean omitNorms = (bits & OMIT_NORMS) != 0;
      boolean storePayloads = (bits & STORE_PAYLOADS) != 0;
      boolean omitTermFreqAndPositions = (bits & OMIT_TERM_FREQ_AND_POSITIONS) != 0;

      // LUCENE-3027: past indices were able to write
      // storePayloads=true when omitTFAP is also true,
      // which is invalid.  We correct that, here:
      if (omitTermFreqAndPositions) {
        storePayloads = false;
      }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653577085/fstmerge_var1_1231306896221603333
      hasVectors |= storeTermVector;
      hasProx |= isIndexed && !omitTermFreqAndPositions;
      final FieldInfo addInternal = addInternal(name, fieldNumber, isIndexed, storeTermVector, storePositionsWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653577085/fstmerge_base_7275571630717895546

      final FieldInfo addInternal = addInternal(name, fieldNumber, isIndexed, storeTermVector, storePositionsWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
=======

      Type docValuesType = null;
      if (format <= FORMAT_INDEX_VALUES) {
        final byte b = input.readByte();
        switch(b) {
        case 0:
          docValuesType = null;
          break;
        case 1:
          docValuesType = Type.INTS;
          break;
        case 2:
          docValuesType = Type.FLOAT_32;
          break;
        case 3:
          docValuesType = Type.FLOAT_64;
          break;
        case 4:
          docValuesType = Type.BYTES_FIXED_STRAIGHT;
          break;
        case 5:
          docValuesType = Type.BYTES_FIXED_DEREF;
          break;
        case 6:
          docValuesType = Type.BYTES_FIXED_SORTED;
          break;
        case 7:
          docValuesType = Type.BYTES_VAR_STRAIGHT;
          break;
        case 8:
          docValuesType = Type.BYTES_VAR_DEREF;
          break;
        case 9:
          docValuesType = Type.BYTES_VAR_SORTED;
          break;
        default:
          throw new IllegalStateException("unhandled indexValues type " + b);
        }
      }
      final FieldInfo addInternal = addInternal(name, fieldNumber, isIndexed, storeTermVector, storePositionsWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions, docValuesType);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653577085/fstmerge_var2_4500620894197342439
      addInternal.setCodecId(codecId);
    }

    if (input.getFilePointer() != input.length()) {
      throw new CorruptIndexException("did not read all bytes from file \"" + fileName + "\": read " + input.getFilePointer() + " vs size " + input.length());
    }    
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f7f69_95cf8/rev_f7f69-95cf8/lucene/src/java/org/apache/lucene/index/FieldInfos.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653577094/fstmerge_var1_3208018057376590484
synchronized private FieldInfo addOrUpdateInternal(String name, int preferredFieldNumber, boolean isIndexed,
                                                     boolean storeTermVector, boolean storePositionWithTermVector, boolean storeOffsetWithTermVector,
                                                     boolean omitNorms, boolean storePayloads, boolean omitTermFreqAndPositions) {
    if (globalFieldNumbers == null) {
      throw new IllegalStateException("FieldInfos are read-only, create a new instance with a global field map to make modifications to FieldInfos");
    }
    assert segmentCodecsBuilder != null : "SegmentCodecsBuilder is set to null but FieldInfos is not read-only";
    FieldInfo fi = fieldInfo(name);
    if (fi == null) {
      final int fieldNumber = nextFieldNumber(name, preferredFieldNumber);
      fi = addInternal(name, fieldNumber, isIndexed, storeTermVector, storePositionWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
    } else {
      fi.update(isIndexed, storeTermVector, storePositionWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
    }
    if (fi.isIndexed && fi.getCodecId() == FieldInfo.UNASSIGNED_CODEC_ID) {
      segmentCodecsBuilder.tryAddAndSet(fi);
    }
    version++;
    return fi;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653577094/fstmerge_base_5438546438164074002
synchronized private FieldInfo addOrUpdateInternal(String name, int preferredFieldNumber, boolean isIndexed,
                                                     boolean storeTermVector, boolean storePositionWithTermVector, boolean storeOffsetWithTermVector,
                                                     boolean omitNorms, boolean storePayloads, boolean omitTermFreqAndPositions) {
    if (globalFieldNumbers == null) {
      throw new IllegalStateException("FieldInfos are read-only, create a new instance with a global field map to make modifications to FieldInfos");
    }
    assert segmentCodecsBuilder != null : "SegmentCodecsBuilder is set to null but FieldInfos is not read-only";
    FieldInfo fi = fieldInfo(name);
    if (fi == null) {
      final int fieldNumber = nextFieldNumber(name, preferredFieldNumber);
      fi = addInternal(name, fieldNumber, isIndexed, storeTermVector, storePositionWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
    } else {
      fi.update(isIndexed, storeTermVector, storePositionWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads, omitTermFreqAndPositions);
    }
    if (fi.isIndexed && fi.getCodecId() == FieldInfo.UNASSIGNED_CODEC_ID) {
      segmentCodecsBuilder.tryAddAndSet(fi);
    }
    return fi;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653577094/fstmerge_var2_4458166523501454129

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f7f69_95cf8/rev_f7f69-95cf8/lucene/src/java/org/apache/lucene/index/FieldInfos.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653584139/fstmerge_var1_452305333640715676
@Override
  public void files(Directory dir, SegmentInfo segmentInfo, String codecId, Set<String> files) throws IOException {
    SepPostingsReaderImpl.files(segmentInfo, codecId, files);
    BlockTermsReader.files(dir, segmentInfo, codecId, files);
    FixedGapTermsIndexReader.files(dir, segmentInfo, codecId, files);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653584139/fstmerge_base_6826109624963955435
@Override
  public void files(Directory dir, SegmentInfo segmentInfo, String codecId, Set<String> files) {
    SepPostingsReaderImpl.files(segmentInfo, codecId, files);
    BlockTermsReader.files(dir, segmentInfo, codecId, files);
    FixedGapTermsIndexReader.files(dir, segmentInfo, codecId, files);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653584139/fstmerge_var2_9015287713419619837

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f7f69_95cf8/rev_f7f69-95cf8/lucene/src/test-framework/org/apache/lucene/index/codecs/mockintblock/MockFixedIntBlockCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653584178/fstmerge_var1_8171455216261797842
@Override
  public void files(Directory dir, SegmentInfo segmentInfo, String codecId, Set<String> files) throws IOException {
    SepPostingsReaderImpl.files(segmentInfo, codecId, files);
    BlockTermsReader.files(dir, segmentInfo, codecId, files);
    FixedGapTermsIndexReader.files(dir, segmentInfo, codecId, files);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653584178/fstmerge_base_9168906936190981492
@Override
  public void files(Directory dir, SegmentInfo segmentInfo, String codecId, Set<String> files) {
    SepPostingsReaderImpl.files(segmentInfo, codecId, files);
    BlockTermsReader.files(dir, segmentInfo, codecId, files);
    FixedGapTermsIndexReader.files(dir, segmentInfo, codecId, files);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653584178/fstmerge_var2_7397452653319610554

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f7f69_95cf8/rev_f7f69-95cf8/lucene/src/test-framework/org/apache/lucene/index/codecs/mockintblock/MockVariableIntBlockCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653584368/fstmerge_var1_5521633135335874641
@Override
  public void files(Directory dir, SegmentInfo segmentInfo, String codecId, Set<String> files) throws IOException {
    SepPostingsReaderImpl.files(segmentInfo, codecId, files);
    BlockTermsReader.files(dir, segmentInfo, codecId, files);
    FixedGapTermsIndexReader.files(dir, segmentInfo, codecId, files);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653584368/fstmerge_base_8064748619134198864
@Override
  public void files(Directory dir, SegmentInfo segmentInfo, String codecId, Set<String> files) {
    SepPostingsReaderImpl.files(segmentInfo, codecId, files);
    BlockTermsReader.files(dir, segmentInfo, codecId, files);
    FixedGapTermsIndexReader.files(dir, segmentInfo, codecId, files);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419653584368/fstmerge_var2_397101228017195159

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f7f69_95cf8/rev_f7f69-95cf8/lucene/src/test-framework/org/apache/lucene/index/codecs/mocksep/MockSepCodec.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a3eaa_43766/rev_a3eaa-43766.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465.revisions
Conflict type: LineBasedMCFd
Conflict body: 
public void deleteDocuments(Term... terms) throws CorruptIndexException, IOException {
    ensureOpen();
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655483971/fstmerge_var1_131223720977719161
      docWriter.deleteTerms(term);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655483971/fstmerge_base_6170936772069860049
      if (docWriter.deleteTerm(term, false)) {
        flush(true, false);
      }
=======
      if (docWriter.deleteTerms(terms)) {
        flush(true, false);
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655483971/fstmerge_var2_8248341444818850010
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Term..)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void deleteDocuments(Query... queries) throws CorruptIndexException, IOException {
    ensureOpen();
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655483981/fstmerge_var1_7963339754483085041
      docWriter.deleteQueries(query);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655483981/fstmerge_base_8989345656839942604
      if (docWriter.deleteQuery(query)) {
        flush(true, false);
      }
=======
      if (docWriter.deleteQueries(queries)) {
        flush(true, false);
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655483981/fstmerge_var2_3500478037945207771
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Query..)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testTSTPersistence() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655510062/fstmerge_var1_4187292089941999156
    runTest(TSTLookup.class, true);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655510062/fstmerge_base_7748536223389265999
    TSTLookup lookup = new TSTLookup();
    for (String k : keys) {
      lookup.add(k, new Float(k.length()));
    }
    File storeDir = new File(TEST_HOME);
    lookup.store(storeDir);
    lookup = new TSTLookup();
    lookup.load(storeDir);
    for (String k : keys) {
      Float val = (Float)lookup.get(k);
      assertNotNull(k, val);
      assertEquals(k, k.length(), val.intValue());
    }
=======
    TSTLookup lookup = new TSTLookup();
    for (String k : keys) {
      lookup.add(k, new Float(k.length()));
    }
    File storeDir = new File(TEST_HOME());
    lookup.store(storeDir);
    lookup = new TSTLookup();
    lookup.load(storeDir);
    for (String k : keys) {
      Float val = (Float)lookup.get(k);
      assertNotNull(k, val);
      assertEquals(k, k.length(), val.intValue());
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655510062/fstmerge_var2_1663721268464131884
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/solr/src/test/org/apache/solr/spelling/suggest/PersistenceTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testJaspellPersistence() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655510065/fstmerge_var1_255725274091711306
    runTest(JaspellLookup.class, true);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655510065/fstmerge_base_455194976907289946
    JaspellLookup lookup = new JaspellLookup();
    for (String k : keys) {
      lookup.add(k, new Float(k.length()));
    }
    File storeDir = new File(TEST_HOME);
    lookup.store(storeDir);
    lookup = new JaspellLookup();
    lookup.load(storeDir);
    for (String k : keys) {
      Float val = (Float)lookup.get(k);
      assertNotNull(k, val);
      assertEquals(k, k.length(), val.intValue());
    }
=======
    JaspellLookup lookup = new JaspellLookup();
    for (String k : keys) {
      lookup.add(k, new Float(k.length()));
    }
    File storeDir = new File(TEST_HOME());
    lookup.store(storeDir);
    lookup = new JaspellLookup();
    lookup.load(storeDir);
    for (String k : keys) {
      Float val = (Float)lookup.get(k);
      assertNotNull(k, val);
      assertEquals(k, k.length(), val.intValue());
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655510065/fstmerge_var2_1511680961719405166
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/solr/src/test/org/apache/solr/spelling/suggest/PersistenceTest.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535606/fstmerge_var1_3436642136909033648
public static String match(String input, String pathAndExpected) throws Exception {
    return match(input, pathAndExpected, DEFAULT_DELTA);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535606/fstmerge_base_3833079590954426688
=======
public static String match(String input, String pathAndExpected) throws Exception {
    int pos = pathAndExpected.indexOf("==");
    String path = pos>=0 ? pathAndExpected.substring(0,pos) : null;
    String expected = pos>=0 ? pathAndExpected.substring(pos+2) : pathAndExpected;
    return match(path, input, expected);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535606/fstmerge_var2_8187065586484081228

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/solr/src/test-framework/org/apache/solr/JSONTestUtil.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535611/fstmerge_var1_7199630704373806982
public static String match(String path, String input, String expected) throws Exception {
    return match(path, input, expected, DEFAULT_DELTA);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535611/fstmerge_base_178867998502430600
=======
public static String match(String path, String input, String expected) throws Exception {
    Object inputObj = ObjectBuilder.fromJSON(input);
    Object expectObj = ObjectBuilder.fromJSON(expected);
    return matchObj(path, inputObj, expectObj);
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535611/fstmerge_var2_8636386439447220082

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/solr/src/test-framework/org/apache/solr/JSONTestUtil.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535617/fstmerge_var1_4967317302547086919
public static String matchObj(String path, Object input, Object expected) throws Exception {
    return matchObj(path,input,expected, DEFAULT_DELTA);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535617/fstmerge_base_3327725031928982617
=======
public static String matchObj(String path, Object input, Object expected) throws Exception {
    CollectionTester tester = new CollectionTester(input);
    boolean reversed = path.startsWith("!");
    String positivePath = reversed ? path.substring(1) : path;
    if (!tester.seek(positivePath) ^ reversed) {
      return "Path not found: " + path;
    }
    if (expected != null && (!tester.match(expected) ^ reversed)) {
      return tester.err + " @ " + tester.getPath();
    }
    return null;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535617/fstmerge_var2_7551036147168579931

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/solr/src/test-framework/org/apache/solr/JSONTestUtil.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535622/fstmerge_var1_4155745110369623168
public CollectionTester(Object val) {
    this(val, JSONTestUtil.DEFAULT_DELTA);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535622/fstmerge_base_3063570196779314710
=======
public CollectionTester(Object val) {
    this.val = val;
    this.valRoot = val;
    path = new ArrayList<Object>();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535622/fstmerge_var2_3186909044277365178

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/solr/src/test-framework/org/apache/solr/JSONTestUtil.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535656/fstmerge_var1_649074412922812207
boolean match() {
    if (expected == val) {
      return true;
    }
    if (expected == null || val == null) {
      setErr("mismatch: '" + expected + "'!='" + val + "'");
      return false;
    }
    if (expected instanceof List) {
      return matchList();
    }
    if (expected instanceof Map) {
      return matchMap();
    }

    // generic fallback
    if (!expected.equals(val)) {

      // make an exception for some numerics
      if ((expected instanceof Integer && val instanceof Long || expected instanceof Long && val instanceof Integer)
          && ((Number)expected).longValue() == ((Number)val).longValue())
      {
        return true;
      } else if ((expected instanceof Float && val instanceof Double || expected instanceof Double && val instanceof Float)) {
        double a = ((Number)expected).doubleValue();
        double b = ((Number)val).doubleValue();
        if (Double.compare(a,b) == 0) return true;
        if (Math.abs(a-b) < delta) return true;
        return false;
      } else {
        setErr("mismatch: '" + expected + "'!='" + val + "'");
        return false;
      }
    }

    // setErr("unknown expected type " + expected.getClass().getName());
    return true;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535656/fstmerge_base_1756863412456451410
=======
boolean match() {
    if (expected == val) {
      return true;
    }
    if (expected == null || val == null) {
      setErr("mismatch: '" + expected + "'!='" + val + "'");
      return false;
    }
    if (expected instanceof List) {
      return matchList();
    }
    if (expected instanceof Map) {
      return matchMap();
    }

    // generic fallback
    if (!expected.equals(val)) {

      // make an exception for some numerics
      if ((expected instanceof Integer && val instanceof Long || expected instanceof Long && val instanceof Integer)
          && ((Number)expected).longValue() == ((Number)val).longValue())
      {
        return true;
      } else if ((expected instanceof Float && val instanceof Double || expected instanceof Double && val instanceof Float)) {
        double a = ((Number)expected).doubleValue();
        double b = ((Number)val).doubleValue();
        if (Double.compare(a,b) == 0) return true;
        if (Math.abs(a-b) < 1e-5) return true;
        return false;
      } else {
        setErr("mismatch: '" + expected + "'!='" + val + "'");
        return false;
      }
    }

    // setErr("unknown expected type " + expected.getClass().getName());
    return true;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535656/fstmerge_var2_7086385277423886413

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/solr/src/test-framework/org/apache/solr/JSONTestUtil.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535816/fstmerge_var1_2234288190672781839
public static void assertJQ(SolrQueryRequest req, String... tests) throws Exception {
    assertJQ(req, JSONTestUtil.DEFAULT_DELTA, tests);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535816/fstmerge_base_6876388236890956029
=======
public static void assertJQ(SolrQueryRequest req, String... tests) throws Exception {
    SolrParams params =  null;
    try {
      params = req.getParams();
      if (!"json".equals(params.get("wt","xml")) || params.get("indent")==null) {
        ModifiableSolrParams newParams = new ModifiableSolrParams(params);
        newParams.set("wt","json");
        if (params.get("indent")==null) newParams.set("indent","true");
        req.setParams(newParams);
      }

      String response;
      boolean failed=true;
      try {
        response = h.query(req);
        failed = false;
      } finally {
        if (failed) {
          log.error("REQUEST FAILED: " + req.getParamString());
        }
      }

      for (String test : tests) {
        String testJSON = test.replace('\'', '"');

        try {
          failed = true;
          String err = JSONTestUtil.match(response, testJSON);
          failed = false;
          if (err != null) {
            log.error("query failed JSON validation. error=" + err +
                "\n expected =" + testJSON +
                "\n response = " + response +
                "\n request = " + req.getParamString()
            );
            throw new RuntimeException(err);
          }
        } finally {
          if (failed) {
            log.error("JSON query validation threw an exception." + 
                "\n expected =" + testJSON +
                "\n response = " + response +
                "\n request = " + req.getParamString()
            );
          }
        }
      }
    } finally {
      // restore the params
      if (params != null && params != req.getParams()) req.setParams(params);
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655535816/fstmerge_var2_1280067547988799580

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/solr/src/test-framework/org/apache/solr/SolrTestCaseJ4.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536195/fstmerge_var1_3019977860498016077
protected void query(Object... q) throws Exception {
    final ModifiableSolrParams params = new ModifiableSolrParams();
    params.add("reqid",Integer.toString(random.nextInt())); // just to help correlate top-level requests w/ sub requests

    for (int i = 0; i < q.length; i += 2) {
      params.add(q[i].toString(), q[i + 1].toString());
    }

    params.add("controlClient","true"); // just to enable easier sorting through log files
    final QueryResponse controlRsp = controlClient.query(params);
    params.remove("controlClient");

    setDistributedParams(params);

    QueryResponse rsp = queryServer(params);

    compareResponses(rsp, controlRsp);

    if (stress > 0) {
      log.info("starting stress...");
      Thread[] threads = new Thread[nThreads];
      for (int i = 0; i < threads.length; i++) {
        threads[i] = new Thread() {
          @Override
          public void run() {
            for (int j = 0; j < stress; j++) {
              int which = r.nextInt(clients.size());
              SolrServer client = clients.get(which);
              try {
                QueryResponse rsp = client.query(new ModifiableSolrParams(params));
                if (verifyStress) {
                  compareResponses(rsp, controlRsp);
                }
              } catch (SolrServerException e) {
                throw new RuntimeException(e);
              }
            }
          }
        };
        threads[i].start();
      }

      for (Thread thread : threads) {
        thread.join();
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536195/fstmerge_base_1137882844186196292
=======
protected void query(Object... q) throws Exception {
    final ModifiableSolrParams params = new ModifiableSolrParams();

    for (int i = 0; i < q.length; i += 2) {
      params.add(q[i].toString(), q[i + 1].toString());
    }

    final QueryResponse controlRsp = controlClient.query(params);

    setDistributedParams(params);

    QueryResponse rsp = queryServer(params);

    compareResponses(rsp, controlRsp);

    if (stress > 0) {
      log.info("starting stress...");
      Thread[] threads = new Thread[nThreads];
      for (int i = 0; i < threads.length; i++) {
        threads[i] = new Thread() {
          @Override
          public void run() {
            for (int j = 0; j < stress; j++) {
              int which = r.nextInt(clients.size());
              SolrServer client = clients.get(which);
              try {
                QueryResponse rsp = client.query(new ModifiableSolrParams(params));
                if (verifyStress) {
                  compareResponses(rsp, controlRsp);
                }
              } catch (SolrServerException e) {
                throw new RuntimeException(e);
              }
            }
          }
        };
        threads[i].start();
      }

      for (Thread thread : threads) {
        thread.join();
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536195/fstmerge_var2_3759117125816855488

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/solr/src/test-framework/org/apache/solr/BaseDistributedSearchTestCase.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536209/fstmerge_var1_6817105771653562175
public static String compare(NamedList a, NamedList b, int flags, Map<String, Integer> handle) {
    boolean ordered = (flags & UNORDERED) == 0;

    int posa = 0, posb = 0;
    int aSkipped = 0, bSkipped = 0;

    for (; ;) {
      if (posa >= a.size() || posb >= b.size()) {
        break;
      }

      String namea, nameb;
      Object vala, valb = null;

      int flagsa, flagsb;
      for (; ;) {
        namea = a.getName(posa);
        vala = a.getVal(posa);
        posa++;
        flagsa = flags(handle, namea);
        if ((flagsa & SKIP) != 0) {
          aSkipped++;
          continue;
        }
        break;
      }

      if (!ordered) posb = 0;  // reset if not ordered

      while (posb < b.size()) {
        nameb = b.getName(posb);
        valb = b.getVal(posb);
        posb++;
        flagsb = flags(handle, nameb);
        if ((flagsb & SKIP) != 0) {
          bSkipped++;
          continue;
        }
        if (eq(namea, nameb)) {
          break;
        }
        if (ordered) {
          return err("." + namea + "!=" + nameb + " (unordered or missing)");
        }
        // if unordered, continue until we find the right field.
      }

      // ok, namea and nameb should be equal here already.
      if ((flagsa & SKIPVAL) != 0) continue;  // keys matching is enough

      String cmp = compare(vala, valb, flagsa, handle);
      if (cmp != null) return "." + namea + cmp;
    }


    if (a.size() - aSkipped != b.size() - bSkipped) {
      return err(".size()==" + a.size() + "," + b.size() + "skipped=" + aSkipped + "," + bSkipped);
    }

    return null;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536209/fstmerge_base_6927411148533713677
=======
public static String compare(NamedList a, NamedList b, int flags, Map<String, Integer> handle) {
    boolean ordered = (flags & UNORDERED) == 0;

    int posa = 0, posb = 0;
    int aSkipped = 0, bSkipped = 0;

    for (; ;) {
      if (posa >= a.size() || posb >= b.size()) {
        break;
      }

      String namea, nameb;
      Object vala, valb = null;

      int flagsa, flagsb;
      for (; ;) {
        namea = a.getName(posa);
        vala = a.getVal(posa);
        posa++;
        flagsa = flags(handle, namea);
        if ((flagsa & SKIP) != 0) {
          aSkipped++;
          continue;
        }
        break;
      }

      if (!ordered) posb = 0;  // reset if not ordered

      while (posb < b.size()) {
        nameb = b.getName(posb);
        valb = b.getVal(posb);
        posb++;
        flagsb = flags(handle, nameb);
        if ((flagsb & SKIP) != 0) {
          bSkipped++;
          continue;
        }
        if (eq(namea, nameb)) {
          break;
        }
        if (ordered) {
          return "." + namea + "!=" + nameb + " (unordered or missing)";
        }
        // if unordered, continue until we find the right field.
      }

      // ok, namea and nameb should be equal here already.
      if ((flagsa & SKIPVAL) != 0) continue;  // keys matching is enough

      String cmp = compare(vala, valb, flagsa, handle);
      if (cmp != null) return "." + namea + cmp;
    }


    if (a.size() - aSkipped != b.size() - bSkipped) {
      return ".size()==" + a.size() + "," + b.size() + "skipped=" + aSkipped + "," + bSkipped;
    }

    return null;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536209/fstmerge_var2_3581611237809962791

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/solr/src/test-framework/org/apache/solr/BaseDistributedSearchTestCase.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536215/fstmerge_var1_8144415083206146715
public static String compare1(Map a, Map b, int flags, Map<String, Integer> handle) {
    String cmp;

    for (Object keya : a.keySet()) {
      Object vala = a.get(keya);
      int flagsa = flags(handle, keya);
      if ((flagsa & SKIP) != 0) continue;
      if (!b.containsKey(keya)) {
        return err("[" + keya + "]==null");
      }
      if ((flagsa & SKIPVAL) != 0) continue;
      Object valb = b.get(keya);
      cmp = compare(vala, valb, flagsa, handle);
      if (cmp != null) return "[" + keya + "]" + cmp;
    }
    return null;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536215/fstmerge_base_6859650725637369542
=======
public static String compare1(Map a, Map b, int flags, Map<String, Integer> handle) {
    String cmp;

    for (Object keya : a.keySet()) {
      Object vala = a.get(keya);
      int flagsa = flags(handle, keya);
      if ((flagsa & SKIP) != 0) continue;
      if (!b.containsKey(keya)) {
        return "[" + keya + "]==null";
      }
      if ((flagsa & SKIPVAL) != 0) continue;
      Object valb = b.get(keya);
      cmp = compare(vala, valb, flagsa, handle);
      if (cmp != null) return "[" + keya + "]" + cmp;
    }
    return null;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536215/fstmerge_var2_2861319482532374196

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/solr/src/test-framework/org/apache/solr/BaseDistributedSearchTestCase.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536229/fstmerge_var1_6841357163928412536
public static String compare(SolrDocumentList a, SolrDocumentList b, int flags, Map<String, Integer> handle) {
    boolean ordered = (flags & UNORDERED) == 0;

    String cmp;
    int f = flags(handle, "maxScore");
    if ((f & SKIPVAL) == 0) {
      cmp = compare(a.getMaxScore(), b.getMaxScore(), 0, handle);
      if (cmp != null) return ".maxScore" + cmp;
    } else {
      if (b.getMaxScore() != null) {
        if (a.getMaxScore() == null) {
          return err(".maxScore missing");
        }
      }
    }

    cmp = compare(a.getNumFound(), b.getNumFound(), 0, handle);
    if (cmp != null) return ".numFound" + cmp;

    cmp = compare(a.getStart(), b.getStart(), 0, handle);
    if (cmp != null) return ".start" + cmp;

    cmp = compare(a.size(), b.size(), 0, handle);
    if (cmp != null) return ".size()" + cmp;

    // only for completely ordered results (ties might be in a different order)
    if (ordered) {
      for (int i = 0; i < a.size(); i++) {
        cmp = compare(a.get(i), b.get(i), 0, handle);
        if (cmp != null) return "[" + i + "]" + cmp;
      }
      return null;
    }

    // unordered case
    for (int i = 0; i < a.size(); i++) {
      SolrDocument doc = a.get(i);
      Object key = doc.getFirstValue("id");
      SolrDocument docb = null;
      if (key == null) {
        // no id field to correlate... must compare ordered
        docb = b.get(i);
      } else {
        for (int j = 0; j < b.size(); j++) {
          docb = b.get(j);
          if (key.equals(docb.getFirstValue("id"))) break;
        }
      }
      // if (docb == null) return "[id="+key+"]";
      cmp = compare(doc, docb, 0, handle);
      if (cmp != null) return "[id=" + key + "]" + cmp;
    }
    return null;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536229/fstmerge_base_3269893324655651012
=======
public static String compare(SolrDocumentList a, SolrDocumentList b, int flags, Map<String, Integer> handle) {
    boolean ordered = (flags & UNORDERED) == 0;

    String cmp;
    int f = flags(handle, "maxScore");
    if ((f & SKIPVAL) == 0) {
      cmp = compare(a.getMaxScore(), b.getMaxScore(), 0, handle);
      if (cmp != null) return ".maxScore" + cmp;
    } else {
      if (b.getMaxScore() != null) {
        if (a.getMaxScore() == null) {
          return ".maxScore missing";
        }
      }
    }

    cmp = compare(a.getNumFound(), b.getNumFound(), 0, handle);
    if (cmp != null) return ".numFound" + cmp;

    cmp = compare(a.getStart(), b.getStart(), 0, handle);
    if (cmp != null) return ".start" + cmp;

    cmp = compare(a.size(), b.size(), 0, handle);
    if (cmp != null) return ".size()" + cmp;

    // only for completely ordered results (ties might be in a different order)
    if (ordered) {
      for (int i = 0; i < a.size(); i++) {
        cmp = compare(a.get(i), b.get(i), 0, handle);
        if (cmp != null) return "[" + i + "]" + cmp;
      }
      return null;
    }

    // unordered case
    for (int i = 0; i < a.size(); i++) {
      SolrDocument doc = a.get(i);
      Object key = doc.getFirstValue("id");
      SolrDocument docb = null;
      if (key == null) {
        // no id field to correlate... must compare ordered
        docb = b.get(i);
      } else {
        for (int j = 0; j < b.size(); j++) {
          docb = b.get(j);
          if (key.equals(docb.getFirstValue("id"))) break;
        }
      }
      // if (docb == null) return "[id="+key+"]";
      cmp = compare(doc, docb, 0, handle);
      if (cmp != null) return "[id=" + key + "]" + cmp;
    }
    return null;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536229/fstmerge_var2_5292575063207168586

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/solr/src/test-framework/org/apache/solr/BaseDistributedSearchTestCase.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536235/fstmerge_var1_8380017426323027799
public static String compare(Object[] a, Object[] b, int flags, Map<String, Integer> handle) {
    if (a.length != b.length) {
      return err(".length:" + a.length + "!=" + b.length);
    }
    for (int i = 0; i < a.length; i++) {
      String cmp = compare(a[i], b[i], flags, handle);
      if (cmp != null) return "[" + i + "]" + cmp;
    }
    return null;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536235/fstmerge_base_2167673516009533638
=======
public static String compare(Object[] a, Object[] b, int flags, Map<String, Integer> handle) {
    if (a.length != b.length) {
      return ".length:" + a.length + "!=" + b.length;
    }
    for (int i = 0; i < a.length; i++) {
      String cmp = compare(a[i], b[i], flags, handle);
      if (cmp != null) return "[" + i + "]" + cmp;
    }
    return null;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536235/fstmerge_var2_1753666160407759496

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/solr/src/test-framework/org/apache/solr/BaseDistributedSearchTestCase.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536240/fstmerge_var1_2236962264405167466
public static String compare(Object a, Object b, int flags, Map<String, Integer> handle) {
    if (a == b) return null;
    if (a == null || b == null) return err(":" + a + "!=" + b);

    if (a instanceof NamedList && b instanceof NamedList) {
      return compare((NamedList) a, (NamedList) b, flags, handle);
    }

    if (a instanceof SolrDocumentList && b instanceof SolrDocumentList) {
      return compare((SolrDocumentList) a, (SolrDocumentList) b, flags, handle);
    }

    if (a instanceof SolrDocument && b instanceof SolrDocument) {
      return compare((SolrDocument) a, (SolrDocument) b, flags, handle);
    }

    if (a instanceof Map && b instanceof Map) {
      return compare((Map) a, (Map) b, flags, handle);
    }

    if (a instanceof Object[] && b instanceof Object[]) {
      return compare((Object[]) a, (Object[]) b, flags, handle);
    }

    if (a instanceof byte[] && b instanceof byte[]) {
      if (!Arrays.equals((byte[]) a, (byte[]) b)) {
        return err(":" + a + "!=" + b);
      }
      return null;
    }

    if (a instanceof List && b instanceof List) {
      return compare(((List) a).toArray(), ((List) b).toArray(), flags, handle);

    }

    if (!(a.equals(b))) {
      return err(":" + a + "!=" + b);
    }

    return null;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536240/fstmerge_base_8044917013809582296
=======
public static String compare(Object a, Object b, int flags, Map<String, Integer> handle) {
    if (a == b) return null;
    if (a == null || b == null) return ":" + a + "!=" + b;

    if (a instanceof NamedList && b instanceof NamedList) {
      return compare((NamedList) a, (NamedList) b, flags, handle);
    }

    if (a instanceof SolrDocumentList && b instanceof SolrDocumentList) {
      return compare((SolrDocumentList) a, (SolrDocumentList) b, flags, handle);
    }

    if (a instanceof SolrDocument && b instanceof SolrDocument) {
      return compare((SolrDocument) a, (SolrDocument) b, flags, handle);
    }

    if (a instanceof Map && b instanceof Map) {
      return compare((Map) a, (Map) b, flags, handle);
    }

    if (a instanceof Object[] && b instanceof Object[]) {
      return compare((Object[]) a, (Object[]) b, flags, handle);
    }

    if (a instanceof byte[] && b instanceof byte[]) {
      if (!Arrays.equals((byte[]) a, (byte[]) b)) {
        return ":" + a + "!=" + b;
      }
      return null;
    }

    if (a instanceof List && b instanceof List) {
      return compare(((List) a).toArray(), ((List) b).toArray(), flags, handle);

    }

    if (!(a.equals(b))) {
      return ":" + a + "!=" + b;
    }

    return null;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419655536240/fstmerge_var2_3670923927615634520

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_47cb9_20465/rev_47cb9-20465/solr/src/test-framework/org/apache/solr/BaseDistributedSearchTestCase.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_fb9ab_31f61/rev_fb9ab-31f61.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_fb9ab_127a0/rev_fb9ab-127a0.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419657402219/fstmerge_var1_4848491908895139908
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419657402219/fstmerge_base_7243264495362590406
CoreReaders(SegmentReader origInstance, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {

      if (termsIndexDivisor == 0) {
        throw new IllegalArgumentException("indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)");
      }

      segment = si.name;
      final SegmentCodecs segmentCodecs = si.getSegmentCodecs();
      this.readBufferSize = readBufferSize;
      this.dir = dir;

      boolean success = false;

      try {
        Directory dir0 = dir;
        if (si.getUseCompoundFile()) {
          cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);
          dir0 = cfsReader;
        }
        cfsDir = dir0;
        si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos
        fieldInfos = si.getFieldInfos();
        
        this.termsIndexDivisor = termsIndexDivisor;
        
        // Ask codec for its Fields
        fields = segmentCodecs.codec().fieldsProducer(new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor));
        assert fields != null;

        success = true;
      } finally {
        if (!success) {
          decRef();
        }
      }

      // Must assign this at the end -- if we hit an
      // exception above core, we don't want to attempt to
      // purge the FieldCache (will hit NPE because core is
      // not assigned yet).
      this.origInstance = origInstance;
    }
=======
CoreReaders(SegmentReader origInstance, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {

      if (termsIndexDivisor == 0) {
        throw new IllegalArgumentException("indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)");
      }

      segment = si.name;
      final SegmentCodecs segmentCodecs = si.getSegmentCodecs();
      this.readBufferSize = readBufferSize;
      this.dir = dir;

      boolean success = false;

      try {
        Directory dir0 = dir;
        if (si.getUseCompoundFile()) {
          cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);
          dir0 = cfsReader;
        }
        cfsDir = dir0;
        si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos
        fieldInfos = si.getFieldInfos();
        
        this.termsIndexDivisor = termsIndexDivisor;
        
        // Ask codec for its Fields
        final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);
        fields = segmentCodecs.codec().fieldsProducer(segmentReadState);
        assert fields != null;
        perDocProducer = segmentCodecs.codec().docsProducer(segmentReadState);
        success = true;
      } finally {
        if (!success) {
          decRef();
        }
      }

      // Must assign this at the end -- if we hit an
      // exception above core, we don't want to attempt to
      // purge the FieldCache (will hit NPE because core is
      // not assigned yet).
      this.origInstance = origInstance;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419657402219/fstmerge_var2_1213152059432792325

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_fb9ab_127a0/rev_fb9ab-127a0/lucene/src/java/org/apache/lucene/index/SegmentReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419657402251/fstmerge_var1_6329349748063726446
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419657402251/fstmerge_base_3426325090870910899
synchronized void decRef() throws IOException {

      if (ref.decrementAndGet() == 0) {

        if (fields != null) {
          fields.close();
        }

        if (termVectorsReaderOrig != null) {
          termVectorsReaderOrig.close();
        }
  
        if (fieldsReaderOrig != null) {
          fieldsReaderOrig.close();
        }
  
        if (cfsReader != null) {
          cfsReader.close();
        }
  
        if (storeCFSReader != null) {
          storeCFSReader.close();
        }

        // Now, notify any ReaderFinished listeners:
        if (origInstance != null) {
          origInstance.notifyReaderFinishedListeners();
        }
      }
    }
=======
synchronized void decRef() throws IOException {
      if (ref.decrementAndGet() == 0) {
        if (fields != null) {
          fields.close();
        }
        
        if (perDocProducer != null) {
          perDocProducer.close();
        }

        if (termVectorsReaderOrig != null) {
          termVectorsReaderOrig.close();
        }
  
        if (fieldsReaderOrig != null) {
          fieldsReaderOrig.close();
        }
  
        if (cfsReader != null) {
          cfsReader.close();
        }
  
        if (storeCFSReader != null) {
          storeCFSReader.close();
        }

        // Now, notify any ReaderFinished listeners:
        if (origInstance != null) {
          origInstance.notifyReaderFinishedListeners();
        }
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419657402251/fstmerge_var2_3688064288329256094

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_fb9ab_127a0/rev_fb9ab-127a0/lucene/src/java/org/apache/lucene/index/SegmentReader.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_712a0_ef68d/rev_712a0-ef68d.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_8d24e_fc68d/rev_8d24e-fc68d.revisions
Conflict type: LineBasedMCFd
Conflict body: 
public static <E extends Exception> void closeSafely(E priorException, Closeable... objects) throws E, IOException {
    Throwable th = null;

    for (Closeable object : objects) {
      try {
        if (object != null) {
          object.close();
        }
      } catch (Throwable t) {
        if (th == null) {
          th = t;
        }
      }
    }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659308696/fstmerge_base_1412686603950723197
    if (priorException != null)
=======
    if (priorException != null) {
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659308696/fstmerge_var2_4817362458250474126
      throw priorException;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659308696/fstmerge_var1_508956619260683493
    } else if (th != null) {
      if (th instanceof IOException) throw (IOException) th;
      if (th instanceof RuntimeException) throw (RuntimeException) th;
      if (th instanceof Error) throw (Error) th;
      throw new RuntimeException(th);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659308696/fstmerge_base_1412686603950723197
    else if (firstIOE != null)
      throw firstIOE;
=======
    } else if (firstIOE != null) {
      throw firstIOE;
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659308696/fstmerge_var2_4817362458250474126
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_8d24e_fc68d/rev_8d24e-fc68d/lucene/src/java/org/apache/lucene/util/IOUtils.java
Conflict type: LineBasedMCFd
Conflict body: 
public FieldsWriter(SegmentWriteState state) throws IOException {
      assert segmentCodecs == state.segmentCodecs;
      final Codec[] codecs = segmentCodecs.codecs;
      for (int i = 0; i < codecs.length; i++) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659313514/fstmerge_var1_7625718820861212256
        boolean success = false;
        try {
          consumers.add(codecs[i].fieldsConsumer(new SegmentWriteState(state, "" + i)));
          success = true;
        } finally {
          if (!success) {
            IOUtils.closeSafely(true, consumers);
          }
        }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659313514/fstmerge_base_3534405039318712942
        consumers.add(codecs[i].fieldsConsumer(new SegmentWriteState(state, "" + i)));
=======
        consumers.add(codecs[i].fieldsConsumer(new SegmentWriteState(state, i)));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659313514/fstmerge_var2_8515403914689850308
      }
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_8d24e_fc68d/rev_8d24e-fc68d/lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659313782/fstmerge_var1_739769875991842711
@Override
    public byte[] getByteBlock() {
      bytesUsed.addAndGet(blockSize);
      return new byte[blockSize];
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659313782/fstmerge_base_3905934543993640067
public byte[] getByteBlock() {
      bytesUsed.addAndGet(blockSize);
      return new byte[blockSize];
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659313782/fstmerge_var2_6288436123073025825

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_8d24e_fc68d/rev_8d24e-fc68d/lucene/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void abort() {
    Throwable th = null;
    
    for (DocFieldProcessorPerField field : fieldHash) {
      while (field != null) {
        final DocFieldProcessorPerField next = field.next;
        try {
          field.abort();
        } catch (Throwable t) {
          if (th == null) {
            th = t;
          }
        }
        field = next;
      }
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659317529/fstmerge_var1_2016975398765594863
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659317529/fstmerge_base_1203240813416034254

=======
    
    for(PerDocConsumer consumer : perDocConsumers.values()) {
      try {
        consumer.close();  // TODO add abort to PerDocConsumer!
      } catch (IOException e) {
        // ignore on abort!
      }
    }

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659317529/fstmerge_var2_7394004549622523844
    try {
      fieldsWriter.abort();
    } catch (Throwable t) {
      if (th == null) {
        th = t;
      }
    }
    
    try {
      consumer.abort();
    } catch (Throwable t) {
      if (th == null) {
        th = t;
      }
    }
    
    // If any errors occured, throw it.
    if (th != null) {
      if (th instanceof RuntimeException) throw (RuntimeException) th;
      if (th instanceof Error) throw (Error) th;
      // defensive code - we should not hit unchecked exceptions
      throw new RuntimeException(th);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_8d24e_fc68d/rev_8d24e-fc68d/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
public void addFile(String file) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659320659/fstmerge_var1_5775501251764398985
      addFile(file, directory);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659320659/fstmerge_base_3658154488662975065
        if (merged)
            throw new IllegalStateException(
                "Can't add extensions after merge has been called");

        if (file == null)
            throw new NullPointerException(
                "file cannot be null");

        if (! ids.add(file))
            throw new IllegalArgumentException(
                "File " + file + " already added");

        FileEntry entry = new FileEntry();
        entry.file = file;
        entries.add(entry);
=======
        if (merged)
            throw new IllegalStateException(
                "Can't add extensions after merge has been called");

        if (file == null)
            throw new NullPointerException(
                "file cannot be null");

        if (! ids.add(file))
            throw new IllegalArgumentException(
                "File " + file + " already added");
        entries.add(new FileEntry(file));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659320659/fstmerge_var2_676409615904702018
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_8d24e_fc68d/rev_8d24e-fc68d/lucene/src/java/org/apache/lucene/index/CompoundFileWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659321275/fstmerge_var1_4360167425450344405
public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, int indexDivisor, Comparator<BytesRef> termComp, String codecId)
    throws IOException {

    this.termComp = termComp;

    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION));
    
    boolean success = false;

    try {
      
      readHeader(in);
      indexInterval = in.readInt();
      this.indexDivisor = indexDivisor;

      if (indexDivisor < 0) {
        totalIndexInterval = indexInterval;
      } else {
        // In case terms index gets loaded, later, on demand
        totalIndexInterval = indexInterval * indexDivisor;
      }
      assert totalIndexInterval > 0;
      
      seekDir(in, dirOffset);

      // Read directory
      final int numFields = in.readVInt();      
      //System.out.println("FGR: init seg=" + segment + " div=" + indexDivisor + " nF=" + numFields);
      for(int i=0;i<numFields;i++) {
        final int field = in.readVInt();
        final int numIndexTerms = in.readVInt();
        final long termsStart = in.readVLong();
        final long indexStart = in.readVLong();
        final long packedIndexStart = in.readVLong();
        final long packedOffsetsStart = in.readVLong();
        assert packedIndexStart >= indexStart: "packedStart=" + packedIndexStart + " indexStart=" + indexStart + " numIndexTerms=" + numIndexTerms + " seg=" + segment;
        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
        fields.put(fieldInfo, new FieldIndexData(fieldInfo, numIndexTerms, indexStart, termsStart, packedIndexStart, packedOffsetsStart));
      }
      success = true;
    } finally {
      if (!success) IOUtils.closeSafely(true, in);
      if (indexDivisor > 0) {
        in.close();
        in = null;
        if (success) {
          indexLoaded = true;
        }
        termBytesReader = termBytes.freeze(true);
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659321275/fstmerge_base_1269627936711842131
public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, int indexDivisor, Comparator<BytesRef> termComp, String codecId)
    throws IOException {

    this.termComp = termComp;

    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION));
    
    boolean success = false;

    try {
      
      readHeader(in);
      indexInterval = in.readInt();
      this.indexDivisor = indexDivisor;

      if (indexDivisor < 0) {
        totalIndexInterval = indexInterval;
      } else {
        // In case terms index gets loaded, later, on demand
        totalIndexInterval = indexInterval * indexDivisor;
      }
      assert totalIndexInterval > 0;
      
      seekDir(in, dirOffset);

      // Read directory
      final int numFields = in.readVInt();      
      //System.out.println("FGR: init seg=" + segment + " div=" + indexDivisor + " nF=" + numFields);
      for(int i=0;i<numFields;i++) {
        final int field = in.readVInt();
        final int numIndexTerms = in.readVInt();
        final long termsStart = in.readVLong();
        final long indexStart = in.readVLong();
        final long packedIndexStart = in.readVLong();
        final long packedOffsetsStart = in.readVLong();
        assert packedIndexStart >= indexStart: "packedStart=" + packedIndexStart + " indexStart=" + indexStart + " numIndexTerms=" + numIndexTerms + " seg=" + segment;
        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
        fields.put(fieldInfo, new FieldIndexData(fieldInfo, numIndexTerms, indexStart, termsStart, packedIndexStart, packedOffsetsStart));
      }
      success = true;
    } finally {
      if (indexDivisor > 0) {
        in.close();
        in = null;
        if (success) {
          indexLoaded = true;
        }
        termBytesReader = termBytes.freeze(true);
      }
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659321275/fstmerge_var2_9176423922408178166

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_8d24e_fc68d/rev_8d24e-fc68d/lucene/src/java/org/apache/lucene/index/codecs/FixedGapTermsIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322221/fstmerge_var1_2878292105103580270
public BlockTermsWriter(TermsIndexWriterBase termsIndexWriter,
      SegmentWriteState state, PostingsWriterBase postingsWriter)
      throws IOException {
    final String termsFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, TERMS_EXTENSION);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322221/fstmerge_base_1319617293978666514
public BlockTermsWriter(
      TermsIndexWriterBase termsIndexWriter,
      SegmentWriteState state,
      PostingsWriterBase postingsWriter)
    throws IOException
  {
    final String termsFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, TERMS_EXTENSION);
=======
public BlockTermsWriter(
      TermsIndexWriterBase termsIndexWriter,
      SegmentWriteState state,
      PostingsWriterBase postingsWriter)
    throws IOException
  {
    final String termsFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecIdAsString(), TERMS_EXTENSION);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322221/fstmerge_var2_3443376475214972936
    this.termsIndexWriter = termsIndexWriter;
    out = state.directory.createOutput(termsFileName);
    boolean success = false;
    try {
      fieldInfos = state.fieldInfos;
      writeHeader(out);
      currentField = null;
      this.postingsWriter = postingsWriter;
      //segment = state.segmentName;
      
      //System.out.println("BTW.init seg=" + state.segmentName);
      
      postingsWriter.start(out); // have consumer write its format/header
      success = true;
    } finally {
      if (!success) {
        IOUtils.closeSafely(true, out);
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_8d24e_fc68d/rev_8d24e-fc68d/lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public SepPostingsWriterImpl(SegmentWriteState state, IntStreamFactory factory, int skipInterval) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322402/fstmerge_var1_6699043607592694340
    freqOut = null;
    freqIndex = null;
    posOut = null;
    posIndex = null;
    payloadOut = null;
    boolean success = false;
    try {
      this.skipInterval = skipInterval;
      this.skipMinimum = skipInterval; /* set to the same for now */
      final String docFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, DOC_EXTENSION);
      docOut = factory.createOutput(state.directory, docFileName);
      docIndex = docOut.index();
      
      if (state.fieldInfos.hasProx()) {
        final String frqFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, FREQ_EXTENSION);
        freqOut = factory.createOutput(state.directory, frqFileName);
        freqIndex = freqOut.index();
        
        final String posFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, POS_EXTENSION);
        posOut = factory.createOutput(state.directory, posFileName);
        posIndex = posOut.index();
        
        // TODO: -- only if at least one field stores payloads?
        final String payloadFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, PAYLOAD_EXTENSION);
        payloadOut = state.directory.createOutput(payloadFileName);
      }
      
      final String skipFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, SKIP_EXTENSION);
      skipOut = state.directory.createOutput(skipFileName);
      
      totalNumDocs = state.numDocs;
      
      skipListWriter = new SepSkipListWriter(skipInterval,
          maxSkipLevels,
          state.numDocs,
          freqOut, docOut,
          posOut, payloadOut);
      
      success = true;
    } finally {
      if (!success) {
        IOUtils.closeSafely(true, docOut, skipOut, freqOut, posOut, payloadOut);
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322402/fstmerge_base_1196346749157009906
    super();
    this.skipInterval = skipInterval;
    this.skipMinimum = skipInterval; /* set to the same for now */
    final String docFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, DOC_EXTENSION);
    docOut = factory.createOutput(state.directory, docFileName);
    docIndex = docOut.index();
=======
    super();
    final String codecIdAsString = state.codecIdAsString();
    this.skipInterval = skipInterval;
    this.skipMinimum = skipInterval; /* set to the same for now */
    final String docFileName = IndexFileNames.segmentFileName(state.segmentName, codecIdAsString, DOC_EXTENSION);
    docOut = factory.createOutput(state.directory, docFileName);
    docIndex = docOut.index();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322402/fstmerge_var2_4741621134455223351

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322402/fstmerge_var1_6699043607592694340
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322402/fstmerge_base_1196346749157009906
    if (state.fieldInfos.hasProx()) {
      final String frqFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, FREQ_EXTENSION);
      freqOut = factory.createOutput(state.directory, frqFileName);
      freqIndex = freqOut.index();

      final String posFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, POS_EXTENSION);
      posOut = factory.createOutput(state.directory, posFileName);
      posIndex = posOut.index();

      // TODO: -- only if at least one field stores payloads?
      final String payloadFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, PAYLOAD_EXTENSION);
      payloadOut = state.directory.createOutput(payloadFileName);

    } else {
      freqOut = null;
      freqIndex = null;
      posOut = null;
      posIndex = null;
      payloadOut = null;
=======
    if (state.fieldInfos.hasProx()) {
      final String frqFileName = IndexFileNames.segmentFileName(state.segmentName, codecIdAsString, FREQ_EXTENSION);
      freqOut = factory.createOutput(state.directory, frqFileName);
      freqIndex = freqOut.index();

      final String posFileName = IndexFileNames.segmentFileName(state.segmentName, codecIdAsString, POS_EXTENSION);
      posOut = factory.createOutput(state.directory, posFileName);
      posIndex = posOut.index();

      // TODO: -- only if at least one field stores payloads?
      final String payloadFileName = IndexFileNames.segmentFileName(state.segmentName, codecIdAsString, PAYLOAD_EXTENSION);
      payloadOut = state.directory.createOutput(payloadFileName);

    } else {
      freqOut = null;
      freqIndex = null;
      posOut = null;
      posIndex = null;
      payloadOut = null;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322402/fstmerge_var2_4741621134455223351
    }
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322402/fstmerge_var1_6699043607592694340
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322402/fstmerge_base_1196346749157009906

    final String skipFileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, SKIP_EXTENSION);
    skipOut = state.directory.createOutput(skipFileName);

    totalNumDocs = state.numDocs;

    skipListWriter = new SepSkipListWriter(skipInterval,
                                           maxSkipLevels,
                                           state.numDocs,
                                           freqOut, docOut,
                                           posOut, payloadOut);
=======

    final String skipFileName = IndexFileNames.segmentFileName(state.segmentName, codecIdAsString, SKIP_EXTENSION);
    skipOut = state.directory.createOutput(skipFileName);

    totalNumDocs = state.numDocs;

    skipListWriter = new SepSkipListWriter(skipInterval,
                                           maxSkipLevels,
                                           state.numDocs,
                                           freqOut, docOut,
                                           posOut, payloadOut);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322402/fstmerge_var2_4741621134455223351
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_8d24e_fc68d/rev_8d24e-fc68d/lucene/src/java/org/apache/lucene/index/codecs/sep/SepPostingsWriterImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
public StandardPostingsWriter(SegmentWriteState state, int skipInterval) throws IOException {
    this.skipInterval = skipInterval;
    this.skipMinimum = skipInterval; /* set to the same for now */
    //this.segment = state.segmentName;
    String fileName = IndexFileNames.segmentFileName(state.segmentName, state.codecIdAsString(), StandardCodec.FREQ_EXTENSION);
    freqOut = state.directory.createOutput(fileName);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322862/fstmerge_var1_695988870175612064
    boolean success = false;
    try {
      if (state.fieldInfos.hasProx()) {
        // At least one field does not omit TF, so create the
        // prox file
        fileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, StandardCodec.PROX_EXTENSION);
        proxOut = state.directory.createOutput(fileName);
      } else {
        // Every field omits TF so we will write no prox file
        proxOut = null;
      }
      
      totalNumDocs = state.numDocs;
      
      skipListWriter = new DefaultSkipListWriter(skipInterval, maxSkipLevels,
          state.numDocs, freqOut, proxOut);
      success = true;
    } finally {
      if (!success) {
        IOUtils.closeSafely(true, freqOut, proxOut);
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322862/fstmerge_base_8121283691611370133

    if (state.fieldInfos.hasProx()) {
      // At least one field does not omit TF, so create the
      // prox file
      fileName = IndexFileNames.segmentFileName(state.segmentName, state.codecId, StandardCodec.PROX_EXTENSION);
      proxOut = state.directory.createOutput(fileName);
    } else {
      // Every field omits TF so we will write no prox file
      proxOut = null;
=======

    if (state.fieldInfos.hasProx()) {
      // At least one field does not omit TF, so create the
      // prox file
      fileName = IndexFileNames.segmentFileName(state.segmentName, state.codecIdAsString(), StandardCodec.PROX_EXTENSION);
      proxOut = state.directory.createOutput(fileName);
    } else {
      // Every field omits TF so we will write no prox file
      proxOut = null;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659322862/fstmerge_var2_6071490679954269407
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_8d24e_fc68d/rev_8d24e-fc68d/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardPostingsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659326358/fstmerge_var1_1481129512707907555
public void addDocument(final Document doc) throws IOException {
    if (r.nextInt(5) == 3) {
      // TODO: maybe, we should simply buffer up added docs
      // (but we need to clone them), and only when
      // getReader, commit, etc. are called, we do an
      // addDocuments?  Would be better testing.
      w.addDocuments(new Iterable<Document>() {

        // @Override -- not until Java 1.6
        public Iterator<Document> iterator() {
          return new Iterator<Document>() {
            boolean done;
            
            // @Override -- not until Java 1.6
            public boolean hasNext() {
              return !done;
            }

            // @Override -- not until Java 1.6
            public void remove() {
              throw new UnsupportedOperationException();
            }

            // @Override -- not until Java 1.6
            public Document next() {
              if (done) {
                throw new IllegalStateException();
              }
              done = true;
              return doc;
            }
          };
        }
        });
    } else {
      w.addDocument(doc);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659326358/fstmerge_base_7489175508559783059
public void addDocument(Document doc) throws IOException {
    w.addDocument(doc);
=======
public void addDocument(Document doc) throws IOException {
    if (doDocValues) {
      randomPerDocFieldValues(r, doc);
    }
    w.addDocument(doc);
    
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659326358/fstmerge_var2_3052461427287630870
    maybeCommit();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_8d24e_fc68d/rev_8d24e-fc68d/lucene/src/test-framework/org/apache/lucene/index/RandomIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659326367/fstmerge_var1_7241719557920908009
public void updateDocument(Term t, final Document doc) throws IOException {
    if (r.nextInt(5) == 3) {
      w.updateDocuments(t, new Iterable<Document>() {

        // @Override -- not until Java 1.6
        public Iterator<Document> iterator() {
          return new Iterator<Document>() {
            boolean done;
            
            // @Override -- not until Java 1.6
            public boolean hasNext() {
              return !done;
            }

            // @Override -- not until Java 1.6
            public void remove() {
              throw new UnsupportedOperationException();
            }

            // @Override -- not until Java 1.6
            public Document next() {
              if (done) {
                throw new IllegalStateException();
              }
              done = true;
              return doc;
            }
          };
        }
        });
    } else {
      w.updateDocument(t, doc);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659326367/fstmerge_base_3658683474486848146
public void updateDocument(Term t, Document doc) throws IOException {
    w.updateDocument(t, doc);
=======
public void updateDocument(Term t, Document doc) throws IOException {
    if (doDocValues) {
      randomPerDocFieldValues(r, doc);
    }
    w.updateDocument(t, doc);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419659326367/fstmerge_var2_5828006506602132610
    maybeCommit();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_8d24e_fc68d/rev_8d24e-fc68d/lucene/src/test-framework/org/apache/lucene/index/RandomIndexWriter.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_af54d_16cc8/rev_af54d-16cc8.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_cfe22_918a2/rev_cfe22-918a2.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c8ab9_14b65/rev_c8ab9-14b65.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_30093_b2f7f/rev_30093-b2f7f.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a53ca_e3b7c/rev_a53ca-e3b7c.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_d2dc3_28e36/rev_d2dc3-28e36.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_e4e4b_96865/rev_e4e4b-96865.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_5529b_090b8/rev_5529b-090b8.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_16ebb_b8b1f/rev_16ebb-b8b1f.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_cb5a9_16ebb/rev_cb5a9-16ebb.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1ea91_09367/rev_1ea91-09367.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419670169111/fstmerge_var1_3186277062039611101
@Test
  public void testErrorHandling() throws Exception {

    try{
      addDoc("uima-not-ignoreErrors", adoc(
            "id",
            "2312312321312",
            "text",
            "SpellCheckComponent got improvement related to recent Lucene changes. \n  "
                    + "Add support for specifying Spelling SuggestWord Comparator to Lucene spell "
                    + "checkers for SpellCheckComponent. Issue SOLR-2053 is already fixed, patch is"
                    + " attached if you need it, but it is also committed to trunk and 3_x branch."
                    + " Last Lucene European Conference has been held in Prague."));
      fail("exception shouldn't be ignored");
    }
    catch(RuntimeException expected){}
    assertU(commit());
    assertQ(req("*:*"), "//*[@numFound='0']");

    addDoc("uima-ignoreErrors", adoc(
            "id",
            "2312312321312",
            "text",
            "SpellCheckComponent got improvement related to recent Lucene changes. \n  "
                    + "Add support for specifying Spelling SuggestWord Comparator to Lucene spell "
                    + "checkers for SpellCheckComponent. Issue SOLR-2053 is already fixed, patch is"
                    + " attached if you need it, but it is also committed to trunk and 3_x branch."
                    + " Last Lucene European Conference has been held in Prague."));
    assertU(commit());
    assertQ(req("*:*"), "//*[@numFound='1']");

    try{
      addDoc("uima-not-ignoreErrors", adoc(
            "id",
            "2312312321312",
            "text",
            "SpellCheckComponent got improvement related to recent Lucene changes."));
      fail("exception shouldn't be ignored");
    }
    catch(StringIndexOutOfBoundsException e){  // SOLR-2579
      fail("exception shouldn't be raised");
    }
    catch(SolrException expected){}

    try{
      addDoc("uima-ignoreErrors", adoc(
            "id",
            "2312312321312",
            "text",
            "SpellCheckComponent got improvement related to recent Lucene changes."));
    }
    catch(StringIndexOutOfBoundsException e){  // SOLR-2579
      fail("exception shouldn't be raised");
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419670169111/fstmerge_base_5357772305446551126
@Test
  public void testErrorHandling() throws Exception {

    try{
      addDoc("uima-not-ignoreErrors", adoc(
            "id",
            "2312312321312",
            "text",
            "SpellCheckComponent got improvement related to recent Lucene changes. \n  "
                    + "Add support for specifying Spelling SuggestWord Comparator to Lucene spell "
                    + "checkers for SpellCheckComponent. Issue SOLR-2053 is already fixed, patch is"
                    + " attached if you need it, but it is also committed to trunk and 3_x branch."
                    + " Last Lucene European Conference has been held in Prague."));
      fail("exception shouldn't be ignored");
    }
    catch(RuntimeException expected){}
    assertU(commit());
    assertQ(req("*:*"), "//*[@numFound='0']");

    addDoc("uima-ignoreErrors", adoc(
            "id",
            "2312312321312",
            "text",
            "SpellCheckComponent got improvement related to recent Lucene changes. \n  "
                    + "Add support for specifying Spelling SuggestWord Comparator to Lucene spell "
                    + "checkers for SpellCheckComponent. Issue SOLR-2053 is already fixed, patch is"
                    + " attached if you need it, but it is also committed to trunk and 3_x branch."
                    + " Last Lucene European Conference has been held in Prague."));
    assertU(commit());
    assertQ(req("*:*"), "//*[@numFound='1']");
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419670169111/fstmerge_var2_18493411333130478

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1ea91_09367/rev_1ea91-09367/solr/contrib/uima/src/test/java/org/apache/solr/uima/processor/UIMAUpdateRequestProcessorTest.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419670169158/fstmerge_var1_5858114485533335494
@Override
  public void processAdd(AddUpdateCommand cmd) throws IOException {
    String text = null;
    try {
      /* get Solr document */
      SolrInputDocument solrInputDocument = cmd.getSolrInputDocument();

      /* get the fields to analyze */
      String[] texts = getTextsToAnalyze(solrInputDocument);
      for (int i = 0; i < texts.length; i++) {
        text = texts[i];
        if (text != null && !"".equals(text)) {
          /* process the text value */
          JCas jcas = processText(text);

          UIMAToSolrMapper uimaToSolrMapper = new UIMAToSolrMapper(solrInputDocument, jcas);
          /* get field mapping from config */
          Map<String, Map<String, MapField>> typesAndFeaturesFieldsMap = solrUIMAConfiguration
                  .getTypesFeaturesFieldsMapping();
          /* map type features on fields */
          for (String typeFQN : typesAndFeaturesFieldsMap.keySet()) {
            uimaToSolrMapper.map(typeFQN, typesAndFeaturesFieldsMap.get(typeFQN));
          }
        }
      }
    } catch (UIMAException e) {
      String logField = solrUIMAConfiguration.getLogField();
      String optionalFieldInfo = logField == null ? "." :
        new StringBuilder(". ").append(logField).append("=")
        .append((String)cmd.getSolrInputDocument().getField(logField).getValue())
        .append(", ").toString();
      int len = Math.min(text.length(), 100);
      if (solrUIMAConfiguration.isIgnoreErrors()) {
        log.warn(new StringBuilder("skip the text processing due to ")
          .append(e.getLocalizedMessage()).append(optionalFieldInfo)
          .append(" text=\"").append(text.substring(0, len)).append("...\"").toString());
      } else {
        throw new SolrException(ErrorCode.SERVER_ERROR,
            new StringBuilder("processing error: ")
              .append(e.getLocalizedMessage()).append(optionalFieldInfo)
              .append(" text=\"").append(text.substring(0, len)).append("...\"").toString(), e);
      }
    }
    super.processAdd(cmd);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419670169158/fstmerge_base_3872389411361076768
@Override
  public void processAdd(AddUpdateCommand cmd) throws IOException {
    String text = null;
    try {
      /* get Solr document */
      SolrInputDocument solrInputDocument = cmd.getSolrInputDocument();

      /* get the fields to analyze */
      String[] texts = getTextsToAnalyze(solrInputDocument);
      for (int i = 0; i < texts.length; i++) {
        text = texts[i];
        if (text != null && !"".equals(text)) {
          /* process the text value */
          JCas jcas = processText(text);

          UIMAToSolrMapper uimaToSolrMapper = new UIMAToSolrMapper(solrInputDocument, jcas);
          /* get field mapping from config */
          Map<String, Map<String, MapField>> typesAndFeaturesFieldsMap = solrUIMAConfiguration
                  .getTypesFeaturesFieldsMapping();
          /* map type features on fields */
          for (String typeFQN : typesAndFeaturesFieldsMap.keySet()) {
            uimaToSolrMapper.map(typeFQN, typesAndFeaturesFieldsMap.get(typeFQN));
          }
        }
      }
    } catch (UIMAException e) {
      String logField = solrUIMAConfiguration.getLogField();
      String optionalFieldInfo = logField == null ? "." :
        new StringBuilder(". ").append(logField).append("=")
        .append((String)cmd.getSolrInputDocument().getField(logField).getValue())
        .append(", ").toString();
      if (solrUIMAConfiguration.isIgnoreErrors())
        log.warn(new StringBuilder("skip the text processing due to ")
          .append(e.getLocalizedMessage()).append(optionalFieldInfo)
          .append(" text=\"").append(text.substring(0, 100)).append("...\"").toString());
      else{
        throw new SolrException(ErrorCode.SERVER_ERROR,
            new StringBuilder("processing error: ")
              .append(e.getLocalizedMessage()).append(optionalFieldInfo)
              .append(" text=\"").append(text.substring(0, 100)).append("...\"").toString(), e);
      }
    }
    super.processAdd(cmd);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419670169158/fstmerge_var2_3961060387377282785

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1ea91_09367/rev_1ea91-09367/solr/contrib/uima/src/main/java/org/apache/solr/uima/processor/UIMAUpdateRequestProcessor.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_7f976_a171c/rev_7f976-a171c.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671176294/fstmerge_var1_6877254360409154520
public void map(String typeName, Map<String, MapField> featureFieldsmapping) throws FieldMappingException {
    try {
      Type type = cas.getTypeSystem().getType(typeName);
      for (FSIterator<FeatureStructure> iterator = cas.getFSIndexRepository().getAllIndexedFS(type); iterator
          .hasNext(); ) {
        FeatureStructure fs = iterator.next();
        for (String featureName : featureFieldsmapping.keySet()) {
          MapField mapField = featureFieldsmapping.get(featureName);
          String fieldNameFeature = mapField.getFieldNameFeature();
          String fieldNameFeatureValue = fieldNameFeature == null ? null :
              fs.getFeatureValueAsString(type.getFeatureByBaseName(fieldNameFeature));
          String fieldName = mapField.getFieldName(fieldNameFeatureValue);
          log.info(new StringBuffer("mapping ").append(typeName).append("@").append(featureName)
              .append(" to ").append(fieldName).toString());
          String featureValue = null;
          if (fs instanceof Annotation && "coveredText".equals(featureName)) {
            featureValue = ((Annotation) fs).getCoveredText();
          } else {
            featureValue = fs.getFeatureValueAsString(type.getFeatureByBaseName(featureName));
          }
          log.info(new StringBuffer("writing ").append(featureValue).append(" in ").append(
              fieldName).toString());
          document.addField(fieldName, featureValue, 1.0f);
        }
      }
    } catch (Exception e) {
      throw new FieldMappingException(e);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671176294/fstmerge_base_5925926764226279006
public void map(String typeName, Map<String, MapField> featureFieldsmapping) {
    try {
      FeatureStructure fsMock = (FeatureStructure) Class.forName(typeName).getConstructor(
              JCas.class).newInstance(cas);
      Type type = fsMock.getType();
      for (FSIterator<FeatureStructure> iterator = cas.getFSIndexRepository().getAllIndexedFS(type); iterator
              .hasNext();) {
        FeatureStructure fs = iterator.next();
        for (String featureName : featureFieldsmapping.keySet()) {
          MapField mapField = featureFieldsmapping.get(featureName);
          String fieldNameFeature = mapField.getFieldNameFeature();
          String fieldNameFeatureValue = fieldNameFeature == null ? null :
            fs.getFeatureValueAsString(type.getFeatureByBaseName(fieldNameFeature));
          String fieldName = mapField.getFieldName(fieldNameFeatureValue);
          log.info(new StringBuffer("mapping ").append(typeName).append("@").append(featureName)
                  .append(" to ").append(fieldName).toString());
          String featureValue = null;
          if (fs instanceof Annotation && "coveredText".equals(featureName)) {
            featureValue = ((Annotation) fs).getCoveredText();
          } else {
            featureValue = fs.getFeatureValueAsString(type.getFeatureByBaseName(featureName));
          }
          log.info(new StringBuffer("writing ").append(featureValue).append(" in ").append(
                  fieldName).toString());
          document.addField(fieldName, featureValue, 1.0f);
        }
      }
    } catch (Exception e) {
      log.error(e.getLocalizedMessage());
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671176294/fstmerge_var2_4364129745202018887

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_7f976_a171c/rev_7f976-a171c/solr/contrib/uima/src/main/java/org/apache/solr/uima/processor/UIMAToSolrMapper.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671176304/fstmerge_var1_3825839824235941539
private void initialize(SolrCore solrCore, SolrUIMAConfiguration config) {
    this.solrCore = solrCore;
    solrUIMAConfiguration = config;
    aeProvider = AEProviderFactory.getInstance().getAEProvider(solrCore.getName(),
            solrUIMAConfiguration.getAePath(), solrUIMAConfiguration.getRuntimeParameters());
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671176304/fstmerge_base_9152298598321743118
private void initialize(SolrCore solrCore, SolrUIMAConfiguration config) {
    solrUIMAConfiguration = config;
    aeProvider = AEProviderFactory.getInstance().getAEProvider(solrCore.getName(),
            solrUIMAConfiguration.getAePath(), solrUIMAConfiguration.getRuntimeParameters());
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671176304/fstmerge_var2_7218453462220327522

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_7f976_a171c/rev_7f976-a171c/solr/contrib/uima/src/main/java/org/apache/solr/uima/processor/UIMAUpdateRequestProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671176310/fstmerge_var1_5279219153478715813
@Override
  public void processAdd(AddUpdateCommand cmd) throws IOException {
    String text = null;
    try {
      /* get Solr document */
      SolrInputDocument solrInputDocument = cmd.getSolrInputDocument();

      /* get the fields to analyze */
      String[] texts = getTextsToAnalyze(solrInputDocument);
      for (int i = 0; i < texts.length; i++) {
        text = texts[i];
        if (text != null && text.length()>0) {
          /* process the text value */
          JCas jcas = processText(text);

          UIMAToSolrMapper uimaToSolrMapper = new UIMAToSolrMapper(solrInputDocument, jcas);
          /* get field mapping from config */
          Map<String, Map<String, MapField>> typesAndFeaturesFieldsMap = solrUIMAConfiguration
                  .getTypesFeaturesFieldsMapping();
          /* map type features on fields */
          for (String typeFQN : typesAndFeaturesFieldsMap.keySet()) {
            uimaToSolrMapper.map(typeFQN, typesAndFeaturesFieldsMap.get(typeFQN));
          }
        }
      }
    } catch (Exception e) {
      String logField = solrUIMAConfiguration.getLogField();
      if(logField == null){
        SchemaField uniqueKeyField = solrCore.getSchema().getUniqueKeyField();
        if(uniqueKeyField != null){
          logField = uniqueKeyField.getName();
        }
      }
      String optionalFieldInfo = logField == null ? "." :
        new StringBuilder(". ").append(logField).append("=")
        .append((String)cmd.getSolrInputDocument().getField(logField).getValue())
        .append(", ").toString();
      int len = Math.min(text.length(), 100);
      if (solrUIMAConfiguration.isIgnoreErrors()) {
        log.warn(new StringBuilder("skip the text processing due to ")
          .append(e.getLocalizedMessage()).append(optionalFieldInfo)
          .append(" text=\"").append(text.substring(0, len)).append("...\"").toString());
      } else {
        throw new SolrException(ErrorCode.SERVER_ERROR,
            new StringBuilder("processing error: ")
              .append(e.getLocalizedMessage()).append(optionalFieldInfo)
              .append(" text=\"").append(text.substring(0, len)).append("...\"").toString(), e);
      }
    }
    super.processAdd(cmd);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671176310/fstmerge_base_2292815575407240348
@Override
  public void processAdd(AddUpdateCommand cmd) throws IOException {
    String text = null;
    try {
      /* get Solr document */
      SolrInputDocument solrInputDocument = cmd.getSolrInputDocument();

      /* get the fields to analyze */
      String[] texts = getTextsToAnalyze(solrInputDocument);
      for (int i = 0; i < texts.length; i++) {
        text = texts[i];
        if (text != null && !"".equals(text)) {
          /* process the text value */
          JCas jcas = processText(text);

          UIMAToSolrMapper uimaToSolrMapper = new UIMAToSolrMapper(solrInputDocument, jcas);
          /* get field mapping from config */
          Map<String, Map<String, MapField>> typesAndFeaturesFieldsMap = solrUIMAConfiguration
                  .getTypesFeaturesFieldsMapping();
          /* map type features on fields */
          for (String typeFQN : typesAndFeaturesFieldsMap.keySet()) {
            uimaToSolrMapper.map(typeFQN, typesAndFeaturesFieldsMap.get(typeFQN));
          }
        }
      }
    } catch (UIMAException e) {
      String logField = solrUIMAConfiguration.getLogField();
      String optionalFieldInfo = logField == null ? "." :
        new StringBuilder(". ").append(logField).append("=")
        .append((String)cmd.getSolrInputDocument().getField(logField).getValue())
        .append(", ").toString();
      int len = Math.min(text.length(), 100);
      if (solrUIMAConfiguration.isIgnoreErrors()) {
        log.warn(new StringBuilder("skip the text processing due to ")
          .append(e.getLocalizedMessage()).append(optionalFieldInfo)
          .append(" text=\"").append(text.substring(0, len)).append("...\"").toString());
      } else {
        throw new SolrException(ErrorCode.SERVER_ERROR,
            new StringBuilder("processing error: ")
              .append(e.getLocalizedMessage()).append(optionalFieldInfo)
              .append(" text=\"").append(text.substring(0, len)).append("...\"").toString(), e);
      }
    }
    super.processAdd(cmd);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671176310/fstmerge_var2_2652009428656959529

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_7f976_a171c/rev_7f976-a171c/solr/contrib/uima/src/main/java/org/apache/solr/uima/processor/UIMAUpdateRequestProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671176316/fstmerge_var1_1662219815155548745
private String[] getTextsToAnalyze(SolrInputDocument solrInputDocument) {
    String[] fieldsToAnalyze = solrUIMAConfiguration.getFieldsToAnalyze();
    boolean merge = solrUIMAConfiguration.isFieldsMerging();
    String[] textVals;
    if (merge) {
      StringBuilder unifiedText = new StringBuilder("");
      for (int i = 0; i < fieldsToAnalyze.length; i++) {
        unifiedText.append(String.valueOf(solrInputDocument.getFieldValue(fieldsToAnalyze[i])));
      }
      textVals = new String[1];
      textVals[0] = unifiedText.toString();
    } else {
      textVals = new String[fieldsToAnalyze.length];
      for (int i = 0; i < fieldsToAnalyze.length; i++) {
        textVals[i] = String.valueOf(solrInputDocument.getFieldValue(fieldsToAnalyze[i]));
      }
    }
    return textVals;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671176316/fstmerge_base_2057465882831534581
private String[] getTextsToAnalyze(SolrInputDocument solrInputDocument) {
    String[] fieldsToAnalyze = solrUIMAConfiguration.getFieldsToAnalyze();
    boolean merge = solrUIMAConfiguration.isFieldsMerging();
    String[] textVals = null;
    if (merge) {
      StringBuilder unifiedText = new StringBuilder("");
      for (int i = 0; i < fieldsToAnalyze.length; i++) {
        unifiedText.append(String.valueOf(solrInputDocument.getFieldValue(fieldsToAnalyze[i])));
      }
      textVals = new String[1];
      textVals[0] = unifiedText.toString();
    } else {
      textVals = new String[fieldsToAnalyze.length];
      for (int i = 0; i < fieldsToAnalyze.length; i++) {
        textVals[i] = String.valueOf(solrInputDocument.getFieldValue(fieldsToAnalyze[i]));
      }
    }
    return textVals;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671176316/fstmerge_var2_2148250574113068659

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_7f976_a171c/rev_7f976-a171c/solr/contrib/uima/src/main/java/org/apache/solr/uima/processor/UIMAUpdateRequestProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671179785/fstmerge_var1_5140936611343177890
@Override
  public void init(Context context) {
    super.init(context);
    // set attributes using  XXX getXXXFromContext(attribute, defualtValue);
    // applies variable resolver and return default if value is not found or null
    // REQUIRED : connection and folder info
    user = getStringFromContext("user", null);
    password = getStringFromContext("password", null);
    host = getStringFromContext("host", null);
    protocol = getStringFromContext("protocol", null);
    folderNames = getStringFromContext("folders", null);
    // validate
    if (host == null || protocol == null || user == null || password == null
            || folderNames == null)
      throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
              "'user|password|protocol|host|folders' are required attributes");

    //OPTIONAL : have defaults and are optional
    recurse = getBoolFromContext("recurse", true);
    String excludes = getStringFromContext("exclude", "");
    if (excludes != null && !excludes.trim().equals("")) {
      exclude = Arrays.asList(excludes.split(","));
    }
    String includes = getStringFromContext("include", "");
    if (includes != null && !includes.trim().equals("")) {
      include = Arrays.asList(includes.split(","));
    }
    batchSize = getIntFromContext("batchSize", 20);
    customFilter = getStringFromContext("customFilter", "");
    String s = getStringFromContext("fetchMailsSince", "");
    if (s != null)
      try {
        fetchMailsSince = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").parse(s);
      } catch (ParseException e) {
        throw new DataImportHandlerException(DataImportHandlerException.SEVERE, "Invalid value for fetchMailSince: " + s, e);
      }

    fetchSize = getIntFromContext("fetchSize", 32 * 1024);
    cTimeout = getIntFromContext("connectTimeout", 30 * 1000);
    rTimeout = getIntFromContext("readTimeout", 60 * 1000);
    processAttachment = getBoolFromContext(
              getStringFromContext("processAttachment",null) == null ? "processAttachement":"processAttachment"
            , true);

    logConfig();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671179785/fstmerge_base_3692941577507014565
@Override
  public void init(Context context) {
    super.init(context);
    // set attributes using  XXX getXXXFromContext(attribute, defualtValue);
    // applies variable resolver and return default if value is not found or null
    // REQUIRED : connection and folder info
    user = getStringFromContext("user", null);
    password = getStringFromContext("password", null);
    host = getStringFromContext("host", null);
    protocol = getStringFromContext("protocol", null);
    folderNames = getStringFromContext("folders", null);
    // validate
    if (host == null || protocol == null || user == null || password == null
            || folderNames == null)
      throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
              "'user|password|protocol|host|folders' are required attributes");

    //OPTIONAL : have defaults and are optional
    recurse = getBoolFromContext("recurse", true);
    String excludes = getStringFromContext("exclude", "");
    if (excludes != null && !excludes.trim().equals("")) {
      exclude = Arrays.asList(excludes.split(","));
    }
    String includes = getStringFromContext("include", "");
    if (includes != null && !includes.trim().equals("")) {
      include = Arrays.asList(includes.split(","));
    }
    batchSize = getIntFromContext("batchSize", 20);
    customFilter = getStringFromContext("customFilter", "");
    String s = getStringFromContext("fetchMailsSince", "");
    if (s != null)
      try {
        fetchMailsSince = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").parse(s);
      } catch (ParseException e) {
        throw new DataImportHandlerException(DataImportHandlerException.SEVERE, "Invalid value for fetchMailSince: " + s, e);
      }

    fetchSize = getIntFromContext("fetchSize", 32 * 1024);
    cTimeout = getIntFromContext("connectTimeout", 30 * 1000);
    rTimeout = getIntFromContext("readTimeout", 60 * 1000);
    processAttachment = getBoolFromContext("processAttachement", true);

    logConfig();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419671179785/fstmerge_var2_702409571221496389

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_7f976_a171c/rev_7f976-a171c/solr/contrib/dataimporthandler/src/extras/main/java/org/apache/solr/handler/dataimport/MailEntityProcessor.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_83ce9_6b6a4/rev_83ce9-6b6a4.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419672178112/fstmerge_var1_1071342626985841154
void persist(Properties p) {
    OutputStream propOutput = null;

    Properties props = readIndexerProperties();

    try {
      props.putAll(p);
      File persistFile = getPersistFile();
      propOutput = new FileOutputStream(persistFile);
      props.store(propOutput, null);
      log.info("Wrote last indexed time to " + persistFile.getAbsolutePath());
    } catch (FileNotFoundException e) {
      throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
              "Unable to persist Index Start Time", e);
    } catch (IOException e) {
      throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
              "Unable to persist Index Start Time", e);
    } finally {
      try {
        if (propOutput != null)
          propOutput.close();
      } catch (IOException e) {
        propOutput = null;
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419672178112/fstmerge_base_483452640972621196
void persist(Properties p) {
    OutputStream propOutput = null;

    Properties props = readIndexerProperties();

    try {
      props.putAll(p);
      String filePath = configDir;
      if (configDir != null && !configDir.endsWith(File.separator))
        filePath += File.separator;
      filePath += persistFilename;
      propOutput = new FileOutputStream(filePath);
      props.store(propOutput, null);
      log.info("Wrote last indexed time to " + persistFilename);
    } catch (FileNotFoundException e) {
      throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
              "Unable to persist Index Start Time", e);
    } catch (IOException e) {
      throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
              "Unable to persist Index Start Time", e);
    } finally {
      try {
        if (propOutput != null)
          propOutput.close();
      } catch (IOException e) {
        propOutput = null;
      }
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419672178112/fstmerge_var2_7028799889129412130

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_83ce9_6b6a4/rev_83ce9-6b6a4/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/SolrWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419672178817/fstmerge_var1_7908612746611832565
DataImporter(InputSource dataConfig, SolrCore core, Map<String, Properties> ds, Map<String, Object> session) {
    if (dataConfig == null)
      throw new DataImportHandlerException(SEVERE,
              "Configuration not found");
    this.core = core;
    this.schema = core.getSchema();
    dataSourceProps = ds;
    if (session == null)
      session = new HashMap<String, Object>();
    coreScopeSession = session;
    loadDataConfig(dataConfig);

    for (Map.Entry<String, SchemaField> entry : schema.getFields().entrySet()) {
      config.lowerNameVsSchemaField.put(entry.getKey().toLowerCase(Locale.ENGLISH), entry.getValue());
    }

    for (DataConfig.Entity e : config.document.entities) {
      Map<String, DataConfig.Field> fields = new HashMap<String, DataConfig.Field>();
      initEntity(e, fields, false);
      verifyWithSchema(fields);
      identifyPk(e);
      if (e.allAttributes.containsKey(SqlEntityProcessor.DELTA_QUERY))
        isDeltaImportSupported = true;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419672178817/fstmerge_base_3110229006031636097
DataImporter(InputSource dataConfig, SolrCore core, Map<String, Properties> ds, Map<String, Object> session) {
    if (dataConfig == null)
      throw new DataImportHandlerException(SEVERE,
              "Configuration not found");
    this.core = core;
    this.schema = core.getSchema();
    dataSourceProps = ds;
    if (session == null)
      session = new HashMap<String, Object>();
    coreScopeSession = session;
    loadDataConfig(dataConfig);

    for (Map.Entry<String, SchemaField> entry : schema.getFields().entrySet()) {
      config.lowerNameVsSchemaField.put(entry.getKey().toLowerCase(Locale.ENGLISH), entry.getValue());
    }

    for (DataConfig.Entity e : config.document.entities) {
      Map<String, DataConfig.Field> fields = new HashMap<String, DataConfig.Field>();
      initEntity(e, fields, false);
      verifyWithSchema(fields);
      identifyPk(e);
    }    
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419672178817/fstmerge_var2_709438046851799639

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_83ce9_6b6a4/rev_83ce9-6b6a4/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DataImporter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419672178895/fstmerge_var1_6954926383056575267
public void doFullImport(SolrWriter writer, RequestParams requestParams) {
    LOG.info("Starting Full Import");
    setStatus(Status.RUNNING_FULL_DUMP);

    setIndexStartTime(new Date());

    try {
      docBuilder = new DocBuilder(this, writer, requestParams);
      checkWritablePersistFile(writer);
      docBuilder.execute();
      if (!requestParams.debug)
        cumulativeStatistics.add(docBuilder.importStatistics);
    } catch (Throwable t) {
      SolrException.log(LOG, "Full Import failed", t);
      docBuilder.rollback();
    } finally {
      setStatus(Status.IDLE);
      config.clearCaches();
      DocBuilder.INSTANCE.set(null);
    }

  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419672178895/fstmerge_base_3917907324122760863
public void doFullImport(SolrWriter writer, RequestParams requestParams) {
    LOG.info("Starting Full Import");
    setStatus(Status.RUNNING_FULL_DUMP);

    setIndexStartTime(new Date());

    try {
      docBuilder = new DocBuilder(this, writer, requestParams);
      docBuilder.execute();
      if (!requestParams.debug)
        cumulativeStatistics.add(docBuilder.importStatistics);
    } catch (Throwable t) {
      SolrException.log(LOG, "Full Import failed", t);
      docBuilder.rollback();
    } finally {
      setStatus(Status.IDLE);
      config.clearCaches();
      DocBuilder.INSTANCE.set(null);
    }

  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419672178895/fstmerge_var2_5854837460429387336

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_83ce9_6b6a4/rev_83ce9-6b6a4/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DataImporter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419672178900/fstmerge_var1_6268134669715555734
public void doDeltaImport(SolrWriter writer, RequestParams requestParams) {
    LOG.info("Starting Delta Import");
    setStatus(Status.RUNNING_DELTA_DUMP);

    try {
      setIndexStartTime(new Date());
      docBuilder = new DocBuilder(this, writer, requestParams);
      checkWritablePersistFile(writer);
      docBuilder.execute();
      if (!requestParams.debug)
        cumulativeStatistics.add(docBuilder.importStatistics);
    } catch (Throwable t) {
      LOG.error("Delta Import Failed", t);
      docBuilder.rollback();
    } finally {
      setStatus(Status.IDLE);
      config.clearCaches();
      DocBuilder.INSTANCE.set(null);
    }

  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419672178900/fstmerge_base_361830364249798318
public void doDeltaImport(SolrWriter writer, RequestParams requestParams) {
    LOG.info("Starting Delta Import");
    setStatus(Status.RUNNING_DELTA_DUMP);

    try {
      setIndexStartTime(new Date());
      docBuilder = new DocBuilder(this, writer, requestParams);
      docBuilder.execute();
      if (!requestParams.debug)
        cumulativeStatistics.add(docBuilder.importStatistics);
    } catch (Throwable t) {
      LOG.error("Delta Import Failed", t);
      docBuilder.rollback();
    } finally {
      setStatus(Status.IDLE);
      config.clearCaches();
      DocBuilder.INSTANCE.set(null);
    }

  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419672178900/fstmerge_var2_998879848044258458

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_83ce9_6b6a4/rev_83ce9-6b6a4/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DataImporter.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_7e81f_3d177/rev_7e81f-3d177.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419673188072/fstmerge_var1_8697683379634347691
@Test
  @SuppressWarnings("unchecked")
  public void testNonWritablePersistFile() throws Exception {
    // See SOLR-2551
    String configDir = h.getCore().getResourceLoader().getConfigDir();
    String filePath = configDir;
    if (configDir != null && !configDir.endsWith(File.separator))
      filePath += File.separator;
    filePath += "dataimport.properties";
    File f = new File(filePath);
    // execute the test only if we are able to set file to read only mode
    if ((f.exists() || f.createNewFile()) && f.setReadOnly()) {
      try {
        List parentRow = new ArrayList();
        parentRow.add(createMap("id", "1"));
        MockDataSource.setIterator(FULLIMPORT_QUERY, parentRow.iterator());

        List childRow = new ArrayList();
        childRow.add(createMap("desc", "hello"));
        MockDataSource.setIterator("select * from y where y.A='1'", childRow
            .iterator());

        runFullImport(dataConfig_delta);
        assertQ(req("id:1"), "//*[@numFound='0']");
      } finally {
        f.delete();
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419673188072/fstmerge_base_7462353450978584091
@Test
  @SuppressWarnings("unchecked")
  public void testNonWritablePersistFile() throws Exception {
    // See SOLR-2551
    String configDir = h.getCore().getResourceLoader().getConfigDir();
    String filePath = configDir;
    if (configDir != null && !configDir.endsWith(File.separator))
      filePath += File.separator;
    filePath += "dataimport.properties";
    File f = new File(filePath);
    // execute the test only if we are able to set file to read only mode
    if ((f.exists() || f.createNewFile()) && f.setReadOnly()) {
      try {
        List parentRow = new ArrayList();
        parentRow.add(createMap("id", "1"));
        MockDataSource.setIterator(FULLIMPORT_QUERY, parentRow.iterator());

        List childRow = new ArrayList();
        childRow.add(createMap("desc", "hello"));
        MockDataSource.setIterator("select * from y where y.A='1'", childRow
            .iterator());

        runFullImport(dataConfig_delta);
        assertQ(req("id:1"), "//*[@numFound='0']");
      } finally {
        f.setWritable(true);
      }
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419673188072/fstmerge_var2_2775807160213911500

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_7e81f_3d177/rev_7e81f-3d177/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestSqlEntityProcessorDelta.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_3b9d2_64c5d/rev_3b9d2-64c5d.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_51204_73188/rev_51204-73188.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_97d59_a7bd9/rev_97d59-a7bd9.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_41547_3be39/rev_41547-3be39.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_00ec8_f9562/rev_00ec8-f9562.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_68143_39747/rev_68143-39747.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419679237504/fstmerge_var1_1704727439779500195
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419679237504/fstmerge_base_6992587354021087728
public CustomScoreQuery(Query subQuery, ValueSourceQuery valSrcQuery) {
	  this(subQuery, valSrcQuery!=null ? // don't want an array that contains a single null.. 
        new ValueSourceQuery[] {valSrcQuery} : new ValueSourceQuery[0]);
  }
=======
public CustomScoreQuery(Query subQuery, ValueSourceQuery... valSrcQueries) {
    this.subQuery = subQuery;
    this.valSrcQueries = valSrcQueries!=null?
        valSrcQueries : new ValueSourceQuery[0];
    if (subQuery == null) throw new IllegalArgumentException("<subquery> must not be null!");
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419679237504/fstmerge_var2_2183689941535544071

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_68143_39747/rev_68143-39747/lucene/src/java/org/apache/lucene/search/function/CustomScoreQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419679237744/fstmerge_var1_7417477499721397955
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419679237744/fstmerge_base_2798819655055477639
public float customScore(int doc, float subQueryScore, float valSrcScores[]) throws IOException {
    if (valSrcScores.length == 1) {
      return customScore(doc, subQueryScore, valSrcScores[0]);
    }
    if (valSrcScores.length == 0) {
      return customScore(doc, subQueryScore, 1);
    }
    float score = subQueryScore;
    for(int i = 0; i < valSrcScores.length; i++) {
      score *= valSrcScores[i];
    }
    return score;
  }
=======
public float customScore(int doc, float subQueryScore, float valSrcScore) throws IOException {
    return subQueryScore * valSrcScore;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419679237744/fstmerge_var2_4969775895549709751

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_68143_39747/rev_68143-39747/lucene/src/java/org/apache/lucene/search/function/CustomScoreProvider.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419679237753/fstmerge_var1_3110166430510733360
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419679237753/fstmerge_base_9188551768982669952
public Explanation customExplain(int doc, Explanation subQueryExpl, Explanation valSrcExpls[]) throws IOException {
    if (valSrcExpls.length == 1) {
      return customExplain(doc, subQueryExpl, valSrcExpls[0]);
    }
    if (valSrcExpls.length == 0) {
      return subQueryExpl;
    }
    float valSrcScore = 1;
    for (int i = 0; i < valSrcExpls.length; i++) {
      valSrcScore *= valSrcExpls[i].getValue();
    }
    Explanation exp = new Explanation( valSrcScore * subQueryExpl.getValue(), "custom score: product of:");
    exp.addDetail(subQueryExpl);
    for (int i = 0; i < valSrcExpls.length; i++) {
      exp.addDetail(valSrcExpls[i]);
    }
    return exp;
  }
=======
public Explanation customExplain(int doc, Explanation subQueryExpl, Explanation valSrcExpl) throws IOException {
    float valSrcScore = 1;
    if (valSrcExpl != null) {
      valSrcScore *= valSrcExpl.getValue();
    }
    Explanation exp = new Explanation( valSrcScore * subQueryExpl.getValue(), "custom score: product of:");
    exp.addDetail(subQueryExpl);
    exp.addDetail(valSrcExpl);
    return exp;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419679237753/fstmerge_var2_4531096173557077478

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_68143_39747/rev_68143-39747/lucene/src/java/org/apache/lucene/search/function/CustomScoreProvider.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae.revisions
Conflict type: LineBasedMCFd
Conflict body: 
private void doTestDgaps(int size, int count1, int count2) throws IOException {
      MockDirectoryWrapper d = new  MockDirectoryWrapper(random, new RAMDirectory());
      d.setPreventDoubleWrite(false);
      BitVector bv = new BitVector(size);
      bv.invertAll();
      for (int i=0; i<count1; i++) {
        bv.clear(i);
        assertEquals(i+1,size-bv.count());
      }
      bv.write(d, "TESTBV", newIOContext(random));
      // gradually increase number of set bits
      for (int i=count1; i<count2; i++) {
        BitVector bv2 = new BitVector(d, "TESTBV", newIOContext(random));
        assertTrue(doCompare(bv,bv2));
        bv = bv2;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680269802/fstmerge_var1_8358126084914648594
        bv.clear(i);
        assertEquals(i+1,size-bv.count());
        bv.write(d, "TESTBV");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680269802/fstmerge_base_5720594877746859927
        bv.set(i);
        assertEquals(i+1,bv.count());
        bv.write(d, "TESTBV");
=======
        bv.set(i);
        assertEquals(i+1,bv.count());
        bv.write(d, "TESTBV", newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680269802/fstmerge_var2_6357407719737665570
      }
      // now start decreasing number of set bits
      for (int i=count2-1; i>=count1; i--) {
        BitVector bv2 = new BitVector(d, "TESTBV", newIOContext(random));
        assertTrue(doCompare(bv,bv2));
        bv = bv2;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680269802/fstmerge_var1_8358126084914648594
        bv.set(i);
        assertEquals(i,size-bv.count());
        bv.write(d, "TESTBV");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680269802/fstmerge_base_5720594877746859927
        bv.clear(i);
        assertEquals(i,bv.count());
        bv.write(d, "TESTBV");
=======
        bv.clear(i);
        assertEquals(i,bv.count());
        bv.write(d, "TESTBV", newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680269802/fstmerge_var2_6357407719737665570
      }
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/test/org/apache/lucene/util/TestBitVector.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testSingleFile() throws IOException {
        int data[] = new int[] { 0, 1, 10, 100 };
        for (int i=0; i<data.length; i++) {
            String name = "t" + data[i];
            createSequenceFile(dir, name, (byte) 0, data[i]);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273418/fstmerge_var1_9059665043953601760
            CompoundFileDirectory csw = dir.createCompoundOutput(name + ".cfs");
            dir.copy(csw, name, name);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273418/fstmerge_base_8225427715689557013
            CompoundFileWriter csw = new CompoundFileWriter(dir, name + ".cfs");
            csw.addFile(name);
=======
            CompoundFileWriter csw = new CompoundFileWriter(dir, name + ".cfs", newIOContext(random));
            csw.addFile(name);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273418/fstmerge_var2_4874238345684497429
            csw.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273418/fstmerge_var1_9059665043953601760
            CompoundFileDirectory csr = dir.openCompoundInput(name + ".cfs", 1024);
            IndexInput expected = dir.openInput(name);
            IndexInput actual = csr.openInput(name);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273418/fstmerge_base_8225427715689557013
            CompoundFileReader csr = new CompoundFileReader(dir, name + ".cfs");
            IndexInput expected = dir.openInput(name);
            IndexInput actual = csr.openInput(name);
=======
            CompoundFileReader csr = new CompoundFileReader(dir, name + ".cfs", newIOContext(random));
            IndexInput expected = dir.openInput(name, newIOContext(random));
            IndexInput actual = csr.openInput(name, newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273418/fstmerge_var2_4874238345684497429
            assertSameStreams(name, expected, actual);
            assertSameSeekBehavior(name, expected, actual);
            expected.close();
            actual.close();
            csr.close();
        }
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/test/org/apache/lucene/index/TestCompoundFile.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testTwoFiles() throws IOException {
        createSequenceFile(dir, "d1", (byte) 0, 15);
        createSequenceFile(dir, "d2", (byte) 0, 114);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273424/fstmerge_var1_3108432852152197351
        CompoundFileDirectory csw = dir.createCompoundOutput("d.cfs");
        dir.copy(csw, "d1", "d1");
        dir.copy(csw, "d2", "d2");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273424/fstmerge_base_4664502618829126650
        CompoundFileWriter csw = new CompoundFileWriter(dir, "d.csf");
        csw.addFile("d1");
        csw.addFile("d2");
=======
        CompoundFileWriter csw = new CompoundFileWriter(dir, "d.csf", newIOContext(random));
        csw.addFile("d1");
        csw.addFile("d2");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273424/fstmerge_var2_8712292997996371626
        csw.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273424/fstmerge_var1_3108432852152197351
        CompoundFileDirectory csr = dir.openCompoundInput("d.cfs", 1024);
        IndexInput expected = dir.openInput("d1");
        IndexInput actual = csr.openInput("d1");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273424/fstmerge_base_4664502618829126650
        CompoundFileReader csr = new CompoundFileReader(dir, "d.csf");
        IndexInput expected = dir.openInput("d1");
        IndexInput actual = csr.openInput("d1");
=======
        CompoundFileReader csr = new CompoundFileReader(dir, "d.csf", newIOContext(random));
        IndexInput expected = dir.openInput("d1", newIOContext(random));
        IndexInput actual = csr.openInput("d1", newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273424/fstmerge_var2_8712292997996371626
        assertSameStreams("d1", expected, actual);
        assertSameSeekBehavior("d1", expected, actual);
        expected.close();
        actual.close();

        expected = dir.openInput("d2", newIOContext(random));
        actual = csr.openInput("d2", newIOContext(random));
        assertSameStreams("d2", expected, actual);
        assertSameSeekBehavior("d2", expected, actual);
        expected.close();
        actual.close();
        csr.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/test/org/apache/lucene/index/TestCompoundFile.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testRandomFiles() throws IOException {
        // Setup the test segment
        String segment = "test";
        int chunk = 1024; // internal buffer size used by the stream
        createRandomFile(dir, segment + ".zero", 0);
        createRandomFile(dir, segment + ".one", 1);
        createRandomFile(dir, segment + ".ten", 10);
        createRandomFile(dir, segment + ".hundred", 100);
        createRandomFile(dir, segment + ".big1", chunk);
        createRandomFile(dir, segment + ".big2", chunk - 1);
        createRandomFile(dir, segment + ".big3", chunk + 1);
        createRandomFile(dir, segment + ".big4", 3 * chunk);
        createRandomFile(dir, segment + ".big5", 3 * chunk - 1);
        createRandomFile(dir, segment + ".big6", 3 * chunk + 1);
        createRandomFile(dir, segment + ".big7", 1000 * chunk);

        // Setup extraneous files
        createRandomFile(dir, "onetwothree", 100);
        createRandomFile(dir, segment + ".notIn", 50);
        createRandomFile(dir, segment + ".notIn2", 51);

        // Now test
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273428/fstmerge_var1_3701403951985747038
        CompoundFileDirectory csw = dir.createCompoundOutput("test.cfs");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273428/fstmerge_base_4141977577220854741
        CompoundFileWriter csw = new CompoundFileWriter(dir, "test.cfs");
=======
        CompoundFileWriter csw = new CompoundFileWriter(dir, "test.cfs", newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273428/fstmerge_var2_1497294979157342331
        final String data[] = new String[] {
            ".zero", ".one", ".ten", ".hundred", ".big1", ".big2", ".big3",
            ".big4", ".big5", ".big6", ".big7"
        };
        for (int i=0; i<data.length; i++) {
            String fileName = segment + data[i];
            dir.copy(csw, fileName, fileName);
        }
        csw.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273428/fstmerge_var1_3701403951985747038
        CompoundFileDirectory csr = dir.openCompoundInput("test.cfs", 1024);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273428/fstmerge_base_4141977577220854741
        CompoundFileReader csr = new CompoundFileReader(dir, "test.cfs");
=======
        CompoundFileReader csr = new CompoundFileReader(dir, "test.cfs", newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273428/fstmerge_var2_1497294979157342331
        for (int i=0; i<data.length; i++) {
            IndexInput check = dir.openInput(segment + data[i], newIOContext(random));
            IndexInput test = csr.openInput(segment + data[i], newIOContext(random));
            assertSameStreams(data[i], check, test);
            assertSameSeekBehavior(data[i], check, test);
            test.close();
            check.close();
        }
        csr.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/test/org/apache/lucene/index/TestCompoundFile.java
Conflict type: LineBasedMCFd
Conflict body: 
private void setUp_2() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273433/fstmerge_var1_1117641408833839635
        CompoundFileDirectory cw = dir.createCompoundOutput("f.comp");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273433/fstmerge_base_5192318757274043238
        CompoundFileWriter cw = new CompoundFileWriter(dir, "f.comp");
=======
        CompoundFileWriter cw = new CompoundFileWriter(dir, "f.comp", newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273433/fstmerge_var2_3050772190081599652
        for (int i=0; i<20; i++) {
            createSequenceFile(dir, "f" + i, (byte) 0, 2000);
            String fileName = "f" + i;
            dir.copy(cw, fileName, fileName);
        }
        cw.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/test/org/apache/lucene/index/TestCompoundFile.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testClonedStreamsClosing() throws IOException {
        setUp_2();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273456/fstmerge_var1_6262118097112700920
        CompoundFileDirectory cr = dir.openCompoundInput("f.comp", 1024);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273456/fstmerge_base_489822165289336336
        CompoundFileReader cr = new CompoundFileReader(dir, "f.comp");
=======
        CompoundFileReader cr = new CompoundFileReader(dir, "f.comp", newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273456/fstmerge_var2_8357000061518925842

        // basic clone
        IndexInput expected = dir.openInput("f11", newIOContext(random));

        // this test only works for FSIndexInput
        assertTrue(_TestHelper.isSimpleFSIndexInput(expected));
        assertTrue(_TestHelper.isSimpleFSIndexInputOpen(expected));

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273456/fstmerge_var1_6262118097112700920
        IndexInput one = cr.openInput("f11");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273456/fstmerge_base_489822165289336336
        IndexInput one = cr.openInput("f11");
        assertTrue(isCSIndexInputOpen(one));
=======
        IndexInput one = cr.openInput("f11", newIOContext(random));
        assertTrue(isCSIndexInputOpen(one));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273456/fstmerge_var2_8357000061518925842

        IndexInput two = (IndexInput) one.clone();

        assertSameStreams("basic clone one", expected, one);
        expected.seek(0);
        assertSameStreams("basic clone two", expected, two);

        // Now close the first stream
        one.close();

        // The following should really fail since we couldn't expect to
        // access a file once close has been called on it (regardless of
        // buffering and/or clone magic)
        expected.seek(0);
        two.seek(0);
        assertSameStreams("basic clone two/2", expected, two);


        // Now close the compound reader
        cr.close();

        // The following may also fail since the compound stream is closed
        expected.seek(0);
        two.seek(0);
        //assertSameStreams("basic clone two/3", expected, two);


        // Now close the second clone
        two.close();
        expected.seek(0);
        two.seek(0);
        //assertSameStreams("basic clone two/4", expected, two);

        expected.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/test/org/apache/lucene/index/TestCompoundFile.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testRandomAccess() throws IOException {
        setUp_2();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273461/fstmerge_var1_6726223006815050016
        CompoundFileDirectory cr = dir.openCompoundInput("f.comp", 1024);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273461/fstmerge_base_2092179320428714534
        CompoundFileReader cr = new CompoundFileReader(dir, "f.comp");
=======
        CompoundFileReader cr = new CompoundFileReader(dir, "f.comp", newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273461/fstmerge_var2_1784558026736644486

        // Open two files
        IndexInput e1 = dir.openInput("f11", newIOContext(random));
        IndexInput e2 = dir.openInput("f3", newIOContext(random));

        IndexInput a1 = cr.openInput("f11", newIOContext(random));
        IndexInput a2 = dir.openInput("f3", newIOContext(random));

        // Seek the first pair
        e1.seek(100);
        a1.seek(100);
        assertEquals(100, e1.getFilePointer());
        assertEquals(100, a1.getFilePointer());
        byte be1 = e1.readByte();
        byte ba1 = a1.readByte();
        assertEquals(be1, ba1);

        // Now seek the second pair
        e2.seek(1027);
        a2.seek(1027);
        assertEquals(1027, e2.getFilePointer());
        assertEquals(1027, a2.getFilePointer());
        byte be2 = e2.readByte();
        byte ba2 = a2.readByte();
        assertEquals(be2, ba2);

        // Now make sure the first one didn't move
        assertEquals(101, e1.getFilePointer());
        assertEquals(101, a1.getFilePointer());
        be1 = e1.readByte();
        ba1 = a1.readByte();
        assertEquals(be1, ba1);

        // Now more the first one again, past the buffer length
        e1.seek(1910);
        a1.seek(1910);
        assertEquals(1910, e1.getFilePointer());
        assertEquals(1910, a1.getFilePointer());
        be1 = e1.readByte();
        ba1 = a1.readByte();
        assertEquals(be1, ba1);

        // Now make sure the second set didn't move
        assertEquals(1028, e2.getFilePointer());
        assertEquals(1028, a2.getFilePointer());
        be2 = e2.readByte();
        ba2 = a2.readByte();
        assertEquals(be2, ba2);

        // Move the second set back, again cross the buffer size
        e2.seek(17);
        a2.seek(17);
        assertEquals(17, e2.getFilePointer());
        assertEquals(17, a2.getFilePointer());
        be2 = e2.readByte();
        ba2 = a2.readByte();
        assertEquals(be2, ba2);

        // Finally, make sure the first set didn't move
        // Now make sure the first one didn't move
        assertEquals(1911, e1.getFilePointer());
        assertEquals(1911, a1.getFilePointer());
        be1 = e1.readByte();
        ba1 = a1.readByte();
        assertEquals(be1, ba1);

        e1.close();
        e2.close();
        a1.close();
        a2.close();
        cr.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/test/org/apache/lucene/index/TestCompoundFile.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testRandomAccessClones() throws IOException {
        setUp_2();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273466/fstmerge_var1_1664425572470126869
        CompoundFileDirectory cr = dir.openCompoundInput("f.comp", 1024);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273466/fstmerge_base_4367852870970096179
        CompoundFileReader cr = new CompoundFileReader(dir, "f.comp");
=======
        CompoundFileReader cr = new CompoundFileReader(dir, "f.comp", newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273466/fstmerge_var2_6418606955333217381

        // Open two files
        IndexInput e1 = cr.openInput("f11", newIOContext(random));
        IndexInput e2 = cr.openInput("f3", newIOContext(random));

        IndexInput a1 = (IndexInput) e1.clone();
        IndexInput a2 = (IndexInput) e2.clone();

        // Seek the first pair
        e1.seek(100);
        a1.seek(100);
        assertEquals(100, e1.getFilePointer());
        assertEquals(100, a1.getFilePointer());
        byte be1 = e1.readByte();
        byte ba1 = a1.readByte();
        assertEquals(be1, ba1);

        // Now seek the second pair
        e2.seek(1027);
        a2.seek(1027);
        assertEquals(1027, e2.getFilePointer());
        assertEquals(1027, a2.getFilePointer());
        byte be2 = e2.readByte();
        byte ba2 = a2.readByte();
        assertEquals(be2, ba2);

        // Now make sure the first one didn't move
        assertEquals(101, e1.getFilePointer());
        assertEquals(101, a1.getFilePointer());
        be1 = e1.readByte();
        ba1 = a1.readByte();
        assertEquals(be1, ba1);

        // Now more the first one again, past the buffer length
        e1.seek(1910);
        a1.seek(1910);
        assertEquals(1910, e1.getFilePointer());
        assertEquals(1910, a1.getFilePointer());
        be1 = e1.readByte();
        ba1 = a1.readByte();
        assertEquals(be1, ba1);

        // Now make sure the second set didn't move
        assertEquals(1028, e2.getFilePointer());
        assertEquals(1028, a2.getFilePointer());
        be2 = e2.readByte();
        ba2 = a2.readByte();
        assertEquals(be2, ba2);

        // Move the second set back, again cross the buffer size
        e2.seek(17);
        a2.seek(17);
        assertEquals(17, e2.getFilePointer());
        assertEquals(17, a2.getFilePointer());
        be2 = e2.readByte();
        ba2 = a2.readByte();
        assertEquals(be2, ba2);

        // Finally, make sure the first set didn't move
        // Now make sure the first one didn't move
        assertEquals(1911, e1.getFilePointer());
        assertEquals(1911, a1.getFilePointer());
        be1 = e1.readByte();
        ba1 = a1.readByte();
        assertEquals(be1, ba1);

        e1.close();
        e2.close();
        a1.close();
        a2.close();
        cr.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/test/org/apache/lucene/index/TestCompoundFile.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testFileNotFound() throws IOException {
        setUp_2();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273471/fstmerge_var1_5867909927729585094
        CompoundFileDirectory cr = dir.openCompoundInput("f.comp", 1024);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273471/fstmerge_base_1962757181943020273
        CompoundFileReader cr = new CompoundFileReader(dir, "f.comp");
=======
        CompoundFileReader cr = new CompoundFileReader(dir, "f.comp", newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273471/fstmerge_var2_7614446129409015608

        // Open two files
        try {
            cr.openInput("bogus", newIOContext(random));
            fail("File not found");

        } catch (IOException e) {
            /* success */
            //System.out.println("SUCCESS: File Not Found: " + e);
        }

        cr.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/test/org/apache/lucene/index/TestCompoundFile.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testReadPastEOF() throws IOException {
        setUp_2();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273476/fstmerge_var1_3168778692657229546
        CompoundFileDirectory cr = dir.openCompoundInput("f.comp", 1024);
        IndexInput is = cr.openInput("f2");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273476/fstmerge_base_1767862269140273079
        CompoundFileReader cr = new CompoundFileReader(dir, "f.comp");
        IndexInput is = cr.openInput("f2");
=======
        CompoundFileReader cr = new CompoundFileReader(dir, "f.comp", newIOContext(random));
        IndexInput is = cr.openInput("f2", newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273476/fstmerge_var2_5384317966872143277
        is.seek(is.length() - 10);
        byte b[] = new byte[100];
        is.readBytes(b, 0, 10);

        try {
            is.readByte();
            fail("Single byte read past end of file");
        } catch (IOException e) {
            /* success */
            //System.out.println("SUCCESS: single byte read past end of file: " + e);
        }

        is.seek(is.length() - 10);
        try {
            is.readBytes(b, 0, 50);
            fail("Block read past end of file");
        } catch (IOException e) {
            /* success */
            //System.out.println("SUCCESS: block read past end of file: " + e);
        }

        is.close();
        cr.close();
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/test/org/apache/lucene/index/TestCompoundFile.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testAddExternalFile() throws IOException {
       createSequenceFile(dir, "d1", (byte) 0, 15);

       Directory newDir = newDirectory();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273485/fstmerge_var1_5676127827190147721
       CompoundFileDirectory csw = newDir.createCompoundOutput("d.cfs");
       dir.copy(csw, "d1", "d1");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273485/fstmerge_base_368067512530149261
       CompoundFileWriter csw = new CompoundFileWriter(newDir, "d.csf");
       csw.addFile("d1", dir);
=======
       CompoundFileWriter csw = new CompoundFileWriter(newDir, "d.csf", newIOContext(random));
       csw.addFile("d1", dir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273485/fstmerge_var2_4872015635924777494
       csw.close();

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273485/fstmerge_var1_5676127827190147721
       CompoundFileDirectory csr = newDir.openCompoundInput("d.cfs", 1024);
       IndexInput expected = dir.openInput("d1");
       IndexInput actual = csr.openInput("d1");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273485/fstmerge_base_368067512530149261
       CompoundFileReader csr = new CompoundFileReader(newDir, "d.csf");
       IndexInput expected = dir.openInput("d1");
       IndexInput actual = csr.openInput("d1");
=======
       CompoundFileReader csr = new CompoundFileReader(newDir, "d.csf", newIOContext(random));
       IndexInput expected = dir.openInput("d1", newIOContext(random));
       IndexInput actual = csr.openInput("d1", newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680273485/fstmerge_var2_4872015635924777494
       assertSameStreams("d1", expected, actual);
       assertSameSeekBehavior("d1", expected, actual);
       expected.close();
       actual.close();
       csr.close();
       
       newDir.close();
   }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/test/org/apache/lucene/index/TestCompoundFile.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testExactFileNames() throws IOException {

    String outputDirName = "lucene.backwardscompat0.index";
    File outputDir = _TestUtil.getTempDir(outputDirName);
    _TestUtil.rmDir(outputDir);

    try {
      Directory dir = newFSDirectory(outputDir);

      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);
      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS

      IndexWriter writer = new IndexWriter(
          dir,
          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).
              setMaxBufferedDocs(-1).
              setRAMBufferSizeMB(16.0).
              setMergePolicy(mergePolicy)
      );
      for(int i=0;i<35;i++) {
        addDoc(writer, i);
      }
      assertEquals("wrong doc count", 35, writer.maxDoc());
      writer.close();

      // Delete one doc so we get a .del file:
      IndexReader reader = IndexReader.open(dir, false);
      Term searchTerm = new Term("id", "7");
      int delCount = reader.deleteDocuments(searchTerm);
      assertEquals("didn't delete the right number of documents", 1, delCount);

      // Set one norm so we get a .s0 file:
      Similarity sim = new DefaultSimilarity();
      reader.setNorm(21, "content", sim.encodeNormValue(1.5f));
      reader.close();

      // The numbering of fields can vary depending on which
      // JRE is in use.  On some JREs we see content bound to
      // field 0; on others, field 1.  So, here we have to
      // figure out which field number corresponds to
      // "content", and then set our expected file names below
      // accordingly:
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680275182/fstmerge_var1_4632240545811167895
      CompoundFileDirectory cfsReader = dir.openCompoundInput("_0.cfs", 1024);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680275182/fstmerge_base_7954506674584095747
      CompoundFileReader cfsReader = new CompoundFileReader(dir, "_0.cfs");
=======
      CompoundFileReader cfsReader = new CompoundFileReader(dir, "_0.cfs", newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680275182/fstmerge_var2_5289469532299528788
      FieldInfos fieldInfos = new FieldInfos(cfsReader, "_0.fnm");
      int contentFieldIndex = -1;
      for (FieldInfo fi : fieldInfos) {
        if (fi.name.equals("content")) {
          contentFieldIndex = fi.number;
          break;
        }
      }
      cfsReader.close();
      assertTrue("could not locate the 'content' field number in the _2.cfs segment", contentFieldIndex != -1);

      // Now verify file names:
      String[] expected = new String[] {"_0.cfs", "_0.cfe",
                               "_0_1.del",
                               "_0_1.s" + contentFieldIndex,
                               "segments_2",
                               "segments.gen",
                               "1.fnx"};

      String[] actual = dir.listAll();
      Arrays.sort(expected);
      Arrays.sort(actual);
      if (!Arrays.equals(expected, actual)) {
        fail("incorrect filenames in index: expected:\n    " + asString(expected) + "\n  actual:\n    " + asString(actual));
      }
      dir.close();
    } finally {
      _TestUtil.rmDir(outputDir);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testDeleteLeftoverFiles() throws IOException {
    MockDirectoryWrapper dir = newDirectory();
    dir.setPreventDoubleWrite(false);

    LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);
    mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS

    IndexWriter writer = new IndexWriter(
        dir,
        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).
            setMaxBufferedDocs(10).
            setMergePolicy(mergePolicy)
    );

    writer.setInfoStream(VERBOSE ? System.out : null);

    int i;
    for(i=0;i<35;i++) {
      addDoc(writer, i);
    }
    mergePolicy.setUseCompoundFile(false);
    for(;i<45;i++) {
      addDoc(writer, i);
    }
    writer.close();

    // Delete one doc so we get a .del file:
    IndexReader reader = IndexReader.open(dir, false);
    Term searchTerm = new Term("id", "7");
    int delCount = reader.deleteDocuments(searchTerm);
    assertEquals("didn't delete the right number of documents", 1, delCount);
    Similarity sim = new DefaultSimilarity();
    // Set one norm so we get a .s0 file:
    reader.setNorm(21, "content", sim.encodeNormValue(1.5f));
    reader.close();

    // Now, artificially create an extra .del file & extra
    // .s0 file:
    String[] files = dir.listAll();

    /*
    for(int j=0;j<files.length;j++) {
      System.out.println(j + ": " + files[j]);
    }
    */

    // The numbering of fields can vary depending on which
    // JRE is in use.  On some JREs we see content bound to
    // field 0; on others, field 1.  So, here we have to
    // figure out which field number corresponds to
    // "content", and then set our expected file names below
    // accordingly:
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680275356/fstmerge_var1_7280800956404055029
    CompoundFileDirectory cfsReader = dir.openCompoundInput("_2.cfs", 1024);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680275356/fstmerge_base_6297738282942776664
    CompoundFileReader cfsReader = new CompoundFileReader(dir, "_2.cfs");
=======
    CompoundFileReader cfsReader = new CompoundFileReader(dir, "_2.cfs", newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680275356/fstmerge_var2_442601315194999620
    FieldInfos fieldInfos = new FieldInfos(cfsReader, "_2.fnm");
    int contentFieldIndex = -1;
    for (FieldInfo fi : fieldInfos) {
      if (fi.name.equals("content")) {
        contentFieldIndex = fi.number;
        break;
      }
    }
    cfsReader.close();
    assertTrue("could not locate the 'content' field number in the _2.cfs segment", contentFieldIndex != -1);

    String normSuffix = "s" + contentFieldIndex;

    // Create a bogus separate norms file for a
    // segment/field that actually has a separate norms file
    // already:
    copyFile(dir, "_2_1." + normSuffix, "_2_2." + normSuffix);

    // Create a bogus separate norms file for a
    // segment/field that actually has a separate norms file
    // already, using the "not compound file" extension:
    copyFile(dir, "_2_1." + normSuffix, "_2_2.f" + contentFieldIndex);

    // Create a bogus separate norms file for a
    // segment/field that does not have a separate norms
    // file already:
    copyFile(dir, "_2_1." + normSuffix, "_1_1." + normSuffix);

    // Create a bogus separate norms file for a
    // segment/field that does not have a separate norms
    // file already using the "not compound file" extension:
    copyFile(dir, "_2_1." + normSuffix, "_1_1.f" + contentFieldIndex);

    // Create a bogus separate del file for a
    // segment that already has a separate del file: 
    copyFile(dir, "_0_1.del", "_0_2.del");

    // Create a bogus separate del file for a
    // segment that does not yet have a separate del file:
    copyFile(dir, "_0_1.del", "_1_1.del");

    // Create a bogus separate del file for a
    // non-existent segment:
    copyFile(dir, "_0_1.del", "_188_1.del");

    // Create a bogus segment file:
    copyFile(dir, "_0.cfs", "_188.cfs");

    // Create a bogus fnm file when the CFS already exists:
    copyFile(dir, "_0.cfs", "_0.fnm");
    
    // Create some old segments file:
    copyFile(dir, "segments_2", "segments");
    copyFile(dir, "segments_2", "segments_1");

    // Create a bogus cfs file shadowing a non-cfs segment:
    assertTrue(dir.fileExists("_3.fdt"));
    assertTrue(!dir.fileExists("_3.cfs"));
    copyFile(dir, "_1.cfs", "_3.cfs");
    
    String[] filesPre = dir.listAll();

    // Open & close a writer: it should delete the above 4
    // files and nothing more:
    writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));
    writer.close();

    String[] files2 = dir.listAll();
    dir.close();

    Arrays.sort(files);
    Arrays.sort(files2);
    
    Set<String> dif = difFiles(files, files2);
    
    if (!Arrays.equals(files, files2)) {
      fail("IndexFileDeleter failed to delete unreferenced extra files: should have deleted " + (filesPre.length-files.length) + " files but only deleted " + (filesPre.length - files2.length) + "; expected files:\n    " + asString(files) + "\n  actual files:\n    " + asString(files2)+"\ndif: "+dif);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/test/org/apache/lucene/index/TestIndexFileDeleter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680276444/fstmerge_var1_6414390198034860874
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680276444/fstmerge_base_4504886254354741523
public void testInts() throws IOException {
    long[] maxMin = new long[] { 
        Long.MIN_VALUE, Long.MAX_VALUE,
        1, Long.MAX_VALUE,
        0, Long.MAX_VALUE,
        -1, Long.MAX_VALUE,
        Long.MIN_VALUE, -1,
        random.nextInt(), random.nextInt() };
    for (int j = 0; j < maxMin.length; j+=2) {
      long maxV = 1;
      final int NUM_VALUES = 777 + random.nextInt(777);
      final long[] values = new long[NUM_VALUES];
      for (int rx = 1; rx < 63; rx++, maxV *= 2) {
        Directory dir = newDirectory();
        final AtomicLong trackBytes = new AtomicLong(0);
        Writer w = Ints.getWriter(dir, "test", false, trackBytes);
        values[0] = maxMin[j];
        w.add(0, values[0]);
        values[1] = maxMin[j+1];
        w.add(1, values[1]);
        for (int i = 2; i < NUM_VALUES; i++) {
          final long v = random.nextLong() % (1 + maxV);
          values[i] = v;
          w.add(i, v);
        }
        final int additionalDocs = 1 + random.nextInt(9);
        w.finish(NUM_VALUES + additionalDocs);
        assertEquals(0, trackBytes.get());

        IndexDocValues r = Ints.getValues(dir, "test", false);
        for (int iter = 0; iter < 2; iter++) {
          Source s = getSource(r);
          for (int i = 0; i < NUM_VALUES; i++) {
            final long v = s.getInt(i);
            assertEquals("index " + i, values[i], v);
          }
        }

        for (int iter = 0; iter < 2; iter++) {
          ValuesEnum iEnum = getEnum(r);
          LongsRef ints = iEnum.getInt();
          for (int i = 0; i < NUM_VALUES + additionalDocs; i++) {
            assertEquals(i, iEnum.nextDoc());
            if (i < NUM_VALUES) {
              assertEquals(values[i], ints.get());
            } else {
              assertEquals(0, ints.get());
            }
          }
          assertEquals(ValuesEnum.NO_MORE_DOCS, iEnum.nextDoc());
          iEnum.close();
        }

        for (int iter = 0; iter < 2; iter++) {
          ValuesEnum iEnum = getEnum(r);
          LongsRef ints = iEnum.getInt();
          for (int i = 0; i < NUM_VALUES + additionalDocs; i += 1 + random.nextInt(25)) {
            assertEquals(i, iEnum.advance(i));
            if (i < NUM_VALUES) {
              assertEquals(values[i], ints.get());
            } else {
              assertEquals(0, ints.get());
            }
          }
          assertEquals(ValuesEnum.NO_MORE_DOCS, iEnum.advance(NUM_VALUES + additionalDocs));
          iEnum.close();
        }
        r.close();
        dir.close();
      }
    }
  }
=======
public void testInts() throws IOException {
    long[] maxMin = new long[] { 
        Long.MIN_VALUE, Long.MAX_VALUE,
        1, Long.MAX_VALUE,
        0, Long.MAX_VALUE,
        -1, Long.MAX_VALUE,
        Long.MIN_VALUE, -1,
        random.nextInt(), random.nextInt() };
    for (int j = 0; j < maxMin.length; j+=2) {
      long maxV = 1;
      final int NUM_VALUES = 777 + random.nextInt(777);
      final long[] values = new long[NUM_VALUES];
      for (int rx = 1; rx < 63; rx++, maxV *= 2) {
        Directory dir = newDirectory();
        final AtomicLong trackBytes = new AtomicLong(0);
        Writer w = Ints.getWriter(dir, "test", false, trackBytes, newIOContext(random));
        values[0] = maxMin[j];
        w.add(0, values[0]);
        values[1] = maxMin[j+1];
        w.add(1, values[1]);
        for (int i = 2; i < NUM_VALUES; i++) {
          final long v = random.nextLong() % (1 + maxV);
          values[i] = v;
          w.add(i, v);
        }
        final int additionalDocs = 1 + random.nextInt(9);
        w.finish(NUM_VALUES + additionalDocs);
        assertEquals(0, trackBytes.get());

        IndexDocValues r = Ints.getValues(dir, "test", false, newIOContext(random));
        for (int iter = 0; iter < 2; iter++) {
          Source s = getSource(r);
          for (int i = 0; i < NUM_VALUES; i++) {
            final long v = s.getInt(i);
            assertEquals("index " + i, values[i], v);
          }
        }

        for (int iter = 0; iter < 2; iter++) {
          ValuesEnum iEnum = getEnum(r);
          LongsRef ints = iEnum.getInt();
          for (int i = 0; i < NUM_VALUES + additionalDocs; i++) {
            assertEquals(i, iEnum.nextDoc());
            if (i < NUM_VALUES) {
              assertEquals(values[i], ints.get());
            } else {
              assertEquals(0, ints.get());
            }
          }
          assertEquals(ValuesEnum.NO_MORE_DOCS, iEnum.nextDoc());
          iEnum.close();
        }

        for (int iter = 0; iter < 2; iter++) {
          ValuesEnum iEnum = getEnum(r);
          LongsRef ints = iEnum.getInt();
          for (int i = 0; i < NUM_VALUES + additionalDocs; i += 1 + random.nextInt(25)) {
            assertEquals(i, iEnum.advance(i));
            if (i < NUM_VALUES) {
              assertEquals(values[i], ints.get());
            } else {
              assertEquals(0, ints.get());
            }
          }
          assertEquals(ValuesEnum.NO_MORE_DOCS, iEnum.advance(NUM_VALUES + additionalDocs));
          iEnum.close();
        }
        r.close();
        dir.close();
      }
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680276444/fstmerge_var2_8128793841293760174

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/test/org/apache/lucene/index/values/TestDocValues.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680283610/fstmerge_var1_4462197689830566064
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680283610/fstmerge_base_4004872874354637598
public CustomScoreQuery(Query subQuery, ValueSourceQuery valSrcQuery) {
	  this(subQuery, valSrcQuery!=null ? // don't want an array that contains a single null.. 
        new ValueSourceQuery[] {valSrcQuery} : new ValueSourceQuery[0]);
  }
=======
public CustomScoreQuery(Query subQuery, ValueSourceQuery... valSrcQueries) {
    this.subQuery = subQuery;
    this.valSrcQueries = valSrcQueries!=null?
        valSrcQueries : new ValueSourceQuery[0];
    if (subQuery == null) throw new IllegalArgumentException("<subquery> must not be null!");
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680283610/fstmerge_var2_2880142639138591704

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/search/function/CustomScoreQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680283858/fstmerge_var1_7254523512574915195
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680283858/fstmerge_base_6277670028603287381
public float customScore(int doc, float subQueryScore, float valSrcScores[]) throws IOException {
    if (valSrcScores.length == 1) {
      return customScore(doc, subQueryScore, valSrcScores[0]);
    }
    if (valSrcScores.length == 0) {
      return customScore(doc, subQueryScore, 1);
    }
    float score = subQueryScore;
    for(int i = 0; i < valSrcScores.length; i++) {
      score *= valSrcScores[i];
    }
    return score;
  }
=======
public float customScore(int doc, float subQueryScore, float valSrcScore) throws IOException {
    return subQueryScore * valSrcScore;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680283858/fstmerge_var2_1275399996861368238

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/search/function/CustomScoreProvider.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680283867/fstmerge_var1_5911811574571614331
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680283867/fstmerge_base_6903481360393495912
public Explanation customExplain(int doc, Explanation subQueryExpl, Explanation valSrcExpls[]) throws IOException {
    if (valSrcExpls.length == 1) {
      return customExplain(doc, subQueryExpl, valSrcExpls[0]);
    }
    if (valSrcExpls.length == 0) {
      return subQueryExpl;
    }
    float valSrcScore = 1;
    for (int i = 0; i < valSrcExpls.length; i++) {
      valSrcScore *= valSrcExpls[i].getValue();
    }
    Explanation exp = new Explanation( valSrcScore * subQueryExpl.getValue(), "custom score: product of:");
    exp.addDetail(subQueryExpl);
    for (int i = 0; i < valSrcExpls.length; i++) {
      exp.addDetail(valSrcExpls[i]);
    }
    return exp;
  }
=======
public Explanation customExplain(int doc, Explanation subQueryExpl, Explanation valSrcExpl) throws IOException {
    float valSrcScore = 1;
    if (valSrcExpl != null) {
      valSrcScore *= valSrcExpl.getValue();
    }
    Explanation exp = new Explanation( valSrcScore * subQueryExpl.getValue(), "custom score: product of:");
    exp.addDetail(subQueryExpl);
    exp.addDetail(valSrcExpl);
    return exp;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680283867/fstmerge_var2_7398843279925308756

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/search/function/CustomScoreProvider.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680288631/fstmerge_var1_9117391435587619309
public final void write(Directory d, String name) throws IOException {
    IndexOutput output = d.createOutput(name);
    try {
      output.writeInt(-2);
      CodecUtil.writeHeader(output, CODEC, VERSION_CURRENT);
      if (isSparse()) { 
        // sparse bit-set more efficiently saved as d-gaps.
        writeClearedDgaps(output);
      } else {
        writeBits(output);
      }
    } finally {
      output.close();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680288631/fstmerge_base_3407786109380773280
public final void write(Directory d, String name) throws IOException {
    IndexOutput output = d.createOutput(name);
    try {
      if (isSparse()) { 
        writeDgaps(output); // sparse bit-set more efficiently saved as d-gaps.
      } else {
        writeBits(output);
      }
    } finally {
      output.close();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680288631/fstmerge_var2_1873721564119966051

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/util/BitVector.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680288636/fstmerge_var1_140520795733383133
public BitVector(Directory d, String name) throws IOException {
    IndexInput input = d.openInput(name);

    try {
      final int firstInt = input.readInt();

      if (firstInt == -2) {
        // New format, with full header & version:
        version = CodecUtil.checkHeader(input, CODEC, VERSION_START, VERSION_CURRENT);
        size = input.readInt();
      } else {
        version = VERSION_PRE;
        size = firstInt;
      }
      if (size == -1) {
        if (version >= VERSION_DGAPS_CLEARED) {
          readClearedDgaps(input);
        } else {
          readSetDgaps(input);
        }
      } else {
        readBits(input);
      }
    } finally {
      input.close();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680288636/fstmerge_base_2279002668954864031
public BitVector(Directory d, String name) throws IOException {
    IndexInput input = d.openInput(name);
    try {
      size = input.readInt();       // read size
      if (size == -1) {
        readDgaps(input);
      } else {
        readBits(input);
      }
    } finally {
      input.close();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680288636/fstmerge_var2_7889117395708483363

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/util/BitVector.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680292472/fstmerge_var1_6889719098423418890
public void copy(Directory to, String src, String dest) throws IOException {
    IndexOutput os = null;
    IndexInput is = null;
    IOException priorException = null;
    try {
      os = to.createOutput(dest);
      is = openInput(src);
      is.copyBytes(os, is.length());
    } catch (IOException ioe) {
      priorException = ioe;
    } finally {
      IOUtils.closeSafely(priorException, os, is);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680292472/fstmerge_base_8483216108963225471
public void copy(Directory to, String src, String dest) throws IOException {
    IndexOutput os = to.createOutput(dest);
    IndexInput is = openInput(src);
    IOException priorException = null;
    try {
      is.copyBytes(os, is.length());
    } catch (IOException ioe) {
      priorException = ioe;
    } finally {
      IOUtils.closeSafely(priorException, os, is);
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680292472/fstmerge_var2_3398674975578736190

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/store/Directory.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680292652/fstmerge_var1_2418195097392682037
public SimpleFSIndexInput(File path, int bufferSize, int chunkSize) throws IOException {
      super(bufferSize);
      this.file = new Descriptor(path, "r"); 
      this.chunkSize = chunkSize;
      this.off = 0L;
      this.end = file.length;
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680292652/fstmerge_base_2952377860184083003
public SimpleFSIndexInput(File path, int bufferSize, int chunkSize) throws IOException {
      super(bufferSize);
      file = new Descriptor(path, "r");
      this.chunkSize = chunkSize;
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680292652/fstmerge_var2_1708246204432223550

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/store/SimpleFSDirectory.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680293140/fstmerge_var1_4676395449902770306
@Override
  public IndexInput openInput(String name, int bufferSize) throws IOException {
    ensureOpen();
    File f = new File(getDirectory(), name);
    RandomAccessFile raf = new RandomAccessFile(f, "r");
    try {
      return new MMapIndexInput(raf, 0, raf.length(), chunkSizePower);
    } finally {
      raf.close();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680293140/fstmerge_base_3633274006525098807
@Override
  public IndexInput openInput(String name, int bufferSize) throws IOException {
    ensureOpen();
    File f = new File(getDirectory(), name);
    RandomAccessFile raf = new RandomAccessFile(f, "r");
    try {
      return new MMapIndexInput(raf, chunkSizePower);
    } finally {
      raf.close();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680293140/fstmerge_var2_7629509715169372028

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/store/MMapDirectory.java
Conflict type: LineBasedMCFd
Conflict body: 
public SegmentInfo(Directory dir, int format, IndexInput input, CodecProvider codecs) throws IOException {
    this.dir = dir;
    if (format <= DefaultSegmentInfosWriter.FORMAT_3_1) {
      version = input.readString();
    }
    name = input.readString();
    docCount = input.readInt();
    delGen = input.readLong();
    docStoreOffset = input.readInt();
    if (docStoreOffset != -1) {
      docStoreSegment = input.readString();
      docStoreIsCompoundFile = input.readByte() == YES;
    } else {
      docStoreSegment = name;
      docStoreIsCompoundFile = false;
    }

    if (format > DefaultSegmentInfosWriter.FORMAT_4_0) {
      // pre-4.0 indexes write a byte if there is a single norms file
      byte b = input.readByte();
      assert 1 == b;
    }

    int numNormGen = input.readInt();
    if (numNormGen == NO) {
      normGen = null;
    } else {
      normGen = new HashMap<Integer, Long>();
      for(int j=0;j<numNormGen;j++) {
        int fieldNumber = j;
        if (format <= DefaultSegmentInfosWriter.FORMAT_4_0) {
          fieldNumber = input.readInt();
        }

        normGen.put(fieldNumber, input.readLong());
      }
    }
    isCompoundFile = input.readByte() == YES;

    delCount = input.readInt();
    assert delCount <= docCount;

    hasProx = input.readByte();

    // System.out.println(Thread.currentThread().getName() + ": si.read hasProx=" + hasProx + " seg=" + name);
    if (format <= DefaultSegmentInfosWriter.FORMAT_4_0) {
      segmentCodecs = new SegmentCodecs(codecs, input);
    } else {
      // codec ID on FieldInfo is 0 so it will simply use the first codec available
      // TODO what todo if preflex is not available in the provider? register it or fail?
      segmentCodecs = new SegmentCodecs(codecs, new Codec[] { codecs.lookup("PreFlex")});
    }
    diagnostics = input.readStringStringMap();

    if (format <= DefaultSegmentInfosWriter.FORMAT_HAS_VECTORS) {
      hasVectors = input.readByte();
    } else {
      final String storesSegment;
      final String ext;
      final boolean isCompoundFile;
      if (docStoreOffset != -1) {
        storesSegment = docStoreSegment;
        isCompoundFile = docStoreIsCompoundFile;
        ext = IndexFileNames.COMPOUND_FILE_STORE_EXTENSION;
      } else {
        storesSegment = name;
        isCompoundFile = getUseCompoundFile();
        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;
      }
      final Directory dirToTest;
      if (isCompoundFile) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680293219/fstmerge_var1_5571118692273777782
        dirToTest = dir.openCompoundInput(IndexFileNames.segmentFileName(storesSegment, "", ext), BufferedIndexInput.BUFFER_SIZE);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680293219/fstmerge_base_4920548927170605780
        dirToTest = new CompoundFileReader(dir, IndexFileNames.segmentFileName(storesSegment, "", ext));
=======
        dirToTest = new CompoundFileReader(dir, IndexFileNames.segmentFileName(storesSegment, "", ext), IOContext.READONCE);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680293219/fstmerge_var2_8740920939419052307
      } else {
        dirToTest = dir;
      }
      try {
        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, "", IndexFileNames.VECTORS_INDEX_EXTENSION)) ? YES : NO;
      } finally {
        if (isCompoundFile) {
          dirToTest.close();
        }
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/SegmentInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
synchronized void loadFieldInfos(Directory dir, boolean checkCompoundFile) throws IOException {
    if (fieldInfos == null) {
      Directory dir0 = dir;
      if (isCompoundFile && checkCompoundFile) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680293224/fstmerge_var1_5000847128249167830
        dir0 = dir.openCompoundInput(IndexFileNames.segmentFileName(name,
            "", IndexFileNames.COMPOUND_FILE_EXTENSION), BufferedIndexInput.BUFFER_SIZE);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680293224/fstmerge_base_547310260216384828
        dir0 = new CompoundFileReader(dir, IndexFileNames.segmentFileName(name,
            "", IndexFileNames.COMPOUND_FILE_EXTENSION));
=======
        dir0 = new CompoundFileReader(dir, IndexFileNames.segmentFileName(name,
            "", IndexFileNames.COMPOUND_FILE_EXTENSION), IOContext.READONCE);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680293224/fstmerge_var2_633075574242829977
      }
      try {
        fieldInfos = new FieldInfos(dir0, IndexFileNames.segmentFileName(name,
            "", IndexFileNames.FIELD_INFOS_EXTENSION));
      } finally {
        if (dir != dir0) {
          dir0.close();
        }
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/SegmentInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
synchronized void openDocStores(SegmentInfo si) throws IOException {
    
    assert si.name.equals(segment);
    
    if (fieldsReaderOrig == null) {
      final Directory storeDir;
      if (si.getDocStoreOffset() != -1) {
        if (si.getDocStoreIsCompoundFile()) {
          assert storeCFSReader == null;
          storeCFSReader = dir.openCompoundInput(
              IndexFileNames.segmentFileName(si.getDocStoreSegment(), "", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION),
              context);
          storeDir = storeCFSReader;
          assert storeDir != null;
        } else {
          storeDir = dir;
          assert storeDir != null;
        }
      } else if (si.getUseCompoundFile()) {
        // In some cases, we were originally opened when CFS
        // was not used, but then we are asked to open doc
        // stores after the segment has switched to CFS
        if (cfsReader == null) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680294088/fstmerge_var1_6758380683812317147
          cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680294088/fstmerge_base_8624820761560377363
          cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);
=======
          cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION), context);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680294088/fstmerge_var2_729443680667244084
        }
        storeDir = cfsReader;
        assert storeDir != null;
      } else {
        storeDir = dir;
        assert storeDir != null;
      }
      
      final String storesSegment = si.getDocStoreSegment();
      fieldsReaderOrig = new FieldsReader(storeDir, storesSegment, fieldInfos, context,
          si.getDocStoreOffset(), si.docCount);
      
      // Verify two sources of "maxDoc" agree:
      if (si.getDocStoreOffset() == -1 && fieldsReaderOrig.size() != si.docCount) {
        throw new CorruptIndexException("doc counts differ for segment " + segment + ": fieldsReader shows " + fieldsReaderOrig.size() + " but segmentInfo shows " + si.docCount);
      }
      
      if (si.getHasVectors()) { // open term vector files only as needed
        termVectorsReaderOrig = new TermVectorsReader(storeDir, storesSegment, fieldInfos, context, si.getDocStoreOffset(), si.docCount);
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/SegmentCoreReaders.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680294091/fstmerge_var1_7988734004160487016
SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {
    
    if (termsIndexDivisor == 0) {
      throw new IllegalArgumentException("indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)");
    }
    
    segment = si.name;
    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();
    this.readBufferSize = readBufferSize;
    this.dir = dir;
    
    boolean success = false;
    
    try {
      Directory dir0 = dir;
      if (si.getUseCompoundFile()) {
        cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);
        dir0 = cfsReader;
      }
      cfsDir = dir0;
      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos
      fieldInfos = si.getFieldInfos();
      
      this.termsIndexDivisor = termsIndexDivisor;
      final Codec codec = segmentCodecs.codec();
      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);
      // Ask codec for its Fields
      fields = codec.fieldsProducer(segmentReadState);
      assert fields != null;
      perDocProducer = codec.docsProducer(segmentReadState);
      success = true;
    } finally {
      if (!success) {
        decRef();
      }
    }
    
    // Must assign this at the end -- if we hit an
    // exception above core, we don't want to attempt to
    // purge the FieldCache (will hit NPE because core is
    // not assigned yet).
    this.owner = owner;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680294091/fstmerge_base_5213313627852667115
SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {
    
    if (termsIndexDivisor == 0) {
      throw new IllegalArgumentException("indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)");
    }
    
    segment = si.name;
    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();
    this.readBufferSize = readBufferSize;
    this.dir = dir;
    
    boolean success = false;
    
    try {
      Directory dir0 = dir;
      if (si.getUseCompoundFile()) {
        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, "", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);
        dir0 = cfsReader;
      }
      cfsDir = dir0;
      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos
      fieldInfos = si.getFieldInfos();
      
      this.termsIndexDivisor = termsIndexDivisor;
      final Codec codec = segmentCodecs.codec();
      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);
      // Ask codec for its Fields
      fields = codec.fieldsProducer(segmentReadState);
      assert fields != null;
      perDocProducer = codec.docsProducer(segmentReadState);
      success = true;
    } finally {
      if (!success) {
        decRef();
      }
    }
    
    // Must assign this at the end -- if we hit an
    // exception above core, we don't want to attempt to
    // purge the FieldCache (will hit NPE because core is
    // not assigned yet).
    this.owner = owner;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680294091/fstmerge_var2_4742343634667024479

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/SegmentCoreReaders.java
Conflict type: LineBasedMCFd
Conflict body: 
public static void main(String [] args) {
    String filename = null;
    boolean extract = false;

    for (int i = 0; i < args.length; ++i) {
      if (args[i].equals("-extract")) {
        extract = true;
      } else if (filename == null) {
        filename = args[i];
      }
    }

    if (filename == null) {
      System.out.println("Usage: org.apache.lucene.index.IndexReader [-extract] <cfsfile>");
      return;
    }

    Directory dir = null;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680294584/fstmerge_var1_1864787415909094174
    CompoundFileDirectory cfr = null;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680294584/fstmerge_base_283893091624099242
    CompoundFileReader cfr = null;
=======
    CompoundFileReader cfr = null;
    IOContext context = IOContext.READ;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680294584/fstmerge_var2_2949232570159894325

    try {
      File file = new File(filename);
      String dirname = file.getAbsoluteFile().getParent();
      filename = file.getName();
      dir = FSDirectory.open(new File(dirname));
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680294584/fstmerge_var1_1864787415909094174
      cfr = dir.openCompoundInput(filename, BufferedIndexInput.BUFFER_SIZE);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680294584/fstmerge_base_283893091624099242
      cfr = new CompoundFileReader(dir, filename);
=======
      cfr = new CompoundFileReader(dir, filename, context);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680294584/fstmerge_var2_2949232570159894325

      String [] files = cfr.listAll();
      ArrayUtil.mergeSort(files);   // sort the array of filename so that the output is more readable

      for (int i = 0; i < files.length; ++i) {
        long len = cfr.fileLength(files[i]);

        if (extract) {
          System.out.println("extract " + files[i] + " with " + len + " bytes to local directory...");
          IndexInput ii = cfr.openInput(files[i], context);

          FileOutputStream f = new FileOutputStream(files[i]);

          // read and write with a small buffer, which is more effective than reading byte by byte
          byte[] buffer = new byte[1024];
          int chunk = buffer.length;
          while(len > 0) {
            final int bufLen = (int) Math.min(chunk, len);
            ii.readBytes(buffer, 0, bufLen);
            f.write(buffer, 0, bufLen);
            len -= bufLen;
          }

          f.close();
          ii.close();
        }
        else
          System.out.println(files[i] + ": " + len + " bytes");
      }
    } catch (IOException ioe) {
      ioe.printStackTrace();
    }
    finally {
      try {
        if (dir != null)
          dir.close();
        if (cfr != null)
          cfr.close();
      }
      catch (IOException ioe) {
        ioe.printStackTrace();
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/IndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680297018/fstmerge_var1_6284934233641594182
final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)
          throws IOException {

    // Now merge all added files
    Collection<String> files = info.files();
    CompoundFileDirectory cfsDir = directory.createCompoundOutput(fileName);
    try {
      for (String file : files) {
        assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) 
                  : ".del file is not allowed in .cfs: " + file;
        assert !IndexFileNames.isSeparateNormsFile(file) 
                  : "separate norms file (.s[0-9]+) is not allowed in .cfs: " + file;
        directory.copy(cfsDir, file, file);
        checkAbort.work(directory.fileLength(file));
      }
    } finally {
      cfsDir.close();
    }

    return files;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680297018/fstmerge_base_7649325311054756804
final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)
          throws IOException {

    // Now merge all added files
    Collection<String> files = info.files();
    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);
    for (String file : files) {
      assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) 
                : ".del file is not allowed in .cfs: " + file;
      assert !IndexFileNames.isSeparateNormsFile(file) 
                : "separate norms file (.s[0-9]+) is not allowed in .cfs: " + file;
      cfsWriter.addFile(file);
    }

    // Perform the merge
    cfsWriter.close();

    return files;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680297018/fstmerge_var2_2718739337838418729

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
Conflict type: LineBasedMCFd
Conflict body: 
SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {
    assert flushedSegment != null;

    SegmentInfo newSegment = flushedSegment.segmentInfo;

    setDiagnostics(newSegment, "flush");
    
    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes(true)));

    boolean success = false;
    try {
      if (useCompoundFile(newSegment)) {
        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, "", IndexFileNames.COMPOUND_FILE_EXTENSION);
        message("creating compound file " + compoundFileName);
        // Now build compound file
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300239/fstmerge_var1_5072897933992903517
        final Directory cfsDir = directory.createCompoundOutput(compoundFileName);
        IOException prior = null;
        try {
          for(String fileName : newSegment.files()) {
            directory.copy(cfsDir, fileName, fileName);
          }
        } catch(IOException ex) {
          prior = ex;
        } finally {
          IOUtils.closeSafely(prior, cfsDir);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300239/fstmerge_base_2085233626901527072
        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);
        for(String fileName : newSegment.files()) {
          cfsWriter.addFile(fileName);
=======
        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName, context);
        for(String fileName : newSegment.files()) {
          cfsWriter.addFile(fileName);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300239/fstmerge_var2_1127840530384955875
        }
        // Perform the merge
        
        synchronized(this) {
          deleter.deleteNewFiles(newSegment.files());
        }

        newSegment.setUseCompoundFile(true);
      }

      // Must write deleted docs after the CFS so we don't
      // slurp the del file into CFS:
      if (flushedSegment.liveDocs != null) {
        final int delCount = flushedSegment.segmentInfo.docCount - flushedSegment.liveDocs.count();
        assert delCount > 0;
        newSegment.setDelCount(delCount);
        newSegment.advanceDelGen();
        final String delFileName = newSegment.getDelFileName();
        if (infoStream != null) {
          message("flush: write " + delCount + " deletes to " + delFileName);
        }
        boolean success2 = false;
        try {
          // TODO: in the NRT case it'd be better to hand
          // this del vector over to the
          // shortly-to-be-opened SegmentReader and let it
          // carry the changes; there's no reason to use
          // filesystem as intermediary here.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300239/fstmerge_var1_5072897933992903517
          flushedSegment.liveDocs.write(directory, delFileName);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300239/fstmerge_base_2085233626901527072
          flushedSegment.deletedDocuments.write(directory, delFileName);
=======
          flushedSegment.deletedDocuments.write(directory, delFileName, context);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300239/fstmerge_var2_1127840530384955875
          success2 = true;
        } finally {
          if (!success2) {
            try {
              directory.deleteFile(delFileName);
            } catch (Throwable t) {
              // suppress this so we keep throwing the
              // original exception
            }
          }
        }
      }

      success = true;
    } finally {
      if (!success) {
        if (infoStream != null) {
          message("hit exception " +
              "reating compound file for newly flushed segment " + newSegment.name);
        }

        synchronized(this) {
          deleter.refresh(newSegment.name);
        }
      }
    }
    return newSegment;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300532/fstmerge_var1_8714623369528936763
private void copySegmentIntoCFS(SegmentInfo info, String segName) throws IOException {
    String segFileName = IndexFileNames.segmentFileName(segName, "", IndexFileNames.COMPOUND_FILE_EXTENSION);
    Collection<String> files = info.files();
    final CompoundFileDirectory cfsdir = directory.createCompoundOutput(segFileName);
    try {
      for (String file : files) {
        String newFileName = segName + IndexFileNames.stripSegmentName(file);
        if (!IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION)
            && !IndexFileNames.isSeparateNormsFile(file)) {
          info.dir.copy(cfsdir, file, file);
        } else {
          assert !directory.fileExists(newFileName): "file \"" + newFileName + "\" already exists";
          info.dir.copy(directory, file, newFileName);
        }
      }
    } finally {
      IOUtils.closeSafely(true, cfsdir);
    }
    
    info.dir = directory;
    info.name = segName;
    info.setUseCompoundFile(true);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300532/fstmerge_base_8403023951937210831
private void copySegmentIntoCFS(SegmentInfo info, String segName) throws IOException {
    String segFileName = IndexFileNames.segmentFileName(segName, "", IndexFileNames.COMPOUND_FILE_EXTENSION);
    Collection<String> files = info.files();
    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, segFileName);
    for (String file : files) {
      String newFileName = segName + IndexFileNames.stripSegmentName(file);
      if (!IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION)
          && !IndexFileNames.isSeparateNormsFile(file)) {
        cfsWriter.addFile(file, info.dir);
      } else {
        assert !directory.fileExists(newFileName): "file \"" + newFileName + "\" already exists";
        info.dir.copy(directory, file, newFileName);
      }
    }
    
    // Create the .cfs
    cfsWriter.close();
    
    info.dir = directory;
    info.name = segName;
    info.setUseCompoundFile(true);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300532/fstmerge_var2_4656156791731661769

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## private Directory directory; ##FSTMerge## private final Directory directory;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/CompoundFileWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## private String fileName; ##FSTMerge## private final String fileName;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/CompoundFileWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## private HashSet<String> ids; ##FSTMerge## private final HashSet<String> ids;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/CompoundFileWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## private LinkedList<FileEntry> entries; ##FSTMerge## private final LinkedList<FileEntry> entries;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/CompoundFileWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ ##FSTMerge## private MergeState.CheckAbort checkAbort; ##FSTMerge## private final MergeState.CheckAbort checkAbort;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/CompoundFileWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300573/fstmerge_var1_2797342225274697310
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300573/fstmerge_base_2193941596569339169
public void close() throws IOException {
        if (merged)
            throw new IllegalStateException("Merge already performed");

        if (entries.isEmpty())
            throw new IllegalStateException("No entries to merge have been defined");

        merged = true;

        // open the compound stream
        IndexOutput os = directory.createOutput(fileName);
        IOException priorException = null;
        try {
            // Write the Version info - must be a VInt because CFR reads a VInt
            // in older versions!
            os.writeVInt(FORMAT_CURRENT);
            
            // Write the number of entries
            os.writeVInt(entries.size());

            // Write the directory with all offsets at 0.
            // Remember the positions of directory entries so that we can
            // adjust the offsets later
            long totalSize = 0;
            for (FileEntry fe : entries) {
                fe.directoryOffset = os.getFilePointer();
                os.writeLong(0);    // for now
                os.writeString(IndexFileNames.stripSegmentName(fe.file));
                totalSize += fe.dir.fileLength(fe.file);
            }

            // Pre-allocate size of file as optimization --
            // this can potentially help IO performance as
            // we write the file and also later during
            // searching.  It also uncovers a disk-full
            // situation earlier and hopefully without
            // actually filling disk to 100%:
            final long finalLength = totalSize+os.getFilePointer();
            os.setLength(finalLength);

            // Open the files and copy their data into the stream.
            // Remember the locations of each file's data section.
            for (FileEntry fe : entries) {
                fe.dataOffset = os.getFilePointer();
                copyFile(fe, os);
            }

            // Write the data offsets into the directory of the compound stream
            for (FileEntry fe : entries) {
                os.seek(fe.directoryOffset);
                os.writeLong(fe.dataOffset);
            }

            assert finalLength == os.length();

            // Close the output stream. Set the os to null before trying to
            // close so that if an exception occurs during the close, the
            // finally clause below will not attempt to close the stream
            // the second time.
            IndexOutput tmp = os;
            os = null;
            tmp.close();
        } catch (IOException e) {
          priorException = e;
        } finally {
          IOUtils.closeSafely(priorException, os);
        }
    }
=======
public void close() throws IOException {
        if (merged)
            throw new IllegalStateException("Merge already performed");

        if (entries.isEmpty())
            throw new IllegalStateException("No entries to merge have been defined");

        merged = true;

        // open the compound stream
        IndexOutput os = directory.createOutput(fileName, context);
        IOException priorException = null;
        try {
            // Write the Version info - must be a VInt because CFR reads a VInt
            // in older versions!
            os.writeVInt(FORMAT_CURRENT);
            
            // Write the number of entries
            os.writeVInt(entries.size());

            // Write the directory with all offsets at 0.
            // Remember the positions of directory entries so that we can
            // adjust the offsets later
            long totalSize = 0;
            for (FileEntry fe : entries) {
                fe.directoryOffset = os.getFilePointer();
                os.writeLong(0);    // for now
                os.writeString(IndexFileNames.stripSegmentName(fe.file));
                totalSize += fe.dir.fileLength(fe.file);
            }

            // Pre-allocate size of file as optimization --
            // this can potentially help IO performance as
            // we write the file and also later during
            // searching.  It also uncovers a disk-full
            // situation earlier and hopefully without
            // actually filling disk to 100%:
            final long finalLength = totalSize+os.getFilePointer();
            os.setLength(finalLength);

            // Open the files and copy their data into the stream.
            // Remember the locations of each file's data section.
            for (FileEntry fe : entries) {
                fe.dataOffset = os.getFilePointer();
                copyFile(fe, os);
            }

            // Write the data offsets into the directory of the compound stream
            for (FileEntry fe : entries) {
                os.seek(fe.directoryOffset);
                os.writeLong(fe.dataOffset);
            }

            assert finalLength == os.length();

            // Close the output stream. Set the os to null before trying to
            // close so that if an exception occurs during the close, the
            // finally clause below will not attempt to close the stream
            // the second time.
            IndexOutput tmp = os;
            os = null;
            tmp.close();
        } catch (IOException e) {
          priorException = e;
        } finally {
          IOUtils.closeSafely(priorException, os);
        }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300573/fstmerge_var2_3369163577746625102

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/CompoundFileWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300578/fstmerge_var1_9141747567604252250
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300578/fstmerge_base_5398280280007856334
private void copyFile(FileEntry source, IndexOutput os) throws IOException {
    IndexInput is = source.dir.openInput(source.file);
    try {
      long startPtr = os.getFilePointer();
      long length = is.length();
      os.copyBytes(is, length);

      if (checkAbort != null) {
        checkAbort.work(length);
      }

      // Verify that the output length diff is equal to original file
      long endPtr = os.getFilePointer();
      long diff = endPtr - startPtr;
      if (diff != length)
        throw new IOException("Difference in the output file offsets " + diff
            + " does not match the original file length " + length);

    } finally {
      is.close();
    }
  }
=======
private void copyFile(FileEntry source, IndexOutput os) throws IOException {
    IndexInput is = source.dir.openInput(source.file, context);
    try {
      long startPtr = os.getFilePointer();
      long length = is.length();
      os.copyBytes(is, length);

      if (checkAbort != null) {
        checkAbort.work(length);
      }

      // Verify that the output length diff is equal to original file
      long endPtr = os.getFilePointer();
      long diff = endPtr - startPtr;
      if (diff != length)
        throw new IOException("Difference in the output file offsets " + diff
            + " does not match the original file length " + length);

    } finally {
      is.close();
    }
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300578/fstmerge_var2_5832653672441862869

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/CompoundFileWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300598/fstmerge_var1_1314815302668456900
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300598/fstmerge_base_118811171281196494
private void loadDeletedDocs() throws IOException {
    // NOTE: the bitvector is stored using the regular directory, not cfs
    if (hasDeletions(si)) {
      deletedDocs = new BitVector(directory(), si.getDelFileName());
      deletedDocsRef = new AtomicInteger(1);
      assert checkDeletedCounts();
      if (deletedDocs.size() != si.docCount) {
        throw new CorruptIndexException("document count mismatch: deleted docs count " + deletedDocs.size() + " vs segment doc count " + si.docCount + " segment=" + si.name);
      }
    } else
      assert si.getDelCount() == 0;
  }
=======
private void loadDeletedDocs() throws IOException {
    // NOTE: the bitvector is stored using the regular directory, not cfs
    if (hasDeletions(si)) {
      deletedDocs = new BitVector(directory(), si.getDelFileName(), IOContext.DEFAULT);
      deletedDocsRef = new AtomicInteger(1);
      assert checkDeletedCounts();
      if (deletedDocs.size() != si.docCount) {
        throw new CorruptIndexException("document count mismatch: deleted docs count " + deletedDocs.size() + " vs segment doc count " + si.docCount + " segment=" + si.name);
      }
    } else
      assert si.getDelCount() == 0;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300598/fstmerge_var2_2217230491746800734

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/SegmentReader.java
Conflict type: LineBasedMCFd
Conflict body: 
private synchronized void commitChanges(Map<String,String> commitUserData) throws IOException {
    if (liveDocsDirty) {               // re-write deleted
      si.advanceDelGen();

      assert liveDocs.length() == si.docCount;

      // We can write directly to the actual name (vs to a
      // .tmp & renaming it) because the file is not live
      // until segments file is written:
      final String delFileName = si.getDelFileName();
      boolean success = false;
      try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300637/fstmerge_var1_7502849335864240169
        liveDocs.write(directory(), delFileName);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300637/fstmerge_base_6457425045528085537
        deletedDocs.write(directory(), delFileName);
=======
        deletedDocs.write(directory(), delFileName, IOContext.DEFAULT);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300637/fstmerge_var2_2410873351801146171
        success = true;
      } finally {
        if (!success) {
          try {
            directory().deleteFile(delFileName);
          } catch (Throwable t) {
            // suppress this so we keep throwing the
            // original exception
          }
        }
      }
      si.setDelCount(si.getDelCount()+pendingDeleteCount);
      pendingDeleteCount = 0;
      assert (maxDoc()-liveDocs.count()) == si.getDelCount(): "delete count mismatch during commit: info=" + si.getDelCount() + " vs BitVector=" + (maxDoc()-liveDocs.count());
    } else {
      assert pendingDeleteCount == 0;
    }

    if (normsDirty) {               // re-write norms
      si.initNormGen();
      for (final SegmentNorms norm : norms.values()) {
        if (norm.dirty) {
          norm.reWrite(si);
        }
      }
    }
    liveDocsDirty = false;
    normsDirty = false;
    hasChanges = false;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/SegmentReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300838/fstmerge_var1_8952077070141965489
public static SegmentReader get(boolean readOnly,
                                  Directory dir,
                                  SegmentInfo si,
                                  int readBufferSize,
                                  boolean doOpenStores,
                                  int termInfosIndexDivisor)
    throws CorruptIndexException, IOException {
    
    SegmentReader instance = new SegmentReader();
    instance.readOnly = readOnly;
    instance.si = si;
    instance.readBufferSize = readBufferSize;

    boolean success = false;

    try {
      instance.core = new SegmentCoreReaders(instance, dir, si, readBufferSize, termInfosIndexDivisor);
      if (doOpenStores) {
        instance.core.openDocStores(si);
      }
      instance.loadLiveDocs();
      instance.openNorms(instance.core.cfsDir, readBufferSize);
      success = true;
    } finally {

      // With lock-less commits, it's entirely possible (and
      // fine) to hit a FileNotFound exception above.  In
      // this case, we want to explicitly close any subset
      // of things that were opened so that we don't have to
      // wait for a GC to do so.
      if (!success) {
        instance.doClose();
      }
    }
    return instance;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300838/fstmerge_base_6009324564933738928
public static SegmentReader get(boolean readOnly,
                                  Directory dir,
                                  SegmentInfo si,
                                  int readBufferSize,
                                  boolean doOpenStores,
                                  int termInfosIndexDivisor)
    throws CorruptIndexException, IOException {
    
    SegmentReader instance = new SegmentReader();
    instance.readOnly = readOnly;
    instance.si = si;
    instance.readBufferSize = readBufferSize;

    boolean success = false;

    try {
      instance.core = new SegmentCoreReaders(instance, dir, si, readBufferSize, termInfosIndexDivisor);
      if (doOpenStores) {
        instance.core.openDocStores(si);
      }
      instance.loadDeletedDocs();
      instance.openNorms(instance.core.cfsDir, readBufferSize);
      success = true;
    } finally {

      // With lock-less commits, it's entirely possible (and
      // fine) to hit a FileNotFound exception above.  In
      // this case, we want to explicitly close any subset
      // of things that were opened so that we don't have to
      // wait for a GC to do so.
      if (!success) {
        instance.doClose();
      }
    }
    return instance;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680300838/fstmerge_var2_5779273232832274033

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/SegmentReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680301592/fstmerge_var1_1765683751060904266
@Override
  public void read(Directory directory, String segmentsFileName, CodecProvider codecs,
          SegmentInfos infos) throws IOException {
    IndexInput input = null;
    try {
      input = openInput(directory, segmentsFileName);
      final int format = input.readInt();
      infos.setFormat(format);
  
      // check that it is a format we can understand
      if (format > DefaultSegmentInfosWriter.FORMAT_MINIMUM)
        throw new IndexFormatTooOldException(segmentsFileName, format,
          DefaultSegmentInfosWriter.FORMAT_MINIMUM, DefaultSegmentInfosWriter.FORMAT_CURRENT);
      if (format < DefaultSegmentInfosWriter.FORMAT_CURRENT)
        throw new IndexFormatTooNewException(segmentsFileName, format,
          DefaultSegmentInfosWriter.FORMAT_MINIMUM, DefaultSegmentInfosWriter.FORMAT_CURRENT);
  
      infos.version = input.readLong(); // read version
      infos.counter = input.readInt(); // read counter
      if (infos.getFormat() <= DefaultSegmentInfosWriter.FORMAT_4_0) {
        infos.setGlobalFieldMapVersion(input.readLong());
      }
      for (int i = input.readInt(); i > 0; i--) { // read segmentInfos
        SegmentInfo si = new SegmentInfo(directory, format, input, codecs);
        if (si.getVersion() == null) {
          // Could be a 3.0 - try to open the doc stores - if it fails, it's a
          // 2.x segment, and an IndexFormatTooOldException will be thrown,
          // which is what we want.
          Directory dir = directory;
          if (si.getDocStoreOffset() != -1) {
            if (si.getDocStoreIsCompoundFile()) {
              dir = dir.openCompoundInput(IndexFileNames.segmentFileName(
                  si.getDocStoreSegment(), "",
                  IndexFileNames.COMPOUND_FILE_STORE_EXTENSION), 1024);
            }
          } else if (si.getUseCompoundFile()) {
            dir = dir.openCompoundInput(IndexFileNames.segmentFileName(
                si.name, "", IndexFileNames.COMPOUND_FILE_EXTENSION), 1024);
          }

          try {
            FieldsReader.checkCodeVersion(dir, si.getDocStoreSegment());
          } finally {
            // If we opened the directory, close it
            if (dir != directory) dir.close();
          }
          
          // Above call succeeded, so it's a 3.0 segment. Upgrade it so the next
          // time the segment is read, its version won't be null and we won't
          // need to open FieldsReader every time for each such segment.
          si.setVersion("3.0");
        } else if (si.getVersion().equals("2.x")) {
          // If it's a 3x index touched by 3.1+ code, then segments record their
          // version, whether they are 2.x ones or not. We detect that and throw
          // appropriate exception.
          throw new IndexFormatTooOldException(si.name, si.getVersion());
        }
        infos.add(si);
      }
      
      infos.userData = input.readStringStringMap();
      finalizeInput(input);
      
    } finally {
      if (input != null) {
        input.close();
      }
    }

  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680301592/fstmerge_base_4783888750344084440
@Override
  public void read(Directory directory, String segmentsFileName, CodecProvider codecs,
          SegmentInfos infos) throws IOException {
    IndexInput input = null;
    try {
      input = openInput(directory, segmentsFileName);
      final int format = input.readInt();
      infos.setFormat(format);
  
      // check that it is a format we can understand
      if (format > DefaultSegmentInfosWriter.FORMAT_MINIMUM)
        throw new IndexFormatTooOldException(segmentsFileName, format,
          DefaultSegmentInfosWriter.FORMAT_MINIMUM, DefaultSegmentInfosWriter.FORMAT_CURRENT);
      if (format < DefaultSegmentInfosWriter.FORMAT_CURRENT)
        throw new IndexFormatTooNewException(segmentsFileName, format,
          DefaultSegmentInfosWriter.FORMAT_MINIMUM, DefaultSegmentInfosWriter.FORMAT_CURRENT);
  
      infos.version = input.readLong(); // read version
      infos.counter = input.readInt(); // read counter
      if (infos.getFormat() <= DefaultSegmentInfosWriter.FORMAT_4_0) {
        infos.setGlobalFieldMapVersion(input.readLong());
      }
      for (int i = input.readInt(); i > 0; i--) { // read segmentInfos
        SegmentInfo si = new SegmentInfo(directory, format, input, codecs);
        if (si.getVersion() == null) {
          // Could be a 3.0 - try to open the doc stores - if it fails, it's a
          // 2.x segment, and an IndexFormatTooOldException will be thrown,
          // which is what we want.
          Directory dir = directory;
          if (si.getDocStoreOffset() != -1) {
            if (si.getDocStoreIsCompoundFile()) {
              dir = new CompoundFileReader(dir, IndexFileNames.segmentFileName(
                  si.getDocStoreSegment(), "",
                  IndexFileNames.COMPOUND_FILE_STORE_EXTENSION), 1024);
            }
          } else if (si.getUseCompoundFile()) {
            dir = new CompoundFileReader(dir, IndexFileNames.segmentFileName(
                si.name, "", IndexFileNames.COMPOUND_FILE_EXTENSION), 1024);
          }

          try {
            FieldsReader.checkCodeVersion(dir, si.getDocStoreSegment());
          } finally {
            // If we opened the directory, close it
            if (dir != directory) dir.close();
          }
          
          // Above call succeeded, so it's a 3.0 segment. Upgrade it so the next
          // time the segment is read, its version won't be null and we won't
          // need to open FieldsReader every time for each such segment.
          si.setVersion("3.0");
        } else if (si.getVersion().equals("2.x")) {
          // If it's a 3x index touched by 3.1+ code, then segments record their
          // version, whether they are 2.x ones or not. We detect that and throw
          // appropriate exception.
          throw new IndexFormatTooOldException(si.name, si.getVersion());
        }
        infos.add(si);
      }
      
      infos.userData = input.readStringStringMap();
      finalizeInput(input);
      
    } finally {
      if (input != null) {
        input.close();
      }
    }

  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680301592/fstmerge_var2_21297153274692340

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/codecs/DefaultSegmentInfosReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680301744/fstmerge_var1_7717817131076681048
protected IndexDocValues loadDocValues(int docCount, Directory dir, String id,
      ValueType type) throws IOException {
    switch (type) {
    case FIXED_INTS_16:
    case FIXED_INTS_32:
    case FIXED_INTS_64:
    case FIXED_INTS_8:
    case VAR_INTS:
      return Ints.getValues(dir, id, docCount);
    case FLOAT_32:
      return Floats.getValues(dir, id, docCount);
    case FLOAT_64:
      return Floats.getValues(dir, id, docCount);
    case BYTES_FIXED_STRAIGHT:
      return Bytes.getValues(dir, id, Bytes.Mode.STRAIGHT, true, docCount);
    case BYTES_FIXED_DEREF:
      return Bytes.getValues(dir, id, Bytes.Mode.DEREF, true, docCount);
    case BYTES_FIXED_SORTED:
      return Bytes.getValues(dir, id, Bytes.Mode.SORTED, true, docCount);
    case BYTES_VAR_STRAIGHT:
      return Bytes.getValues(dir, id, Bytes.Mode.STRAIGHT, false, docCount);
    case BYTES_VAR_DEREF:
      return Bytes.getValues(dir, id, Bytes.Mode.DEREF, false, docCount);
    case BYTES_VAR_SORTED:
      return Bytes.getValues(dir, id, Bytes.Mode.SORTED, false, docCount);
    default:
      throw new IllegalStateException("unrecognized index values mode " + type);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680301744/fstmerge_base_983617245960299674
protected IndexDocValues loadDocValues(int docCount, Directory dir, String id,
      ValueType type) throws IOException {
    switch (type) {
    case INTS:
      return Ints.getValues(dir, id, false);
    case FLOAT_32:
      return Floats.getValues(dir, id, docCount);
    case FLOAT_64:
      return Floats.getValues(dir, id, docCount);
    case BYTES_FIXED_STRAIGHT:
      return Bytes.getValues(dir, id, Bytes.Mode.STRAIGHT, true, docCount);
    case BYTES_FIXED_DEREF:
      return Bytes.getValues(dir, id, Bytes.Mode.DEREF, true, docCount);
    case BYTES_FIXED_SORTED:
      return Bytes.getValues(dir, id, Bytes.Mode.SORTED, true, docCount);
    case BYTES_VAR_STRAIGHT:
      return Bytes.getValues(dir, id, Bytes.Mode.STRAIGHT, false, docCount);
    case BYTES_VAR_DEREF:
      return Bytes.getValues(dir, id, Bytes.Mode.DEREF, false, docCount);
    case BYTES_VAR_SORTED:
      return Bytes.getValues(dir, id, Bytes.Mode.SORTED, false, docCount);
    default:
      throw new IllegalStateException("unrecognized index values mode " + type);
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680301744/fstmerge_var2_4007244641891616563

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/codecs/DefaultDocValuesProducer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  synchronized public void loadTermsIndex(int indexDivisor) throws IOException {
    if (tis == null) {
      Directory dir0;
      if (si.getUseCompoundFile()) {
        // In some cases, we were originally opened when CFS
        // was not used, but then we are asked to open the
        // terms reader with index, the segment has switched
        // to CFS

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304280/fstmerge_var1_7214604824847728495
        if (!(dir instanceof CompoundFileDirectory)) {
          dir0 = cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(si.name, "", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304280/fstmerge_base_3501090585447458376
        if (!(dir instanceof CompoundFileReader)) {
          dir0 = cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(si.name, "", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);
=======
        if (!(dir instanceof CompoundFileReader)) {
          dir0 = cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(si.name, "", IndexFileNames.COMPOUND_FILE_EXTENSION), context);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304280/fstmerge_var2_8520864663787697939
        } else {
          dir0 = dir;
        }
        dir0 = cfsReader;
      } else {
        dir0 = dir;
      }

      tis = new TermInfosReader(dir0, si.name, fieldInfos, context, indexDivisor);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304703/fstmerge_var1_4115718134462726163
public static Writer getWriter(Directory dir, String id, Mode mode,
      Comparator<BytesRef> comp, boolean fixedSize, AtomicLong bytesUsed)
      throws IOException {
    // TODO -- i shouldn't have to specify fixed? can
    // track itself & do the write thing at write time?
    if (comp == null) {
      comp = BytesRef.getUTF8SortedAsUnicodeComparator();
    }

    if (fixedSize) {
      if (mode == Mode.STRAIGHT) {
        return new FixedStraightBytesImpl.Writer(dir, id, bytesUsed);
      } else if (mode == Mode.DEREF) {
        return new FixedDerefBytesImpl.Writer(dir, id, bytesUsed);
      } else if (mode == Mode.SORTED) {
        return new FixedSortedBytesImpl.Writer(dir, id, comp, bytesUsed);
      }
    } else {
      if (mode == Mode.STRAIGHT) {
        return new VarStraightBytesImpl.Writer(dir, id, bytesUsed);
      } else if (mode == Mode.DEREF) {
        return new VarDerefBytesImpl.Writer(dir, id, bytesUsed);
      } else if (mode == Mode.SORTED) {
        return new VarSortedBytesImpl.Writer(dir, id, comp, bytesUsed);
      }
    }

    throw new IllegalArgumentException("");
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304703/fstmerge_base_8319206008222618111
public static Writer getWriter(Directory dir, String id, Mode mode,
      Comparator<BytesRef> comp, boolean fixedSize, AtomicLong bytesUsed)
      throws IOException {
    // TODO -- i shouldn't have to specify fixed? can
    // track itself & do the write thing at write time?
    if (comp == null) {
      comp = BytesRef.getUTF8SortedAsUnicodeComparator();
    }

    if (fixedSize) {
      if (mode == Mode.STRAIGHT) {
        return new FixedStraightBytesImpl.Writer(dir, id);
      } else if (mode == Mode.DEREF) {
        return new FixedDerefBytesImpl.Writer(dir, id, bytesUsed);
      } else if (mode == Mode.SORTED) {
        return new FixedSortedBytesImpl.Writer(dir, id, comp, bytesUsed);
      }
    } else {
      if (mode == Mode.STRAIGHT) {
        return new VarStraightBytesImpl.Writer(dir, id, bytesUsed);
      } else if (mode == Mode.DEREF) {
        return new VarDerefBytesImpl.Writer(dir, id, bytesUsed);
      } else if (mode == Mode.SORTED) {
        return new VarSortedBytesImpl.Writer(dir, id, comp, bytesUsed);
      }
    }

    throw new IllegalArgumentException("");
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304703/fstmerge_var2_4157781862591934267

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/values/Bytes.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304784/fstmerge_var1_4730423341351593242
public Writer(Directory dir, String id, AtomicLong bytesUsed)
        throws IOException {
      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed);
      pool = new ByteBlockPool(new DirectTrackingAllocator(bytesUsed));
      docToAddress = new long[1];
      pool.nextBuffer(); // init
      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304784/fstmerge_base_8445501747648475805
public Writer(Directory dir, String id, AtomicLong bytesUsed)
        throws IOException {
      super(dir, id, CODEC_NAME, VERSION_CURRENT, true, null, bytesUsed);
      docToAddress = new long[1];
      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT);
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304784/fstmerge_var2_136567995662916753

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/values/VarStraightBytesImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304874/fstmerge_var1_996377864407109824
public Writer(Directory dir, String id, Comparator<BytesRef> comp,
        Allocator allocator, AtomicLong bytesUsed) throws IOException {
      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed);
      this.hash = new BytesRefHash(new ByteBlockPool(allocator),
          BytesRefHash.DEFAULT_CAPACITY, new TrackingDirectBytesStartArray(
              BytesRefHash.DEFAULT_CAPACITY, bytesUsed));
      this.comp = comp;
      docToEntry = new int[1];
      docToEntry[0] = -1;
      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304874/fstmerge_base_2851288623344559965
public Writer(Directory dir, String id, Comparator<BytesRef> comp,
        Allocator allocator, AtomicLong bytesUsed) throws IOException {
      super(dir, id, CODEC_NAME, VERSION_CURRENT, true,
          new ByteBlockPool(allocator), bytesUsed);
      this.comp = comp;
      docToEntry = new int[1];
      docToEntry[0] = -1;
      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT);

    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304874/fstmerge_var2_8367591755312562839

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/values/VarSortedBytesImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304967/fstmerge_var1_1238356534516745909
public Writer(Directory dir, String id, Comparator<BytesRef> comp,
        Allocator allocator, AtomicLong bytesUsed) throws IOException {
      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed);
      ByteBlockPool pool = new ByteBlockPool(allocator);
      hash = new BytesRefHash(pool, BytesRefHash.DEFAULT_CAPACITY,
          new TrackingDirectBytesStartArray(BytesRefHash.DEFAULT_CAPACITY,
              bytesUsed));
      docToEntry = new int[1];
      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT);
      this.comp = comp;
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304967/fstmerge_base_4796987161408527178
public Writer(Directory dir, String id, Comparator<BytesRef> comp,
        Allocator allocator, AtomicLong bytesUsed) throws IOException {
      super(dir, id, CODEC_NAME, VERSION_CURRENT, true,
          new ByteBlockPool(allocator), bytesUsed);
      docToEntry = new int[1];
      // docToEntry[0] = -1;
      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT);
      this.comp = comp;
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680304967/fstmerge_var2_6740167231664626305

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/values/FixedSortedBytesImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305069/fstmerge_var1_4370381203815893222
public Writer(Directory dir, String id, Allocator allocator,
        AtomicLong bytesUsed) throws IOException {
      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed);
      hash = new BytesRefHash(new ByteBlockPool(allocator),
          BytesRefHash.DEFAULT_CAPACITY, new TrackingDirectBytesStartArray(
              BytesRefHash.DEFAULT_CAPACITY, bytesUsed));
      docToID = new int[1];
      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305069/fstmerge_base_8014291152584370845
public Writer(Directory dir, String id, Allocator allocator,
        AtomicLong bytesUsed) throws IOException {
      super(dir, id, CODEC_NAME, VERSION_CURRENT, true,
          new ByteBlockPool(allocator), bytesUsed);
      docToID = new int[1];
      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT); // TODO BytesRefHash
                                                            // uses bytes too!
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305069/fstmerge_var2_1168665705724318824

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/values/FixedDerefBytesImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305389/fstmerge_var1_5094637904347381268
protected FloatsWriter(Directory dir, String id, int precision,
        AtomicLong bytesUsed) throws IOException {
      super(bytesUsed);
      this.id = id;
      this.precision = (byte) precision;
      this.dir = dir;
     
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305389/fstmerge_base_712532160351130138
protected FloatsWriter(Directory dir, String id, int precision,
        AtomicLong bytesUsed) throws IOException {
      super(bytesUsed);
      this.id = id;
      this.precision = (byte) precision;
      datOut = dir.createOutput(IndexFileNames.segmentFileName(id, "",
          Writer.DATA_EXTENSION));
      boolean success = false;
      try {
        CodecUtil.writeHeader(datOut, CODEC_NAME, VERSION_CURRENT);
        assert datOut.getFilePointer() == CodecUtil.headerLength(CODEC_NAME);
        datOut.writeByte(this.precision);
        success = true;
      } finally {
        if (!success) {
          IOUtils.closeSafely(true, datOut);
        }
      }
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305389/fstmerge_var2_3966730217632591351

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/values/Floats.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305407/fstmerge_var1_7723129018599569520
protected Float4Writer(Directory dir, String id, AtomicLong bytesUsed)
        throws IOException {
      super(dir, id, 4, bytesUsed);
      values = new int[1];
      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305407/fstmerge_base_8310567767122667255
protected Float4Writer(Directory dir, String id, AtomicLong bytesUsed)
        throws IOException {
      super(dir, id, 4, bytesUsed);
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305407/fstmerge_var2_1549226701607644535

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/values/Floats.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305425/fstmerge_var1_5271764103845821157
protected Float8Writer(Directory dir, String id, AtomicLong bytesUsed)
        throws IOException {
      super(dir, id, 8, bytesUsed);
      values = new long[1];
      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_LONG);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305425/fstmerge_base_6910668556884219429
protected Float8Writer(Directory dir, String id, AtomicLong bytesUsed)
        throws IOException {
      super(dir, id, 8, bytesUsed);
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305425/fstmerge_var2_8872842539390972883

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/values/Floats.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305618/fstmerge_var1_2688879632832012150
public Writer(Directory dir, String id, Allocator allocator,
        AtomicLong bytesUsed) throws IOException {
      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed);
      hash = new BytesRefHash(new ByteBlockPool(allocator), 16, array);
      docToAddress = new int[1];
      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305618/fstmerge_base_2935188906498370678
public Writer(Directory dir, String id, Allocator allocator,
        AtomicLong bytesUsed) throws IOException {
      super(dir, id, CODEC_NAME, VERSION_CURRENT, true,
          new ByteBlockPool(allocator), bytesUsed);
      docToAddress = new int[1];
      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT);
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305618/fstmerge_var2_1398274743059229462

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/values/VarDerefBytesImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305964/fstmerge_var1_3758622441048723419
public static Writer create(ValueType type, String id, Directory directory,
      Comparator<BytesRef> comp, AtomicLong bytesUsed) throws IOException {
    if (comp == null) {
      comp = BytesRef.getUTF8SortedAsUnicodeComparator();
    }
    switch (type) {
    case FIXED_INTS_16:
    case FIXED_INTS_32:
    case FIXED_INTS_64:
    case FIXED_INTS_8:
    case VAR_INTS:
      return Ints.getWriter(directory, id, bytesUsed, type);
    case FLOAT_32:
      return Floats.getWriter(directory, id, 4, bytesUsed);
    case FLOAT_64:
      return Floats.getWriter(directory, id, 8, bytesUsed);
    case BYTES_FIXED_STRAIGHT:
      return Bytes.getWriter(directory, id, Bytes.Mode.STRAIGHT, comp, true,
          bytesUsed);
    case BYTES_FIXED_DEREF:
      return Bytes.getWriter(directory, id, Bytes.Mode.DEREF, comp, true,
          bytesUsed);
    case BYTES_FIXED_SORTED:
      return Bytes.getWriter(directory, id, Bytes.Mode.SORTED, comp, true,
          bytesUsed);
    case BYTES_VAR_STRAIGHT:
      return Bytes.getWriter(directory, id, Bytes.Mode.STRAIGHT, comp, false,
          bytesUsed);
    case BYTES_VAR_DEREF:
      return Bytes.getWriter(directory, id, Bytes.Mode.DEREF, comp, false,
          bytesUsed);
    case BYTES_VAR_SORTED:
      return Bytes.getWriter(directory, id, Bytes.Mode.SORTED, comp, false,
          bytesUsed);

    default:
      throw new IllegalArgumentException("Unknown Values: " + type);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305964/fstmerge_base_4557594327789430300
public static Writer create(ValueType type, String id, Directory directory,
      Comparator<BytesRef> comp, AtomicLong bytesUsed) throws IOException {
    if (comp == null) {
      comp = BytesRef.getUTF8SortedAsUnicodeComparator();
    }
    switch (type) {
    case INTS:
      return Ints.getWriter(directory, id, true, bytesUsed);
    case FLOAT_32:
      return Floats.getWriter(directory, id, 4, bytesUsed);
    case FLOAT_64:
      return Floats.getWriter(directory, id, 8, bytesUsed);
    case BYTES_FIXED_STRAIGHT:
      return Bytes.getWriter(directory, id, Bytes.Mode.STRAIGHT, comp, true,
          bytesUsed);
    case BYTES_FIXED_DEREF:
      return Bytes.getWriter(directory, id, Bytes.Mode.DEREF, comp, true,
          bytesUsed);
    case BYTES_FIXED_SORTED:
      return Bytes.getWriter(directory, id, Bytes.Mode.SORTED, comp, true,
          bytesUsed);
    case BYTES_VAR_STRAIGHT:
      return Bytes.getWriter(directory, id, Bytes.Mode.STRAIGHT, comp, false,
          bytesUsed);
    case BYTES_VAR_DEREF:
      return Bytes.getWriter(directory, id, Bytes.Mode.DEREF, comp, false,
          bytesUsed);
    case BYTES_VAR_SORTED:
      return Bytes.getWriter(directory, id, Bytes.Mode.SORTED, comp, false,
          bytesUsed);
    default:
      throw new IllegalArgumentException("Unknown Values: " + type);
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419680305964/fstmerge_var2_4445098400442247230

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_6e8e0_28cae/rev_6e8e0-28cae/lucene/src/java/org/apache/lucene/index/values/Writer.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_2c0c8/rev_4469c-2c0c8.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac.revisions
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public PerDocValues docsProducer(SegmentReadState state) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682439106/fstmerge_var1_6669405282736963165
      return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, getDocValuesUseCFS(), getDocValuesSortComparator());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682439106/fstmerge_base_8581341736821752006
      return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId);
=======
      return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, state.context);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682439106/fstmerge_var2_8227540142848017737
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/test/org/apache/lucene/index/TestDocTermOrds.java
Conflict type: LineBasedMCFd
Conflict body: 
public void runTestBytes(final Bytes.Mode mode, final boolean fixedSize)
      throws IOException {

    final BytesRef bytesRef = new BytesRef();

    final Comparator<BytesRef> comp = mode == Bytes.Mode.SORTED ? BytesRef
        .getUTF8SortedAsUnicodeComparator() : null;

    Directory dir = newDirectory();
    final AtomicLong trackBytes = new AtomicLong(0);
    Writer w = Bytes.getWriter(dir, "test", mode, comp, fixedSize, trackBytes, newIOContext(random));
    int maxDoc = 220;
    final String[] values = new String[maxDoc];
    final int fixedLength = 1 + atLeast(50);
    for (int i = 0; i < 100; i++) {
      final String s;
      if (i > 0 && random.nextInt(5) <= 2) {
        // use prior value
        s = values[2 * random.nextInt(i)];
      } else {
        s = _TestUtil.randomFixedByteLengthUnicodeString(random, fixedSize? fixedLength : 1 + random.nextInt(39));
      }
      values[2 * i] = s;

      UnicodeUtil.UTF16toUTF8(s, 0, s.length(), bytesRef);
      w.add(2 * i, bytesRef);
    }
    w.finish(maxDoc);
    assertEquals(0, trackBytes.get());

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682443472/fstmerge_var1_4734955644262310135
    IndexDocValues r = Bytes.getValues(dir, "test", mode, fixedSize, maxDoc, comp);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682443472/fstmerge_base_4603023697251670770
    IndexDocValues r = Bytes.getValues(dir, "test", mode, fixedSize, maxDoc);
=======
    IndexDocValues r = Bytes.getValues(dir, "test", mode, fixedSize, maxDoc, newIOContext(random));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682443472/fstmerge_var2_6751613141945034228
    for (int iter = 0; iter < 2; iter++) {
      ValuesEnum bytesEnum = getEnum(r);
      assertNotNull("enum is null", bytesEnum);
      BytesRef ref = bytesEnum.bytes();

      for (int i = 0; i < 2; i++) {
        final int idx = 2 * i;
        assertEquals("doc: " + idx, idx, bytesEnum.advance(idx));
        String utf8String = ref.utf8ToString();
        assertEquals("doc: " + idx + " lenLeft: " + values[idx].length()
            + " lenRight: " + utf8String.length(), values[idx], utf8String);
      }
      assertEquals(ValuesEnum.NO_MORE_DOCS, bytesEnum.advance(maxDoc));
      assertEquals(ValuesEnum.NO_MORE_DOCS, bytesEnum.advance(maxDoc + 1));

      bytesEnum.close();
    }

    // Verify we can load source twice:
    for (int iter = 0; iter < 2; iter++) {
      Source s;
      IndexDocValues.SortedSource ss;
      if (mode == Bytes.Mode.SORTED) {
        // default is unicode so we can simply pass null here
        s = ss = getSortedSource(r, random.nextBoolean() ? comp : null);  
      } else {
        s = getSource(r);
        ss = null;
      }
      for (int i = 0; i < 100; i++) {
        final int idx = 2 * i;
        assertNotNull("doc " + idx + "; value=" + values[idx], s.getBytes(idx,
            bytesRef));
        assertEquals("doc " + idx, values[idx], s.getBytes(idx, bytesRef)
            .utf8ToString());
        if (ss != null) {
          assertEquals("doc " + idx, values[idx], ss.getByOrd(ss.ord(idx),
              bytesRef).utf8ToString());
         int ord = ss
              .getByValue(new BytesRef(values[idx]));
          assertTrue(ord >= 0);
          assertEquals(ss.ord(idx), ord);
        }
      }

      // Lookup random strings:
      if (mode == Bytes.Mode.SORTED) {
        final int numValues = ss.getValueCount();
        for (int i = 0; i < 1000; i++) {
          BytesRef bytesValue = new BytesRef(_TestUtil.randomFixedByteLengthUnicodeString(random, fixedSize? fixedLength : 1 + random.nextInt(39)));
          int ord = ss.getByValue(bytesValue);
          if (ord >= 0) {
            assertTrue(bytesValue
                .bytesEquals(ss.getByOrd(ord, bytesRef)));
            int count = 0;
            for (int k = 0; k < 100; k++) {
              if (bytesValue.utf8ToString().equals(values[2 * k])) {
                assertEquals(ss.ord(2 * k), ord);
                count++;
              }
            }
            assertTrue(count > 0);
          } else {
            assert ord < 0;
            int insertIndex = (-ord)-1;
            if (insertIndex == 0) {
              final BytesRef firstRef = ss.getByOrd(1, bytesRef);
              // random string was before our first
              assertTrue(firstRef.compareTo(bytesValue) > 0);
            } else if (insertIndex == numValues) {
              final BytesRef lastRef = ss.getByOrd(numValues-1, bytesRef);
              // random string was after our last
              assertTrue(lastRef.compareTo(bytesValue) < 0);
            } else {
              final BytesRef before = (BytesRef) ss.getByOrd(insertIndex-1, bytesRef)
              .clone();
              BytesRef after = ss.getByOrd(insertIndex, bytesRef);
              assertTrue(comp.compare(before, bytesValue) < 0);
              assertTrue(comp.compare(bytesValue, after) < 0);
            }
          }
        }
      }
    }

    r.close();
    dir.close();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/test/org/apache/lucene/index/values/TestDocValues.java
Conflict type: LineBasedMCFd
Conflict body: 
public void close() throws IOException {
    if (closed) {
      throw new IllegalStateException("already closed");
    }
    IOException priorException = null;
    IndexOutput entryTableOut = null;
    try {
      initDataOut();
      if (!pendingEntries.isEmpty() || outputTaken.get()) {
        throw new IllegalStateException("CFS has pending open files");
      }
      closed = true;
      // open the compound stream
      assert dataOut != null;
      long finalLength = dataOut.getFilePointer();
      assert assertFileLength(finalLength, dataOut);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460164/fstmerge_var1_3590165439488171351
    } catch (IOException e) {
      priorException = e;
    } finally {
      IOUtils.closeSafely(priorException, dataOut);
    }
    try {
      entryTableOut = directory.createOutput(entryTableName);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460164/fstmerge_base_5449342807833445412
      entryTableOut = directory.createOutput(entryTableName);
=======
      entryTableOut = directory.createOutput(entryTableName, IOContext.DEFAULT);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460164/fstmerge_var2_4496175096793317326
      writeEntryTable(entries.values(), entryTableOut);
    } catch (IOException e) {
      priorException = e;
    } finally {
      IOUtils.closeSafely(priorException, entryTableOut);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/java/org/apache/lucene/store/CompoundFileWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460294/fstmerge_var1_7153545188189107834
public CompoundFileDirectory(Directory directory, String fileName, int readBufferSize) throws IOException {

    this.directory = directory;
    this.fileName = fileName;
    this.readBufferSize = readBufferSize;
    this.isOpen = false;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460294/fstmerge_base_818457411242865462
public CompoundFileDirectory(Directory directory, String fileName, int readBufferSize) throws IOException {
    assert !(directory instanceof CompoundFileDirectory) : "compound file inside of compound file: " + fileName;
    this.directory = directory;
    this.fileName = fileName;
    this.readBufferSize = readBufferSize;
    this.isOpen = false;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460294/fstmerge_var2_844313925773857516

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/java/org/apache/lucene/store/CompoundFileDirectory.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460306/fstmerge_var1_8679208586656064652
@Override
  public IndexOutput createOutput(String name) throws IOException {
    ensureOpen();
    return writer.createOutput(name);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460306/fstmerge_base_8566741016957727902
@Override
  public IndexOutput createOutput(String name) throws IOException {
    ensureOpen();
    initWriter();
    return writer.createOutput(name);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460306/fstmerge_var2_4418547168466160762

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/java/org/apache/lucene/store/CompoundFileDirectory.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460311/fstmerge_var1_7932420424682598128
@Override
  public CompoundFileDirectory openCompoundInput(String name, int bufferSize) throws IOException {
    FileEntry fileEntry = this.entries.get(IndexFileNames.stripSegmentName(name));
    if (fileEntry == null) {
      throw new FileNotFoundException("file " + name + " does not exists in this CFS");
    }
    return new NestedCompoundFileDirectory(name, bufferSize, fileEntry.offset, fileEntry.length);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460311/fstmerge_base_2223996610274194266
@Override
  public final CompoundFileDirectory openCompoundInput(String name, int bufferSize) throws IOException {
    // NOTE: final to make nested compounding impossible.
    throw new UnsupportedOperationException();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460311/fstmerge_var2_1860475273815106535

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/java/org/apache/lucene/store/CompoundFileDirectory.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460314/fstmerge_var1_7947125834950693155
@Override
  public CompoundFileDirectory createCompoundOutput(String name)
      throws IOException {
    throw new UnsupportedOperationException("can not create nested CFS, create seperately and use Directory.copy instead");
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460314/fstmerge_base_3848935932937693016
@Override
  public CompoundFileDirectory createCompoundOutput(String name)
      throws IOException {
    // NOTE: final to make nested compounding impossible.
    throw new UnsupportedOperationException();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682460314/fstmerge_var2_6638971047020663995

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/java/org/apache/lucene/store/CompoundFileDirectory.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public DocValuesConsumer addValuesField(FieldInfo field) throws IOException {
    return Writer.create(field.getDocValues(),
        docValuesId(segmentName, codecId, field.number),
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682468448/fstmerge_var1_8451274734988263189
        directory, comparator, bytesUsed);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682468448/fstmerge_base_5904146400202522403
        // TODO can we have a compound file per segment and codec for
        // docvalues?
        directory, comparator, bytesUsed);
=======
        // TODO can we have a compound file per segment and codec for
        // docvalues?
        directory, comparator, bytesUsed, IOContext.DEFAULT);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682468448/fstmerge_var2_8835111925661404763
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/java/org/apache/lucene/index/codecs/DefaultDocValuesConsumer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682468914/fstmerge_var1_7586240533604352131
protected TreeMap<String, IndexDocValues> load(FieldInfos fieldInfos,
      String segment, int docCount, Directory dir, int codecId)
      throws IOException {
    TreeMap<String, IndexDocValues> values = new TreeMap<String, IndexDocValues>();
    boolean success = false;
    try {

      for (FieldInfo fieldInfo : fieldInfos) {
        if (codecId == fieldInfo.getCodecId() && fieldInfo.hasDocValues()) {
          final String field = fieldInfo.name;
          // TODO can we have a compound file per segment and codec for
          // docvalues?
          final String id = DefaultDocValuesConsumer.docValuesId(segment,
              codecId, fieldInfo.number);
          values.put(field,
              loadDocValues(docCount, dir, id, fieldInfo.getDocValues(), sortComparator));
        }
      }
      success = true;
    } finally {
      if (!success) {
        // if we fail we must close all opened resources if there are any
        closeInternal(values.values());
      }
    }
    return values;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682468914/fstmerge_base_5331069494168778305
protected TreeMap<String, IndexDocValues> load(FieldInfos fieldInfos,
      String segment, int docCount, Directory dir, int codecId)
      throws IOException {
    TreeMap<String, IndexDocValues> values = new TreeMap<String, IndexDocValues>();
    boolean success = false;
    try {

      for (FieldInfo fieldInfo : fieldInfos) {
        if (codecId == fieldInfo.getCodecId() && fieldInfo.hasDocValues()) {
          final String field = fieldInfo.name;
          // TODO can we have a compound file per segment and codec for
          // docvalues?
          final String id = DefaultDocValuesConsumer.docValuesId(segment,
              codecId, fieldInfo.number);
          values.put(field,
              loadDocValues(docCount, dir, id, fieldInfo.getDocValues()));
        }
      }
      success = true;
    } finally {
      if (!success) {
        // if we fail we must close all opened resources if there are any
        closeDocValues(values.values());
      }
    }
    return values;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682468914/fstmerge_var2_7222598102954748139

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/java/org/apache/lucene/index/codecs/DefaultDocValuesProducer.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public PerDocValues docsProducer(SegmentReadState state) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682470065/fstmerge_var1_3060025897953543199
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, getDocValuesUseCFS(), getDocValuesSortComparator());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682470065/fstmerge_base_2710765227648776051
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId);
=======
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, state.context);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682470065/fstmerge_var2_2714913005946666958
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/java/org/apache/lucene/index/codecs/standard/StandardCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public PerDocValues docsProducer(SegmentReadState state) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682470548/fstmerge_var1_8860849742242826473
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, getDocValuesUseCFS(), getDocValuesSortComparator());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682470548/fstmerge_base_9019791903361398121
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId);
=======
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, IOContext.READONCE);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682470548/fstmerge_var2_4163439853870641752
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/java/org/apache/lucene/index/codecs/memory/MemoryCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public PerDocValues docsProducer(SegmentReadState state) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682470643/fstmerge_var1_6875872009909529802
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, getDocValuesUseCFS(), getDocValuesSortComparator());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682470643/fstmerge_base_9213164909193824196
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId);
=======
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, state.context);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682470643/fstmerge_var2_5113018601719135103
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/java/org/apache/lucene/index/codecs/simpletext/SimpleTextCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public PerDocValues docsProducer(SegmentReadState state) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682470873/fstmerge_var1_1694215780922775140
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, getDocValuesUseCFS(), getDocValuesSortComparator());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682470873/fstmerge_base_8996343330404685492
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId);
=======
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, state.context);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682470873/fstmerge_var2_2727282253779821696
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/java/org/apache/lucene/index/codecs/pulsing/PulsingCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public PerDocValues docsProducer(SegmentReadState state) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682475648/fstmerge_var1_1210062138711915977
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, getDocValuesUseCFS(), getDocValuesSortComparator());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682475648/fstmerge_base_3686899308636384446
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId);
=======
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, state.context);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682475648/fstmerge_var2_7466712221903971683
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/test-framework/org/apache/lucene/index/codecs/mockintblock/MockFixedIntBlockCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public PerDocValues docsProducer(SegmentReadState state) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682475695/fstmerge_var1_13944580696184444
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, getDocValuesUseCFS(), getDocValuesSortComparator());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682475695/fstmerge_base_7554153601019328573
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId);
=======
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, state.context);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682475695/fstmerge_var2_9073117833216345673
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/test-framework/org/apache/lucene/index/codecs/mockintblock/MockVariableIntBlockCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public PerDocValues docsProducer(SegmentReadState state) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682475872/fstmerge_var1_7394069698024049046
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, getDocValuesUseCFS(), getDocValuesSortComparator());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682475872/fstmerge_base_2173655489847019023
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId);
=======
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, state.context);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682475872/fstmerge_var2_6357818673317913949
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/test-framework/org/apache/lucene/index/codecs/mocksep/MockSepCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public PerDocValues docsProducer(SegmentReadState state) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682475971/fstmerge_var1_7354221256334445196
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, getDocValuesUseCFS(), getDocValuesSortComparator());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682475971/fstmerge_base_4408175135014979181
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId);
=======
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, state.context);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682475971/fstmerge_var2_2784252742236351799
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/src/test-framework/org/apache/lucene/index/codecs/mockrandom/MockRandomCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public PerDocValues docsProducer(SegmentReadState state) throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682485604/fstmerge_var1_167372036808928135
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, getDocValuesUseCFS(), getDocValuesSortComparator());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682485604/fstmerge_base_7887394254734796575
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId);
=======
    return new DefaultDocValuesProducer(state.segmentInfo, state.dir, state.fieldInfos, state.codecId, state.context);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419682485604/fstmerge_var2_2141985457525754445
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4469c_f32ac/rev_4469c-f32ac/lucene/contrib/misc/src/java/org/apache/lucene/index/codecs/appending/AppendingCodec.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_45243_4469c/rev_45243-4469c.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_79e50_2bc07/rev_79e50-2bc07.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684685851/fstmerge_var1_6190571022581709391
public void testTwoServers() throws Exception {
    LBHttpSolrServer lbHttpSolrServer = new LBHttpSolrServer(httpClient, solr[0].getUrl(), solr[1].getUrl());
    lbHttpSolrServer.setAliveCheckInterval(500);
    SolrQuery solrQuery = new SolrQuery("*:*");
    QueryResponse resp = null;
    solr[0].jetty.stop();
    solr[0].jetty = null;
    resp = lbHttpSolrServer.query(solrQuery);
    String name = resp.getResults().get(0).getFieldValue("name").toString();
    Assert.assertEquals("solr1", name);
    resp = lbHttpSolrServer.query(solrQuery);
    name = resp.getResults().get(0).getFieldValue("name").toString();
    Assert.assertEquals("solr1", name);
    solr[1].jetty.stop();
    solr[1].jetty = null;
    solr[0].startJetty();
    Thread.sleep(1200);
    try {
      resp = lbHttpSolrServer.query(solrQuery);
    } catch(SolrServerException e) {
      // try again after a pause in case the error is lack of time to start server
      Thread.sleep(3000);
      resp = lbHttpSolrServer.query(solrQuery);
    }
    name = resp.getResults().get(0).getFieldValue("name").toString();
    Assert.assertEquals("solr0", name);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684685851/fstmerge_base_8788436179658636722
public void testTwoServers() throws Exception {
    LBHttpSolrServer lbHttpSolrServer = new LBHttpSolrServer(httpClient, solr[0].getUrl(), solr[1].getUrl());
    lbHttpSolrServer.setAliveCheckInterval(500);
    SolrQuery solrQuery = new SolrQuery("*:*");
    Set<String> names = new HashSet<String>();
    QueryResponse resp = null;
    solr[0].jetty.stop();
    solr[0].jetty = null;
    resp = lbHttpSolrServer.query(solrQuery);
    String name = resp.getResults().get(0).getFieldValue("name").toString();
    Assert.assertEquals("solr1", name);
    resp = lbHttpSolrServer.query(solrQuery);
    name = resp.getResults().get(0).getFieldValue("name").toString();
    Assert.assertEquals("solr1", name);
    solr[1].jetty.stop();
    solr[1].jetty = null;
    solr[0].startJetty();
    Thread.sleep(1200);
    try {
      resp = lbHttpSolrServer.query(solrQuery);
    } catch(SolrServerException e) {
      // try again after a pause in case the error is lack of time to start server
      Thread.sleep(3000);
      resp = lbHttpSolrServer.query(solrQuery);
    }
    name = resp.getResults().get(0).getFieldValue("name").toString();
    Assert.assertEquals("solr0", name);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684685851/fstmerge_var2_993904956969360480

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_79e50_2bc07/rev_79e50-2bc07/solr/src/test/org/apache/solr/client/solrj/TestLBHttpSolrServer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684689824/fstmerge_var1_8945144202812522590
public void setUp() throws Exception {
      System.setProperty("solr.test.sys.prop1", "propone");
      System.setProperty("solr.test.sys.prop2", "proptwo");

      File home = new File(TEMP_DIR, 
                           getClass().getName() + "-" + 
                           System.currentTimeMillis());
                           

      homeDir = new File(home, name);
      dataDir = new File(homeDir, "data");
      confDir = new File(homeDir, "conf");

      homeDir.mkdirs();
      dataDir.mkdirs();
      confDir.mkdirs();

      copyConfigFile(getSolrConfigFile(), "solrconfig.xml");
      copyConfigFile(getSchemaFile(), "schema.xml");
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684689824/fstmerge_base_7642502884737281318
public void setUp() throws Exception {
      System.setProperty("solr.test.sys.prop1", "propone");
      System.setProperty("solr.test.sys.prop2", "proptwo");

      File home = new File(TEMP_DIR, 
                           getClass().getName() + "-" + 
                           System.currentTimeMillis());
                           

      homeDir = new File(home, name);
      dataDir = new File(homeDir, "data");
      confDir = new File(homeDir, "conf");

      homeDir.mkdirs();
      dataDir.mkdirs();
      confDir.mkdirs();

      File f = new File(confDir, "solrconfig.xml");
      copyConfigFile(getSolrConfigFile(), "solrconfig.xml");
      copyConfigFile(getSchemaFile(), "schema.xml");
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684689824/fstmerge_var2_5601941323279331052

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_79e50_2bc07/rev_79e50-2bc07/solr/src/test/org/apache/solr/handler/TestReplicationHandler.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ private static final HashSet<String> NL_TAGS = new HashSet<String>
    (Arrays.asList("lst", "arr",
                   "bool",
                   "str",
                   "int","long",
                   "float","double")); ##FSTMerge## private static final HashSet<String> NL_TAGS = new HashSet<String>(Arrays.asList("lst","str","int","bool","arr","float","double")); ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_79e50_2bc07/rev_79e50-2bc07/solr/src/java/org/apache/solr/core/PluginInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684700439/fstmerge_var1_6022889375670279344
public RefCntRamDirectory(Directory dir) throws IOException {
    this();
    for (String file : dir.listAll()) {
      dir.copy(this, file, file, IOContext.DEFAULT);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684700439/fstmerge_base_8154561097691690497
public RefCntRamDirectory(Directory dir) throws IOException {
    this();
    for (String file : dir.listAll()) {
      dir.copy(this, file, file);
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684700439/fstmerge_var2_6375090224118262220

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_79e50_2bc07/rev_79e50-2bc07/solr/src/java/org/apache/solr/core/RefCntRamDirectory.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684700488/fstmerge_var1_8697087085152131512
public CoreDescriptor(CoreContainer coreContainer, String name, String instanceDir) {
    this.coreContainer = coreContainer;
    this.name = name;
    
    if(coreContainer.getZkController() != null) {
      this.cloudDesc = new CloudDescriptor();
      // cloud collection defaults to core name
      cloudDesc.setCollectionName(name.isEmpty() ? coreContainer.getDefaultCoreName() : name);
      this.cloudDesc.setShardId(coreContainer.getZkController().getNodeName() + "_" + name);
    }
    
    if (name == null) {
      throw new RuntimeException("Core needs a name");
    }
    if (instanceDir == null) {
      throw new NullPointerException("Missing required \'instanceDir\'");
    }
    instanceDir = SolrResourceLoader.normalizeDir(instanceDir);
    this.instanceDir = instanceDir;
    this.configName = getDefaultConfigName();
    this.schemaName = getDefaultSchemaName();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684700488/fstmerge_base_7161255604471390866
public CoreDescriptor(CoreContainer coreContainer, String name, String instanceDir) {
    this.coreContainer = coreContainer;
    this.name = name;
    
    if(coreContainer.getZkController() != null) {
      this.cloudDesc = new CloudDescriptor();
      // cloud collection defaults to core name
      cloudDesc.setCollectionName(name == "" ? coreContainer.getDefaultCoreName() : name);
      this.cloudDesc.setShardId(coreContainer.getZkController().getNodeName() + "_" + name);
    }
    
    if (name == null) {
      throw new RuntimeException("Core needs a name");
    }
    if (instanceDir == null) {
      throw new NullPointerException("Missing required \'instanceDir\'");
    }
    instanceDir = SolrResourceLoader.normalizeDir(instanceDir);
    this.instanceDir = instanceDir;
    this.configName = getDefaultConfigName();
    this.schemaName = getDefaultSchemaName();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684700488/fstmerge_var2_1648036324349534747

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_79e50_2bc07/rev_79e50-2bc07/solr/src/java/org/apache/solr/core/CoreDescriptor.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684706567/fstmerge_var1_3182885364055557526
private List<AttributeSource> analyzeTokenStream(TokenStream tokenStream) {
    final List<AttributeSource> tokens = new ArrayList<AttributeSource>();
    final PositionIncrementAttribute posIncrAtt = tokenStream.addAttribute(PositionIncrementAttribute.class);
    final TokenTrackingAttribute trackerAtt = tokenStream.addAttribute(TokenTrackingAttribute.class);
    // for backwards compatibility, add all "common" attributes
    tokenStream.addAttribute(OffsetAttribute.class);
    tokenStream.addAttribute(TypeAttribute.class);
    try {
      tokenStream.reset();
      int position = 0;
      while (tokenStream.incrementToken()) {
        position += posIncrAtt.getPositionIncrement();
        trackerAtt.setActPosition(position);
        tokens.add(tokenStream.cloneAttributes());
      }
    } catch (IOException ioe) {
      throw new RuntimeException("Error occured while iterating over tokenstream", ioe);
    }

    return tokens;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684706567/fstmerge_base_7317567162914378366
private List<AttributeSource> analyzeTokenStream(TokenStream tokenStream) {
    final List<AttributeSource> tokens = new ArrayList<AttributeSource>();
    final PositionIncrementAttribute posIncrAtt = tokenStream.addAttribute(PositionIncrementAttribute.class);
    final TokenTrackingAttribute trackerAtt = tokenStream.addAttribute(TokenTrackingAttribute.class);
    // for backwards compatibility, add all "common" attributes
    tokenStream.addAttribute(OffsetAttribute.class);
    tokenStream.addAttribute(TypeAttribute.class);
    final BytesRef bytes = new BytesRef();
    try {
      tokenStream.reset();
      int position = 0;
      while (tokenStream.incrementToken()) {
        position += posIncrAtt.getPositionIncrement();
        trackerAtt.setActPosition(position);
        tokens.add(tokenStream.cloneAttributes());
      }
    } catch (IOException ioe) {
      throw new RuntimeException("Error occured while iterating over tokenstream", ioe);
    }

    return tokens;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684706567/fstmerge_var2_7706688352441628521

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_79e50_2bc07/rev_79e50-2bc07/solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684711920/fstmerge_var1_9012598774759016464
@Override
  public void write(byte b[]) throws IOException {
    write(b,0,b.length);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684711920/fstmerge_base_5732102708433840372
public void write(byte b) throws IOException {
    if (pos >= buf.length) {
      out.write(buf);
      written += pos;
      pos=0;
    }
    buf[pos++] = b;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419684711920/fstmerge_var2_61299226168383336

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_79e50_2bc07/rev_79e50-2bc07/solr/src/common/org/apache/solr/common/util/FastOutputStream.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ab64c_d723e/rev_ab64c-d723e.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419685796804/fstmerge_var1_6069091916840560606
public SolrQuery addFacetQuery(String f) {
    this.add(FacetParams.FACET_QUERY, f);
    this.set(FacetParams.FACET, true);
    return this;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419685796804/fstmerge_base_214747327299900135
public SolrQuery addFacetQuery(String f) {
    this.add(FacetParams.FACET_QUERY, f);
    return this;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419685796804/fstmerge_var2_4415729602798188226

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ab64c_d723e/rev_ab64c-d723e/solr/src/solrj/org/apache/solr/client/solrj/SolrQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419685797946/fstmerge_var1_9219666257004446223
public List<Count> getValues() {
     return _values == null ? Collections.<Count>emptyList() : _values;
   }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419685797946/fstmerge_base_1659736947496688921
public List<Count> getValues() {
     return _values;
   }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419685797946/fstmerge_var2_912293531714572701

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ab64c_d723e/rev_ab64c-d723e/solr/src/solrj/org/apache/solr/client/solrj/response/FacetField.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419685817771/fstmerge_var1_4101768878762336970
@Override
  public void write(byte b[]) throws IOException {
    write(b,0,b.length);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419685817771/fstmerge_base_6880813827587303327
public void write(byte b) throws IOException {
    if (pos >= buf.length) {
      out.write(buf);
      written += pos;
      pos=0;
    }
    buf[pos++] = b;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419685817771/fstmerge_var2_7657729237234799058

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ab64c_d723e/rev_ab64c-d723e/solr/src/common/org/apache/solr/common/util/FastOutputStream.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_15b8b_72d48/rev_15b8b-72d48.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419686937880/fstmerge_var1_2940472296544282879
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419686937880/fstmerge_base_8660909670675911648
@Override
  public void write(byte b[]) throws IOException {
    write(b,0,b.length);
  }
=======
public void write(byte b) throws IOException {
    if (pos >= buf.length) {
      out.write(buf);
      written += pos;
      pos=0;
    }
    buf[pos++] = b;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419686937880/fstmerge_var2_7637021563294476908

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_15b8b_72d48/rev_15b8b-72d48/solr/src/common/org/apache/solr/common/util/FastOutputStream.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_90e99_55aa8/rev_90e99-55aa8.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_7ad79_9650b/rev_7ad79-9650b.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c69d5_79527/rev_c69d5-79527.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419691151891/fstmerge_var1_973328034390953632
public int deleteDocuments(Term term) throws StaleReaderException, CorruptIndexException, LockObtainFailedException, IOException {
    ensureOpen();
    DocsEnum docs = MultiFields.getTermDocsEnum(this,
                                                MultiFields.getLiveDocs(this),
                                                term.field(),
                                                term.bytes(),
                                                false);
    if (docs == null) {
      return 0;
    }
    int n = 0;
    int doc;
    while ((doc = docs.nextDoc()) != DocsEnum.NO_MORE_DOCS) {
      deleteDocument(doc);
      n++;
    }
    return n;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419691151891/fstmerge_base_5255984039658261017
public int deleteDocuments(Term term) throws StaleReaderException, CorruptIndexException, LockObtainFailedException, IOException {
    ensureOpen();
    DocsEnum docs = MultiFields.getTermDocsEnum(this,
                                                MultiFields.getLiveDocs(this),
                                                term.field(),
                                                term.bytes());
    if (docs == null) return 0;
    int n = 0;
    int doc;
    while ((doc = docs.nextDoc()) != DocsEnum.NO_MORE_DOCS) {
      deleteDocument(doc);
      n++;
    }
    return n;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419691151891/fstmerge_var2_6658299549526896663

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c69d5_79527/rev_c69d5-79527/lucene/src/java/org/apache/lucene/index/IndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419691170400/fstmerge_var1_5759269460789619449
public void reSetNorms(String field) throws IOException {
    Similarity fieldSim = sim.get(field); 
    IndexReader reader = null;
    try {
      reader = IndexReader.open(dir, false);

      final List<IndexReader> subReaders = new ArrayList<IndexReader>();
      ReaderUtil.gatherSubReaders(subReaders, reader);

      final FieldInvertState invertState = new FieldInvertState();
      for(IndexReader subReader : subReaders) {
        final Bits liveDocs = subReader.getLiveDocs();

        int[] termCounts = new int[subReader.maxDoc()];
        Fields fields = subReader.fields();
        if (fields != null) {
          Terms terms = fields.terms(field);
          if (terms != null) {
            TermsEnum termsEnum = terms.iterator(null);
            DocsEnum docs = null;
            DocsEnum docsAndFreqs = null;
            while(termsEnum.next() != null) {
              docsAndFreqs = termsEnum.docs(liveDocs, docsAndFreqs, true);
              final DocsEnum docs2;
              if (docsAndFreqs != null) {
                docs2 = docsAndFreqs;
              } else {
                docs2 = docs = termsEnum.docs(liveDocs, docs, false);
              }
              while(true) {
                int docID = docs2.nextDoc();
                if (docID != docs.NO_MORE_DOCS) {
                  termCounts[docID] += docsAndFreqs == null ? 1 : docsAndFreqs.freq();
                } else {
                  break;
                }
              }
            }
          }
        }

        invertState.setBoost(1.0f);
        for (int d = 0; d < termCounts.length; d++) {
          if (liveDocs == null || liveDocs.get(d)) {
            invertState.setLength(termCounts[d]);
            subReader.setNorm(d, field, fieldSim.computeNorm(invertState));
          }
        }
      }
      
    } finally {
      if (null != reader) reader.close();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419691170400/fstmerge_base_5923600836942327282
public void reSetNorms(String field) throws IOException {
    Similarity fieldSim = sim.get(field); 
    IndexReader reader = null;
    try {
      reader = IndexReader.open(dir, false);

      final List<IndexReader> subReaders = new ArrayList<IndexReader>();
      ReaderUtil.gatherSubReaders(subReaders, reader);

      final FieldInvertState invertState = new FieldInvertState();
      for(IndexReader subReader : subReaders) {
        final Bits liveDocs = subReader.getLiveDocs();

        int[] termCounts = new int[subReader.maxDoc()];
        Fields fields = subReader.fields();
        if (fields != null) {
          Terms terms = fields.terms(field);
          if (terms != null) {
            TermsEnum termsEnum = terms.iterator(null);
            DocsEnum docs = null;
            while(termsEnum.next() != null) {
              docs = termsEnum.docs(liveDocs, docs);
              while(true) {
                int docID = docs.nextDoc();
                if (docID != docs.NO_MORE_DOCS) {
                  termCounts[docID] += docs.freq();
                } else {
                  break;
                }
              }
            }
          }
        }

        invertState.setBoost(1.0f);
        for (int d = 0; d < termCounts.length; d++) {
          if (liveDocs == null || liveDocs.get(d)) {
            invertState.setLength(termCounts[d]);
            subReader.setNorm(d, field, fieldSim.computeNorm(invertState));
          }
        }
      }
      
    } finally {
      if (null != reader) reader.close();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419691170400/fstmerge_var2_7814497143563252805

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c69d5_79527/rev_c69d5-79527/lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f86a2_08a8c/rev_f86a2-08a8c.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419694416269/fstmerge_var1_5151876724074329207
private void openNorms(Directory cfsDir, IOContext context) throws IOException {
    boolean normsInitiallyEmpty = norms.isEmpty(); // only used for assert
    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)
    int maxDoc = maxDoc();
    for (FieldInfo fi : core.fieldInfos) {
      if (norms.containsKey(fi.name)) {
        // in case this SegmentReader is being re-opened, we might be able to
        // reuse some norm instances and skip loading them here
        continue;
      }
      if (fi.isIndexed && !fi.omitNorms) {
        Directory d = directory();
        String fileName = si.getNormFileName(fi.number);
        if (!si.hasSeparateNorms(fi.number)) {
          d = cfsDir;
        }
        
        // singleNormFile means multiple norms share this file
        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);
        IndexInput normInput = null;
        long normSeek;

        if (singleNormFile) {
          normSeek = nextNormSeek;
          if (singleNormStream == null) {
            singleNormStream = d.openInput(fileName, context);
            singleNormRef = new AtomicInteger(1);
          } else {
            singleNormRef.incrementAndGet();
          }
          // All norms in the .nrm file can share a single IndexInput since
          // they are only used in a synchronized context.
          // If this were to change in the future, a clone could be done here.
          normInput = singleNormStream;
        } else {
          normInput = d.openInput(fileName, context);
          // if the segment was created in 3.2 or after, we wrote the header for sure,
          // and don't need to do the sketchy file size check. otherwise, we check 
          // if the size is exactly equal to maxDoc to detect a headerless file.
          // NOTE: remove this check in Lucene 5.0!
          String version = si.getVersion();
          final boolean isUnversioned = 
            (version == null || StringHelper.getVersionComparator().compare(version, "3.2") < 0)
            && normInput.length() == maxDoc();
          if (isUnversioned) {
            normSeek = 0;
          } else {
            normSeek = SegmentNorms.NORMS_HEADER.length;
          }
        }

        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));
        nextNormSeek += maxDoc; // increment also if some norms are separate
      }
    }
    assert singleNormStream == null || !normsInitiallyEmpty || nextNormSeek == singleNormStream.length();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419694416269/fstmerge_base_6584206776123939224
private void openNorms(Directory cfsDir, IOContext context) throws IOException {
    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)
    int maxDoc = maxDoc();
    for (FieldInfo fi : core.fieldInfos) {
      if (norms.containsKey(fi.name)) {
        // in case this SegmentReader is being re-opened, we might be able to
        // reuse some norm instances and skip loading them here
        continue;
      }
      if (fi.isIndexed && !fi.omitNorms) {
        Directory d = directory();
        String fileName = si.getNormFileName(fi.number);
        if (!si.hasSeparateNorms(fi.number)) {
          d = cfsDir;
        }
        
        // singleNormFile means multiple norms share this file
        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);
        IndexInput normInput = null;
        long normSeek;

        if (singleNormFile) {
          normSeek = nextNormSeek;
          if (singleNormStream == null) {
            singleNormStream = d.openInput(fileName, context);
            singleNormRef = new AtomicInteger(1);
          } else {
            singleNormRef.incrementAndGet();
          }
          // All norms in the .nrm file can share a single IndexInput since
          // they are only used in a synchronized context.
          // If this were to change in the future, a clone could be done here.
          normInput = singleNormStream;
        } else {
          normInput = d.openInput(fileName, context);
          // if the segment was created in 3.2 or after, we wrote the header for sure,
          // and don't need to do the sketchy file size check. otherwise, we check 
          // if the size is exactly equal to maxDoc to detect a headerless file.
          // NOTE: remove this check in Lucene 5.0!
          String version = si.getVersion();
          final boolean isUnversioned = 
            (version == null || StringHelper.getVersionComparator().compare(version, "3.2") < 0)
            && normInput.length() == maxDoc();
          if (isUnversioned) {
            normSeek = 0;
          } else {
            normSeek = SegmentNorms.NORMS_HEADER.length;
          }
        }

        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));
        nextNormSeek += maxDoc; // increment also if some norms are separate
      }
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419694416269/fstmerge_var2_940818418050853453

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f86a2_08a8c/rev_f86a2-08a8c/lucene/src/java/org/apache/lucene/index/SegmentReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419694423065/fstmerge_var1_2576597771259078564
@Override
  public void flush(Map<FieldInfo,InvertedDocEndConsumerPerField> fieldsToFlush, SegmentWriteState state) throws IOException {
    if (!state.fieldInfos.hasNorms()) {
      return;
    }

    final String normsFileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.NORMS_EXTENSION);
    IndexOutput normsOut = state.directory.createOutput(normsFileName, state.context);
    boolean success = false;
    try {
      normsOut.writeBytes(SegmentNorms.NORMS_HEADER, 0, SegmentNorms.NORMS_HEADER.length);

      int normCount = 0;

      for (FieldInfo fi : state.fieldInfos) {
        final NormsWriterPerField toWrite = (NormsWriterPerField) fieldsToFlush.get(fi);
        int upto = 0;
        // we must check the final value of omitNorms for the fieldinfo, it could have 
        // changed for this field since the first time we added it.
        if (!fi.omitNorms && toWrite != null && toWrite.upto > 0) {
          normCount++;

          int docID = 0;
          for (; docID < state.numDocs; docID++) {
            if (upto < toWrite.upto && toWrite.docIDs[upto] == docID) {
              normsOut.writeByte(toWrite.norms[upto]);
              upto++;
            } else {
              normsOut.writeByte((byte) 0);
            }
          }

          // we should have consumed every norm
          assert upto == toWrite.upto;

          toWrite.reset();
        } else if (fi.isIndexed && !fi.omitNorms) {
          normCount++;
          // Fill entire field with default norm:
          for(;upto<state.numDocs;upto++)
            normsOut.writeByte((byte) 0);
        }

        assert 4+normCount*(long)state.numDocs == normsOut.getFilePointer() : ".nrm file size mismatch: expected=" + (4+normCount*(long)state.numDocs) + " actual=" + normsOut.getFilePointer();
      }
      success = true;
    } finally {
      if (success) {
        IOUtils.close(normsOut);
      } else {
        IOUtils.closeWhileHandlingException(normsOut);
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419694423065/fstmerge_base_8181687262553175163
@Override
  public void flush(Map<FieldInfo,InvertedDocEndConsumerPerField> fieldsToFlush, SegmentWriteState state) throws IOException {
    if (!state.fieldInfos.hasNorms()) {
      return;
    }

    final String normsFileName = IndexFileNames.segmentFileName(state.segmentName, "", IndexFileNames.NORMS_EXTENSION);
    IndexOutput normsOut = state.directory.createOutput(normsFileName, state.context);
    boolean success = false;
    try {
      normsOut.writeBytes(SegmentNorms.NORMS_HEADER, 0, SegmentNorms.NORMS_HEADER.length);

      int normCount = 0;

      for (FieldInfo fi : state.fieldInfos) {
        final NormsWriterPerField toWrite = (NormsWriterPerField) fieldsToFlush.get(fi);
        int upto = 0;
        if (toWrite != null && toWrite.upto > 0) {
          normCount++;

          int docID = 0;
          for (; docID < state.numDocs; docID++) {
            if (upto < toWrite.upto && toWrite.docIDs[upto] == docID) {
              normsOut.writeByte(toWrite.norms[upto]);
              upto++;
            } else {
              normsOut.writeByte((byte) 0);
            }
          }

          // we should have consumed every norm
          assert upto == toWrite.upto;

          toWrite.reset();
        } else if (fi.isIndexed && !fi.omitNorms) {
          normCount++;
          // Fill entire field with default norm:
          for(;upto<state.numDocs;upto++)
            normsOut.writeByte((byte) 0);
        }

        assert 4+normCount*state.numDocs == normsOut.getFilePointer() : ".nrm file size mismatch: expected=" + (4+normCount*state.numDocs) + " actual=" + normsOut.getFilePointer();
      }
      success = true;
    } finally {
      if (success) {
        IOUtils.close(normsOut);
      } else {
        IOUtils.closeWhileHandlingException(normsOut);
      }
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419694423065/fstmerge_var2_7922832568413580995

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f86a2_08a8c/rev_f86a2-08a8c/lucene/src/java/org/apache/lucene/index/NormsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419694427617/fstmerge_var1_3504029635960755739
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419694427617/fstmerge_base_8701842307075550408
public void testCodec() throws Exception {
    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());
    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));
    
    cfg.setCodec(new AppendingCodec());
    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);
    IndexWriter writer = new IndexWriter(dir, cfg);
    Document doc = new Document();
    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);
    storedTextType.setStoreTermVectors(true);
    storedTextType.setStoreTermVectorPositions(true);
    storedTextType.setStoreTermVectorOffsets(true);
    doc.add(newField("f", text, storedTextType));
    writer.addDocument(doc);
    writer.commit();
    writer.addDocument(doc);
    writer.forceMerge(1);
    writer.close();
    IndexReader reader = IndexReader.open(dir, null, true, 1);
    assertEquals(2, reader.numDocs());
    Document doc2 = reader.document(0);
    assertEquals(text, doc2.get("f"));
    Fields fields = MultiFields.getFields(reader);
    Terms terms = fields.terms("f");
    assertNotNull(terms);
    TermsEnum te = terms.iterator(null);
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("quick")));
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("brown")));
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("fox")));
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("jumped")));
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("over")));
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("lazy")));
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("dog")));
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("the")));
    DocsEnum de = te.docs(null, null, true);
    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);
    assertEquals(2, de.freq());
    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);
    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);
    reader.close();
  }
=======
public void testCodec() throws Exception {
    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());
    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));
    
    cfg.setCodec(new AppendingCodec());
    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);
    IndexWriter writer = new IndexWriter(dir, cfg);
    Document doc = new Document();
    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);
    storedTextType.setStoreTermVectors(true);
    storedTextType.setStoreTermVectorPositions(true);
    storedTextType.setStoreTermVectorOffsets(true);
    doc.add(newField("f", text, storedTextType));
    writer.addDocument(doc);
    writer.commit();
    writer.addDocument(doc);
    writer.forceMerge(1);
    writer.close();
    IndexReader reader = IndexReader.open(dir, 1);
    assertEquals(2, reader.numDocs());
    Document doc2 = reader.document(0);
    assertEquals(text, doc2.get("f"));
    Fields fields = MultiFields.getFields(reader);
    Terms terms = fields.terms("f");
    assertNotNull(terms);
    TermsEnum te = terms.iterator(null);
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("quick")));
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("brown")));
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("fox")));
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("jumped")));
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("over")));
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("lazy")));
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("dog")));
    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef("the")));
    DocsEnum de = te.docs(null, null, true);
    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);
    assertEquals(2, de.freq());
    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);
    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);
    reader.close();
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419694427617/fstmerge_var2_2350030136079201780

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f86a2_08a8c/rev_f86a2-08a8c/lucene/contrib/misc/src/test/org/apache/lucene/index/codecs/appending/TestAppendingCodec.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_eb864_8f1ec/rev_eb864-8f1ec.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_d40b2_43736/rev_d40b2-43736.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_70635_ea857/rev_70635-ea857.revisions
Conflict type: LineBasedMCFd
Conflict body: 
private void mergeFieldInfos() throws IOException {
    // mapping from all docvalues fields found to their promoted types
    // this is because FieldInfos does not store the valueSize
    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();

    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {
      final IndexReader reader = readerAndLiveDocs.reader;
      if (reader instanceof SegmentReader) {
        SegmentReader segmentReader = (SegmentReader) reader;
        FieldInfos readerFieldInfos = segmentReader.fieldInfos();
        for (FieldInfo fi : readerFieldInfos) {
          FieldInfo merged = mergeState.fieldInfos.add(fi);
          // update the type promotion mapping for this reader
          if (fi.hasDocValues()) {
            TypePromoter previous = docValuesTypes.get(merged);
            docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); 
          }
        }
      } else {
        addIndexed(reader, mergeState.fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION_OFFSET), true, true, true, false, IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
        addIndexed(reader, mergeState.fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION), true, true, false, false, IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
        addIndexed(reader, mergeState.fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_OFFSET), true, false, true, false, IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
        addIndexed(reader, mergeState.fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR), true, false, false, false, IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
        addIndexed(reader, mergeState.fieldInfos, reader.getFieldNames(FieldOption.OMIT_POSITIONS), false, false, false, false, IndexOptions.DOCS_AND_FREQS);
        addIndexed(reader, mergeState.fieldInfos, reader.getFieldNames(FieldOption.OMIT_TERM_FREQ_AND_POSITIONS), false, false, false, false, IndexOptions.DOCS_ONLY);
        addIndexed(reader, mergeState.fieldInfos, reader.getFieldNames(FieldOption.STORES_PAYLOADS), false, false, false, true, IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
        addIndexed(reader, mergeState.fieldInfos, reader.getFieldNames(FieldOption.INDEXED), false, false, false, false, IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
        mergeState.fieldInfos.addOrUpdate(reader.getFieldNames(FieldOption.UNINDEXED), false);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419704839812/fstmerge_var1_5205376511551663065
        Collection<String> dvNames = reader.getFieldNames(FieldOption.DOC_VALUES);
        mergeState.fieldInfos.addOrUpdate(dvNames, false);
        for (String dvName : dvNames) {
          mergeState.fieldInfos.fieldInfo(dvName).setDocValues(reader.docValues(dvName).type());
        }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419704839812/fstmerge_base_2727639211184517144
        mergeState.fieldInfos.addOrUpdate(reader.getFieldNames(FieldOption.DOC_VALUES), false);
=======
        Collection<String> dvNames = reader.getFieldNames(FieldOption.DOC_VALUES);
        mergeState.fieldInfos.addOrUpdate(dvNames, false);
        for (String dvName : dvNames) {
          FieldInfo merged = mergeState.fieldInfos.fieldInfo(dvName);
          IndexDocValues docValues = reader.docValues(dvName);
          merged.setDocValuesType(docValues.type());
          TypePromoter previous = docValuesTypes.get(merged);
          docValuesTypes.put(merged, mergeDocValuesType(previous, docValues));
        }
      }
    }
    
    // update any promoted doc values types:
    for (Map.Entry<FieldInfo,TypePromoter> e : docValuesTypes.entrySet()) {
      FieldInfo fi = e.getKey();
      TypePromoter promoter = e.getValue();
      if (promoter == null) {
        fi.resetDocValuesType(null);
      } else {
        assert promoter != TypePromoter.getIdentityPromoter();
        if (fi.getDocValuesType() != promoter.type()) {
          // reset the type if we got promoted
          fi.resetDocValuesType(promoter.type());
        }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419704839812/fstmerge_var2_5138383504104751280
      }
    }
    
    // write the merged infos
    FieldInfosWriter fieldInfosWriter = codec.fieldInfosFormat().getFieldInfosWriter();
    fieldInfosWriter.write(directory, segment, mergeState.fieldInfos, context);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_70635_ea857/rev_70635-ea857/lucene/src/java/org/apache/lucene/index/SegmentMerger.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_7eb15_7c786/rev_7eb15-7c786.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_01228_ce9ed/rev_01228-ce9ed.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_dc771_e6008/rev_dc771-e6008.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f06ef_6c275/rev_f06ef-6c275.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_12924_df83d/rev_12924-df83d.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_e63fe_58db6/rev_e63fe-58db6.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_cfb97_5b238/rev_cfb97-5b238.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2baf8_b9f07/rev_2baf8-b9f07.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f6b1a_0c38b/rev_f6b1a-0c38b.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419757614899/fstmerge_var1_632795205583438805
public Explanation idfExplain(CollectionStatistics collectionStats, TermStatistics termStats) {
    final long df = termStats.docFreq();
    final long max = collectionStats.maxDoc();
    final float idf = idf(df, max);
    return new Explanation(idf, "idf(docFreq=" + df + ", maxDocs=" + max + ")");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419757614899/fstmerge_base_8652920114861724257
public Explanation idfExplain(CollectionStatistics collectionStats, TermStatistics termStats) {
    final int df = termStats.docFreq();
    final int max = collectionStats.maxDoc();
    final float idf = idf(df, max);
    return new Explanation(idf, "idf(docFreq=" + df + ", maxDocs=" + max + ")");
=======
public Explanation idfExplain(CollectionStatistics collectionStats, TermStatistics termStats[]) {
    final int max = collectionStats.maxDoc();
    float idf = 0.0f;
    final Explanation exp = new Explanation();
    exp.setDescription("idf(), sum of:");
    for (final TermStatistics stat : termStats ) {
      final int df = stat.docFreq();
      final float termIdf = idf(df, max);
      exp.addDetail(new Explanation(termIdf, "idf(docFreq=" + df + ", maxDocs=" + max + ")"));
      idf += termIdf;
    }
    exp.setValue(idf);
    return exp;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419757614899/fstmerge_var2_5829132927437134842
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f6b1a_0c38b/rev_f6b1a-0c38b/lucene/src/java/org/apache/lucene/search/similarities/TFIDFSimilarity.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419757615357/fstmerge_var1_5673219257475875799
public Explanation idfExplain(CollectionStatistics collectionStats, TermStatistics termStats) {
    final long df = termStats.docFreq();
    final long max = collectionStats.maxDoc();
    final float idf = idf(df, max);
    return new Explanation(idf, "idf(docFreq=" + df + ", maxDocs=" + max + ")");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419757615357/fstmerge_base_8400177958940712699
public Explanation idfExplain(CollectionStatistics collectionStats, TermStatistics termStats) {
    final int df = termStats.docFreq();
    final int max = collectionStats.maxDoc();
    final float idf = idf(df, max);
    return new Explanation(idf, "idf(docFreq=" + df + ", maxDocs=" + max + ")");
=======
public Explanation idfExplain(CollectionStatistics collectionStats, TermStatistics termStats[]) {
    final int max = collectionStats.maxDoc();
    float idf = 0.0f;
    final Explanation exp = new Explanation();
    exp.setDescription("idf(), sum of:");
    for (final TermStatistics stat : termStats ) {
      final int df = stat.docFreq();
      final float termIdf = idf(df, max);
      exp.addDetail(new Explanation(termIdf, "idf(docFreq=" + df + ", maxDocs=" + max + ")"));
      idf += termIdf;
    }
    exp.setValue(idf);
    return exp;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419757615357/fstmerge_var2_7735358550367903928
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f6b1a_0c38b/rev_f6b1a-0c38b/lucene/src/java/org/apache/lucene/search/similarities/BM25Similarity.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419757639065/fstmerge_var1_4896627151689041087
synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {

    assert testPoint("startCommitMerge");

    if (hitOOM) {
      throw new IllegalStateException("this writer hit an OutOfMemoryError; cannot complete merge");
    }

    if (infoStream.isEnabled("IW")) {
      infoStream.message("IW", "commitMerge: " + segString(merge.segments) + " index=" + segString());
    }

    assert merge.registerDone;

    // If merge was explicitly aborted, or, if rollback() or
    // rollbackTransaction() had been called since our merge
    // started (which results in an unqualified
    // deleter.refresh() call that will remove any index
    // file that current segments does not reference), we
    // abort this merge
    if (merge.isAborted()) {
      if (infoStream.isEnabled("IW")) {
        infoStream.message("IW", "commitMerge: skip: it was aborted");
      }
      return false;
    }

    final ReadersAndLiveDocs mergedDeletes = commitMergedDeletes(merge);

    assert mergedDeletes == null || mergedDeletes.pendingDeleteCount != 0;

    // If the doc store we are using has been closed and
    // is in now compound format (but wasn't when we
    // started), then we will switch to the compound
    // format as well:

    assert !segmentInfos.contains(merge.info);

    final boolean allDeleted = merge.segments.size() == 0 ||
      merge.info.docCount == 0 ||
      (mergedDeletes != null &&
       mergedDeletes.pendingDeleteCount == merge.info.docCount);

    if (infoStream.isEnabled("IW")) {
      if (allDeleted) {
        infoStream.message("IW", "merged segment " + merge.info + " is 100% deleted" +  (keepFullyDeletedSegments ? "" : "; skipping insert"));
      }
    }

    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;

    // If we merged no segments then we better be dropping
    // the new segment:
    assert merge.segments.size() > 0 || dropSegment;

    assert merge.info.docCount != 0 || keepFullyDeletedSegments || dropSegment;

    segmentInfos.applyMergeChanges(merge, dropSegment);
    
    if (dropSegment) {
      readerPool.drop(merge.info);
      deleter.deleteNewFiles(merge.info.files());
      assert !segmentInfos.contains(merge.info);
    } else {
      if (mergedDeletes != null && !poolReaders) {
        mergedDeletes.writeLiveDocs(directory);
        readerPool.drop(merge.info);
      }
    }

    // Must close before checkpoint, otherwise IFD won't be
    // able to delete the held-open files from the merge
    // readers:
    closeMergeReaders(merge, false);

    // Must note the change to segmentInfos so any commits
    // in-flight don't lose it:
    checkpoint();

    if (infoStream.isEnabled("IW")) {
      infoStream.message("IW", "after commit: " + segString());
    }

    if (merge.maxNumSegments != -1 && !dropSegment) {
      // cascade the forceMerge:
      if (!segmentsToMerge.containsKey(merge.info)) {
        segmentsToMerge.put(merge.info, Boolean.FALSE);
      }
    }

    return true;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419757639065/fstmerge_base_2281004319618405124
synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {

    assert testPoint("startCommitMerge");

    if (hitOOM) {
      throw new IllegalStateException("this writer hit an OutOfMemoryError; cannot complete merge");
    }

    if (infoStream.isEnabled("IW")) {
      infoStream.message("IW", "commitMerge: " + segString(merge.segments) + " index=" + segString());
    }

    assert merge.registerDone;

    // If merge was explicitly aborted, or, if rollback() or
    // rollbackTransaction() had been called since our merge
    // started (which results in an unqualified
    // deleter.refresh() call that will remove any index
    // file that current segments does not reference), we
    // abort this merge
    if (merge.isAborted()) {
      if (infoStream.isEnabled("IW")) {
        infoStream.message("IW", "commitMerge: skip: it was aborted");
      }
      return false;
    }

    final ReadersAndLiveDocs mergedDeletes = commitMergedDeletes(merge);

    assert mergedDeletes == null || mergedDeletes.pendingDeleteCount != 0;

    // If the doc store we are using has been closed and
    // is in now compound format (but wasn't when we
    // started), then we will switch to the compound
    // format as well:

    assert !segmentInfos.contains(merge.info);

    final boolean allDeleted = merge.segments.size() == 0 ||
      merge.info.docCount == 0 ||
      (mergedDeletes != null &&
       mergedDeletes.pendingDeleteCount == merge.info.docCount);

    if (infoStream.isEnabled("IW")) {
      if (allDeleted) {
        infoStream.message("IW", "merged segment " + merge.info + " is 100% deleted" +  (keepFullyDeletedSegments ? "" : "; skipping insert"));
      }
    }

    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;

    // If we merged no segments then we better be dropping
    // the new segment:
    assert merge.segments.size() > 0 || dropSegment;

    assert merge.info.docCount != 0 || keepFullyDeletedSegments || dropSegment;

    segmentInfos.applyMergeChanges(merge, dropSegment);
    
    if (dropSegment) {
      readerPool.drop(merge.info);
      deleter.deleteNewFiles(merge.info.files());
      assert !segmentInfos.contains(merge.info);
    } else {
      if (mergedDeletes != null && !poolReaders) {
        mergedDeletes.writeLiveDocs(directory);
        readerPool.drop(merge.info);
      }
    }
    
    // Must note the change to segmentInfos so any commits
    // in-flight don't lose it:
    checkpoint();

    if (infoStream.isEnabled("IW")) {
      infoStream.message("IW", "after commit: " + segString());
    }

    closeMergeReaders(merge, false);

    if (merge.maxNumSegments != -1 && !dropSegment) {
      // cascade the forceMerge:
      if (!segmentsToMerge.containsKey(merge.info)) {
        segmentsToMerge.put(merge.info, Boolean.FALSE);
      }
    }

    return true;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419757639065/fstmerge_var2_2888691817954123214

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f6b1a_0c38b/rev_f6b1a-0c38b/lucene/src/java/org/apache/lucene/index/IndexWriter.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_b1d45_2f1b9/rev_b1d45-2f1b9.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_df023_6e4d7/rev_df023-6e4d7.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_401da_28785/rev_401da-28785.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_097e9_401da/rev_097e9-401da.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17808_097e9/rev_17808-097e9.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17808_2c281/rev_17808-2c281.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419826386128/fstmerge_var1_3895911819858084028
public Explanation idfExplain(CollectionStatistics collectionStats, TermStatistics termStats) {
    final long df = termStats.docFreq();
    final long max = collectionStats.maxDoc();
    final float idf = idf(df, max);
    return new Explanation(idf, "idf(docFreq=" + df + ", maxDocs=" + max + ")");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419826386128/fstmerge_base_727567645361317842
public Explanation idfExplain(CollectionStatistics collectionStats, TermStatistics termStats) {
    final int df = termStats.docFreq();
    final int max = collectionStats.maxDoc();
    final float idf = idf(df, max);
    return new Explanation(idf, "idf(docFreq=" + df + ", maxDocs=" + max + ")");
=======
public Explanation idfExplain(CollectionStatistics collectionStats, TermStatistics termStats[]) {
    final int max = collectionStats.maxDoc();
    float idf = 0.0f;
    final Explanation exp = new Explanation();
    exp.setDescription("idf(), sum of:");
    for (final TermStatistics stat : termStats ) {
      final int df = stat.docFreq();
      final float termIdf = idf(df, max);
      exp.addDetail(new Explanation(termIdf, "idf(docFreq=" + df + ", maxDocs=" + max + ")"));
      idf += termIdf;
    }
    exp.setValue(idf);
    return exp;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419826386128/fstmerge_var2_4826793388818283446
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17808_2c281/rev_17808-2c281/lucene/src/java/org/apache/lucene/search/similarities/TFIDFSimilarity.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419826386567/fstmerge_var1_6670965477512888099
public Explanation idfExplain(CollectionStatistics collectionStats, TermStatistics termStats) {
    final long df = termStats.docFreq();
    final long max = collectionStats.maxDoc();
    final float idf = idf(df, max);
    return new Explanation(idf, "idf(docFreq=" + df + ", maxDocs=" + max + ")");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419826386567/fstmerge_base_4684714064932397699
public Explanation idfExplain(CollectionStatistics collectionStats, TermStatistics termStats) {
    final int df = termStats.docFreq();
    final int max = collectionStats.maxDoc();
    final float idf = idf(df, max);
    return new Explanation(idf, "idf(docFreq=" + df + ", maxDocs=" + max + ")");
=======
public Explanation idfExplain(CollectionStatistics collectionStats, TermStatistics termStats[]) {
    final int max = collectionStats.maxDoc();
    float idf = 0.0f;
    final Explanation exp = new Explanation();
    exp.setDescription("idf(), sum of:");
    for (final TermStatistics stat : termStats ) {
      final int df = stat.docFreq();
      final float termIdf = idf(df, max);
      exp.addDetail(new Explanation(termIdf, "idf(docFreq=" + df + ", maxDocs=" + max + ")"));
      idf += termIdf;
    }
    exp.setValue(idf);
    return exp;
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419826386567/fstmerge_var2_8546807132141436713
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17808_2c281/rev_17808-2c281/lucene/src/java/org/apache/lucene/search/similarities/BM25Similarity.java
Conflict type: LineBasedMCFd
Conflict body: 
private final void mergeTerms(SegmentWriteState segmentWriteState) throws CorruptIndexException, IOException {
    
    final List<Fields> fields = new ArrayList<Fields>();
    final List<ReaderUtil.Slice> slices = new ArrayList<ReaderUtil.Slice>();

    int docBase = 0;

    for(int readerIndex=0;readerIndex<mergeState.readers.size();readerIndex++) {
      final MergeState.IndexReaderAndLiveDocs r = mergeState.readers.get(readerIndex);
      final Fields f = r.reader.fields();
      final int maxDoc = r.reader.maxDoc();
      if (f != null) {
        slices.add(new ReaderUtil.Slice(docBase, maxDoc, readerIndex));
        fields.add(f);
      }
      docBase += maxDoc;
    }

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419826406554/fstmerge_var1_465398780029124181
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419826406554/fstmerge_base_3859474615923744117
    final int numReaders = mergeState.readers.size();

    docBase = 0;

    for(int i=0;i<numReaders;i++) {

      final MergeState.IndexReaderAndLiveDocs reader = mergeState.readers.get(i);

      mergeState.docBase[i] = docBase;
      final int maxDoc = reader.reader.maxDoc();
      if (reader.liveDocs != null) {
        int delCount = 0;
        final Bits liveDocs = reader.liveDocs;
        assert liveDocs != null;
        final int[] docMap = mergeState.docMaps[i] = new int[maxDoc];
        int newDocID = 0;
        for(int j=0;j<maxDoc;j++) {
          if (!liveDocs.get(j)) {
            docMap[j] = -1;
            delCount++;
          } else {
            docMap[j] = newDocID++;
          }
        }
        docBase += maxDoc - delCount;
      } else {
        docBase += maxDoc;
      }

      if (mergeState.payloadProcessorProvider != null) {
        mergeState.dirPayloadProcessor[i] = mergeState.payloadProcessorProvider.getDirProcessor(reader.reader.directory());
      }
    }

=======
    final int numReaders = mergeState.readers.size();

    docBase = 0;

    for(int i=0;i<numReaders;i++) {

      final MergeState.IndexReaderAndLiveDocs reader = mergeState.readers.get(i);

      mergeState.docBase[i] = docBase;
      final int maxDoc = reader.reader.maxDoc();
      if (reader.liveDocs != null) {
        int delCount = 0;
        final Bits liveDocs = reader.liveDocs;
        assert liveDocs != null;
        final int[] docMap = mergeState.docMaps[i] = new int[maxDoc];
        int newDocID = 0;
        for(int j=0;j<maxDoc;j++) {
          if (!liveDocs.get(j)) {
            docMap[j] = -1;
            delCount++;
          } else {
            docMap[j] = newDocID++;
          }
        }
        docBase += maxDoc - delCount;
      } else {
        docBase += maxDoc;
      }

      if (mergeState.payloadProcessorProvider != null) {
        // nocommit: this was original, is the change correct:
        // mergeState.dirPayloadProcessor[i] = mergeState.payloadProcessorProvider.getDirProcessor(reader.reader.directory());
        mergeState.dirPayloadProcessor[i] = mergeState.payloadProcessorProvider.getDirProcessor(directory);
      }
    }

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419826406554/fstmerge_var2_3951247941319291168
    final FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(segmentWriteState);
    boolean success = false;
    try {
      consumer.merge(mergeState,
                     new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),
                                     slices.toArray(ReaderUtil.Slice.EMPTY_ARRAY)));
      success = true;
    } finally {
      if (success) {
        IOUtils.close(consumer);
      } else {
        IOUtils.closeWhileHandlingException(consumer);
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_17808_2c281/rev_17808-2c281/lucene/src/java/org/apache/lucene/index/SegmentMerger.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_43ede_cb07a/rev_43ede-cb07a.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419841362996/fstmerge_var1_1202662678183773351
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419841362996/fstmerge_base_2161180841823340400
public void testLastModified() throws Exception {
      for(int i=0;i<2;i++) {
        final Directory dir = newDirectory();
        assertFalse(IndexReader.indexExists(dir));
        IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE));
        addDocumentWithFields(writer);
        assertTrue(IndexWriter.isLocked(dir));		// writer open, so dir is locked
        writer.close();
        assertTrue(IndexReader.indexExists(dir));
        IndexReader reader = IndexReader.open(dir);
        assertFalse(IndexWriter.isLocked(dir));		// reader only, no lock
        long version = IndexReader.lastModified(dir);
        if (i == 1) {
          long version2 = IndexReader.lastModified(dir);
          assertEquals(version, version2);
        }
        reader.close();
        // modify index and check version has been
        // incremented:
        Thread.sleep(1000);

        writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE));
        addDocumentWithFields(writer);
        writer.close();
        reader = IndexReader.open(dir);
        assertTrue("old lastModified is " + version + "; new lastModified is " + IndexReader.lastModified(dir), version <= IndexReader.lastModified(dir));
        reader.close();
        dir.close();
      }
    }
=======
public void testLastModified() throws Exception {
      for(int i=0;i<2;i++) {
        final Directory dir = newDirectory();
        assertFalse(DirectoryReader.indexExists(dir));
        IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE));
        addDocumentWithFields(writer);
        assertTrue(IndexWriter.isLocked(dir));		// writer open, so dir is locked
        writer.close();
        assertTrue(DirectoryReader.indexExists(dir));
        DirectoryReader reader = DirectoryReader.open(dir);
        assertFalse(IndexWriter.isLocked(dir));		// reader only, no lock
        long version = DirectoryReader.lastModified(dir);
        if (i == 1) {
          long version2 = DirectoryReader.lastModified(dir);
          assertEquals(version, version2);
        }
        reader.close();
        // modify index and check version has been
        // incremented:
        Thread.sleep(1000);

        writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE));
        addDocumentWithFields(writer);
        writer.close();
        reader = DirectoryReader.open(dir);
        assertTrue("old lastModified is " + version + "; new lastModified is " + DirectoryReader.lastModified(dir), version <= DirectoryReader.lastModified(dir));
        reader.close();
        dir.close();
      }
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419841362996/fstmerge_var2_2841641210431130885

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_43ede_cb07a/rev_43ede-cb07a/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419841363001/fstmerge_var1_3468086505878038656
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419841363001/fstmerge_base_6481598409875821835
public void testVersion() throws IOException {
      Directory dir = newDirectory();
      assertFalse(IndexReader.indexExists(dir));
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));
      addDocumentWithFields(writer);
      assertTrue(IndexWriter.isLocked(dir));		// writer open, so dir is locked
      writer.close();
      assertTrue(IndexReader.indexExists(dir));
      IndexReader reader = IndexReader.open(dir);
      assertFalse(IndexWriter.isLocked(dir));		// reader only, no lock
      long version = IndexReader.getCurrentVersion(dir);
      reader.close();
      // modify index and check version has been
      // incremented:
      writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE));
      addDocumentWithFields(writer);
      writer.close();
      reader = IndexReader.open(dir);
      assertTrue("old version is " + version + "; new version is " + IndexReader.getCurrentVersion(dir), version < IndexReader.getCurrentVersion(dir));
      reader.close();
      dir.close();
    }
=======
public void testVersion() throws IOException {
      Directory dir = newDirectory();
      assertFalse(DirectoryReader.indexExists(dir));
      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));
      addDocumentWithFields(writer);
      assertTrue(IndexWriter.isLocked(dir));		// writer open, so dir is locked
      writer.close();
      assertTrue(DirectoryReader.indexExists(dir));
      DirectoryReader reader = DirectoryReader.open(dir);
      assertFalse(IndexWriter.isLocked(dir));		// reader only, no lock
      long version = DirectoryReader.getCurrentVersion(dir);
      reader.close();
      // modify index and check version has been
      // incremented:
      writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE));
      addDocumentWithFields(writer);
      writer.close();
      reader = DirectoryReader.open(dir);
      assertTrue("old version is " + version + "; new version is " + DirectoryReader.getCurrentVersion(dir), version < DirectoryReader.getCurrentVersion(dir));
      reader.close();
      dir.close();
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1419841363001/fstmerge_var2_5410263349729462625

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_43ede_cb07a/rev_43ede-cb07a/lucene/src/test/org/apache/lucene/index/TestIndexReader.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_d7ec8_750f8/rev_d7ec8-750f8.revisions

=========================================================
=========================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_ad43e_5d6cb/rev_ad43e-5d6cb.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4313f_54a59/rev_4313f-54a59.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_d1f69_e6adc/rev_d1f69-e6adc.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_28562_5d00d/rev_28562-5d00d.revisions
Conflict type: LineBasedMCFd
Conflict body: 
public BinaryDocValuesWriter(FieldInfo fieldInfo, Counter iwBytesUsed) {
    this.fieldInfo = fieldInfo;
    this.bytes = new PagedBytes(BLOCK_BITS);
    this.bytesOut = bytes.getDataOutput();
    this.lengths = new AppendingDeltaPackedLongBuffer(PackedInts.COMPACT);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488926889/fstmerge_var1_7550459937938241243
    this.iwBytesUsed = iwBytesUsed;
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488926889/fstmerge_base_7166976281556252355
=======
    this.iwBytesUsed = iwBytesUsed;
    this.docsWithField = new OpenBitSet();
    this.bytesUsed = docsWithFieldBytesUsed();
    iwBytesUsed.addAndGet(bytesUsed);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488926889/fstmerge_var2_6071013662210846095
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_28562_5d00d/rev_28562-5d00d/lucene/core/src/java/org/apache/lucene/index/BinaryDocValuesWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void addValue(int docID, BytesRef value) {
    if (docID < addedValues) {
      throw new IllegalArgumentException("DocValuesField \"" + fieldInfo.name + "\" appears more than once in this document (only one value is allowed per field)");
    }
    if (value == null) {
      throw new IllegalArgumentException("field=\"" + fieldInfo.name + "\": null value not allowed");
    }
    if (value.length > MAX_LENGTH) {
      throw new IllegalArgumentException("DocValuesField \"" + fieldInfo.name + "\" is too large, must be <= " + MAX_LENGTH);
    }

    // Fill in any holes:
    while(addedValues < docID) {
      addedValues++;
      lengths.add(0);
    }
    addedValues++;
    lengths.add(value.length);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488926929/fstmerge_var1_4588974653483158187
    try {
      bytesOut.writeBytes(value.bytes, value.offset, value.length);
    } catch (IOException ioe) {
      // Should never happen!
      throw new RuntimeException(ioe);
    }
    updateBytesUsed();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488926929/fstmerge_base_1858864034223659659
    pool.append(value);
=======
    pool.append(value);
    docsWithField.set(docID);
    updateBytesUsed();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488926929/fstmerge_var2_6472381156697384090
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_28562_5d00d/rev_28562-5d00d/lucene/core/src/java/org/apache/lucene/index/BinaryDocValuesWriter.java
Conflict type: SameSignatureCM
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488926931/fstmerge_var1_1687166331745191357
private void updateBytesUsed() {
    final long newBytesUsed = lengths.ramBytesUsed() + bytes.ramBytesUsed();
    iwBytesUsed.addAndGet(newBytesUsed - bytesUsed);
    bytesUsed = newBytesUsed;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488926931/fstmerge_base_91142295740262233
=======
private void updateBytesUsed() {
    final long newBytesUsed = docsWithFieldBytesUsed();
    iwBytesUsed.addAndGet(newBytesUsed - bytesUsed);
    bytesUsed = newBytesUsed;
  }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488926931/fstmerge_var2_878598658735931994

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_28562_5d00d/rev_28562-5d00d/lucene/core/src/java/org/apache/lucene/index/BinaryDocValuesWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
    public BytesRef next() {
      if (!hasNext()) {
        throw new NoSuchElementException();
      }
      final BytesRef v;
      if (upto < size) {
        int length = (int) lengthsIterator.next();
        value.grow(length);
        value.length = length;
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488926940/fstmerge_var1_3759113092743259289
        try {
          bytesIterator.readBytes(value.bytes, value.offset, value.length);
        } catch (IOException ioe) {
          // Should never happen!
          throw new RuntimeException(ioe);
        }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488926940/fstmerge_base_288326266593166934
        pool.readBytes(byteOffset, value.bytes, value.offset, value.length);
        byteOffset += length;
=======
        pool.readBytes(byteOffset, value.bytes, value.offset, value.length);
        byteOffset += length;
        if (docsWithField.get(upto)) {
          v = value;
        } else {
          v = null;
        }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488926940/fstmerge_var2_635780160701184870
      } else {
        v = null;
      }
      upto++;
      return v;
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_28562_5d00d/rev_28562-5d00d/lucene/core/src/java/org/apache/lucene/index/BinaryDocValuesWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void addBinaryField(FieldInfo field, Iterable<BytesRef> values) throws IOException {
    // examine the values to determine best type to use
    HashSet<BytesRef> uniqueValues = new HashSet<BytesRef>();
    int minLength = Integer.MAX_VALUE;
    int maxLength = Integer.MIN_VALUE;
    for (BytesRef b : values) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488950360/fstmerge_var1_3157472308349934788
      if (b.length > Lucene40DocValuesFormat.MAX_BINARY_FIELD_LENGTH) {
        throw new IllegalArgumentException("DocValuesField \"" + field.name + "\" is too large, must be <= " + Lucene40DocValuesFormat.MAX_BINARY_FIELD_LENGTH);
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488950360/fstmerge_base_1732040002735556584
=======
      if (b == null) {
        b = new BytesRef(); // 4.0 doesnt distinguish
      }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420488950360/fstmerge_var2_8326530697102191008
      minLength = Math.min(minLength, b.length);
      maxLength = Math.max(maxLength, b.length);
      if (uniqueValues != null) {
        if (uniqueValues.add(BytesRef.deepCopyOf(b))) {
          if (uniqueValues.size() > 256) {
            uniqueValues = null;
          }
        }
      }
    }
    
    int maxDoc = state.segmentInfo.getDocCount();
    final boolean fixed = minLength == maxLength;
    final boolean dedup = uniqueValues != null && uniqueValues.size() * 2 < maxDoc;
    
    if (dedup) {
      // we will deduplicate and deref values
      boolean success = false;
      IndexOutput data = null;
      IndexOutput index = null;
      String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name + "_" + Integer.toString(field.number), segmentSuffix, "dat");
      String indexName = IndexFileNames.segmentFileName(state.segmentInfo.name + "_" + Integer.toString(field.number), segmentSuffix, "idx");
      try {
        data = dir.createOutput(dataName, state.context);
        index = dir.createOutput(indexName, state.context);
        if (fixed) {
          addFixedDerefBytesField(field, data, index, values, minLength);
        } else {
          addVarDerefBytesField(field, data, index, values);
        }
        success = true;
      } finally {
        if (success) {
          IOUtils.close(data, index);
        } else {
          IOUtils.closeWhileHandlingException(data, index);
        }
      }
    } else {
      // we dont deduplicate, just write values straight
      if (fixed) {
        // fixed byte[]
        String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name + "_" + Integer.toString(field.number), segmentSuffix, "dat");
        IndexOutput data = dir.createOutput(fileName, state.context);
        boolean success = false;
        try {
          addFixedStraightBytesField(field, data, values, minLength);
          success = true;
        } finally {
          if (success) {
            IOUtils.close(data);
          } else {
            IOUtils.closeWhileHandlingException(data);
          }
        }
      } else {
        // variable byte[]
        boolean success = false;
        IndexOutput data = null;
        IndexOutput index = null;
        String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name + "_" + Integer.toString(field.number), segmentSuffix, "dat");
        String indexName = IndexFileNames.segmentFileName(state.segmentInfo.name + "_" + Integer.toString(field.number), segmentSuffix, "idx");
        try {
          data = dir.createOutput(dataName, state.context);
          index = dir.createOutput(indexName, state.context);
          addVarStraightBytesField(field, data, index, values);
          success = true;
        } finally {
          if (success) {
            IOUtils.close(data, index);
          } else {
            IOUtils.closeWhileHandlingException(data, index);
          }
        }
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_28562_5d00d/rev_28562-5d00d/lucene/test-framework/src/java/org/apache/lucene/codecs/lucene40/Lucene40DocValuesWriter.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_69ccd_b0154/rev_69ccd-b0154.revisions
Conflict type: LineBasedMCFd
Conflict body: 
public void deleteDocuments(Term... terms) throws IOException {
    ensureOpen();
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420490896996/fstmerge_var1_2145601199413778335
      if (docWriter.deleteTerms(term)) {
        processEvents(true, false);
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420490896996/fstmerge_base_1545893934146437255
      docWriter.deleteTerms(term);
=======
      docWriter.deleteTerms(terms);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420490896996/fstmerge_var2_3434660644688924299
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Term..)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_69ccd_b0154/rev_69ccd-b0154/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void deleteDocuments(Query... queries) throws IOException {
    ensureOpen();
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420490897007/fstmerge_var1_6586209338012353897
      if (docWriter.deleteQueries(query)) {
        processEvents(true, false);
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420490897007/fstmerge_base_7737639374453532109
      docWriter.deleteQueries(query);
=======
      docWriter.deleteQueries(queries);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420490897007/fstmerge_var2_2507330830158018046
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Query..)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_69ccd_b0154/rev_69ccd-b0154/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_95095_0c9a3/rev_95095-0c9a3.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f2f66_1be7a/rev_f2f66-1be7a.revisions
Conflict type: ModifierList
Conflict body: 
~~FSTMerge~~ @SuppressCodecs({"MockFixedIntBlock", "MockVariableIntBlock", "MockSep", "MockRandom", "Lucene40", "Lucene41", "Lucene42"})
public ##FSTMerge## @SuppressCodecs({"MockFixedIntBlock", "MockVariableIntBlock", "MockSep", "MockRandom", "Lucene40", "Lucene41"})
public ##FSTMerge## @SuppressCodecs({"MockFixedIntBlock", "MockVariableIntBlock", "MockSep", "MockRandom", "Lucene40", "Lucene41", "TempSep", "TempFixedIntBlock", "TempVariableIntBlock", "TempRandom"})
public
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f2f66_1be7a/rev_f2f66-1be7a/lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
Conflict type: LineBasedMCFd
Conflict body: 
public void deleteDocuments(Term... terms) throws IOException {
    ensureOpen();
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420494814565/fstmerge_var1_6805276928488241642
      if (docWriter.deleteTerms(term)) {
        processEvents(true, false);
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420494814565/fstmerge_base_7369461288672344779
      docWriter.deleteTerms(term);
=======
      docWriter.deleteTerms(terms);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420494814565/fstmerge_var2_8690097336966338583
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Term..)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f2f66_1be7a/rev_f2f66-1be7a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
public void deleteDocuments(Query... queries) throws IOException {
    ensureOpen();
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420494814574/fstmerge_var1_5842313609591616597
      if (docWriter.deleteQueries(query)) {
        processEvents(true, false);
      }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420494814574/fstmerge_base_5792672271235540434
      docWriter.deleteQueries(query);
=======
      docWriter.deleteQueries(queries);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420494814574/fstmerge_var2_7424484529526835285
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Query..)");
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f2f66_1be7a/rev_f2f66-1be7a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_7632e_9a1f2/rev_7632e-9a1f2.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_7f808_2ad4b/rev_7f808-2ad4b.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_30b55_b595d/rev_30b55-b595d.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_60bff_1d3cd/rev_60bff-1d3cd.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_9912d_83918/rev_9912d-83918.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_67e16_4a9ec/rev_67e16-4a9ec.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_833bb_dbcdd/rev_833bb-dbcdd.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_eaa81_c01bb/rev_eaa81-c01bb.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1b950_1cf28/rev_1b950-1cf28.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_b1634_350f7/rev_b1634-350f7.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c3ef4_cb9cc/rev_c3ef4-cb9cc.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ee47_d80c1/rev_2ee47-d80c1.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420520497242/fstmerge_var1_3686167120048242293
@Override
  public void score(Collector collector) throws IOException {
    assert topScorer != TopScorer.NO;
    if (SCORE_COLLECTOR.isOverriddenAsOf(this.in.getClass())) {
      if (random.nextBoolean()) {
        try {
          final boolean remaining = in.score(collector, DocsEnum.NO_MORE_DOCS, in.nextDoc());
          assert !remaining;
        } catch (UnsupportedOperationException e) {
          in.score(collector);
        }
      } else {
        in.score(collector);
      }
    } else {
      // score(Collector) has not been overridden, use the super method in
      // order to benefit from all assertions
      if (collector.acceptsDocsOutOfOrder() && random.nextBoolean()) {
        scoreInRandomOrder(collector);
      } else {
        super.score(collector);
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420520497242/fstmerge_base_6014917125774997496
@Override
  public void score(Collector collector) throws IOException {
    assert topScorer != TopScorer.NO;
    if (SCORE_COLLECTOR.isOverriddenAsOf(this.in.getClass())) {
      if (random.nextBoolean()) {
        try {
          final boolean remaining = in.score(collector, DocsEnum.NO_MORE_DOCS, in.nextDoc());
          assert !remaining;
        } catch (UnsupportedOperationException e) {
          in.score(collector);
        }
      } else {
        in.score(collector);
      }
    } else {
      // score(Collector) has not been overridden, use the super method in
      // order to benefit from all assertions
      super.score(collector);
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420520497242/fstmerge_var2_2200087559141203014

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2ee47_d80c1/rev_2ee47-d80c1/lucene/test-framework/src/java/org/apache/lucene/search/AssertingScorer.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_4f6c2_19d85/rev_4f6c2-19d85.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97.revisions
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void beforeClass() throws Exception {
    // Create a temporary directory that holds a core NOT named "collection1". Use the smallest configuration sets
    // we can so we don't copy that much junk around.
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524696880/fstmerge_var1_4356970371511359386
    tmpSolrHome = dataDir + File.separator + SolrTestCaseJ4Test.class.getSimpleName() + System.currentTimeMillis();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524696880/fstmerge_base_235771245427790065
    createTempDir();
    tmpSolrHome = TEMP_DIR + File.separator + SolrTestCaseJ4Test.class.getSimpleName() + System.currentTimeMillis();
=======
    tmpSolrHome = createTempDir().getAbsolutePath();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524696880/fstmerge_var2_7521953433801028451

    File subHome = new File(new File(tmpSolrHome, "core0"), "conf");
    assertTrue("Failed to make subdirectory ", subHome.mkdirs());
    String top = SolrTestCaseJ4.TEST_HOME() + "/collection1/conf";
    FileUtils.copyFile(new File(top, "schema-tiny.xml"), new File(subHome, "schema-tiny.xml"));
    FileUtils.copyFile(new File(top, "solrconfig-minimal.xml"), new File(subHome, "solrconfig-minimal.xml"));
    FileUtils.copyFile(new File(top, "solrconfig.snippet.randomindexconfig.xml"), new File(subHome, "solrconfig.snippet.randomindexconfig.xml"));

    FileUtils.copyDirectory(new File(tmpSolrHome, "core0"), new File(tmpSolrHome, "core1"));

    FileUtils.copyFile(getFile("solr/solr-multicore.xml"), new File(tmpSolrHome, "solr.xml"));

    initCore("solrconfig-minimal.xml", "schema-tiny.xml", tmpSolrHome, "core1");
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/SolrTestCaseJ4Test.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void beforeTest() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524697076/fstmerge_var1_5053329925857204185
    File homeDir = new File(dataDir,
                            "solrtest-TestSolrCoreProperties-" + System.currentTimeMillis());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524697076/fstmerge_base_2894444548888086884
    File homeDir = new File(TEMP_DIR,
                            "solrtest-TestSolrCoreProperties-" + System.currentTimeMillis());
=======
    File homeDir = createTempDir();

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524697076/fstmerge_var2_5283634655190204813
    File collDir = new File(homeDir, "collection1");
    File dataDir = new File(collDir, "data");
    File confDir = new File(collDir, "conf");

    homeDir.mkdirs();
    collDir.mkdirs();
    dataDir.mkdirs();
    confDir.mkdirs();

    FileUtils.copyFile(new File(SolrTestCaseJ4.TEST_HOME(), "solr.xml"), new File(homeDir, "solr.xml"));
    String src_dir = TEST_HOME() + "/collection1/conf";
    FileUtils.copyFile(new File(src_dir, "schema-tiny.xml"), 
                       new File(confDir, "schema.xml"));
    FileUtils.copyFile(new File(src_dir, "solrconfig-solcoreproperties.xml"), 
                       new File(confDir, "solrconfig.xml"));
    FileUtils.copyFile(new File(src_dir, "solrconfig.snippet.randomindexconfig.xml"), 
                       new File(confDir, "solrconfig.snippet.randomindexconfig.xml"));

    Properties p = new Properties();
    p.setProperty("foo.foo1", "f1");
    p.setProperty("foo.foo2", "f2");
    Writer fos = new OutputStreamWriter(new FileOutputStream(new File(confDir, "solrcore.properties")), StandardCharsets.UTF_8);
    p.store(fos, null);
    IOUtils.close(fos);

    createJetty(homeDir.getAbsolutePath(), null, null);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/TestSolrCoreProperties.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  private static void setupTempDirAndCoreWithManagedSchema() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524697785/fstmerge_var1_7198920483221041090
    solrHome = new File(dataDir, TestSearcherReuse.class.getSimpleName());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524697785/fstmerge_base_8863959565849296928
    createTempDir();
    solrHome = new File(TEMP_DIR, TestSearcherReuse.class.getSimpleName());
=======
    solrHome = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524697785/fstmerge_var2_7977172526432063926
    solrHome = solrHome.getAbsoluteFile();

    File confDir = new File(solrHome, confPath);
    File testHomeConfDir = new File(TEST_HOME(), confPath);
    FileUtils.copyFileToDirectory(new File(testHomeConfDir, "solrconfig-managed-schema.xml"), confDir);
    FileUtils.copyFileToDirectory(new File(testHomeConfDir, "solrconfig.snippet.randomindexconfig.xml"), confDir);
    FileUtils.copyFileToDirectory(new File(testHomeConfDir, "schema-id-and-version-fields-only.xml"), confDir);

    // initCore will trigger an upgrade to managed schema, since the solrconfig has
    // <schemaFactory class="ManagedIndexSchemaFactory" ... />
    System.setProperty("managed.schema.mutable", "true");
    initCore("solrconfig-managed-schema.xml", "schema-id-and-version-fields-only.xml", 
             solrHome.getPath());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/search/TestSearcherReuse.java
Conflict type: LineBasedMCFd
Conflict body: 
@Before
  private void initManagedSchemaCore() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524697953/fstmerge_var1_8524227701572160372
    final String tmpSolrHomePath
        = dataDir + File.separator + TestManagedSchema.class.getSimpleName() + System.currentTimeMillis();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524697953/fstmerge_base_6921359036958878016
    createTempDir();
    final String tmpSolrHomePath
        = TEMP_DIR + File.separator + TestManagedSchema.class.getSimpleName() + System.currentTimeMillis();
=======
    final String tmpSolrHomePath = createTempDir().getAbsolutePath();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524697953/fstmerge_var2_594000823606345821
    tmpSolrHome = new File(tmpSolrHomePath).getAbsoluteFile();
    tmpConfDir = new File(tmpSolrHome, confDir);
    File testHomeConfDir = new File(TEST_HOME(), confDir);
    final String configFileName = "solrconfig-managed-schema.xml";
    final String schemaFileName = "schema-id-and-version-fields-only.xml";
    FileUtils.copyFileToDirectory(new File(testHomeConfDir, configFileName), tmpConfDir);
    FileUtils.copyFileToDirectory(new File(testHomeConfDir, schemaFileName), tmpConfDir);
    FileUtils.copyFileToDirectory(new File(testHomeConfDir, "solrconfig.snippet.randomindexconfig.xml"), tmpConfDir);

    // initCore will trigger an upgrade to managed schema, since the solrconfig has
    // <schemaFactory class="ManagedIndexSchemaFactory" ... />
    System.setProperty("managed.schema.mutable", "true");
    System.setProperty("enable.update.log", "true");
    initCore(configFileName, schemaFileName, tmpSolrHome.getPath());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/search/TestAddFieldRealTimeGet.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  @Before
  public void setUp() throws Exception {
    super.setUp();
    clearIndex();
    assertU(commit());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524698593/fstmerge_var1_7868906871296384424
    indexDir1 = new File(dataDir, this.getClass().getName()
        + "_testSplit1");
    indexDir2 = new File(dataDir, this.getClass().getName()
        + "_testSplit2");
    indexDir3 = new File(dataDir, this.getClass().getName()
        + "_testSplit3");

    if (indexDir1.exists()) {
      FileUtils.deleteDirectory(indexDir1);
    }
    assertTrue("Failed to mkdirs indexDir1 for split index", indexDir1.mkdirs());

    if (indexDir2.exists()) {
      FileUtils.deleteDirectory(indexDir2);
    }
    assertTrue("Failed to mkdirs indexDir2 for split index", indexDir2.mkdirs());

    if (indexDir3.exists()) {
      FileUtils.deleteDirectory(indexDir3);
    }
    assertTrue("Failed to mkdirs indexDir3 for split index", indexDir3.mkdirs());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524698593/fstmerge_base_1679507924462941100
    indexDir1 = new File(TEMP_DIR, this.getClass().getName()
        + "_testSplit1");
    indexDir2 = new File(TEMP_DIR, this.getClass().getName()
        + "_testSplit2");
    indexDir3 = new File(TEMP_DIR, this.getClass().getName()
        + "_testSplit3");

    if (indexDir1.exists()) {
      FileUtils.deleteDirectory(indexDir1);
    }
    assertTrue("Failed to mkdirs indexDir1 for split index", indexDir1.mkdirs());

    if (indexDir2.exists()) {
      FileUtils.deleteDirectory(indexDir2);
    }
    assertTrue("Failed to mkdirs indexDir2 for split index", indexDir2.mkdirs());

    if (indexDir3.exists()) {
      FileUtils.deleteDirectory(indexDir3);
    }
    assertTrue("Failed to mkdirs indexDir3 for split index", indexDir3.mkdirs());
=======
    indexDir1 = createTempDir("_testSplit1");
    indexDir2 = createTempDir("_testSplit2");
    indexDir3 = createTempDir("_testSplit3");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524698593/fstmerge_var2_8407460876438891504
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/update/SolrIndexSplitterTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testSplitByRouteKey() throws Exception  {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524698628/fstmerge_var1_4008706449841297774
    File indexDir = new File(dataDir, this.getClass().getName() + "testSplitByRouteKey");
    if (indexDir.exists())  {
      FileUtils.deleteDirectory(indexDir);
    }
    indexDir.mkdirs();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524698628/fstmerge_base_4256614588624961005
    File indexDir = new File(TEMP_DIR, this.getClass().getName() + "testSplitByRouteKey");
    if (indexDir.exists())  {
      FileUtils.deleteDirectory(indexDir);
    }
    indexDir.mkdirs();
=======
    File indexDir = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524698628/fstmerge_var2_8950428090427341153

    CompositeIdRouter r1 = new CompositeIdRouter();
    String splitKey = "sea-line!";
    String key2 = "soul-raising!";

    // murmur2 has a collision on the above two keys
    assertEquals(r1.keyHashRange(splitKey), r1.keyHashRange(key2));

    /*
    More strings with collisions on murmur2 for future reference:
    "Drava" "dessert spoon"
    "Bighorn" "pleasure lover"
    "attributable to" "second edition"
    "sea-line" "soul-raising"
    "lift direction" "testimony meeting"
     */

    for (int i=0; i<10; i++)  {
      assertU(adoc("id", splitKey + i));
      assertU(adoc("id", key2 + i));
    }
    assertU(commit());
    assertJQ(req("q", "*:*"), "/response/numFound==20");

    DocRouter.Range splitKeyRange = r1.keyHashRange(splitKey);

    LocalSolrQueryRequest request = null;
    Directory directory = null;
    try {
      request = lrf.makeRequest("q", "dummy");
      SplitIndexCommand command = new SplitIndexCommand(request,
          Lists.newArrayList(indexDir.getAbsolutePath()), null, Lists.newArrayList(splitKeyRange), new CompositeIdRouter(), null, splitKey);
      new SolrIndexSplitter(command).split();
      directory = h.getCore().getDirectoryFactory().get(indexDir.getAbsolutePath(),
          DirectoryFactory.DirContext.DEFAULT, h.getCore().getSolrConfig().indexConfig.lockType);
      DirectoryReader reader = DirectoryReader.open(directory);
      assertEquals("split index has wrong number of documents", 10, reader.numDocs());
      reader.close();
      h.getCore().getDirectoryFactory().release(directory);
      directory = null;
    } finally {
      if (request != null)  {
        request.close();
      }
      if (directory != null)  {
        h.getCore().getDirectoryFactory().release(directory);
      }
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/update/SolrIndexSplitterTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Before
  private void initManagedSchemaCore() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524698742/fstmerge_var1_6226327158404152112
    final String tmpSolrHomePath
        = dataDir + File.separator + TestManagedSchema.class.getSimpleName() + System.currentTimeMillis();
    tmpSolrHome = new File(tmpSolrHomePath).getAbsoluteFile();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524698742/fstmerge_base_4843977915743005433
    createTempDir();
    final String tmpSolrHomePath
        = TEMP_DIR + File.separator + TestManagedSchema.class.getSimpleName() + System.currentTimeMillis();
    tmpSolrHome = new File(tmpSolrHomePath).getAbsoluteFile();
=======
    tmpSolrHome = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524698742/fstmerge_var2_6274160651975892912
    tmpConfDir = new File(tmpSolrHome, confDir);
    File testHomeConfDir = new File(TEST_HOME(), confDir);
    FileUtils.copyFileToDirectory(new File(testHomeConfDir, SOLRCONFIG_XML), tmpConfDir);
    FileUtils.copyFileToDirectory(new File(testHomeConfDir, SCHEMA_XML), tmpConfDir);

    // initCore will trigger an upgrade to managed schema, since the solrconfig*.xml has
    // <schemaFactory class="ManagedIndexSchemaFactory" ... />
    initCore(SOLRCONFIG_XML, SCHEMA_XML, tmpSolrHome.getPath());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/update/processor/AddSchemaFieldsUpdateProcessorFactoryTest.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ private static final File solrHomeDirectory = new File(dataDir, "CacheHeaderTest"); ##FSTMerge## private static final File solrHomeDirectory = new File(TEMP_DIR, "CacheHeaderTest"); ##FSTMerge## private static File solrHomeDirectory;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/servlet/CacheHeaderTest.java
Conflict type: LineBasedMCFd
Conflict body: 
protected File makeFile(String contents, String charset) {
    try {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699111/fstmerge_var1_2573318333943163155
      File f = TestUtil.createTempFile("cachetest_csv", null, dataDir);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699111/fstmerge_base_6574962795809497276
      File f = TestUtil.createTempFile("cachetest_csv", null, TEMP_DIR);
=======
      File f = TestUtil.createTempFile("cachetest_csv", null, initCoreDataDir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699111/fstmerge_var2_6686625168986302106
      Writer out = new OutputStreamWriter(new FileOutputStream(f), charset);
      out.write(contents);
      out.close();
      return f;
    } catch (Exception e) {
      throw new RuntimeException(e);
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/servlet/CacheHeaderTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void simpleCoreDescriptorIsPersisted() throws IOException {
    
    final String solrxml = "<solr><cores></cores></solr>";
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699334/fstmerge_var1_6046534432625687691

    final File solrHomeDirectory = new File(dataDir, "ZkControllerTest");
    try {
      if (solrHomeDirectory.exists()) {
        FileUtils.deleteDirectory(solrHomeDirectory);
      }
      copyMinFullSetup(solrHomeDirectory);

      CoreContainer cc = new CoreContainer(solrHomeDirectory.getAbsolutePath());

      final CoreDescriptor cd = new CoreDescriptor(cc, "testcore", "instance/dir/");
      List<CoreDescriptor> cds = ImmutableList.of(cd);

      SolrXMLCoresLocator persistor = new SolrXMLCoresLocator(solrxml, null);
      String xml = persistor.buildSolrXML(cds);
      
      assertTrue(xml.contains("<solr><cores>"));
      assertTrue(xml.contains("name=\"testcore\""));
      assertTrue(xml.contains("instanceDir=\"instance/dir/\""));
      assertTrue(xml.contains("</cores></solr>"));
    } finally {
      if (solrHomeDirectory.exists()) {
        FileUtils.deleteDirectory(solrHomeDirectory);
      }

    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699334/fstmerge_base_1546704789402212392

    final File solrHomeDirectory = new File(TEMP_DIR, "ZkControllerTest");
    try {
      if (solrHomeDirectory.exists()) {
        FileUtils.deleteDirectory(solrHomeDirectory);
      }
      copyMinFullSetup(solrHomeDirectory);

      CoreContainer cc = new CoreContainer(solrHomeDirectory.getAbsolutePath());

      final CoreDescriptor cd = new CoreDescriptor(cc, "testcore", "instance/dir/");
      List<CoreDescriptor> cds = ImmutableList.of(cd);

      SolrXMLCoresLocator persistor = new SolrXMLCoresLocator(solrxml, null);
      String xml = persistor.buildSolrXML(cds);
      
      assertTrue(xml.contains("<solr><cores>"));
      assertTrue(xml.contains("name=\"testcore\""));
      assertTrue(xml.contains("instanceDir=\"instance/dir/\""));
      assertTrue(xml.contains("</cores></solr>"));
    } finally {
      if (solrHomeDirectory.exists()) {
        FileUtils.deleteDirectory(solrHomeDirectory);
      }

    }
=======
    
    final File solrHomeDirectory = createTempDir();
    
    copyMinFullSetup(solrHomeDirectory);
    
    CoreContainer cc = new CoreContainer(solrHomeDirectory.getAbsolutePath());
    
    final CoreDescriptor cd = new CoreDescriptor(cc, "testcore",
        "instance/dir/");
    List<CoreDescriptor> cds = ImmutableList.of(cd);
    
    SolrXMLCoresLocator persistor = new SolrXMLCoresLocator(solrxml, null);
    String xml = persistor.buildSolrXML(cds);
    
    assertTrue(xml.contains("<solr><cores>"));
    assertTrue(xml.contains("name=\"testcore\""));
    assertTrue(xml.contains("instanceDir=\"instance/dir/\""));
    assertTrue(xml.contains("</cores></solr>"));
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699334/fstmerge_var2_7337885719421626324
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/core/TestSolrXmlPersistor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699551/fstmerge_var1_2942833649028640812

    dataDir = new File(dataDir,
        getClass().getName() + "-" + System.currentTimeMillis() + System.getProperty("file.separator") + "solr"
        + System.getProperty("file.separator") + "data");
    dataDir.mkdirs();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699551/fstmerge_base_8346976391820053528

    dataDir = new File(TEMP_DIR,
        getClass().getName() + "-" + System.currentTimeMillis() + System.getProperty("file.separator") + "solr"
        + System.getProperty("file.separator") + "data");
    dataDir.mkdirs();
=======
    
    File tmpDataDir = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699551/fstmerge_var2_30665555947364380

    solrConfig = TestHarness.createConfig(getSolrHome(), "solrconfig.xml");
    h = new TestHarness( tmpDataDir.getAbsolutePath(),
        solrConfig,
        "schema12.xml");
    lrf = h.getRequestFactory
    ("standard",0,20,CommonParams.VERSION,"2.2");
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testConfigSetOnCoreReload() throws IOException {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699640/fstmerge_var1_5401590955417842711
    File testDirectory = new File(dataDir, "core-reload");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699640/fstmerge_base_4707119858353271521
    File testDirectory = new File(TEMP_DIR, "core-reload");
=======
    File testDirectory = new File(initCoreDataDir, "core-reload");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699640/fstmerge_var2_8997513523660670697
    testDirectory.mkdirs();
    File configSetsDir = new File(testDirectory, "configsets");

    FileUtils.copyDirectory(getFile("solr/configsets"), configSetsDir);

    String csd = configSetsDir.getAbsolutePath();
    System.setProperty("configsets", csd);

    SolrResourceLoader loader = new SolrResourceLoader(testDirectory.getAbsolutePath());
    CoreContainer container = new CoreContainer(loader, ConfigSolr.fromString(loader, solrxml));
    container.load();

    // We initially don't have a /get handler defined
    SolrCore core = container.create("core1", testDirectory + "/core", "configSet", "configset-2");
    container.register(core, false);
    assertThat("No /get handler should be defined in the initial configuration",
        core.getRequestHandler("/get"), is(nullValue()));

    // Now copy in a config with a /get handler and reload
    FileUtils.copyFile(getFile("solr/collection1/conf/solrconfig-withgethandler.xml"),
        new File(new File(configSetsDir, "configset-2/conf"), "solrconfig.xml"));
    container.reload("core1");

    core = container.getCore("core1");
    assertThat("A /get handler should be defined in the reloaded configuration",
        core.getRequestHandler("/get"), is(notNullValue()));
    core.close();

    container.shutdown();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/core/TestConfigSets.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699646/fstmerge_var1_1568163630929462410
public CoreContainer setupContainer(String testName, String configSetsBaseDir) {

    File testDirectory = new File(dataDir, testName);
    testDirectory.mkdirs();

    System.setProperty("configsets", configSetsBaseDir);

    SolrResourceLoader loader = new SolrResourceLoader(testDirectory.getAbsolutePath());
    CoreContainer container = new CoreContainer(loader, ConfigSolr.fromString(loader, solrxml));
    container.load();

    return container;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699646/fstmerge_base_7654874981196778937
public CoreContainer setupContainer(String testName, String configSetsBaseDir) {

    File testDirectory = new File(TEMP_DIR, testName);
    testDirectory.mkdirs();

    System.setProperty("configsets", configSetsBaseDir);

    SolrResourceLoader loader = new SolrResourceLoader(testDirectory.getAbsolutePath());
    CoreContainer container = new CoreContainer(loader, ConfigSolr.fromString(loader, solrxml));
    container.load();

    return container;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524699646/fstmerge_var2_307258997707906831

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/core/TestConfigSets.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ private final File solrHome = new File(dataDir, TestSolrXml.getClassName() + File.separator + "solrHome"); ##FSTMerge## private final File solrHome = new File(TEMP_DIR, TestSolrXml.getClassName() + File.separator + "solrHome"); ##FSTMerge## private final File solrHome = createTempDir();
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/core/TestSolrXml.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void beforeTest() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524700751/fstmerge_var1_6168619333506237766
    File homeDir = new File(dataDir,
                            "solrtest-TestBinaryField-" + System.currentTimeMillis());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524700751/fstmerge_base_8016662044653261175
    File homeDir = new File(TEMP_DIR,
                            "solrtest-TestBinaryField-" + System.currentTimeMillis());
=======
    File homeDir = createTempDir();

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524700751/fstmerge_var2_4933348671926734205
    File collDir = new File(homeDir, "collection1");
    File dataDir = new File(collDir, "data");
    File confDir = new File(collDir, "conf");

    homeDir.mkdirs();
    collDir.mkdirs();
    dataDir.mkdirs();
    confDir.mkdirs();

    FileUtils.copyFile(new File(SolrTestCaseJ4.TEST_HOME(), "solr.xml"), new File(homeDir, "solr.xml"));

    String src_dir = TEST_HOME() + "/collection1/conf";
    FileUtils.copyFile(new File(src_dir, "schema-binaryfield.xml"), 
                       new File(confDir, "schema.xml"));
    FileUtils.copyFile(new File(src_dir, "solrconfig-basic.xml"), 
                       new File(confDir, "solrconfig.xml"));
    FileUtils.copyFile(new File(src_dir, "solrconfig.snippet.randomindexconfig.xml"), 
                       new File(confDir, "solrconfig.snippet.randomindexconfig.xml"));

    createJetty(homeDir.getAbsolutePath(), null, null);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/schema/TestBinaryField.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  @Before
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524700969/fstmerge_var1_2538321546063424493

    zkDir = dataDir.getAbsolutePath() + File.separator
        + "zookeeper/server1/data";
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524700969/fstmerge_base_5597026271596278419
    createTempDir();
    zkDir = dataDir.getAbsolutePath() + File.separator
        + "zookeeper/server1/data";
=======

    zkDir = createTempDir("zkData").getAbsolutePath();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524700969/fstmerge_var2_2075777656098948947
    zkServer = new ZkTestServer(zkDir);
    zkServer.run();
    home = ExternalPaths.EXAMPLE_HOME;
    
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/cloud/TestZkChroot.java
Conflict type: LineBasedMCFd
Conflict body: 
private void setUpZkAndDiskXml(boolean toZk, boolean leaveOnLocal) throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701118/fstmerge_var1_849535740161556816
    recurseDelete(dataDir);
    File solrHome = new File(dataDir, "home");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701118/fstmerge_base_1799878057248240526

    createTempDir();
    File solrHome = new File(dataDir, "home");
=======
    File tmpDir = createTempDir();
    recurseDelete(tmpDir);
    File solrHome = new File(tmpDir, "home");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701118/fstmerge_var2_165405332786494338
    copyMinConf(new File(solrHome, "myCollect"));
    if (leaveOnLocal) {
      FileUtils.copyFile(new File(SolrTestCaseJ4.TEST_HOME(), "solr-stress-new.xml"), new File(solrHome, "solr.xml"));
    }

    System.setProperty("solr.solr.home", solrHome.getAbsolutePath());

    ignoreException("No UpdateLog found - cannot sync");
    ignoreException("No UpdateLog found - cannot recover");

    System.setProperty("zkClientTimeout", "8000");

    zkDir = tmpDir.getAbsolutePath() + File.separator
        + "zookeeper" + System.currentTimeMillis() + "/server1/data";
    zkServer = new ZkTestServer(zkDir);
    zkServer.run();
    System.setProperty("zkHost", zkServer.getZkAddress());
    AbstractZkTestCase.buildZooKeeper(zkServer.getZkHost(),
        zkServer.getZkAddress(), "solrconfig.xml", "schema.xml");

    zkClient = new SolrZkClient(zkServer.getZkAddress(), AbstractZkTestCase.TIMEOUT);

    if (toZk) {
      zkClient.makePath("solr.xml", XML_FOR_ZK.getBytes(StandardCharsets.UTF_8), true);
    }

    zkClient.close();

    log.info("####SETUP_START " + getTestName());

    // set some system properties for use by tests
    System.setProperty("solr.test.sys.prop1", "propone");
    System.setProperty("solr.test.sys.prop2", "proptwo");

    Method method = SolrDispatchFilter.class.getDeclaredMethod("loadConfigSolr", SolrResourceLoader.class);
    method.setAccessible(true);

    Object obj = method.invoke(new SolrDispatchFilter(), new SolrResourceLoader(null));
    cfg = (ConfigSolr) obj;

    log.info("####SETUP_END " + getTestName());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/cloud/SolrXmlInZkTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  @Before
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701187/fstmerge_var1_7990252686865867395
    
    dataDir2 = new File(dataDir, getSimpleClassName() + "-core1-"
        + System.currentTimeMillis());
    dataDir2.mkdirs();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701187/fstmerge_base_379073479409849546
    
    createTempDir();
    dataDir2 = new File(TEMP_DIR, getSimpleClassName() + "-core1-"
        + System.currentTimeMillis());
    dataDir2.mkdirs();
=======
    dataDir1 = createTempDir();
    dataDir2  = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701187/fstmerge_var2_6732762078821190881

    home = ExternalPaths.EXAMPLE_MULTICORE_HOME;
    System.setProperty("solr.solr.home", home);
    System.setProperty( "solr.core0.data.dir", dataDir1.getCanonicalPath() ); 
    System.setProperty( "solr.core1.data.dir", dataDir2.getCanonicalPath() ); 
    
    zkDir = dataDir1.getAbsolutePath() + File.separator
        + "zookeeper/server1/data";
    zkServer = new ZkTestServer(zkDir);
    zkServer.run();
    
    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkHost(), AbstractZkTestCase.TIMEOUT);
    zkClient.makePath("/solr", false, true);
    zkClient.close();
    
    System.setProperty("zkHost", zkServer.getZkAddress());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/cloud/TestMultiCoreConfBootstrap.java
Conflict type: LineBasedMCFd
Conflict body: 
private void brindDownShardIndexSomeDocsAndRecover() throws Exception {
    SolrQuery query = new SolrQuery("*:*");
    query.set("distrib", false);
    
    commit();
    
    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient
        .query(query).getResults().getNumFound();

    query("q", "*:*", "sort", "n_tl1 desc");
    
    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();
    
    assertEquals(5, oldLiveNodes);
    
    // kill a shard
    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);
    
    // ensure shard is dead
    try {
      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,
          "specific doc!");
      fail("This server should be down and this update should have failed");
    } catch (SolrServerException e) {
      // expected..
    }
    
    commit();
    
    query("q", "*:*", "sort", "n_tl1 desc");
    
    // long cloudClientDocs = cloudClient.query(new
    // SolrQuery("*:*")).getResults().getNumFound();
    // System.out.println("clouddocs:" + cloudClientDocs);
    
    // try to index to a living shard at shard2

  
    long numFound1 = cloudClient.query(new SolrQuery("*:*")).getResults().getNumFound();
    
    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);
    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,
        "specific doc!");
    
    commit();
    
    checkShardConsistency(true, false);
    
    query("q", "*:*", "sort", "n_tl1 desc");
    

    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);

    long numFound2 = cloudClient.query(new SolrQuery("*:*")).getResults().getNumFound();
    
    assertEquals(numFound1 + 1, numFound2);
    
    SolrInputDocument doc = new SolrInputDocument();
    doc.addField("id", 1001);
    
    controlClient.add(doc);
    
    // try adding a doc with CloudSolrServer
    UpdateRequest ureq = new UpdateRequest();
    ureq.add(doc);
    // ureq.setParam("update.chain", DISTRIB_UPDATE_CHAIN);
    
    try {
      ureq.process(cloudClient);
    } catch(SolrServerException e){
      // try again
      Thread.sleep(3500);
      ureq.process(cloudClient);
    }
    
    commit();
    
    query("q", "*:*", "sort", "n_tl1 desc");
    
    long numFound3 = cloudClient.query(new SolrQuery("*:*")).getResults().getNumFound();
    
    // lets just check that the one doc since last commit made it in...
    assertEquals(numFound2 + 1, numFound3);
    
    // test debugging
    testDebugQueries();
    
    if (VERBOSE) {
      System.err.println(controlClient.query(new SolrQuery("*:*")).getResults()
          .getNumFound());
      
      for (SolrServer client : clients) {
        try {
          SolrQuery q = new SolrQuery("*:*");
          q.set("distrib", false);
          System.err.println(client.query(q).getResults()
              .getNumFound());
        } catch (Exception e) {
          
        }
      }
    }
    // TODO: This test currently fails because debug info is obtained only
    // on shards with matches.
    // query("q","matchesnothing","fl","*,score", "debugQuery", "true");
    
    // this should trigger a recovery phase on deadShard
    ChaosMonkey.start(deadShard.jetty);
    
    // make sure we have published we are recovering
    Thread.sleep(1500);
    
    waitForRecoveriesToFinish(false);
    
    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient
        .query(query).getResults().getNumFound();
    // if we properly recovered, we should now have the couple missing docs that
    // came in while shard was down
    checkShardConsistency(true, false);
    
    
    // recover over 100 docs so we do more than just peer sync (replicate recovery)
    chaosMonkey.stopJetty(deadShard);

    for (int i = 0; i < 226; i++) {
      doc = new SolrInputDocument();
      doc.addField("id", 2000 + i);
      controlClient.add(doc);
      ureq = new UpdateRequest();
      ureq.add(doc);
      // ureq.setParam("update.chain", DISTRIB_UPDATE_CHAIN);
      ureq.process(cloudClient);
    }
    commit();
    
    Thread.sleep(1500);
    
    ChaosMonkey.start(deadShard.jetty);
    
    // make sure we have published we are recovering
    Thread.sleep(1500);
    
    waitForThingsToLevelOut(45);
    
    Thread.sleep(500);
    
    waitForRecoveriesToFinish(false);
    
    checkShardConsistency(true, false);
    
    // try a backup command
    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;
    ModifiableSolrParams params = new ModifiableSolrParams();
    params.set("qt", "/replication");
    params.set("command", "backup");
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701246/fstmerge_var1_4234286628464522481
    File location = new File(dataDir, BasicDistributedZk2Test.class.getName() + "-backupdir-" + System.currentTimeMillis());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701246/fstmerge_base_8719156642844977696
    File location = new File(TEMP_DIR, BasicDistributedZk2Test.class.getName() + "-backupdir-" + System.currentTimeMillis());
=======
    File location = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701246/fstmerge_var2_5379283949031511614
    params.set("location", location.getAbsolutePath());

    QueryRequest request = new QueryRequest(params);
    NamedList<Object> results = client.request(request );
    
    checkForBackupSuccess(client, location);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testUpConfigLinkConfigClearZk() throws Exception {
    File tmpDir = createTempDir();
    
    // test upconfig
    String confsetname = "confsetone";
    String[] args = new String[] {
        "-zkhost",
        zkServer.getZkAddress(),
        "-cmd",
        "upconfig",
        "-confdir",
        ExternalPaths.EXAMPLE_HOME + File.separator + "collection1"
            + File.separator + "conf", "-confname", confsetname};
    ZkCLI.main(args);
    
    assertTrue(zkClient.exists(ZkController.CONFIGS_ZKNODE + "/" + confsetname, true));

    // print help
    // ZkCLI.main(new String[0]);
    
    // test linkconfig
    args = new String[] {"-zkhost", zkServer.getZkAddress(), "-cmd",
        "linkconfig", "-collection", "collection1", "-confname", confsetname};
    ZkCLI.main(args);
    
    ZkNodeProps collectionProps = ZkNodeProps.load(zkClient.getData(ZkStateReader.COLLECTIONS_ZKNODE + "/collection1", null, null, true));
    assertTrue(collectionProps.containsKey("configName"));
    assertEquals(confsetname, collectionProps.getStr("configName"));
    
    // test down config
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701352/fstmerge_var1_39722675417495494
    File confDir = new File(dataDir,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701352/fstmerge_base_7569613391104273890
    File confDir = new File(TEMP_DIR,
=======
    File confDir = new File(tmpDir,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701352/fstmerge_var2_1061146445742035423
        "solrtest-confdropspot-" + this.getClass().getName() + "-" + System.currentTimeMillis());
    assertFalse(confDir.exists());

    args = new String[] {"-zkhost", zkServer.getZkAddress(), "-cmd",
        "downconfig", "-confdir", confDir.getAbsolutePath(), "-confname", confsetname};
    ZkCLI.main(args);
    
    File[] files = confDir.listFiles();
    List<String> zkFiles = zkClient.getChildren(ZkController.CONFIGS_ZKNODE + "/" + confsetname, null, true);
    assertEquals(files.length, zkFiles.size());
    
    File sourceConfDir = new File(ExternalPaths.EXAMPLE_HOME + File.separator + "collection1"
            + File.separator + "conf");
    // filter out all directories starting with . (e.g. .svn)
    Collection<File> sourceFiles = FileUtils.listFiles(sourceConfDir, TrueFileFilter.INSTANCE, new RegexFileFilter("[^\\.].*"));
    for (File sourceFile :sourceFiles){
        int indexOfRelativePath = sourceFile.getAbsolutePath().lastIndexOf("collection1" + File.separator + "conf");
        String relativePathofFile = sourceFile.getAbsolutePath().substring(indexOfRelativePath + 17, sourceFile.getAbsolutePath().length());
        File downloadedFile = new File(confDir,relativePathofFile);
        assertTrue(downloadedFile.getAbsolutePath() + " does not exist source:" + sourceFile.getAbsolutePath(), downloadedFile.exists());
        assertTrue("Content didn't change",FileUtils.contentEquals(sourceFile,downloadedFile));
    }
    
   
    // test reset zk
    args = new String[] {"-zkhost", zkServer.getZkAddress(), "-cmd",
        "clear", "/"};
    ZkCLI.main(args);

    assertEquals(0, zkClient.getChildren("/", null, true).size());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/cloud/ZkCLITest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testGetFile() throws Exception {
    File tmpDir = createTempDir();
    
    String getNode = "/getFileNode";
    byte [] data = new String("getFileNode-data").getBytes(StandardCharsets.UTF_8);
    this.zkClient.create(getNode, data, CreateMode.PERSISTENT, true);

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701363/fstmerge_var1_1815736958323831871
    File file = new File(dataDir,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701363/fstmerge_base_8386168667921910775
    File file = new File(TEMP_DIR,
=======
    File file = new File(tmpDir,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701363/fstmerge_var2_3044155513670579496
        "solrtest-getfile-" + this.getClass().getName() + "-" + System.currentTimeMillis());
    String[] args = new String[] {"-zkhost", zkServer.getZkAddress(), "-cmd",
        "getfile", getNode, file.getAbsolutePath()};
    ZkCLI.main(args);

    byte [] readData = FileUtils.readFileToByteArray(file);
    assertArrayEquals(data, readData);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/cloud/ZkCLITest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testGetFileNotExists() throws Exception {
    File tmpDir = createTempDir();
    String getNode = "/getFileNotExistsNode";

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701369/fstmerge_var1_7256068488479279747
    File file = new File(dataDir,
        "solrtest-getfilenotexists-" + this.getClass().getName() + "-" + System.currentTimeMillis());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701369/fstmerge_base_2602427307338187650
    File file = new File(TEMP_DIR,
        "solrtest-getfilenotexists-" + this.getClass().getName() + "-" + System.currentTimeMillis());
=======
    File file = File.createTempFile("newfile", null, tmpDir);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701369/fstmerge_var2_7464140790655567787
    String[] args = new String[] {"-zkhost", zkServer.getZkAddress(), "-cmd",
        "getfile", getNode, file.getAbsolutePath()};
    try {
      ZkCLI.main(args);
      fail("Expected NoNodeException");
    } catch (KeeperException.NoNodeException ex) {
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/cloud/ZkCLITest.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void setupClass() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701671/fstmerge_var1_3061204796535940577
    dfsCluster = HdfsTestUtil.setupClass(new File(dataDir,
        HdfsCollectionsAPIDistributedZkTest.class.getName() + "_"
            + System.currentTimeMillis()).getAbsolutePath());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701671/fstmerge_base_8810154691541087718
    dfsCluster = HdfsTestUtil.setupClass(new File(TEMP_DIR,
        HdfsCollectionsAPIDistributedZkTest.class.getName() + "_"
            + System.currentTimeMillis()).getAbsolutePath());
=======
    dfsCluster = HdfsTestUtil.setupClass(createTempDir().getAbsolutePath());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701671/fstmerge_var2_6379966110006689609
    
    System.setProperty("solr.hdfs.home", dfsCluster.getURI().toString() + "/solr");
    System.setProperty("solr.hdfs.blockcache.enabled", "false");
    
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsCollectionsAPIDistributedZkTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void setupClass() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701687/fstmerge_var1_6134386109654940686
    dfsCluster = HdfsTestUtil.setupClass(new File(dataDir,
        HdfsUnloadDistributedZkTest.class.getName() + "_"
            + System.currentTimeMillis()).getAbsolutePath());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701687/fstmerge_base_5451168865245782966
    dfsCluster = HdfsTestUtil.setupClass(new File(TEMP_DIR,
        HdfsUnloadDistributedZkTest.class.getName() + "_"
            + System.currentTimeMillis()).getAbsolutePath());
=======
    dfsCluster = HdfsTestUtil.setupClass(createTempDir().getAbsolutePath());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701687/fstmerge_var2_5492474562324048877
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsUnloadDistributedZkTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void setupClass() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701702/fstmerge_var1_159445190069536033
    dfsCluster = HdfsTestUtil.setupClass(new File(dataDir,
        HdfsBasicDistributedZk2Test.class.getName() + "_"
            + System.currentTimeMillis()).getAbsolutePath());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701702/fstmerge_base_2092838204354803300
    dfsCluster = HdfsTestUtil.setupClass(new File(TEMP_DIR,
        HdfsBasicDistributedZk2Test.class.getName() + "_"
            + System.currentTimeMillis()).getAbsolutePath());
=======
    dfsCluster = HdfsTestUtil.setupClass(createTempDir().getAbsolutePath());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701702/fstmerge_var2_4634181805825127402
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsBasicDistributedZk2Test.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void setupClass() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701718/fstmerge_var1_7005350567256705032
    dfsCluster = HdfsTestUtil.setupClass(new File(dataDir,
        HdfsBasicDistributedZk2Test.class.getName() + "_"
            + System.currentTimeMillis()).getAbsolutePath());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701718/fstmerge_base_7601503833512194201
    dfsCluster = HdfsTestUtil.setupClass(new File(TEMP_DIR,
        HdfsBasicDistributedZk2Test.class.getName() + "_"
            + System.currentTimeMillis()).getAbsolutePath());
=======
    dfsCluster = HdfsTestUtil.setupClass(createTempDir().getAbsolutePath());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701718/fstmerge_var2_7773212237028892632
    System.setProperty("solr.hdfs.blockcache.blocksperbank", "2048");
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsRecoveryZkTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void setupClass() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701733/fstmerge_var1_1379569486936373815
    dfsCluster = HdfsTestUtil.setupClass(new File(dataDir,
        HdfsBasicDistributedZk2Test.class.getName() + "_"
            + System.currentTimeMillis()).getAbsolutePath());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701733/fstmerge_base_8914586086282728873
    dfsCluster = HdfsTestUtil.setupClass(new File(TEMP_DIR,
        HdfsBasicDistributedZk2Test.class.getName() + "_"
            + System.currentTimeMillis()).getAbsolutePath());
=======
    dfsCluster = HdfsTestUtil.setupClass(createTempDir().getAbsolutePath());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701733/fstmerge_var2_3153678085994568607
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsSyncSliceTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void setupClass() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701753/fstmerge_var1_5373498778855165533
    dfsCluster = HdfsTestUtil.setupClass(new File(dataDir,
        HdfsBasicDistributedZk2Test.class.getName() + "_"
            + System.currentTimeMillis()).getAbsolutePath());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701753/fstmerge_base_5276200588405935670
    dfsCluster = HdfsTestUtil.setupClass(new File(TEMP_DIR,
        HdfsBasicDistributedZk2Test.class.getName() + "_"
            + System.currentTimeMillis()).getAbsolutePath());
=======
    dfsCluster = HdfsTestUtil.setupClass(createTempDir().getAbsolutePath());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701753/fstmerge_var2_5362793306567579806
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsChaosMonkeySafeLeaderTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void setupClass() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701772/fstmerge_var1_6884638879582852227
    dfsCluster = HdfsTestUtil.setupClass(new File(dataDir,
        HdfsBasicDistributedZk2Test.class.getName() + "_"
            + System.currentTimeMillis()).getAbsolutePath());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701772/fstmerge_base_982731002238405547
    dfsCluster = HdfsTestUtil.setupClass(new File(TEMP_DIR,
        HdfsBasicDistributedZk2Test.class.getName() + "_"
            + System.currentTimeMillis()).getAbsolutePath());
=======
    dfsCluster = HdfsTestUtil.setupClass(createTempDir().getAbsolutePath());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701772/fstmerge_var2_1684327905069506617
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsBasicDistributedZkTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void beforeClass() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701788/fstmerge_var1_2405775347757302091
    dfsCluster = HdfsTestUtil.setupClass(dataDir.getAbsolutePath()
        + File.separator + HdfsLockFactoryTest.class.getName() + "_hdfsdir-"
        + System.currentTimeMillis());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701788/fstmerge_base_3812244917731369764
    createTempDir();
    dfsCluster = HdfsTestUtil.setupClass(TEMP_DIR.getAbsolutePath()
        + File.separator + HdfsLockFactoryTest.class.getName() + "_hdfsdir-"
        + System.currentTimeMillis());
=======
    dfsCluster = HdfsTestUtil.setupClass(createTempDir().getAbsolutePath());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701788/fstmerge_var2_110461649692557646
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/store/hdfs/HdfsLockFactoryTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Before
  public void setUp() throws Exception {
    super.setUp();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701842/fstmerge_var1_459776564944533110
    file = new File(dataDir, HdfsDirectory.class.getName() + "-" + System.currentTimeMillis());
    rm(file);
    file.mkdirs();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701842/fstmerge_base_21161364941226119
    file = new File(TEMP_DIR, HdfsDirectory.class.getName() + "-" + System.currentTimeMillis());
    rm(file);
    file.mkdirs();
=======
    file = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524701842/fstmerge_var2_2364251596653199483
    FSDirectory dir = FSDirectory.open(new File(file, "base"));
    mapperCache = new MapperCache();
    directory = new BlockDirectory("test", dir, mapperCache, null, true, true);
    random = random();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/store/blockcache/BlockDirectoryTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testFieldType() throws Exception {
    FileBasedSpellChecker checker = new FileBasedSpellChecker();
    NamedList spellchecker = new NamedList();
    spellchecker.add("classname", FileBasedSpellChecker.class.getName());
    spellchecker.add(SolrSpellChecker.DICTIONARY_NAME, "external");
    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, "spellings.txt");
    spellchecker.add(AbstractLuceneSpellChecker.FIELD, "teststop");
    spellchecker.add(FileBasedSpellChecker.SOURCE_FILE_CHAR_ENCODING, "UTF-8");
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702756/fstmerge_var1_907174184583083208
    File indexDir = new File(dataDir, "spellingIdx" + new Date().getTime());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702756/fstmerge_base_8410155894244288112
    File indexDir = new File(TEMP_DIR, "spellingIdx" + new Date().getTime());
=======
    File indexDir = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702756/fstmerge_var2_8470836259033326461
    indexDir.mkdirs();
    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());
    spellchecker.add(SolrSpellChecker.FIELD_TYPE, "teststop");
    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);
    SolrCore core = h.getCore();
    String dictName = checker.init(spellchecker, core);
    assertTrue(dictName + " is not equal to " + "external", dictName.equals("external") == true);
    checker.build(core, null);

    RefCounted<SolrIndexSearcher> searcher = core.getSearcher();
    Collection<Token> tokens = queryConverter.convert("Solar");

    SpellingOptions spellOpts = new SpellingOptions(tokens, searcher.get().getIndexReader());
    SpellingResult result = checker.getSuggestions(spellOpts);
    assertTrue("result is null and it shouldn't be", result != null);
    //should be lowercased, b/c we are using a lowercasing analyzer
    Map<String, Integer> suggestions = result.get(tokens.iterator().next());
    assertTrue("suggestions Size: " + suggestions.size() + " is not: " + 1, suggestions.size() == 1);
    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();
    assertTrue(entry.getKey() + " is not equal to " + "solr", entry.getKey().equals("solr") == true);
    assertTrue(entry.getValue() + " does not equal: " + SpellingResult.NO_FREQUENCY_INFO, entry.getValue() == SpellingResult.NO_FREQUENCY_INFO);

    //test something not in the spell checker
    spellOpts.tokens = queryConverter.convert("super");
    result = checker.getSuggestions(spellOpts);
    assertTrue("result is null and it shouldn't be", result != null);
    suggestions = result.get(tokens.iterator().next());
    assertTrue("suggestions is not null and it should be", suggestions == null);
    searcher.decref();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/spelling/FileBasedSpellCheckerTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testSpelling() throws Exception {
    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();

    NamedList spellchecker = new NamedList();
    spellchecker.add("classname", IndexBasedSpellChecker.class.getName());

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702803/fstmerge_var1_4717846835500135231
    File indexDir = new File(dataDir, "spellingIdx" + new Date().getTime());
    indexDir.mkdirs();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702803/fstmerge_base_1020006503419781599
    File indexDir = new File(TEMP_DIR, "spellingIdx" + new Date().getTime());
    indexDir.mkdirs();
=======
    File indexDir = createTempDir();

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702803/fstmerge_var2_6719374525006033556
    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());
    spellchecker.add(AbstractLuceneSpellChecker.FIELD, "title");
    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);
    SolrCore core = h.getCore();

    String dictName = checker.init(spellchecker, core);
    assertTrue(dictName + " is not equal to " + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,
            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);
    RefCounted<SolrIndexSearcher> holder = core.getSearcher();
    SolrIndexSearcher searcher = holder.get();
    try {
    checker.build(core, searcher);

    IndexReader reader = searcher.getIndexReader();
    Collection<Token> tokens = queryConverter.convert("documemt");
    SpellingOptions spellOpts = new SpellingOptions(tokens, reader);
    SpellingResult result = checker.getSuggestions(spellOpts);
    assertTrue("result is null and it shouldn't be", result != null);
    //should be lowercased, b/c we are using a lowercasing analyzer
    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());
    assertTrue("documemt is null and it shouldn't be", suggestions != null);
    assertTrue("documemt Size: " + suggestions.size() + " is not: " + 1, suggestions.size() == 1);
    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();
    assertTrue(entry.getKey() + " is not equal to " + "document", entry.getKey().equals("document") == true);
    assertTrue(entry.getValue() + " does not equal: " + SpellingResult.NO_FREQUENCY_INFO, entry.getValue() == SpellingResult.NO_FREQUENCY_INFO);

    //test something not in the spell checker
    spellOpts.tokens = queryConverter.convert("super");
    result = checker.getSuggestions(spellOpts);
    assertTrue("result is null and it shouldn't be", result != null);
    suggestions = result.get(spellOpts.tokens.iterator().next());
    assertTrue("suggestions size should be 0", suggestions.size()==0);

    //test something that is spelled correctly
    spellOpts.tokens = queryConverter.convert("document");
    result = checker.getSuggestions(spellOpts);
    assertTrue("result is null and it shouldn't be", result != null);
    suggestions = result.get(spellOpts.tokens.iterator().next());
    assertTrue("suggestions is null and it shouldn't be", suggestions == null);

    //Has multiple possibilities, but the exact exists, so that should be returned
    spellOpts.tokens = queryConverter.convert("red");
    spellOpts.count = 2;
    result = checker.getSuggestions(spellOpts);
    assertNotNull(result);
    suggestions = result.get(spellOpts.tokens.iterator().next());
    assertTrue("suggestions is not null and it should be", suggestions == null);

    //Try out something which should have multiple suggestions
    spellOpts.tokens = queryConverter.convert("bug");
    result = checker.getSuggestions(spellOpts);
    assertNotNull(result);
    suggestions = result.get(spellOpts.tokens.iterator().next());
    assertNotNull(suggestions);
    assertTrue("suggestions Size: " + suggestions.size() + " is not: " + 2, suggestions.size() == 2);

    entry = suggestions.entrySet().iterator().next();
    assertTrue(entry.getKey() + " is equal to " + "bug and it shouldn't be", entry.getKey().equals("bug") == false);
    assertTrue(entry.getValue() + " does not equal: " + SpellingResult.NO_FREQUENCY_INFO, entry.getValue() == SpellingResult.NO_FREQUENCY_INFO);

    entry = suggestions.entrySet().iterator().next();
    assertTrue(entry.getKey() + " is equal to " + "bug and it shouldn't be", entry.getKey().equals("bug") == false);
    assertTrue(entry.getValue() + " does not equal: " + SpellingResult.NO_FREQUENCY_INFO, entry.getValue() == SpellingResult.NO_FREQUENCY_INFO);
    } finally {
      holder.decref();
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testExtendedResults() throws Exception {
    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();
    NamedList spellchecker = new NamedList();
    spellchecker.add("classname", IndexBasedSpellChecker.class.getName());

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702810/fstmerge_var1_92939144606322030
    File indexDir = new File(dataDir, "spellingIdx" + new Date().getTime());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702810/fstmerge_base_6260232714527863859
    File indexDir = new File(TEMP_DIR, "spellingIdx" + new Date().getTime());
=======
    File indexDir = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702810/fstmerge_var2_3932857316256768745
    indexDir.mkdirs();
    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());
    spellchecker.add(AbstractLuceneSpellChecker.FIELD, "title");
    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);
    SolrCore core = h.getCore();
    String dictName = checker.init(spellchecker, core);
    assertTrue(dictName + " is not equal to " + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,
            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);
    RefCounted<SolrIndexSearcher> holder = core.getSearcher();
    SolrIndexSearcher searcher = holder.get();
    try {
    checker.build(core, searcher);

    IndexReader reader = searcher.getIndexReader();
    Collection<Token> tokens = queryConverter.convert("documemt");
    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);
    SpellingResult result = checker.getSuggestions(spellOpts);
    assertTrue("result is null and it shouldn't be", result != null);
    //should be lowercased, b/c we are using a lowercasing analyzer
    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());
    assertTrue("documemt is null and it shouldn't be", suggestions != null);
    assertTrue("documemt Size: " + suggestions.size() + " is not: " + 1, suggestions.size() == 1);
    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();
    assertTrue(entry.getKey() + " is not equal to " + "document", entry.getKey().equals("document") == true);
    assertTrue(entry.getValue() + " does not equal: " + 2, entry.getValue() == 2);

    //test something not in the spell checker
    spellOpts.tokens = queryConverter.convert("super");
    result = checker.getSuggestions(spellOpts);
    assertTrue("result is null and it shouldn't be", result != null);
    suggestions = result.get(spellOpts.tokens.iterator().next());
    assertTrue("suggestions size should be 0", suggestions.size()==0);

    spellOpts.tokens = queryConverter.convert("document");
    result = checker.getSuggestions(spellOpts);
    assertTrue("result is null and it shouldn't be", result != null);
    suggestions = result.get(spellOpts.tokens.iterator().next());
    assertTrue("suggestions is not null and it should be", suggestions == null);
    } finally {
      holder.decref();
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testAlternateDistance() throws Exception {
    TestSpellChecker checker = new TestSpellChecker();
    NamedList spellchecker = new NamedList();
    spellchecker.add("classname", IndexBasedSpellChecker.class.getName());

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702828/fstmerge_var1_5401301208678851919
    File indexDir = new File(dataDir, "spellingIdx" + new Date().getTime());
    indexDir.mkdirs();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702828/fstmerge_base_9147967806534641032
    File indexDir = new File(TEMP_DIR, "spellingIdx" + new Date().getTime());
    indexDir.mkdirs();
=======
    File indexDir = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702828/fstmerge_var2_8758719286273883923
    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());
    spellchecker.add(AbstractLuceneSpellChecker.FIELD, "title");
    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);
    spellchecker.add(AbstractLuceneSpellChecker.STRING_DISTANCE, JaroWinklerDistance.class.getName());
    SolrCore core = h.getCore();
    String dictName = checker.init(spellchecker, core);
    assertTrue(dictName + " is not equal to " + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,
            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);
    RefCounted<SolrIndexSearcher> holder = core.getSearcher();
    SolrIndexSearcher searcher = holder.get();
    try {
    checker.build(core, searcher);
    SpellChecker sc = checker.getSpellChecker();
    assertTrue("sc is null and it shouldn't be", sc != null);
    StringDistance sd = sc.getStringDistance();
    assertTrue("sd is null and it shouldn't be", sd != null);
    assertTrue("sd is not an instance of " + JaroWinklerDistance.class.getName(), sd instanceof JaroWinklerDistance);
    } finally {
      holder.decref();
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  public void testAlternateLocation() throws Exception {
    String[] ALT_DOCS = new String[]{
            "jumpin jack flash",
            "Sargent Peppers Lonely Hearts Club Band",
            "Born to Run",
            "Thunder Road",
            "Londons Burning",
            "A Horse with No Name",
            "Sweet Caroline"
    };

    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();
    NamedList spellchecker = new NamedList();
    spellchecker.add("classname", IndexBasedSpellChecker.class.getName());
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702834/fstmerge_var1_2972151972547649265

    File indexDir = new File(dataDir, "spellingIdx" + new Date().getTime());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702834/fstmerge_base_2352793021387270558

    File indexDir = new File(TEMP_DIR, "spellingIdx" + new Date().getTime());
=======
    
    File tmpDir = createTempDir();
    File indexDir = new File(tmpDir, "spellingIdx");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702834/fstmerge_var2_4777635985211254925
    //create a standalone index
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702834/fstmerge_var1_2972151972547649265
    File altIndexDir = new File(dataDir, "alternateIdx" + new Date().getTime());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702834/fstmerge_base_2352793021387270558
    File altIndexDir = new File(TEMP_DIR, "alternateIdx" + new Date().getTime());
=======
    File altIndexDir = new File(tmpDir, "alternateIdx" + new Date().getTime());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524702834/fstmerge_var2_4777635985211254925
    Directory dir = newFSDirectory(altIndexDir);
    IndexWriter iw = new IndexWriter(
        dir,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT))
    );
    for (int i = 0; i < ALT_DOCS.length; i++) {
      Document doc = new Document();
      doc.add(new TextField("title", ALT_DOCS[i], Field.Store.YES));
      iw.addDocument(doc);
    }
    iw.forceMerge(1);
    iw.close();
    dir.close();
    indexDir.mkdirs();
    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());
    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());
    spellchecker.add(AbstractLuceneSpellChecker.FIELD, "title");
    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);
    SolrCore core = h.getCore();
    String dictName = checker.init(spellchecker, core);
    assertTrue(dictName + " is not equal to " + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,
            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);
    RefCounted<SolrIndexSearcher> holder = core.getSearcher();
    SolrIndexSearcher searcher = holder.get();
    try {
    checker.build(core, searcher);

    IndexReader reader = searcher.getIndexReader();
    Collection<Token> tokens = queryConverter.convert("flesh");
    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);
    SpellingResult result = checker.getSuggestions(spellOpts);
    assertTrue("result is null and it shouldn't be", result != null);
    //should be lowercased, b/c we are using a lowercasing analyzer
    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());
    assertTrue("flesh is null and it shouldn't be", suggestions != null);
    assertTrue("flesh Size: " + suggestions.size() + " is not: " + 1, suggestions.size() == 1);
    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();
    assertTrue(entry.getKey() + " is not equal to " + "flash", entry.getKey().equals("flash") == true);
    assertTrue(entry.getValue() + " does not equal: " + 1, entry.getValue() == 1);

    //test something not in the spell checker
    spellOpts.tokens = queryConverter.convert("super");
    result = checker.getSuggestions(spellOpts);
    assertTrue("result is null and it shouldn't be", result != null);
    suggestions = result.get(spellOpts.tokens.iterator().next());
    assertTrue("suggestions size should be 0", suggestions.size()==0);

    spellOpts.tokens = queryConverter.convert("Caroline");
    result = checker.getSuggestions(spellOpts);
    assertTrue("result is null and it shouldn't be", result != null);
    suggestions = result.get(spellOpts.tokens.iterator().next());
    assertTrue("suggestions is not null and it should be", suggestions == null);
    } finally {
      holder.decref();
    }
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Before
  public void before() throws IOException {
    File tmpDir = initCoreDataDir;
    // by default, use relative file in dataDir
    healthcheckFile = new File(tmpDir, fileName);
    String fileNameParam = fileName;

    // sometimes randomly use an absolute File path instead 
    if (random().nextBoolean()) {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524703400/fstmerge_var1_2001245369243997954
      healthcheckFile = new File(dataDir, fileName);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524703400/fstmerge_base_5742849128768945213
      healthcheckFile = new File(TEMP_DIR, fileName);
=======
      healthcheckFile = new File(tmpDir, fileName);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524703400/fstmerge_var2_7019957828181314573
      fileNameParam = healthcheckFile.getAbsolutePath();
    } 
      
    if (healthcheckFile.exists()) FileUtils.forceDelete(healthcheckFile);

    handler = new PingRequestHandler();
    NamedList initParams = new NamedList();
    initParams.add(PingRequestHandler.HEALTHCHECK_FILE_PARAM,
                   fileNameParam);
    handler.init(initParams);
    handler.inform(h.getCore());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/handler/PingRequestHandlerTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void beforeClass() throws Exception {
    useFactory(null); // I require FS-based indexes for this test.

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524703556/fstmerge_var1_1680660641821719722
    solrHomeDirectory = new File(dataDir, "solrHome/" + CoreAdminCreateDiscoverTest.getClassName());
    if (solrHomeDirectory.exists()) {
      FileUtils.deleteDirectory(solrHomeDirectory);
    }
    assertTrue("Failed to mkdirs workDir", solrHomeDirectory.mkdirs());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524703556/fstmerge_base_1446152617870541892
    solrHomeDirectory = new File(TEMP_DIR, "solrHome/" + CoreAdminCreateDiscoverTest.getClassName());
    if (solrHomeDirectory.exists()) {
      FileUtils.deleteDirectory(solrHomeDirectory);
    }
    assertTrue("Failed to mkdirs workDir", solrHomeDirectory.mkdirs());
=======
    solrHomeDirectory = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524703556/fstmerge_var2_3684001998902793388

    setupNoCoreTest(solrHomeDirectory, null);

    admin = new CoreAdminHandler(h.getCoreContainer());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/handler/admin/CoreAdminCreateDiscoverTest.java
Conflict type: LineBasedMCFd
Conflict body: 
private static File createSolrHome() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524703785/fstmerge_var1_6787609669483596406
    File workDir = new File(dataDir, DistributedDebugComponentTest.class.getName());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524703785/fstmerge_base_8670014237563974655
    File workDir = new File(TEMP_DIR, DistributedDebugComponentTest.class.getName());
=======
    File workDir = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524703785/fstmerge_var2_7716571708721876828
    setupJettyTestHome(workDir, "collection1");
    FileUtils.copyDirectory(new File(workDir, "collection1"), new File(workDir, "collection2"));
    return workDir;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception {
    saveProp = System.getProperty("solr.directoryFactory");
    System.setProperty("solr.directoryFactory", "solr.StandardDirectoryFactory");
    super.setUp();
    File dataDir1 = createTempDir();
    // setup datadirs
    System.setProperty( "solr.core0.data.dir", dataDir1.getCanonicalPath() );

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524717780/fstmerge_var1_857350991031569841
    dataDir2 = new File(dataDir, getClass().getName() + "-"
        + System.currentTimeMillis());
    dataDir2.mkdirs();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524717780/fstmerge_base_7268961016805343445
    dataDir2 = new File(TEMP_DIR, getClass().getName() + "-"
        + System.currentTimeMillis());
    dataDir2.mkdirs();
=======
    dataDir2 = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524717780/fstmerge_var2_8176042928629961941

    System.setProperty( "solr.core1.data.dir", this.dataDir2.getCanonicalPath() );

    setupCoreContainer();
    SolrCore.log.info("CORES=" + cores + " : " + cores.getCoreNames());

  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/solrj/src/test/org/apache/solr/client/solrj/MergeIndexesExampleTestBase.java
Conflict type: LineBasedMCFd
Conflict body: 
@Override
  public void setUp() throws Exception 
  {
    super.setUp();
    System.setProperty("solr.solr.home", ExternalPaths.EXAMPLE_HOME);
    System.setProperty("tests.shardhandler.randomSeed", Long.toString(random().nextLong()));

<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718108/fstmerge_var1_7161835646570492668
    File dataDir = new File(this.dataDir,
        getClass().getName() + "-" + System.currentTimeMillis());
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718108/fstmerge_base_2470950408139758157
    File dataDir = new File(LuceneTestCase.TEMP_DIR,
        getClass().getName() + "-" + System.currentTimeMillis());
=======
    File dataDir = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718108/fstmerge_var2_4870268478065788337
    dataDir.mkdirs();

    System.setProperty("solr.data.dir", dataDir.getCanonicalPath());
    String path = ExternalPaths.WEBAPP_HOME;

    server = new Server(port);
    // insecure: only use for tests!!!!
    server.setSessionIdManager(new HashSessionIdManager(new Random(random().nextLong())));
    new WebAppContext(server, path, context );

    SocketConnector connector = new SocketConnector();
    connector.setMaxIdleTime(1000 * 60 * 60);
    connector.setSoLingerTime(-1);
    connector.setPort(0);
    server.setConnectors(new Connector[]{connector});
    server.setStopAtShutdown( true );
    
    server.start();
    port = connector.getLocalPort();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/JettyWebappTest.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718145/fstmerge_var1_6109583719224700097
protected void createTempDir() {
    if (tempDir == null) {
      tempDir = new File(dataDir, "solrtest-" + getTestClass().getSimpleName() + "-" + System.currentTimeMillis());
      tempDir.mkdirs();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718145/fstmerge_base_5244400595883113245
protected void createTempDir() {
    if (tempDir == null) {
      tempDir = new File(TEMP_DIR, "solrtest-" + getTestClass().getSimpleName() + "-" + System.currentTimeMillis());
      tempDir.mkdirs();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718145/fstmerge_var2_5844835187429424321

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/AbstractEmbeddedSolrServerTestCase.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testFileStream() throws IOException 
  {
    InputStream is = new SolrResourceLoader(null, null).openResource( "solrj/README" );
    assertNotNull( is );
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718248/fstmerge_var1_5033115342828007976
    File file = new File(dataDir, "README");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718248/fstmerge_base_6457105064701978248
    File file = new File(TEMP_DIR, "README");
=======
    File file = TestUtil.createTempFile("README", "", createTempDir());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718248/fstmerge_var2_3820381852037634229
    FileOutputStream os = new FileOutputStream(file);
    IOUtils.copy(is, os);
    os.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718248/fstmerge_base_6457105064701978248
=======
    is.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718248/fstmerge_var2_3820381852037634229
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718248/fstmerge_var1_5033115342828007976
    ContentStreamBase stream = new ContentStreamBase.FileStream(file);
    InputStream s = stream.getStream();
    FileInputStream fis = new FileInputStream(file);
    InputStreamReader isr = new InputStreamReader(
        new FileInputStream(file), StandardCharsets.UTF_8);
    Reader r = stream.getReader();
    try {
      assertEquals(file.length(), stream.getSize().intValue());
      assertTrue(IOUtils.contentEquals(fis, s));
      assertTrue(IOUtils.contentEquals(isr, r));
    } finally {
      s.close();
      r.close();
      isr.close();
      fis.close();
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718248/fstmerge_base_6457105064701978248
    ContentStreamBase stream = new ContentStreamBase.FileStream( file );
    assertEquals( file.length(), stream.getSize().intValue() );
    assertTrue( IOUtils.contentEquals( new FileInputStream( file ), stream.getStream() ) );
    assertTrue( IOUtils.contentEquals( new InputStreamReader(new FileInputStream(file), "UTF-8"), stream.getReader() ) );
=======
    ContentStreamBase stream = new ContentStreamBase.FileStream(file);
    InputStream s = stream.getStream();
    FileInputStream fis = new FileInputStream(file);
    InputStreamReader isr = new InputStreamReader(
        new FileInputStream(file), "UTF-8");
    try {
      assertEquals(file.length(), stream.getSize().intValue());
      assertTrue(IOUtils.contentEquals(fis, s));
      assertTrue(IOUtils.contentEquals(isr, stream.getReader()));
    } finally {
      s.close();
      isr.close();
      fis.close();
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718248/fstmerge_var2_3820381852037634229
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/solrj/src/test/org/apache/solr/common/util/ContentStreamTest.java
Conflict type: LineBasedMCFd
Conflict body: 
public void testURLStream() throws IOException 
  {
    InputStream is = new SolrResourceLoader(null, null).openResource( "solrj/README" );
    assertNotNull( is );
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718254/fstmerge_var1_8798962096283082486
    File file = new File(dataDir, "README");
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718254/fstmerge_base_4201021180402363086
    File file = new File(TEMP_DIR, "README");
=======
    File file = new File(createTempDir(), "README");
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718254/fstmerge_var2_6415278003791216963
    FileOutputStream os = new FileOutputStream(file);
    IOUtils.copy(is, os);
    os.close();
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718254/fstmerge_base_4201021180402363086
=======
    is.close();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718254/fstmerge_var2_6415278003791216963
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718254/fstmerge_var1_8798962096283082486
    ContentStreamBase stream = new ContentStreamBase.URLStream(new URL(file
        .toURI().toASCIIString()));
    InputStream s = stream.getStream();
    FileInputStream fis = new FileInputStream(file);
    FileInputStream fis2 = new FileInputStream(file);
    InputStreamReader isr = new InputStreamReader(fis, StandardCharsets.UTF_8);
    Reader r = stream.getReader();
    try {
      assertTrue(IOUtils.contentEquals(fis2, s));
      assertEquals(file.length(), stream.getSize().intValue());
      assertTrue(IOUtils.contentEquals(isr, r));
      assertEquals(file.length(), stream.getSize().intValue());
    } finally {
      r.close();
      s.close();
      isr.close();
      fis.close();
      fis2.close();
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718254/fstmerge_base_4201021180402363086
    ContentStreamBase stream = new ContentStreamBase.URLStream( new URL(file.toURI().toASCIIString()) );
    assertTrue( IOUtils.contentEquals( new FileInputStream( file ), stream.getStream() ) );
    assertEquals( file.length(), stream.getSize().intValue() );
    assertTrue( IOUtils.contentEquals( new InputStreamReader(new FileInputStream(file), "UTF-8"), stream.getReader() ) );
    assertEquals( file.length(), stream.getSize().intValue() );
=======
    ContentStreamBase stream = new ContentStreamBase.URLStream(new URL(file
        .toURI().toASCIIString()));
    InputStream s = stream.getStream();
    FileInputStream fis = new FileInputStream(file);
    FileInputStream fis2 = new FileInputStream(file);
    InputStreamReader isr = new InputStreamReader(fis, "UTF-8");
    Reader r = stream.getReader();
    try {
      assertTrue(IOUtils.contentEquals(fis2, s));
      assertEquals(file.length(), stream.getSize().intValue());
      assertTrue(IOUtils.contentEquals(isr, r));
      assertEquals(file.length(), stream.getSize().intValue());
    } finally {
      r.close();
      s.close();
      isr.close();
      fis.close();
      fis2.close();
    }
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524718254/fstmerge_var2_6415278003791216963
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/solrj/src/test/org/apache/solr/common/util/ContentStreamTest.java
Conflict type: LineBasedMCFd
Conflict body: 
public void setUp() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524722188/fstmerge_var1_7853705607282547006

      File home = new File(dataDir,
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524722188/fstmerge_base_4981761130806811554

      File home = new File(TEMP_DIR,
=======
      File home = new File(dataDir,
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524722188/fstmerge_var2_293390154401594394
              getClass().getName() + "-" + System.currentTimeMillis());

      homeDir = new File(home, "inst");
      dataDir = new File(homeDir + "/collection1", "data");
      confDir = new File(homeDir + "/collection1", "conf");

      homeDir.mkdirs();
      dataDir.mkdirs();
      confDir.mkdirs();

      FileUtils.copyFile(getFile(getSolrXmlFile()), new File(homeDir, "solr.xml"));
      File f = new File(confDir, "solrconfig.xml");
      FileUtils.copyFile(getFile(getSolrConfigFile()), f);
      f = new File(confDir, "schema.xml");

      FileUtils.copyFile(getFile(getSchemaFile()), f);
      f = new File(confDir, "data-config.xml");
      FileUtils.copyFile(getFile(CONF_DIR + "dataconfig-contentstream.xml"), f);
    }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestContentStreamDataSource.java
Conflict type: LineBasedMCFd
Conflict body: 
public void test() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524722233/fstmerge_var1_7088188865308477591
    File tmpdir = File.createTempFile("test", "tmp", TEMP_DIR);
    tmpdir.delete();
    tmpdir.mkdir();
    tmpdir.deleteOnExit();
    createFile(tmpdir, "a.txt", "a line one\na line two\na line three".getBytes(StandardCharsets.UTF_8), false);
    createFile(tmpdir, "b.txt", "b line one\nb line two".getBytes(StandardCharsets.UTF_8), false);
    createFile(tmpdir, "c.txt", "c line one\nc line two\nc line three\nc line four".getBytes(StandardCharsets.UTF_8), false);
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524722233/fstmerge_base_2603388532960049062
    File tmpdir = File.createTempFile("test", "tmp", TEMP_DIR);
    tmpdir.delete();
    tmpdir.mkdir();
    tmpdir.deleteOnExit();
    createFile(tmpdir, "a.txt", "a line one\na line two\na line three".getBytes("UTF-8"), false);
    createFile(tmpdir, "b.txt", "b line one\nb line two".getBytes("UTF-8"), false);
    createFile(tmpdir, "c.txt", "c line one\nc line two\nc line three\nc line four".getBytes("UTF-8"), false);
=======
    File tmpdir = TestUtil.createTempDir(LuceneTestCase.getTestClass().getSimpleName());
    createFile(tmpdir, "a.txt", "a line one\na line two\na line three".getBytes("UTF-8"), false);
    createFile(tmpdir, "b.txt", "b line one\nb line two".getBytes("UTF-8"), false);
    createFile(tmpdir, "c.txt", "c line one\nc line two\nc line three\nc line four".getBytes("UTF-8"), false);
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524722233/fstmerge_var2_9135582637180685758
    
    String config = generateConfig(tmpdir);
    LocalSolrQueryRequest request = lrf.makeRequest(
        "command", "full-import", "dataConfig", config,
        "clean", "true", "commit", "true", "synchronous", "true", "indent", "true");
    h.query("/dataimport", request);
    
    assertQ(req("*:*"), "//*[@numFound='9']");
    assertQ(req("id:?\\ line\\ one"), "//*[@numFound='3']");
    assertQ(req("id:a\\ line*"), "//*[@numFound='3']");
    assertQ(req("id:b\\ line*"), "//*[@numFound='2']");
    assertQ(req("id:c\\ line*"), "//*[@numFound='4']");    
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestFileListWithLineEntityProcessor.java
Conflict type: LineBasedMCFd
Conflict body: 
@Test
  @Ignore("Fix Me. See SOLR-4103.")
  public void testFileListEntityProcessor_lastIndexTime() throws Exception  {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524722288/fstmerge_var1_5641733075869532262
    File tmpdir = File.createTempFile("test", "tmp", dataDir);
    tmpdir.delete();
    tmpdir.mkdir();
    tmpdir.deleteOnExit();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524722288/fstmerge_base_4503212650028101566
    File tmpdir = File.createTempFile("test", "tmp", TEMP_DIR);
    tmpdir.delete();
    tmpdir.mkdir();
    tmpdir.deleteOnExit();
=======
    File tmpdir = File.createTempFile("test", "tmp", createTempDir());
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524722288/fstmerge_var2_166892858807447686

    Map<String, String> params = createMap("baseDir", tmpdir.getAbsolutePath());

    createFile(tmpdir, "a.xml", "a.xml".getBytes(StandardCharsets.UTF_8), true);
    createFile(tmpdir, "b.xml", "b.xml".getBytes(StandardCharsets.UTF_8), true);
    createFile(tmpdir, "c.props", "c.props".getBytes(StandardCharsets.UTF_8), true);
    runFullImport(dataConfigFileList, params);
    assertQ(req("*:*"), "//*[@numFound='3']");

    // Add a new file after a full index is done
    createFile(tmpdir, "t.xml", "t.xml".getBytes(StandardCharsets.UTF_8), false);
    runFullImport(dataConfigFileList, params);
    // we should find only 1 because by default clean=true is passed
    // and this particular import should find only one file t.xml
    assertQ(req("*:*"), "//*[@numFound='1']");
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestDocBuilder2.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void createTempSolrHomeAndCore() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524722379/fstmerge_var1_2572100618177776135
    tmpSolrHome = dataDir + File.separator + TestNonWritablePersistFile.class.getSimpleName() + System.currentTimeMillis();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524722379/fstmerge_base_2657627950922316897
    createTempDir();
    tmpSolrHome = TEMP_DIR + File.separator + TestNonWritablePersistFile.class.getSimpleName() + System.currentTimeMillis();
=======
    tmpSolrHome = createTempDir().getAbsolutePath();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524722379/fstmerge_var2_192928477621227338
    FileUtils.copyDirectory(getFile("dih/solr"), new File(tmpSolrHome).getAbsoluteFile());
    initCore("dataimport-solrconfig.xml", "dataimport-schema.xml", 
             new File(tmpSolrHome).getAbsolutePath());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestNonWritablePersistFile.java
Conflict type: LineBasedMCFd
Conflict body: 
protected void setupHadoopConfig(Configuration config) throws IOException {
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524723416/fstmerge_var1_4707118857242201375
    String tempDir = dataDir + "/test-morphlines-" + System.currentTimeMillis();
    new File(tempDir).mkdirs();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524723416/fstmerge_base_2138545180683931822
    String tempDir = TEMP_DIR + "/test-morphlines-" + System.currentTimeMillis();
    new File(tempDir).mkdirs();
=======
    String tempDir = createTempDir().getAbsolutePath();

>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524723416/fstmerge_var2_1661264235940403232
    FileUtils.copyFile(new File(RESOURCES_DIR + "/custom-mimetypes.xml"), new File(tempDir + "/custom-mimetypes.xml"));

    AbstractSolrMorphlineTestBase.setupMorphline(tempDir, "test-morphlines/solrCellDocumentTypes", true);
    
    config.set(MorphlineMapRunner.MORPHLINE_FILE_PARAM, tempDir + "/test-morphlines/solrCellDocumentTypes.conf");
    config.set(SolrOutputFormat.ZIP_NAME, solrHomeZip.getName());
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MRUnitBase.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ private static final File solrHomeDirectory = new File(dataDir, MorphlineGoLiveMiniMRTest.class.getName()); ##FSTMerge## private static final File solrHomeDirectory = new File(TEMP_DIR, MorphlineGoLiveMiniMRTest.class.getName()); ##FSTMerge## private final File solrHomeDirectory = createTempDir();
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MapReduceIndexerToolArgumentParserTest.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ private static final File solrHomeDirectory = new File(dataDir, MorphlineBasicMiniMRTest.class.getName()); ##FSTMerge## private static final File solrHomeDirectory = new File(TEMP_DIR, MorphlineBasicMiniMRTest.class.getName()); ##FSTMerge## private static File solrHomeDirectory;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MorphlineBasicMiniMRTest.java
Conflict type: LineBasedMCFd
Conflict body: 
@BeforeClass
  public static void setupClass() throws Exception {
    solrHomeDirectory = createTempDir();
    assumeTrue(
        "Currently this test can only be run without the lucene test security policy in place",
        System.getProperty("java.security.manager", "").equals(""));
    
    assumeFalse("HDFS tests were disabled by -Dtests.disableHdfs",
        Boolean.parseBoolean(System.getProperty("tests.disableHdfs", "false")));
    
    assumeFalse("FIXME: This test does not work with Windows because of native library requirements", Constants.WINDOWS);
    assumeFalse("FIXME: This test fails under Java 8 due to the Saxon dependency - see SOLR-1301", Constants.JRE_IS_MINIMUM_JAVA8);
    assumeFalse("FIXME: This test fails under J9 due to the Saxon dependency - see SOLR-1301", System.getProperty("java.vm.info", "<?>").contains("IBM J9"));
    
    AbstractZkTestCase.SOLRHOME = solrHomeDirectory;
    FileUtils.copyDirectory(MINIMR_CONF_DIR, solrHomeDirectory);
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524723584/fstmerge_var1_7276167536589293518
    
    tempDir = dataDir + "/test-morphlines-" + System.currentTimeMillis();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524723584/fstmerge_base_7198057478508870816
    
    tempDir = TEMP_DIR + "/test-morphlines-" + System.currentTimeMillis();
=======
    File dataDir = createTempDir();
    tempDir = dataDir.getAbsolutePath();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524723584/fstmerge_var2_2319682789986060114
    new File(tempDir).mkdirs();
    FileUtils.copyFile(new File(RESOURCES_DIR + "/custom-mimetypes.xml"), new File(tempDir + "/custom-mimetypes.xml"));
    
    AbstractSolrMorphlineTestBase.setupMorphline(tempDir, "test-morphlines/solrCellDocumentTypes", true);
    
    System.setProperty("hadoop.log.dir", new File(solrHomeDirectory, "logs").getAbsolutePath());
    
    int taskTrackers = 1;
    int dataNodes = 2;
//    String proxyUser = System.getProperty("user.name");
//    String proxyGroup = "g";
//    StringBuilder sb = new StringBuilder();
//    sb.append("127.0.0.1,localhost");
//    for (InetAddress i : InetAddress.getAllByName(InetAddress.getLocalHost().getHostName())) {
//      sb.append(",").append(i.getCanonicalHostName());
//    }
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524723584/fstmerge_base_7198057478508870816
    createTempDir();
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524723584/fstmerge_var2_2319682789986060114
    new File(dataDir, "nm-local-dirs").mkdirs();
    
    System.setProperty("solr.hdfs.blockcache.enabled", "false");
    
    System.setProperty("test.build.dir", dataDir + File.separator + "hdfs" + File.separator + "test-build-dir");
    System.setProperty("test.build.data", dataDir + File.separator + "hdfs" + File.separator + "build");
    System.setProperty("test.cache.data", dataDir + File.separator + "hdfs" + File.separator + "cache");

    JobConf conf = new JobConf();
    conf.set("dfs.block.access.token.enable", "false");
    conf.set("dfs.permissions", "true");
    conf.set("hadoop.security.authentication", "simple");
    conf.set(YarnConfiguration.NM_LOCAL_DIRS, dataDir.getPath() + File.separator +  "nm-local-dirs");
    conf.set(YarnConfiguration.DEFAULT_NM_LOG_DIRS, dataDir + File.separator +  "nm-logs");
    conf.set("testWorkDir", dataDir.getPath() + File.separator +  "testWorkDir");

    dfsCluster = new MiniDFSCluster(conf, dataNodes, true, null);
    FileSystem fileSystem = dfsCluster.getFileSystem();
    fileSystem.mkdirs(new Path("/tmp"));
    fileSystem.mkdirs(new Path("/user"));
    fileSystem.mkdirs(new Path("/hadoop/mapred/system"));
    fileSystem.setPermission(new Path("/tmp"), FsPermission.valueOf("-rwxrwxrwx"));
    fileSystem.setPermission(new Path("/user"), FsPermission.valueOf("-rwxrwxrwx"));
    fileSystem.setPermission(new Path("/hadoop/mapred/system"), FsPermission.valueOf("-rwx------"));
    String nnURI = fileSystem.getUri().toString();
    int numDirs = 1;
    String[] racks = null;
    String[] hosts = null;

    mrCluster = new MiniMRCluster(0, 0, taskTrackers, nnURI, numDirs, racks, hosts, null, conf);
    ProxyUsers.refreshSuperUserGroupsConfiguration(conf);
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MorphlineBasicMiniMRTest.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ private static final File solrHomeDirectory = new File(dataDir, AbstractSolrMorphlineZkTestBase.class.getName()); ##FSTMerge## private static final File solrHomeDirectory = new File(TEMP_DIR, AbstractSolrMorphlineZkTestBase.class.getName()); ##FSTMerge## private static File solrHomeDirectory;
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/contrib/morphlines-core/src/test/org/apache/solr/morphlines/solr/AbstractSolrMorphlineZkTestBase.java
Conflict type: LineBasedMCFd
Conflict body: 
@Before
  public void setUp() throws Exception {
    super.setUp();
    collector = new Collector();
    
    if (EXTERNAL_SOLR_SERVER_URL != null) {
      //solrServer = new ConcurrentUpdateSolrServer(EXTERNAL_SOLR_SERVER_URL, 2, 2);
      //solrServer = new SafeConcurrentUpdateSolrServer(EXTERNAL_SOLR_SERVER_URL, 2, 2);
      solrServer = new HttpSolrServer(EXTERNAL_SOLR_SERVER_URL);
      ((HttpSolrServer)solrServer).setParser(new XMLResponseParser());
    } else {
      if (TEST_WITH_EMBEDDED_SOLR_SERVER) {
        solrServer = new EmbeddedTestSolrServer(h.getCoreContainer(), "");
      } else {
        throw new RuntimeException("Not yet implemented");
        //solrServer = new TestSolrServer(getSolrServer());
      }
    }

    int batchSize = SEQ_NUM2.incrementAndGet() % 2 == 0 ? 100 : 1; //SolrInspector.DEFAULT_SOLR_SERVER_BATCH_SIZE : 1;
    testServer = new SolrServerDocumentLoader(solrServer, batchSize);
    deleteAllDocuments();
    
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524725003/fstmerge_var1_4896605329854082604
    tempDir = new File(dataDir + "/test-morphlines-" + System.currentTimeMillis()).getAbsolutePath();
    new File(tempDir).mkdirs();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524725003/fstmerge_base_8687145671577110950
    tempDir = new File(TEMP_DIR + "/test-morphlines-" + System.currentTimeMillis()).getAbsolutePath();
    new File(tempDir).mkdirs();
=======
    tempDir = createTempDir().getAbsolutePath();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524725003/fstmerge_var2_598354621725062996
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/contrib/morphlines-core/src/test/org/apache/solr/morphlines/solr/AbstractSolrMorphlineTestBase.java
Conflict type: LineBasedMCFd
Conflict body: 
public static String setupSolrHome() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524725488/fstmerge_var1_1016966796313090830
    // make a solr home underneath the test's TEMP_DIR
    File tmpFile = File.createTempFile("test", "tmp", dataDir);
    tmpFile.delete();
    tmpFile.mkdir();
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524725488/fstmerge_base_4639633683463683193
    // make a solr home underneath the test's TEMP_DIR
    File tmpFile = File.createTempFile("test", "tmp", TEMP_DIR);
    tmpFile.delete();
    tmpFile.mkdir();
=======
    File tmpFile = createTempDir();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524725488/fstmerge_var2_2630046529735723398
    
    // make data and conf dirs
    new File(tmpFile + "/collection1", "data").mkdirs();
    File confDir = new File(tmpFile + "/collection1", "conf");
    confDir.mkdirs();
    
    // copy over configuration files
    FileUtils.copyFile(getFile("analysis-extras/solr/collection1/conf/solrconfig-icucollate.xml"), new File(confDir, "solrconfig.xml"));
    FileUtils.copyFile(getFile("analysis-extras/solr/collection1/conf/schema-icucollate-dv.xml"), new File(confDir, "schema.xml"));
    
    // generate custom collation rules (DIN 5007-2), saving to customrules.dat
    RuleBasedCollator baseCollator = (RuleBasedCollator) Collator.getInstance(new ULocale("de", "DE"));

    String DIN5007_2_tailorings =
      "& ae , a\u0308 & AE , A\u0308"+
      "& oe , o\u0308 & OE , O\u0308"+
      "& ue , u\u0308 & UE , u\u0308";

    RuleBasedCollator tailoredCollator = new RuleBasedCollator(baseCollator.getRules() + DIN5007_2_tailorings);
    String tailoredRules = tailoredCollator.getRules();
    FileOutputStream os = new FileOutputStream(new File(confDir, "customrules.dat"));
    IOUtils.write(tailoredRules, os, "UTF-8");
    os.close();

    return tmpFile.getAbsolutePath();
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/contrib/analysis-extras/src/test/org/apache/solr/schema/TestICUCollationFieldDocValues.java
Conflict type: LineBasedMCFd
Conflict body: 
public static String setupSolrHome() throws Exception {
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524725532/fstmerge_var1_952571543660311259
    // make a solr home underneath the test's TEMP_DIR
    File tmpFile = File.createTempFile("test", "tmp", dataDir);
    tmpFile.delete();
    tmpFile.mkdir();
    
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524725532/fstmerge_base_5801468650791101480
    // make a solr home underneath the test's TEMP_DIR
    File tmpFile = File.createTempFile("test", "tmp", TEMP_DIR);
    tmpFile.delete();
    tmpFile.mkdir();
    
=======
    String tmpFile = createTempDir().getAbsolutePath();
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420524725532/fstmerge_var2_472300704196008096
    // make data and conf dirs
    new File(tmpFile  + "/collection1", "data").mkdirs();
    File confDir = new File(tmpFile + "/collection1", "conf");
    confDir.mkdirs();
    
    // copy over configuration files
    FileUtils.copyFile(getFile("analysis-extras/solr/collection1/conf/solrconfig-icucollate.xml"), new File(confDir, "solrconfig.xml"));
    FileUtils.copyFile(getFile("analysis-extras/solr/collection1/conf/schema-icucollate.xml"), new File(confDir, "schema.xml"));
    
    // generate custom collation rules (DIN 5007-2), saving to customrules.dat
    RuleBasedCollator baseCollator = (RuleBasedCollator) Collator.getInstance(new ULocale("de", "DE"));

    String DIN5007_2_tailorings =
      "& ae , a\u0308 & AE , A\u0308"+
      "& oe , o\u0308 & OE , O\u0308"+
      "& ue , u\u0308 & UE , u\u0308";

    RuleBasedCollator tailoredCollator = new RuleBasedCollator(baseCollator.getRules() + DIN5007_2_tailorings);
    String tailoredRules = tailoredCollator.getRules();
    FileOutputStream os = new FileOutputStream(new File(confDir, "customrules.dat"));
    IOUtils.write(tailoredRules, os, "UTF-8");
    os.close();

    return tmpFile;
  }

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c100f_9af97/rev_c100f-9af97/solr/contrib/analysis-extras/src/test/org/apache/solr/schema/TestICUCollationField.java

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_e39d3_89b52/rev_e39d3-89b52.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_c780f_e39d3/rev_c780f-e39d3.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_d7df2_3b7a9/rev_d7df2-3b7a9.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_d6025_feca0/rev_d6025-feca0.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_54512_d6025/rev_54512-d6025.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1864b_b5712/rev_1864b-b5712.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_1e124_7eaed/rev_1e124-7eaed.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_35c74_a17b4/rev_35c74-a17b4.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_60120_b1f58/rev_60120-b1f58.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_cf21e_2ce5c/rev_cf21e-2ce5c.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_fac13_0f5c9/rev_fac13-0f5c9.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_bd95e_09fb2/rev_bd95e-09fb2.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_461d0_680fe/rev_461d0-680fe.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_f233d_a127d/rev_f233d-a127d.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_d8640_43d05/rev_d8640-43d05.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_373ca_5c1a5/rev_373ca-5c1a5.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_3b262_fdf29/rev_3b262-fdf29.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_58a75_3b262/rev_58a75-3b262.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_65765_aacfc/rev_65765-aacfc.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_44d12_29577/rev_44d12-29577.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_04986_44d12/rev_04986-44d12.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_5e7e8_46606/rev_5e7e8-46606.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_bcb44_4167b/rev_bcb44-4167b.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_862da_bcb44/rev_862da-bcb44.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_2cafb_63fc4/rev_2cafb-63fc4.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_b253a_88d95/rev_b253a-88d95.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_66c9b_587d7/rev_66c9b-587d7.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_5b90a_6136b/rev_5b90a-6136b.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_e4a19_b4995/rev_e4a19-b4995.revisions

==================================================================================================================
Revision: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4.revisions
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519044/fstmerge_var1_5081470812762085138
private Searcher getIndex (boolean even, boolean odd)
  throws IOException {
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);

    for (int i=0; i<data.length; ++i) {
      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {
        Document doc = new Document();
        doc.add (new Field ("tracer",   data[i][0], Field.Store.YES, Field.Index.NO));
        doc.add (new Field ("contents", data[i][1], Field.Store.NO, Field.Index.ANALYZED));
        if (data[i][2] != null) doc.add (new Field ("int",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][3] != null) doc.add (new Field ("float",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][4] != null) doc.add (new Field ("string",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][5] != null) doc.add (new Field ("custom",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][6] != null) doc.add (new Field ("i18n",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][7] != null) doc.add (new Field ("long",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][8] != null) doc.add (new Field ("double",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][9] != null) doc.add (new Field ("short",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][10] != null) doc.add (new Field ("byte",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][11] != null) doc.add (new Field ("parser",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));
        doc.setBoost(2);  // produce some scores above 1.0
        writer.addDocument (doc);
      }
    }
    IndexReader reader = writer.getReader();
    writer.close ();
    IndexSearcher s = new IndexSearcher (reader);
    s.setDefaultFieldSortScoring(true, true);
    return s;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519044/fstmerge_base_8319951735821317157
private Searcher getIndex (boolean even, boolean odd)
  throws IOException {
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));

    for (int i=0; i<data.length; ++i) {
      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {
        Document doc = new Document();
        doc.add (new Field ("tracer",   data[i][0], Field.Store.YES, Field.Index.NO));
        doc.add (new Field ("contents", data[i][1], Field.Store.NO, Field.Index.ANALYZED));
        if (data[i][2] != null) doc.add (new Field ("int",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][3] != null) doc.add (new Field ("float",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][4] != null) doc.add (new Field ("string",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][5] != null) doc.add (new Field ("custom",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][6] != null) doc.add (new Field ("i18n",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][7] != null) doc.add (new Field ("long",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][8] != null) doc.add (new Field ("double",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][9] != null) doc.add (new Field ("short",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][10] != null) doc.add (new Field ("byte",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));
        if (data[i][11] != null) doc.add (new Field ("parser",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));
        doc.setBoost(2);  // produce some scores above 1.0
        writer.addDocument (doc);
      }
    }
    IndexReader reader = writer.getReader();
    writer.close ();
    IndexSearcher s = new IndexSearcher (reader);
    s.setDefaultFieldSortScoring(true, true);
    return s;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519044/fstmerge_var2_5161220118024086893

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestSort.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519250/fstmerge_var1_1243413542892704850
public void setUp() throws Exception {
    super.setUp();
    Random random = newRandom();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
    Document doc = new Document();
    Field titleField = new Field("title", "some title", Field.Store.NO,
        Field.Index.ANALYZED);
    Field field = new Field(FN, "", Field.Store.NO,
        Field.Index.ANALYZED);
    Field footerField = new Field("footer", "a footer", Field.Store.NO,
        Field.Index.ANALYZED);
    doc.add(titleField);
    doc.add(field);
    doc.add(footerField);
    field.setValue("\uD866\uDF05abcdef");
    writer.addDocument(doc);
    field.setValue("\uD866\uDF06ghijkl");
    writer.addDocument(doc);
    // this sorts before the previous two in UTF-8/UTF-32, but after in UTF-16!!!
    field.setValue("\uFB94mnopqr"); 
    writer.addDocument(doc);
    field.setValue("\uFB95stuvwx"); // this one too.
    writer.addDocument(doc);
    field.setValue("a\uFFFCbc");
    writer.addDocument(doc);
    field.setValue("a\uFFFDbc");
    writer.addDocument(doc);
    field.setValue("a\uFFFEbc");
    writer.addDocument(doc);
    field.setValue("a\uFB94bc");
    writer.addDocument(doc);
    field.setValue("bacadaba");
    writer.addDocument(doc);
    field.setValue("\uFFFD");
    writer.addDocument(doc);
    field.setValue("\uFFFD\uD866\uDF05");
    writer.addDocument(doc);
    field.setValue("\uFFFD\uFFFD");
    writer.addDocument(doc);
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519250/fstmerge_base_7901148816357314309
public void setUp() throws Exception {
    super.setUp();
    Random random = newRandom();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    Field titleField = new Field("title", "some title", Field.Store.NO,
        Field.Index.ANALYZED);
    Field field = new Field(FN, "", Field.Store.NO,
        Field.Index.ANALYZED);
    Field footerField = new Field("footer", "a footer", Field.Store.NO,
        Field.Index.ANALYZED);
    doc.add(titleField);
    doc.add(field);
    doc.add(footerField);
    field.setValue("\uD866\uDF05abcdef");
    writer.addDocument(doc);
    field.setValue("\uD866\uDF06ghijkl");
    writer.addDocument(doc);
    // this sorts before the previous two in UTF-8/UTF-32, but after in UTF-16!!!
    field.setValue("\uFB94mnopqr"); 
    writer.addDocument(doc);
    field.setValue("\uFB95stuvwx"); // this one too.
    writer.addDocument(doc);
    field.setValue("a\uFFFCbc");
    writer.addDocument(doc);
    field.setValue("a\uFFFDbc");
    writer.addDocument(doc);
    field.setValue("a\uFFFEbc");
    writer.addDocument(doc);
    field.setValue("a\uFB94bc");
    writer.addDocument(doc);
    field.setValue("bacadaba");
    writer.addDocument(doc);
    field.setValue("\uFFFD");
    writer.addDocument(doc);
    field.setValue("\uFFFD\uD866\uDF05");
    writer.addDocument(doc);
    field.setValue("\uFFFD\uFFFD");
    writer.addDocument(doc);
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519250/fstmerge_var2_5675250745291473834

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestAutomatonQueryUnicode.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519284/fstmerge_var1_3064450451360865228
@Override
  protected void setUp() throws Exception {                  
    super.setUp();
    random = newRandom();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, new MockAnalyzer(MockTokenizer.SIMPLE, true));
    //writer.setUseCompoundFile(true);
    //writer.infoStream = System.out;
    for (int i = 0; i < 1000; i++) {
      Document doc = new Document();
      Field.TermVector termVector;
      int mod3 = i % 3;
      int mod2 = i % 2;
      if (mod2 == 0 && mod3 == 0){
        termVector = Field.TermVector.WITH_POSITIONS_OFFSETS;
      }
      else if (mod2 == 0){
        termVector = Field.TermVector.WITH_POSITIONS;
      }
      else if (mod3 == 0){
        termVector = Field.TermVector.WITH_OFFSETS;
      }
      else {
        termVector = Field.TermVector.YES;
      }
      doc.add(new Field("field", English.intToEnglish(i),
          Field.Store.YES, Field.Index.ANALYZED, termVector));
      //test no term vectors too
      doc.add(new Field("noTV", English.intToEnglish(i),
          Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519284/fstmerge_base_5511048265870700199
@Override
  protected void setUp() throws Exception {                  
    super.setUp();
    random = newRandom();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));
    //writer.setUseCompoundFile(true);
    //writer.infoStream = System.out;
    for (int i = 0; i < 1000; i++) {
      Document doc = new Document();
      Field.TermVector termVector;
      int mod3 = i % 3;
      int mod2 = i % 2;
      if (mod2 == 0 && mod3 == 0){
        termVector = Field.TermVector.WITH_POSITIONS_OFFSETS;
      }
      else if (mod2 == 0){
        termVector = Field.TermVector.WITH_POSITIONS;
      }
      else if (mod3 == 0){
        termVector = Field.TermVector.WITH_OFFSETS;
      }
      else {
        termVector = Field.TermVector.YES;
      }
      doc.add(new Field("field", English.intToEnglish(i),
          Field.Store.YES, Field.Index.ANALYZED, termVector));
      //test no term vectors too
      doc.add(new Field("noTV", English.intToEnglish(i),
          Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519284/fstmerge_var2_5650312842275532297

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestTermVectors.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519302/fstmerge_var1_1314645989987725146
public void testTermVectorsFieldOrder() throws IOException {
    Directory dir = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));
    Document doc = new Document();
    doc.add(new Field("c", "some content here", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    doc.add(new Field("a", "some content here", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    doc.add(new Field("b", "some content here", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    doc.add(new Field("x", "some content here", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);
    IndexReader reader = writer.getReader();
    writer.close();
    TermFreqVector[] v = reader.getTermFreqVectors(0);
    assertEquals(4, v.length);
    String[] expectedFields = new String[]{"a", "b", "c", "x"};
    int[] expectedPositions = new int[]{1, 2, 0};
    for(int i=0;i<v.length;i++) {
      TermPositionVector posVec = (TermPositionVector) v[i];
      assertEquals(expectedFields[i], posVec.getField());
      BytesRef[] terms = posVec.getTerms();
      assertEquals(3, terms.length);
      assertEquals("content", terms[0].utf8ToString());
      assertEquals("here", terms[1].utf8ToString());
      assertEquals("some", terms[2].utf8ToString());
      for(int j=0;j<3;j++) {
        int[] positions = posVec.getTermPositions(j);
        assertEquals(1, positions.length);
        assertEquals(expectedPositions[j], positions[0]);
      }
    }
    reader.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519302/fstmerge_base_4380877765494867042
public void testTermVectorsFieldOrder() throws IOException {
    Directory dir = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));
    Document doc = new Document();
    doc.add(new Field("c", "some content here", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    doc.add(new Field("a", "some content here", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    doc.add(new Field("b", "some content here", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    doc.add(new Field("x", "some content here", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);
    IndexReader reader = writer.getReader();
    writer.close();
    TermFreqVector[] v = reader.getTermFreqVectors(0);
    assertEquals(4, v.length);
    String[] expectedFields = new String[]{"a", "b", "c", "x"};
    int[] expectedPositions = new int[]{1, 2, 0};
    for(int i=0;i<v.length;i++) {
      TermPositionVector posVec = (TermPositionVector) v[i];
      assertEquals(expectedFields[i], posVec.getField());
      BytesRef[] terms = posVec.getTerms();
      assertEquals(3, terms.length);
      assertEquals("content", terms[0].utf8ToString());
      assertEquals("here", terms[1].utf8ToString());
      assertEquals("some", terms[2].utf8ToString());
      for(int j=0;j<3;j++) {
        int[] positions = posVec.getTermPositions(j);
        assertEquals(1, positions.length);
        assertEquals(expectedPositions[j], positions[0]);
      }
    }
    reader.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519302/fstmerge_var2_1980985464400353369

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestTermVectors.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519316/fstmerge_var1_4123168311968210269
public void testKnownSetOfDocuments() throws IOException {
    String test1 = "eating chocolate in a computer lab"; //6 terms
    String test2 = "computer in a computer lab"; //5 terms
    String test3 = "a chocolate lab grows old"; //5 terms
    String test4 = "eating chocolate with a chocolate lab in an old chocolate colored computer lab"; //13 terms
    Map<String,Integer> test4Map = new HashMap<String,Integer>();
    test4Map.put("chocolate", Integer.valueOf(3));
    test4Map.put("lab", Integer.valueOf(2));
    test4Map.put("eating", Integer.valueOf(1));
    test4Map.put("computer", Integer.valueOf(1));
    test4Map.put("with", Integer.valueOf(1));
    test4Map.put("a", Integer.valueOf(1));
    test4Map.put("colored", Integer.valueOf(1));
    test4Map.put("in", Integer.valueOf(1));
    test4Map.put("an", Integer.valueOf(1));
    test4Map.put("computer", Integer.valueOf(1));
    test4Map.put("old", Integer.valueOf(1));
    
    Document testDoc1 = new Document();
    setupDoc(testDoc1, test1);
    Document testDoc2 = new Document();
    setupDoc(testDoc2, test2);
    Document testDoc3 = new Document();
    setupDoc(testDoc3, test3);
    Document testDoc4 = new Document();
    setupDoc(testDoc4, test4);
    
    Directory dir = new MockRAMDirectory();
    
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true))
        .setOpenMode(OpenMode.CREATE));
    writer.addDocument(testDoc1);
    writer.addDocument(testDoc2);
    writer.addDocument(testDoc3);
    writer.addDocument(testDoc4);
    IndexReader reader = writer.getReader();
    writer.close();
    IndexSearcher knownSearcher = new IndexSearcher(reader);
    FieldsEnum fields = MultiFields.getFields(knownSearcher.reader).iterator();
    
    DocsEnum docs = null;
    while(fields.next() != null) {
      TermsEnum terms = fields.terms();
      while(terms.next() != null) {
        String text = terms.term().utf8ToString();
        docs = terms.docs(MultiFields.getDeletedDocs(knownSearcher.reader), docs);
        
        while (docs.nextDoc() != DocsEnum.NO_MORE_DOCS) {
          int docId = docs.docID();
          int freq = docs.freq();
          //System.out.println("Doc Id: " + docId + " freq " + freq);
          TermFreqVector vector = knownSearcher.reader.getTermFreqVector(docId, "field");
          //float tf = sim.tf(freq);
          //float idf = sim.idf(knownSearcher.docFreq(term), knownSearcher.maxDoc());
          //float qNorm = sim.queryNorm()
          //This is fine since we don't have stop words
          //float lNorm = sim.lengthNorm("field", vector.getTerms().length);
          //float coord = sim.coord()
          //System.out.println("TF: " + tf + " IDF: " + idf + " LenNorm: " + lNorm);
          assertTrue(vector != null);
          BytesRef[] vTerms = vector.getTerms();
          int [] freqs = vector.getTermFrequencies();
          for (int i = 0; i < vTerms.length; i++)
          {
            if (text.equals(vTerms[i].utf8ToString()))
            {
              assertTrue(freqs[i] == freq);
            }
          }
        }
      }
      //System.out.println("--------");
    }
    Query query = new TermQuery(new Term("field", "chocolate"));
    ScoreDoc[] hits = knownSearcher.search(query, null, 1000).scoreDocs;
    //doc 3 should be the first hit b/c it is the shortest match
    assertTrue(hits.length == 3);
    /*System.out.println("Hit 0: " + hits.id(0) + " Score: " + hits.score(0) + " String: " + hits.doc(0).toString());
      System.out.println("Explain: " + knownSearcher.explain(query, hits.id(0)));
      System.out.println("Hit 1: " + hits.id(1) + " Score: " + hits.score(1) + " String: " + hits.doc(1).toString());
      System.out.println("Explain: " + knownSearcher.explain(query, hits.id(1)));
      System.out.println("Hit 2: " + hits.id(2) + " Score: " + hits.score(2) + " String: " +  hits.doc(2).toString());
      System.out.println("Explain: " + knownSearcher.explain(query, hits.id(2)));*/
    assertTrue(hits[0].doc == 2);
    assertTrue(hits[1].doc == 3);
    assertTrue(hits[2].doc == 0);
    TermFreqVector vector = knownSearcher.reader.getTermFreqVector(hits[1].doc, "field");
    assertTrue(vector != null);
    //System.out.println("Vector: " + vector);
    BytesRef[] terms = vector.getTerms();
    int [] freqs = vector.getTermFrequencies();
    assertTrue(terms != null && terms.length == 10);
    for (int i = 0; i < terms.length; i++) {
      String term = terms[i].utf8ToString();
      //System.out.println("Term: " + term);
      int freq = freqs[i];
      assertTrue(test4.indexOf(term) != -1);
      Integer freqInt = test4Map.get(term);
      assertTrue(freqInt != null);
      assertTrue(freqInt.intValue() == freq);        
    }
    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());
    knownSearcher.reader.getTermFreqVector(hits[1].doc, mapper);
    SortedSet<TermVectorEntry> vectorEntrySet = mapper.getTermVectorEntrySet();
    assertTrue("mapper.getTermVectorEntrySet() Size: " + vectorEntrySet.size() + " is not: " + 10, vectorEntrySet.size() == 10);
    TermVectorEntry last = null;
    for (final TermVectorEntry tve : vectorEntrySet) {
      if (tve != null && last != null)
      {
        assertTrue("terms are not properly sorted", last.getFrequency() >= tve.getFrequency());
        Integer expectedFreq =  test4Map.get(tve.getTerm().utf8ToString());
        //we expect double the expectedFreq, since there are two fields with the exact same text and we are collapsing all fields
        assertTrue("Frequency is not correct:", tve.getFrequency() == 2*expectedFreq.intValue());
      }
      last = tve;
      
    }
    
    FieldSortedTermVectorMapper fieldMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());
    knownSearcher.reader.getTermFreqVector(hits[1].doc, fieldMapper);
    Map<String,SortedSet<TermVectorEntry>> map = fieldMapper.getFieldToTerms();
    assertTrue("map Size: " + map.size() + " is not: " + 2, map.size() == 2);
    vectorEntrySet = map.get("field");
    assertTrue("vectorEntrySet is null and it shouldn't be", vectorEntrySet != null);
    assertTrue("vectorEntrySet Size: " + vectorEntrySet.size() + " is not: " + 10, vectorEntrySet.size() == 10);
    knownSearcher.close();
    reader.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519316/fstmerge_base_4618877751101657880
public void testKnownSetOfDocuments() throws IOException {
    String test1 = "eating chocolate in a computer lab"; //6 terms
    String test2 = "computer in a computer lab"; //5 terms
    String test3 = "a chocolate lab grows old"; //5 terms
    String test4 = "eating chocolate with a chocolate lab in an old chocolate colored computer lab"; //13 terms
    Map<String,Integer> test4Map = new HashMap<String,Integer>();
    test4Map.put("chocolate", Integer.valueOf(3));
    test4Map.put("lab", Integer.valueOf(2));
    test4Map.put("eating", Integer.valueOf(1));
    test4Map.put("computer", Integer.valueOf(1));
    test4Map.put("with", Integer.valueOf(1));
    test4Map.put("a", Integer.valueOf(1));
    test4Map.put("colored", Integer.valueOf(1));
    test4Map.put("in", Integer.valueOf(1));
    test4Map.put("an", Integer.valueOf(1));
    test4Map.put("computer", Integer.valueOf(1));
    test4Map.put("old", Integer.valueOf(1));
    
    Document testDoc1 = new Document();
    setupDoc(testDoc1, test1);
    Document testDoc2 = new Document();
    setupDoc(testDoc2, test2);
    Document testDoc3 = new Document();
    setupDoc(testDoc3, test3);
    Document testDoc4 = new Document();
    setupDoc(testDoc4, test4);
    
    Directory dir = new MockRAMDirectory();
    
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true))
        .setOpenMode(OpenMode.CREATE));
    writer.addDocument(testDoc1);
    writer.addDocument(testDoc2);
    writer.addDocument(testDoc3);
    writer.addDocument(testDoc4);
    IndexReader reader = writer.getReader();
    writer.close();
    IndexSearcher knownSearcher = new IndexSearcher(reader);
    FieldsEnum fields = MultiFields.getFields(knownSearcher.reader).iterator();
    
    DocsEnum docs = null;
    while(fields.next() != null) {
      TermsEnum terms = fields.terms();
      while(terms.next() != null) {
        String text = terms.term().utf8ToString();
        docs = terms.docs(MultiFields.getDeletedDocs(knownSearcher.reader), docs);
        
        while (docs.nextDoc() != DocsEnum.NO_MORE_DOCS) {
          int docId = docs.docID();
          int freq = docs.freq();
          //System.out.println("Doc Id: " + docId + " freq " + freq);
          TermFreqVector vector = knownSearcher.reader.getTermFreqVector(docId, "field");
          //float tf = sim.tf(freq);
          //float idf = sim.idf(knownSearcher.docFreq(term), knownSearcher.maxDoc());
          //float qNorm = sim.queryNorm()
          //This is fine since we don't have stop words
          //float lNorm = sim.lengthNorm("field", vector.getTerms().length);
          //float coord = sim.coord()
          //System.out.println("TF: " + tf + " IDF: " + idf + " LenNorm: " + lNorm);
          assertTrue(vector != null);
          BytesRef[] vTerms = vector.getTerms();
          int [] freqs = vector.getTermFrequencies();
          for (int i = 0; i < vTerms.length; i++)
          {
            if (text.equals(vTerms[i].utf8ToString()))
            {
              assertTrue(freqs[i] == freq);
            }
          }
        }
      }
      //System.out.println("--------");
    }
    Query query = new TermQuery(new Term("field", "chocolate"));
    ScoreDoc[] hits = knownSearcher.search(query, null, 1000).scoreDocs;
    //doc 3 should be the first hit b/c it is the shortest match
    assertTrue(hits.length == 3);
    /*System.out.println("Hit 0: " + hits.id(0) + " Score: " + hits.score(0) + " String: " + hits.doc(0).toString());
      System.out.println("Explain: " + knownSearcher.explain(query, hits.id(0)));
      System.out.println("Hit 1: " + hits.id(1) + " Score: " + hits.score(1) + " String: " + hits.doc(1).toString());
      System.out.println("Explain: " + knownSearcher.explain(query, hits.id(1)));
      System.out.println("Hit 2: " + hits.id(2) + " Score: " + hits.score(2) + " String: " +  hits.doc(2).toString());
      System.out.println("Explain: " + knownSearcher.explain(query, hits.id(2)));*/
    assertTrue(hits[0].doc == 2);
    assertTrue(hits[1].doc == 3);
    assertTrue(hits[2].doc == 0);
    TermFreqVector vector = knownSearcher.reader.getTermFreqVector(hits[1].doc, "field");
    assertTrue(vector != null);
    //System.out.println("Vector: " + vector);
    BytesRef[] terms = vector.getTerms();
    int [] freqs = vector.getTermFrequencies();
    assertTrue(terms != null && terms.length == 10);
    for (int i = 0; i < terms.length; i++) {
      String term = terms[i].utf8ToString();
      //System.out.println("Term: " + term);
      int freq = freqs[i];
      assertTrue(test4.indexOf(term) != -1);
      Integer freqInt = test4Map.get(term);
      assertTrue(freqInt != null);
      assertTrue(freqInt.intValue() == freq);        
    }
    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());
    knownSearcher.reader.getTermFreqVector(hits[1].doc, mapper);
    SortedSet<TermVectorEntry> vectorEntrySet = mapper.getTermVectorEntrySet();
    assertTrue("mapper.getTermVectorEntrySet() Size: " + vectorEntrySet.size() + " is not: " + 10, vectorEntrySet.size() == 10);
    TermVectorEntry last = null;
    for (final TermVectorEntry tve : vectorEntrySet) {
      if (tve != null && last != null)
      {
        assertTrue("terms are not properly sorted", last.getFrequency() >= tve.getFrequency());
        Integer expectedFreq =  test4Map.get(tve.getTerm().utf8ToString());
        //we expect double the expectedFreq, since there are two fields with the exact same text and we are collapsing all fields
        assertTrue("Frequency is not correct:", tve.getFrequency() == 2*expectedFreq.intValue());
      }
      last = tve;
      
    }
    
    FieldSortedTermVectorMapper fieldMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());
    knownSearcher.reader.getTermFreqVector(hits[1].doc, fieldMapper);
    Map<String,SortedSet<TermVectorEntry>> map = fieldMapper.getFieldToTerms();
    assertTrue("map Size: " + map.size() + " is not: " + 2, map.size() == 2);
    vectorEntrySet = map.get("field");
    assertTrue("vectorEntrySet is null and it shouldn't be", vectorEntrySet != null);
    assertTrue("vectorEntrySet Size: " + vectorEntrySet.size() + " is not: " + 10, vectorEntrySet.size() == 10);
    knownSearcher.close();
    reader.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519316/fstmerge_var2_4046456345936970118

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestTermVectors.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519330/fstmerge_var1_8961660450089710351
public void testRareVectors() throws IOException {
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true))
        .setOpenMode(OpenMode.CREATE));
    for (int i = 0; i < 100; i++) {
      Document doc = new Document();
      doc.add(new Field("field", English.intToEnglish(i),
                        Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.NO));
      writer.addDocument(doc);
    }
    for(int i=0;i<10;i++) {
      Document doc = new Document();
      doc.add(new Field("field", English.intToEnglish(100+i),
                        Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
      writer.addDocument(doc);
    }

    IndexReader reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);

    Query query = new TermQuery(new Term("field", "hundred"));
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(10, hits.length);
    for (int i = 0; i < hits.length; i++) {
      TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);
      assertTrue(vector != null);
      assertTrue(vector.length == 1);
    }
    reader.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519330/fstmerge_base_1146648071810422038
public void testRareVectors() throws IOException {
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true))
        .setOpenMode(OpenMode.CREATE));
    for (int i = 0; i < 100; i++) {
      Document doc = new Document();
      doc.add(new Field("field", English.intToEnglish(i),
                        Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.NO));
      writer.addDocument(doc);
    }
    for(int i=0;i<10;i++) {
      Document doc = new Document();
      doc.add(new Field("field", English.intToEnglish(100+i),
                        Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
      writer.addDocument(doc);
    }

    IndexReader reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);

    Query query = new TermQuery(new Term("field", "hundred"));
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(10, hits.length);
    for (int i = 0; i < hits.length; i++) {
      TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);
      assertTrue(vector != null);
      assertTrue(vector.length == 1);
    }
    reader.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519330/fstmerge_var2_3134352976102673404

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestTermVectors.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519335/fstmerge_var1_6059201704467211172
public void testMixedVectrosVectors() throws IOException {
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, 
        new MockAnalyzer(MockTokenizer.SIMPLE, true)).setOpenMode(OpenMode.CREATE));
    Document doc = new Document();
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.NO));
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.YES));
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS));
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_OFFSETS));
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);
    IndexReader reader = writer.getReader();
    writer.close();

    searcher = new IndexSearcher(reader);

    Query query = new TermQuery(new Term("field", "one"));
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);

    TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[0].doc);
    assertTrue(vector != null);
    assertTrue(vector.length == 1);
    TermPositionVector tfv = (TermPositionVector) vector[0];
    assertTrue(tfv.getField().equals("field"));
    BytesRef[] terms = tfv.getTerms();
    assertEquals(1, terms.length);
    assertEquals(terms[0].utf8ToString(), "one");
    assertEquals(5, tfv.getTermFrequencies()[0]);

    int[] positions = tfv.getTermPositions(0);
    assertEquals(5, positions.length);
    for(int i=0;i<5;i++)
      assertEquals(i, positions[i]);
    TermVectorOffsetInfo[] offsets = tfv.getOffsets(0);
    assertEquals(5, offsets.length);
    for(int i=0;i<5;i++) {
      assertEquals(4*i, offsets[i].getStartOffset());
      assertEquals(4*i+3, offsets[i].getEndOffset());
    }
    reader.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519335/fstmerge_base_7901100524038243556
public void testMixedVectrosVectors() throws IOException {
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, 
        new MockAnalyzer(MockTokenizer.SIMPLE, true)).setOpenMode(OpenMode.CREATE));
    Document doc = new Document();
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.NO));
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.YES));
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS));
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_OFFSETS));
    doc.add(new Field("field", "one",
                      Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
    writer.addDocument(doc);
    IndexReader reader = writer.getReader();
    writer.close();

    searcher = new IndexSearcher(reader);

    Query query = new TermQuery(new Term("field", "one"));
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);

    TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[0].doc);
    assertTrue(vector != null);
    assertTrue(vector.length == 1);
    TermPositionVector tfv = (TermPositionVector) vector[0];
    assertTrue(tfv.getField().equals("field"));
    BytesRef[] terms = tfv.getTerms();
    assertEquals(1, terms.length);
    assertEquals(terms[0].utf8ToString(), "one");
    assertEquals(5, tfv.getTermFrequencies()[0]);

    int[] positions = tfv.getTermPositions(0);
    assertEquals(5, positions.length);
    for(int i=0;i<5;i++)
      assertEquals(i, positions[i]);
    TermVectorOffsetInfo[] offsets = tfv.getOffsets(0);
    assertEquals(5, offsets.length);
    for(int i=0;i<5;i++) {
      assertEquals(4*i, offsets[i].getStartOffset());
      assertEquals(4*i+3, offsets[i].getEndOffset());
    }
    reader.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519335/fstmerge_var2_3456336086735073048

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestTermVectors.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519350/fstmerge_var1_7751703676121066054
@Override
  protected void setUp() throws Exception {
    super.setUp();
    Random rand = newRandom();
    index = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, index);
    RandomGen random = new RandomGen(rand);
    for (int i = 0; i < INDEX_SIZE; ++i) { // don't decrease; if to low the
                                           // problem doesn't show up
      Document doc = new Document();
      if ((i % 5) != 0) { // some documents must not have an entry in the first
                          // sort field
        doc.add(new Field("publicationDate_", random.getLuceneDate(),
            Field.Store.YES, Field.Index.NOT_ANALYZED));
      }
      if ((i % 7) == 0) { // some documents to match the query (see below)
        doc.add(new Field("content", "test", Field.Store.YES,
            Field.Index.ANALYZED));
      }
      // every document has a defined 'mandant' field
      doc.add(new Field("mandant", Integer.toString(i % 3), Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
    query = new TermQuery(new Term("content", "test"));
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519350/fstmerge_base_6736405056845788448
@Override
  protected void setUp() throws Exception {
    super.setUp();
    Random rand = newRandom();
    index = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, index, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    RandomGen random = new RandomGen(rand);
    for (int i = 0; i < INDEX_SIZE; ++i) { // don't decrease; if to low the
                                           // problem doesn't show up
      Document doc = new Document();
      if ((i % 5) != 0) { // some documents must not have an entry in the first
                          // sort field
        doc.add(new Field("publicationDate_", random.getLuceneDate(),
            Field.Store.YES, Field.Index.NOT_ANALYZED));
      }
      if ((i % 7) == 0) { // some documents to match the query (see below)
        doc.add(new Field("content", "test", Field.Store.YES,
            Field.Index.ANALYZED));
      }
      // every document has a defined 'mandant' field
      doc.add(new Field("mandant", Integer.toString(i % 3), Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
    query = new TermQuery(new Term("content", "test"));
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519350/fstmerge_var2_7292562362125412936

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestCustomSearcherSort.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519411/fstmerge_var1_1668553698201511102
public void testPhrasePrefix() throws IOException {
    MockRAMDirectory indexStore = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);
    add("blueberry pie", writer);
    add("blueberry strudel", writer);
    add("blueberry pizza", writer);
    add("blueberry chewing gum", writer);
    add("bluebird pizza", writer);
    add("bluebird foobar pizza", writer);
    add("piccadilly circus", writer);
    
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // search for "blueberry pi*":
    MultiPhraseQuery query1 = new MultiPhraseQuery();
    // search for "strawberry pi*":
    MultiPhraseQuery query2 = new MultiPhraseQuery();
    query1.add(new Term("body", "blueberry"));
    query2.add(new Term("body", "strawberry"));
    
    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();
    
    // this TermEnum gives "piccadilly", "pie" and "pizza".
    String prefix = "pi";
    TermsEnum te = MultiFields.getFields(reader).terms("body").iterator();
    te.seek(new BytesRef(prefix));
    do {
      String s = te.term().utf8ToString();
      if (s.startsWith(prefix)) {
        termsWithPrefix.add(new Term("body", s));
      } else {
        break;
      }
    } while (te.next() != null);
    
    query1.add(termsWithPrefix.toArray(new Term[0]));
    assertEquals("body:\"blueberry (piccadilly pie pizza)\"", query1.toString());
    query2.add(termsWithPrefix.toArray(new Term[0]));
    assertEquals("body:\"strawberry (piccadilly pie pizza)\"", query2
        .toString());
    
    ScoreDoc[] result;
    result = searcher.search(query1, null, 1000).scoreDocs;
    assertEquals(2, result.length);
    result = searcher.search(query2, null, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    // search for "blue* pizza":
    MultiPhraseQuery query3 = new MultiPhraseQuery();
    termsWithPrefix.clear();
    prefix = "blue";
    te.seek(new BytesRef(prefix));
    
    do {
      if (te.term().utf8ToString().startsWith(prefix)) {
        termsWithPrefix.add(new Term("body", te.term().utf8ToString()));
      }
    } while (te.next() != null);
    
    query3.add(termsWithPrefix.toArray(new Term[0]));
    query3.add(new Term("body", "pizza"));
    
    result = searcher.search(query3, null, 1000).scoreDocs;
    assertEquals(2, result.length); // blueberry pizza, bluebird pizza
    assertEquals("body:\"(blueberry bluebird) pizza\"", query3.toString());
    
    // test slop:
    query3.setSlop(1);
    result = searcher.search(query3, null, 1000).scoreDocs;
    
    // just make sure no exc:
    searcher.explain(query3, 0);
    
    assertEquals(3, result.length); // blueberry pizza, bluebird pizza, bluebird
                                    // foobar pizza
    
    MultiPhraseQuery query4 = new MultiPhraseQuery();
    try {
      query4.add(new Term("field1", "foo"));
      query4.add(new Term("field2", "foobar"));
      fail();
    } catch (IllegalArgumentException e) {
      // okay, all terms must belong to the same field
    }
    
    writer.close();
    searcher.close();
    reader.close();
    indexStore.close();
    
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519411/fstmerge_base_6570243081198637794
public void testPhrasePrefix() throws IOException {
    MockRAMDirectory indexStore = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    add("blueberry pie", writer);
    add("blueberry strudel", writer);
    add("blueberry pizza", writer);
    add("blueberry chewing gum", writer);
    add("bluebird pizza", writer);
    add("bluebird foobar pizza", writer);
    add("piccadilly circus", writer);
    
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // search for "blueberry pi*":
    MultiPhraseQuery query1 = new MultiPhraseQuery();
    // search for "strawberry pi*":
    MultiPhraseQuery query2 = new MultiPhraseQuery();
    query1.add(new Term("body", "blueberry"));
    query2.add(new Term("body", "strawberry"));
    
    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();
    
    // this TermEnum gives "piccadilly", "pie" and "pizza".
    String prefix = "pi";
    TermsEnum te = MultiFields.getFields(reader).terms("body").iterator();
    te.seek(new BytesRef(prefix));
    do {
      String s = te.term().utf8ToString();
      if (s.startsWith(prefix)) {
        termsWithPrefix.add(new Term("body", s));
      } else {
        break;
      }
    } while (te.next() != null);
    
    query1.add(termsWithPrefix.toArray(new Term[0]));
    assertEquals("body:\"blueberry (piccadilly pie pizza)\"", query1.toString());
    query2.add(termsWithPrefix.toArray(new Term[0]));
    assertEquals("body:\"strawberry (piccadilly pie pizza)\"", query2
        .toString());
    
    ScoreDoc[] result;
    result = searcher.search(query1, null, 1000).scoreDocs;
    assertEquals(2, result.length);
    result = searcher.search(query2, null, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    // search for "blue* pizza":
    MultiPhraseQuery query3 = new MultiPhraseQuery();
    termsWithPrefix.clear();
    prefix = "blue";
    te.seek(new BytesRef(prefix));
    
    do {
      if (te.term().utf8ToString().startsWith(prefix)) {
        termsWithPrefix.add(new Term("body", te.term().utf8ToString()));
      }
    } while (te.next() != null);
    
    query3.add(termsWithPrefix.toArray(new Term[0]));
    query3.add(new Term("body", "pizza"));
    
    result = searcher.search(query3, null, 1000).scoreDocs;
    assertEquals(2, result.length); // blueberry pizza, bluebird pizza
    assertEquals("body:\"(blueberry bluebird) pizza\"", query3.toString());
    
    // test slop:
    query3.setSlop(1);
    result = searcher.search(query3, null, 1000).scoreDocs;
    
    // just make sure no exc:
    searcher.explain(query3, 0);
    
    assertEquals(3, result.length); // blueberry pizza, bluebird pizza, bluebird
                                    // foobar pizza
    
    MultiPhraseQuery query4 = new MultiPhraseQuery();
    try {
      query4.add(new Term("field1", "foo"));
      query4.add(new Term("field2", "foobar"));
      fail();
    } catch (IllegalArgumentException e) {
      // okay, all terms must belong to the same field
    }
    
    writer.close();
    searcher.close();
    reader.close();
    indexStore.close();
    
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519411/fstmerge_var2_1211513375082912155

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519422/fstmerge_var1_3398356056282022622
public void testBooleanQueryContainingSingleTermPrefixQuery()
      throws IOException {
    // this tests against bug 33161 (now fixed)
    // In order to cause the bug, the outer query must have more than one term
    // and all terms required.
    // The contained PhraseMultiQuery must contain exactly one term array.
    
    MockRAMDirectory indexStore = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);
    add("blueberry pie", writer);
    add("blueberry chewing gum", writer);
    add("blue raspberry pie", writer);
    
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    // This query will be equivalent to +body:pie +body:"blue*"
    BooleanQuery q = new BooleanQuery();
    q.add(new TermQuery(new Term("body", "pie")), BooleanClause.Occur.MUST);
    
    MultiPhraseQuery trouble = new MultiPhraseQuery();
    trouble.add(new Term[] {new Term("body", "blueberry"),
        new Term("body", "blue")});
    q.add(trouble, BooleanClause.Occur.MUST);
    
    // exception will be thrown here without fix
    ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
    
    assertEquals("Wrong number of hits", 2, hits.length);
    
    // just make sure no exc:
    searcher.explain(q, 0);
    
    writer.close();
    searcher.close();
    reader.close();
    indexStore.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519422/fstmerge_base_4226578322927152144
public void testBooleanQueryContainingSingleTermPrefixQuery()
      throws IOException {
    // this tests against bug 33161 (now fixed)
    // In order to cause the bug, the outer query must have more than one term
    // and all terms required.
    // The contained PhraseMultiQuery must contain exactly one term array.
    
    MockRAMDirectory indexStore = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    add("blueberry pie", writer);
    add("blueberry chewing gum", writer);
    add("blue raspberry pie", writer);
    
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    // This query will be equivalent to +body:pie +body:"blue*"
    BooleanQuery q = new BooleanQuery();
    q.add(new TermQuery(new Term("body", "pie")), BooleanClause.Occur.MUST);
    
    MultiPhraseQuery trouble = new MultiPhraseQuery();
    trouble.add(new Term[] {new Term("body", "blueberry"),
        new Term("body", "blue")});
    q.add(trouble, BooleanClause.Occur.MUST);
    
    // exception will be thrown here without fix
    ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
    
    assertEquals("Wrong number of hits", 2, hits.length);
    
    // just make sure no exc:
    searcher.explain(q, 0);
    
    writer.close();
    searcher.close();
    reader.close();
    indexStore.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519422/fstmerge_var2_2404848540421674196

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519427/fstmerge_var1_473813092684440586
public void testPhrasePrefixWithBooleanQuery() throws IOException {
    MockRAMDirectory indexStore = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);
    add("This is a test", "object", writer);
    add("a note", "note", writer);
    
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // This query will be equivalent to +type:note +body:"a t*"
    BooleanQuery q = new BooleanQuery();
    q.add(new TermQuery(new Term("type", "note")), BooleanClause.Occur.MUST);
    
    MultiPhraseQuery trouble = new MultiPhraseQuery();
    trouble.add(new Term("body", "a"));
    trouble
        .add(new Term[] {new Term("body", "test"), new Term("body", "this")});
    q.add(trouble, BooleanClause.Occur.MUST);
    
    // exception will be thrown here without fix for #35626:
    ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
    assertEquals("Wrong number of hits", 0, hits.length);
    writer.close();
    searcher.close();
    reader.close();
    indexStore.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519427/fstmerge_base_6516183712514790926
public void testPhrasePrefixWithBooleanQuery() throws IOException {
    MockRAMDirectory indexStore = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    add("This is a test", "object", writer);
    add("a note", "note", writer);
    
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // This query will be equivalent to +type:note +body:"a t*"
    BooleanQuery q = new BooleanQuery();
    q.add(new TermQuery(new Term("type", "note")), BooleanClause.Occur.MUST);
    
    MultiPhraseQuery trouble = new MultiPhraseQuery();
    trouble.add(new Term("body", "a"));
    trouble
        .add(new Term[] {new Term("body", "test"), new Term("body", "this")});
    q.add(trouble, BooleanClause.Occur.MUST);
    
    // exception will be thrown here without fix for #35626:
    ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
    assertEquals("Wrong number of hits", 0, hits.length);
    writer.close();
    searcher.close();
    reader.close();
    indexStore.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519427/fstmerge_var2_5997368529320342817

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519432/fstmerge_var1_3751029237570974684
public void testNoDocs() throws Exception {
    MockRAMDirectory indexStore = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);
    add("a note", "note", writer);
    
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    MultiPhraseQuery q = new MultiPhraseQuery();
    q.add(new Term("body", "a"));
    q.add(new Term[] {new Term("body", "nope"), new Term("body", "nope")});
    assertEquals("Wrong number of hits", 0,
        searcher.search(q, null, 1).totalHits);
    
    // just make sure no exc:
    searcher.explain(q, 0);
    
    writer.close();
    searcher.close();
    reader.close();
    indexStore.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519432/fstmerge_base_4196282423014452879
public void testNoDocs() throws Exception {
    MockRAMDirectory indexStore = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    add("a note", "note", writer);
    
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    MultiPhraseQuery q = new MultiPhraseQuery();
    q.add(new Term("body", "a"));
    q.add(new Term[] {new Term("body", "nope"), new Term("body", "nope")});
    assertEquals("Wrong number of hits", 0,
        searcher.search(q, null, 1).totalHits);
    
    // just make sure no exc:
    searcher.explain(q, 0);
    
    writer.close();
    searcher.close();
    reader.close();
    indexStore.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519432/fstmerge_var2_1137713953858950857

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519497/fstmerge_var1_4469997975745777037
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    for (int i = 0; i < values.length; i++) {
      Document doc = new Document();
      doc
          .add(new Field(FIELD, values[i], Field.Store.YES,
              Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    indexReader = writer.getReader();
    writer.close();
    indexSearcher = new IndexSearcher(indexReader);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519497/fstmerge_base_2103513928580936579
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < values.length; i++) {
      Document doc = new Document();
      doc
          .add(new Field(FIELD, values[i], Field.Store.YES,
              Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    indexReader = writer.getReader();
    writer.close();
    indexSearcher = new IndexSearcher(indexReader);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519497/fstmerge_var2_6783320891613216910

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestTermScorer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519532/fstmerge_var1_2034910321378139397
public void testNot() throws Exception {
    RAMDirectory store = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), store);

    Document d1 = new Document();
    d1.add(new Field("field", "a b", Field.Store.YES, Field.Index.ANALYZED));

    writer.addDocument(d1);
    IndexReader reader = writer.getReader();

    Searcher searcher = new IndexSearcher(reader);
      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, "field", new MockAnalyzer());
    Query query = parser.parse("a NOT b");
    //System.out.println(query);
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    writer.close();
    searcher.close();
    reader.close();
    store.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519532/fstmerge_base_4371597970530869556
public void testNot() throws Exception {
    RAMDirectory store = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), store, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));

    Document d1 = new Document();
    d1.add(new Field("field", "a b", Field.Store.YES, Field.Index.ANALYZED));

    writer.addDocument(d1);
    IndexReader reader = writer.getReader();

    Searcher searcher = new IndexSearcher(reader);
      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, "field", new MockAnalyzer());
    Query query = parser.parse("a NOT b");
    //System.out.println(query);
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    writer.close();
    searcher.close();
    reader.close();
    store.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519532/fstmerge_var2_2616142313708302258

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestNot.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519811/fstmerge_var1_2660932210299868895
public void testMultiValuedNRQ() throws Exception {
    final Random rnd = newRandom();

    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rnd, directory);
    
    DecimalFormat format = new DecimalFormat("00000000000", new DecimalFormatSymbols(Locale.US));
    
    for (int l=0; l<5000*_TestUtil.getRandomMultiplier(); l++) {
      Document doc = new Document();
      for (int m=0, c=rnd.nextInt(10); m<=c; m++) {
        int value = rnd.nextInt(Integer.MAX_VALUE);
        doc.add(new Field("asc", format.format(value), Field.Store.NO, Field.Index.NOT_ANALYZED));
        doc.add(new NumericField("trie", Field.Store.NO, true).setIntValue(value));
      }
      writer.addDocument(doc);
    }
    IndexReader reader = writer.getReader();
    writer.close();
    
    Searcher searcher=new IndexSearcher(reader);
    for (int i=0; i<50*_TestUtil.getRandomMultiplier(); i++) {
      int lower=rnd.nextInt(Integer.MAX_VALUE);
      int upper=rnd.nextInt(Integer.MAX_VALUE);
      if (lower>upper) {
        int a=lower; lower=upper; upper=a;
      }
      TermRangeQuery cq=new TermRangeQuery("asc", format.format(lower), format.format(upper), true, true);
      NumericRangeQuery<Integer> tq=NumericRangeQuery.newIntRange("trie", lower, upper, true, true);
      TopDocs trTopDocs = searcher.search(cq, 1);
      TopDocs nrTopDocs = searcher.search(tq, 1);
      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", trTopDocs.totalHits, nrTopDocs.totalHits );
    }
    searcher.close();
    reader.close();
    directory.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519811/fstmerge_base_1744262962037425620
public void testMultiValuedNRQ() throws Exception {
    final Random rnd = newRandom();

    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rnd, directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    
    DecimalFormat format = new DecimalFormat("00000000000", new DecimalFormatSymbols(Locale.US));
    
    for (int l=0; l<5000*_TestUtil.getRandomMultiplier(); l++) {
      Document doc = new Document();
      for (int m=0, c=rnd.nextInt(10); m<=c; m++) {
        int value = rnd.nextInt(Integer.MAX_VALUE);
        doc.add(new Field("asc", format.format(value), Field.Store.NO, Field.Index.NOT_ANALYZED));
        doc.add(new NumericField("trie", Field.Store.NO, true).setIntValue(value));
      }
      writer.addDocument(doc);
    }
    IndexReader reader = writer.getReader();
    writer.close();
    
    Searcher searcher=new IndexSearcher(reader);
    for (int i=0; i<50*_TestUtil.getRandomMultiplier(); i++) {
      int lower=rnd.nextInt(Integer.MAX_VALUE);
      int upper=rnd.nextInt(Integer.MAX_VALUE);
      if (lower>upper) {
        int a=lower; lower=upper; upper=a;
      }
      TermRangeQuery cq=new TermRangeQuery("asc", format.format(lower), format.format(upper), true, true);
      NumericRangeQuery<Integer> tq=NumericRangeQuery.newIntRange("trie", lower, upper, true, true);
      TopDocs trTopDocs = searcher.search(cq, 1);
      TopDocs nrTopDocs = searcher.search(tq, 1);
      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", trTopDocs.totalHits, nrTopDocs.totalHits );
    }
    searcher.close();
    reader.close();
    directory.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519811/fstmerge_var2_1287658125270813352

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestMultiValuedNumericRangeQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519823/fstmerge_var1_6036028867712530419
public void testNullDocIdSet() throws Exception {
    // Tests that if a Filter produces a null DocIdSet, which is given to
    // IndexSearcher, everything works fine. This came up in LUCENE-1754.
    Directory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
    Document doc = new Document();
    doc.add(new Field("c", "val", Store.NO, Index.NOT_ANALYZED_NO_NORMS));
    writer.addDocument(doc);
    IndexReader reader = writer.getReader();
    writer.close();
    
    // First verify the document is searchable.
    IndexSearcher searcher = new IndexSearcher(reader);
    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);
    
    // Now search w/ a Filter which returns a null DocIdSet
    Filter f = new Filter() {
      @Override
      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {
        return null;
      }
    };
    
    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);
    searcher.close();
    reader.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519823/fstmerge_base_7723384255179038048
public void testNullDocIdSet() throws Exception {
    // Tests that if a Filter produces a null DocIdSet, which is given to
    // IndexSearcher, everything works fine. This came up in LUCENE-1754.
    Directory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    doc.add(new Field("c", "val", Store.NO, Index.NOT_ANALYZED_NO_NORMS));
    writer.addDocument(doc);
    IndexReader reader = writer.getReader();
    writer.close();
    
    // First verify the document is searchable.
    IndexSearcher searcher = new IndexSearcher(reader);
    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);
    
    // Now search w/ a Filter which returns a null DocIdSet
    Filter f = new Filter() {
      @Override
      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {
        return null;
      }
    };
    
    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);
    searcher.close();
    reader.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519823/fstmerge_var2_6938985079109372728

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestDocIdSet.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519831/fstmerge_var1_1499506415639636582
public void testMethod() throws Exception {
    RAMDirectory directory = new RAMDirectory();

    String[] values = new String[] { "1", "2", "3", "4" };

    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    for (int i = 0; i < values.length; i++) {
      Document doc = new Document();
      doc.add(new Field(FIELD, values[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    IndexReader ir = writer.getReader();
    writer.close();

    BooleanQuery booleanQuery1 = new BooleanQuery();
    booleanQuery1.add(new TermQuery(new Term(FIELD, "1")), BooleanClause.Occur.SHOULD);
    booleanQuery1.add(new TermQuery(new Term(FIELD, "2")), BooleanClause.Occur.SHOULD);

    BooleanQuery query = new BooleanQuery();
    query.add(booleanQuery1, BooleanClause.Occur.MUST);
    query.add(new TermQuery(new Term(FIELD, "9")), BooleanClause.Occur.MUST_NOT);

    IndexSearcher indexSearcher = new IndexSearcher(ir);
    ScoreDoc[] hits = indexSearcher.search(query, null, 1000).scoreDocs;
    assertEquals("Number of matched documents", 2, hits.length);
    ir.close();
    directory.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519831/fstmerge_base_4687444649827118401
public void testMethod() throws Exception {
    RAMDirectory directory = new RAMDirectory();

    String[] values = new String[] { "1", "2", "3", "4" };

    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < values.length; i++) {
      Document doc = new Document();
      doc.add(new Field(FIELD, values[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    IndexReader ir = writer.getReader();
    writer.close();

    BooleanQuery booleanQuery1 = new BooleanQuery();
    booleanQuery1.add(new TermQuery(new Term(FIELD, "1")), BooleanClause.Occur.SHOULD);
    booleanQuery1.add(new TermQuery(new Term(FIELD, "2")), BooleanClause.Occur.SHOULD);

    BooleanQuery query = new BooleanQuery();
    query.add(booleanQuery1, BooleanClause.Occur.MUST);
    query.add(new TermQuery(new Term(FIELD, "9")), BooleanClause.Occur.MUST_NOT);

    IndexSearcher indexSearcher = new IndexSearcher(ir);
    ScoreDoc[] hits = indexSearcher.search(query, null, 1000).scoreDocs;
    assertEquals("Number of matched documents", 2, hits.length);
    ir.close();
    directory.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519831/fstmerge_var2_6580191086525433814

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestBooleanScorer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519838/fstmerge_var1_2813574526871496828
@Override
  protected void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    dir = new MockRAMDirectory();
    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.
    // currently, this means 'empty tokens' arent created/tested in the enumeration:
    // <mikemccand> it's like having a big hairy scary monster in the basement but being upset that it doesn't have fangs
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));
    
    Document doc = new Document();
    Field field = new Field("field", "", Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field);
    List<String> terms = new ArrayList<String>();
    for (int i = 0; i < 2000*_TestUtil.getRandomMultiplier(); i++) {
      String s = _TestUtil.randomUnicodeString(random);
      field.setValue(s);
      terms.add(s);
      writer.addDocument(doc);
    }

    if (VERBOSE) {
      // utf16 order
      Collections.sort(terms);
      System.out.println("UTF16 order:");
      for(String s : terms) {
        System.out.println("  " + UnicodeUtil.toHexString(s));
      }
    }
    
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519838/fstmerge_base_7915616822564814871
@Override
  protected void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    dir = new MockRAMDirectory();
    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.
    // currently, this means 'empty tokens' arent created/tested in the enumeration:
    // <mikemccand> it's like having a big hairy scary monster in the basement but being upset that it doesn't have fangs
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new IndexWriterConfig(TEST_VERSION_CURRENT,
                                                                                        new MockAnalyzer(MockTokenizer.KEYWORD, false)));
    
    Document doc = new Document();
    Field field = new Field("field", "", Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field);

    for (int i = 0; i < 2000*_TestUtil.getRandomMultiplier(); i++) {
      field.setValue(_TestUtil.randomUnicodeString(random));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519838/fstmerge_var2_5753435353591401024

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestRegexpRandom2.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519865/fstmerge_var1_4768510852688488687
public void testRegexps() throws Exception {

    for (int i = 0; i < 1000*_TestUtil.getRandomMultiplier(); i++) {
      String reg = AutomatonTestUtil.randomRegexp(random).toString();
      assertSame(reg);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519865/fstmerge_base_8657130750154895277
public void testRegexps() throws Exception {
      for (int i = 0; i < 1000*_TestUtil.getRandomMultiplier(); i++)
        assertSame(AutomatonTestUtil.randomRegexp(random).toString());
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519865/fstmerge_var2_2137594580508042321

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestRegexpRandom2.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519874/fstmerge_var1_1142327528739187066
public void testBasic() throws Exception {
    Directory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
    Document doc = new Document();
    doc.add(new Field("field", "value", Store.NO, Index.ANALYZED));
    writer.addDocument(doc);
    IndexReader reader = writer.getReader();
    writer.close();

    TermQuery termQuery = new TermQuery(new Term("field", "value"));

    // should not throw exception with primitive query
    QueryWrapperFilter qwf = new QueryWrapperFilter(termQuery);

    IndexSearcher searcher = new IndexSearcher(reader);
    TopDocs hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
    assertEquals(1, hits.totalHits);
    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
    assertEquals(1, hits.totalHits);

    // should not throw exception with complex primitive query
    BooleanQuery booleanQuery = new BooleanQuery();
    booleanQuery.add(termQuery, Occur.MUST);
    booleanQuery.add(new TermQuery(new Term("field", "missing")),
        Occur.MUST_NOT);
    qwf = new QueryWrapperFilter(termQuery);

    hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
    assertEquals(1, hits.totalHits);
    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
    assertEquals(1, hits.totalHits);

    // should not throw exception with non primitive Query (doesn't implement
    // Query#createWeight)
    qwf = new QueryWrapperFilter(new FuzzyQuery(new Term("field", "valu")));

    hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
    assertEquals(1, hits.totalHits);
    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
    assertEquals(1, hits.totalHits);

    // test a query with no hits
    termQuery = new TermQuery(new Term("field", "not_exist"));
    qwf = new QueryWrapperFilter(termQuery);
    hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
    assertEquals(0, hits.totalHits);
    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
    assertEquals(0, hits.totalHits);
    searcher.close();
    reader.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519874/fstmerge_base_1937100103768788876
public void testBasic() throws Exception {
    Directory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    doc.add(new Field("field", "value", Store.NO, Index.ANALYZED));
    writer.addDocument(doc);
    IndexReader reader = writer.getReader();
    writer.close();

    TermQuery termQuery = new TermQuery(new Term("field", "value"));

    // should not throw exception with primitive query
    QueryWrapperFilter qwf = new QueryWrapperFilter(termQuery);

    IndexSearcher searcher = new IndexSearcher(reader);
    TopDocs hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
    assertEquals(1, hits.totalHits);
    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
    assertEquals(1, hits.totalHits);

    // should not throw exception with complex primitive query
    BooleanQuery booleanQuery = new BooleanQuery();
    booleanQuery.add(termQuery, Occur.MUST);
    booleanQuery.add(new TermQuery(new Term("field", "missing")),
        Occur.MUST_NOT);
    qwf = new QueryWrapperFilter(termQuery);

    hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
    assertEquals(1, hits.totalHits);
    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
    assertEquals(1, hits.totalHits);

    // should not throw exception with non primitive Query (doesn't implement
    // Query#createWeight)
    qwf = new QueryWrapperFilter(new FuzzyQuery(new Term("field", "valu")));

    hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
    assertEquals(1, hits.totalHits);
    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
    assertEquals(1, hits.totalHits);

    // test a query with no hits
    termQuery = new TermQuery(new Term("field", "not_exist"));
    qwf = new QueryWrapperFilter(termQuery);
    hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
    assertEquals(0, hits.totalHits);
    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
    assertEquals(0, hits.totalHits);
    searcher.close();
    reader.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583519874/fstmerge_var2_3941046009084704254

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520005/fstmerge_var1_8242950149069271743
@Override
  protected void setUp() throws Exception {
    super.setUp();
    String[] data = new String[] { "A 1 2 3 4 5 6", "Z       4 5 6", null,
        "B   2   4 5 6", "Y     3   5 6", null, "C     3     6",
        "X       4 5 6" };

    small = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, small, new MockAnalyzer(MockTokenizer.WHITESPACE, false));

    for (int i = 0; i < data.length; i++) {
      Document doc = new Document();
      doc.add(new Field("id", String.valueOf(i), Field.Store.YES,
          Field.Index.NOT_ANALYZED));// Field.Keyword("id",String.valueOf(i)));
      doc
          .add(new Field("all", "all", Field.Store.YES,
              Field.Index.NOT_ANALYZED));// Field.Keyword("all","all"));
      if (null != data[i]) {
        doc.add(new Field("data", data[i], Field.Store.YES,
            Field.Index.ANALYZED));// Field.Text("data",data[i]));
      }
      writer.addDocument(doc);
    }

    reader = writer.getReader();
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520005/fstmerge_base_6977081568593775939
@Override
  protected void setUp() throws Exception {
    super.setUp();
    String[] data = new String[] { "A 1 2 3 4 5 6", "Z       4 5 6", null,
        "B   2   4 5 6", "Y     3   5 6", null, "C     3     6",
        "X       4 5 6" };

    small = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, small, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));

    for (int i = 0; i < data.length; i++) {
      Document doc = new Document();
      doc.add(new Field("id", String.valueOf(i), Field.Store.YES,
          Field.Index.NOT_ANALYZED));// Field.Keyword("id",String.valueOf(i)));
      doc
          .add(new Field("all", "all", Field.Store.YES,
              Field.Index.NOT_ANALYZED));// Field.Keyword("all","all"));
      if (null != data[i]) {
        doc.add(new Field("data", data[i], Field.Store.YES,
            Field.Index.ANALYZED));// Field.Text("data",data[i]));
      }
      writer.addDocument(doc);
    }

    reader = writer.getReader();
    writer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520005/fstmerge_var2_2525003656574665707

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestMultiTermConstantScore.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520076/fstmerge_var1_8833196698798277872
public void testFarsi() throws Exception {

    /* build an index */
    RAMDirectory farsiIndex = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, farsiIndex, new MockAnalyzer(MockTokenizer.SIMPLE, true));
    Document doc = new Document();
    doc.add(new Field("content", "\u0633\u0627\u0628", Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc
        .add(new Field("body", "body", Field.Store.YES,
            Field.Index.NOT_ANALYZED));
    writer.addDocument(doc);

    IndexReader reader = writer.getReader();
    writer.close();

    IndexSearcher search = new IndexSearcher(reader);

    // Neither Java 1.4.2 nor 1.5.0 has Farsi Locale collation available in
    // RuleBasedCollator. However, the Arabic Locale seems to order the Farsi
    // characters properly.
    Collator c = Collator.getInstance(new Locale("ar"));

    // Unicode order would include U+0633 in [ U+062F - U+0698 ], but Farsi
    // orders the U+0698 character before the U+0633 character, so the single
    // index Term below should NOT be returned by a ConstantScoreRangeQuery
    // with a Farsi Collator (or an Arabic one for the case when Farsi is
    // not supported).
    ScoreDoc[] result = search.search(csrq("content", "\u062F", "\u0698", T, T,
        c), null, 1000).scoreDocs;
    assertEquals("The index Term should not be included.", 0, result.length);

    result = search.search(csrq("content", "\u0633", "\u0638", T, T, c), null,
        1000).scoreDocs;
    assertEquals("The index Term should be included.", 1, result.length);
    search.close();
    reader.close();
    farsiIndex.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520076/fstmerge_base_5310564030269592914
public void testFarsi() throws Exception {

    /* build an index */
    RAMDirectory farsiIndex = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, farsiIndex, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));
    Document doc = new Document();
    doc.add(new Field("content", "\u0633\u0627\u0628", Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc
        .add(new Field("body", "body", Field.Store.YES,
            Field.Index.NOT_ANALYZED));
    writer.addDocument(doc);

    IndexReader reader = writer.getReader();
    writer.close();

    IndexSearcher search = new IndexSearcher(reader);

    // Neither Java 1.4.2 nor 1.5.0 has Farsi Locale collation available in
    // RuleBasedCollator. However, the Arabic Locale seems to order the Farsi
    // characters properly.
    Collator c = Collator.getInstance(new Locale("ar"));

    // Unicode order would include U+0633 in [ U+062F - U+0698 ], but Farsi
    // orders the U+0698 character before the U+0633 character, so the single
    // index Term below should NOT be returned by a ConstantScoreRangeQuery
    // with a Farsi Collator (or an Arabic one for the case when Farsi is
    // not supported).
    ScoreDoc[] result = search.search(csrq("content", "\u062F", "\u0698", T, T,
        c), null, 1000).scoreDocs;
    assertEquals("The index Term should not be included.", 0, result.length);

    result = search.search(csrq("content", "\u0633", "\u0638", T, T, c), null,
        1000).scoreDocs;
    assertEquals("The index Term should be included.", 1, result.length);
    search.close();
    reader.close();
    farsiIndex.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520076/fstmerge_var2_2390380043422956079

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestMultiTermConstantScore.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520081/fstmerge_var1_2609863552456745159
public void testDanish() throws Exception {

    /* build an index */
    RAMDirectory danishIndex = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, danishIndex, new MockAnalyzer(MockTokenizer.SIMPLE, true));

    // Danish collation orders the words below in the given order
    // (example taken from TestSort.testInternationalSort() ).
    String[] words = { "H\u00D8T", "H\u00C5T", "MAND" };
    for (int docnum = 0 ; docnum < words.length ; ++docnum) {   
      Document doc = new Document();
      doc.add(new Field("content", words[docnum], 
                        Field.Store.YES, Field.Index.NOT_ANALYZED));
      doc.add(new Field("body", "body",
                        Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    IndexReader reader = writer.getReader();
    writer.close();

    IndexSearcher search = new IndexSearcher(reader);

    Collator c = Collator.getInstance(new Locale("da", "dk"));

    // Unicode order would not include "H\u00C5T" in [ "H\u00D8T", "MAND" ],
    // but Danish collation does.
    ScoreDoc[] result = search.search
      (csrq("content", "H\u00D8T", "MAND", F, F, c), null, 1000).scoreDocs;
    assertEquals("The index Term should be included.", 1, result.length);

    result = search.search
      (csrq("content", "H\u00C5T", "MAND", F, F, c), null, 1000).scoreDocs;
    assertEquals("The index Term should not be included.", 0, result.length);
    search.close();
    reader.close();
    danishIndex.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520081/fstmerge_base_9050153375677947925
public void testDanish() throws Exception {

    /* build an index */
    RAMDirectory danishIndex = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, danishIndex, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));

    // Danish collation orders the words below in the given order
    // (example taken from TestSort.testInternationalSort() ).
    String[] words = { "H\u00D8T", "H\u00C5T", "MAND" };
    for (int docnum = 0 ; docnum < words.length ; ++docnum) {   
      Document doc = new Document();
      doc.add(new Field("content", words[docnum], 
                        Field.Store.YES, Field.Index.NOT_ANALYZED));
      doc.add(new Field("body", "body",
                        Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    IndexReader reader = writer.getReader();
    writer.close();

    IndexSearcher search = new IndexSearcher(reader);

    Collator c = Collator.getInstance(new Locale("da", "dk"));

    // Unicode order would not include "H\u00C5T" in [ "H\u00D8T", "MAND" ],
    // but Danish collation does.
    ScoreDoc[] result = search.search
      (csrq("content", "H\u00D8T", "MAND", F, F, c), null, 1000).scoreDocs;
    assertEquals("The index Term should be included.", 1, result.length);

    result = search.search
      (csrq("content", "H\u00C5T", "MAND", F, F, c), null, 1000).scoreDocs;
    assertEquals("The index Term should not be included.", 0, result.length);
    search.close();
    reader.close();
    danishIndex.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520081/fstmerge_var2_2870039351843702143

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestMultiTermConstantScore.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520086/fstmerge_var1_3011544196951232606
@Override
  protected void setUp() throws Exception {
    super.setUp();
    // Create an index writer.
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);

    // oldest doc:
    // Add the first document.  text = "Document 1"  dateTime = Oct 10 03:25:22 EDT 2007
    writer.addDocument(createDocument("Document 1", 1192001122000L));
    // Add the second document.  text = "Document 2"  dateTime = Oct 10 03:25:26 EDT 2007 
    writer.addDocument(createDocument("Document 2", 1192001126000L));
    // Add the third document.  text = "Document 3"  dateTime = Oct 11 07:12:13 EDT 2007 
    writer.addDocument(createDocument("Document 3", 1192101133000L));
    // Add the fourth document.  text = "Document 4"  dateTime = Oct 11 08:02:09 EDT 2007
    writer.addDocument(createDocument("Document 4", 1192104129000L));
    // latest doc:
    // Add the fifth document.  text = "Document 5"  dateTime = Oct 12 13:25:43 EDT 2007
    writer.addDocument(createDocument("Document 5", 1192209943000L));

    reader = writer.getReader();
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520086/fstmerge_base_920993889037776313
@Override
  protected void setUp() throws Exception {
    super.setUp();
    // Create an index writer.
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));

    // oldest doc:
    // Add the first document.  text = "Document 1"  dateTime = Oct 10 03:25:22 EDT 2007
    writer.addDocument(createDocument("Document 1", 1192001122000L));
    // Add the second document.  text = "Document 2"  dateTime = Oct 10 03:25:26 EDT 2007 
    writer.addDocument(createDocument("Document 2", 1192001126000L));
    // Add the third document.  text = "Document 3"  dateTime = Oct 11 07:12:13 EDT 2007 
    writer.addDocument(createDocument("Document 3", 1192101133000L));
    // Add the fourth document.  text = "Document 4"  dateTime = Oct 11 08:02:09 EDT 2007
    writer.addDocument(createDocument("Document 4", 1192104129000L));
    // latest doc:
    // Add the fifth document.  text = "Document 5"  dateTime = Oct 12 13:25:43 EDT 2007
    writer.addDocument(createDocument("Document 5", 1192209943000L));

    reader = writer.getReader();
    writer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520086/fstmerge_var2_6766595280518164325

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestDateSort.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520164/fstmerge_var1_4898590491185193528
@Override
  protected void setUp() throws Exception {
    super.setUp();
    
    // populate an index with 30 documents, this should be enough for the test.
    // The documents have no content - the test uses MatchAllDocsQuery().
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
    for (int i = 0; i < 30; i++) {
      writer.addDocument(new Document());
    }
    reader = writer.getReader();
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520164/fstmerge_base_3484890592186320288
@Override
  protected void setUp() throws Exception {
    super.setUp();
    
    // populate an index with 30 documents, this should be enough for the test.
    // The documents have no content - the test uses MatchAllDocsQuery().
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < 30; i++) {
      writer.addDocument(new Document());
    }
    reader = writer.getReader();
    writer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520164/fstmerge_var2_5880697423426700529

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestTopDocsCollector.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520355/fstmerge_var1_1936590560736287353
@Override
  protected void setUp() throws Exception {
    super.setUp();
    final String docText[] = {
        "docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero",
        "one blah three",
        "one foo three multiOne",
        "one foobar three multiThree",
        "blueberry pancakes",
        "blueberry pie",
        "blueberry strudel",
        "blueberry pizza",
    };
    directory = new RAMDirectory();
    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory);
    
    for (int i=0; i<N_DOCS; i++) {
      add(docText[i%docText.length], iw);
    }
    reader = iw.getReader();
    iw.close();
    searcher = new IndexSearcher(reader);

    String qtxt = "one";
    // start from 1, so that the 0th doc never matches
    for (int i = 1; i < docText.length; i++) {
      qtxt += ' ' + docText[i]; // large query so that search will be longer
    }
    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());
    query = queryParser.parse(qtxt);
    
    // warm the searcher
    searcher.search(query, null, 1000);

  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520355/fstmerge_base_6389724869300696629
@Override
  protected void setUp() throws Exception {
    super.setUp();
    final String docText[] = {
        "docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero",
        "one blah three",
        "one foo three multiOne",
        "one foobar three multiThree",
        "blueberry pancakes",
        "blueberry pie",
        "blueberry strudel",
        "blueberry pizza",
    };
    directory = new RAMDirectory();
    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    
    for (int i=0; i<N_DOCS; i++) {
      add(docText[i%docText.length], iw);
    }
    reader = iw.getReader();
    iw.close();
    searcher = new IndexSearcher(reader);

    String qtxt = "one";
    // start from 1, so that the 0th doc never matches
    for (int i = 1; i < docText.length; i++) {
      qtxt += ' ' + docText[i]; // large query so that search will be longer
    }
    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());
    query = queryParser.parse(qtxt);
    
    // warm the searcher
    searcher.search(query, null, 1000);

  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520355/fstmerge_var2_3542484670897522110

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520462/fstmerge_var1_5805752999748863984
@BeforeClass
  public static void beforeClass() throws Exception {
    directory = new RAMDirectory();
    Random random = newStaticRandom(TestNumericRangeQuery32.class);
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
    
    NumericField
      field8 = new NumericField("field8", 8, Field.Store.YES, true),
      field4 = new NumericField("field4", 4, Field.Store.YES, true),
      field2 = new NumericField("field2", 2, Field.Store.YES, true),
      fieldNoTrie = new NumericField("field"+Integer.MAX_VALUE, Integer.MAX_VALUE, Field.Store.YES, true),
      ascfield8 = new NumericField("ascfield8", 8, Field.Store.NO, true),
      ascfield4 = new NumericField("ascfield4", 4, Field.Store.NO, true),
      ascfield2 = new NumericField("ascfield2", 2, Field.Store.NO, true);
    
    Document doc = new Document();
    // add fields, that have a distance to test general functionality
    doc.add(field8); doc.add(field4); doc.add(field2); doc.add(fieldNoTrie);
    // add ascending fields with a distance of 1, beginning at -noDocs/2 to test the correct splitting of range and inclusive/exclusive
    doc.add(ascfield8); doc.add(ascfield4); doc.add(ascfield2);
    
    // Add a series of noDocs docs with increasing int values
    for (int l=0; l<noDocs; l++) {
      int val=distance*l+startOffset;
      field8.setIntValue(val);
      field4.setIntValue(val);
      field2.setIntValue(val);
      fieldNoTrie.setIntValue(val);

      val=l-(noDocs/2);
      ascfield8.setIntValue(val);
      ascfield4.setIntValue(val);
      ascfield2.setIntValue(val);
      writer.addDocument(doc);
    }
  
    reader = writer.getReader();
    searcher=new IndexSearcher(reader);
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520462/fstmerge_base_4075691822174785306
@BeforeClass
  public static void beforeClass() throws Exception {
    directory = new RAMDirectory();
    Random random = newStaticRandom(TestNumericRangeQuery32.class);
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    
    NumericField
      field8 = new NumericField("field8", 8, Field.Store.YES, true),
      field4 = new NumericField("field4", 4, Field.Store.YES, true),
      field2 = new NumericField("field2", 2, Field.Store.YES, true),
      fieldNoTrie = new NumericField("field"+Integer.MAX_VALUE, Integer.MAX_VALUE, Field.Store.YES, true),
      ascfield8 = new NumericField("ascfield8", 8, Field.Store.NO, true),
      ascfield4 = new NumericField("ascfield4", 4, Field.Store.NO, true),
      ascfield2 = new NumericField("ascfield2", 2, Field.Store.NO, true);
    
    Document doc = new Document();
    // add fields, that have a distance to test general functionality
    doc.add(field8); doc.add(field4); doc.add(field2); doc.add(fieldNoTrie);
    // add ascending fields with a distance of 1, beginning at -noDocs/2 to test the correct splitting of range and inclusive/exclusive
    doc.add(ascfield8); doc.add(ascfield4); doc.add(ascfield2);
    
    // Add a series of noDocs docs with increasing int values
    for (int l=0; l<noDocs; l++) {
      int val=distance*l+startOffset;
      field8.setIntValue(val);
      field4.setIntValue(val);
      field2.setIntValue(val);
      fieldNoTrie.setIntValue(val);

      val=l-(noDocs/2);
      ascfield8.setIntValue(val);
      ascfield4.setIntValue(val);
      ascfield2.setIntValue(val);
      writer.addDocument(doc);
    }
  
    reader = writer.getReader();
    searcher=new IndexSearcher(reader);
    writer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520462/fstmerge_var2_6820885724555380718

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520980/fstmerge_var1_1669864534818656820
public void testNullOrSubScorer() throws Throwable {
    Directory dir = new MockRAMDirectory();
    RandomIndexWriter w = new RandomIndexWriter(newRandom(), dir);
    Document doc = new Document();
    doc.add(new Field("field", "a b c d", Field.Store.NO, Field.Index.ANALYZED));
    w.addDocument(doc);
    IndexReader r = w.getReader();
    IndexSearcher s = new IndexSearcher(r);
    BooleanQuery q = new BooleanQuery();
    q.add(new TermQuery(new Term("field", "a")), BooleanClause.Occur.SHOULD);

    // PhraseQuery w/ no terms added returns a null scorer
    PhraseQuery pq = new PhraseQuery();
    q.add(pq, BooleanClause.Occur.SHOULD);
    assertEquals(1, s.search(q, 10).totalHits);

    // A required clause which returns null scorer should return null scorer to
    // IndexSearcher.
    q = new BooleanQuery();
    pq = new PhraseQuery();
    q.add(new TermQuery(new Term("field", "a")), BooleanClause.Occur.SHOULD);
    q.add(pq, BooleanClause.Occur.MUST);
    assertEquals(0, s.search(q, 10).totalHits);

    DisjunctionMaxQuery dmq = new DisjunctionMaxQuery(1.0f);
    dmq.add(new TermQuery(new Term("field", "a")));
    dmq.add(pq);
    assertEquals(1, s.search(dmq, 10).totalHits);
    
    r.close();
    w.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520980/fstmerge_base_400779127382323460
public void testNullOrSubScorer() throws Throwable {
    Directory dir = new MockRAMDirectory();
    RandomIndexWriter w = new RandomIndexWriter(newRandom(), dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    doc.add(new Field("field", "a b c d", Field.Store.NO, Field.Index.ANALYZED));
    w.addDocument(doc);
    IndexReader r = w.getReader();
    IndexSearcher s = new IndexSearcher(r);
    BooleanQuery q = new BooleanQuery();
    q.add(new TermQuery(new Term("field", "a")), BooleanClause.Occur.SHOULD);

    // PhraseQuery w/ no terms added returns a null scorer
    PhraseQuery pq = new PhraseQuery();
    q.add(pq, BooleanClause.Occur.SHOULD);
    assertEquals(1, s.search(q, 10).totalHits);

    // A required clause which returns null scorer should return null scorer to
    // IndexSearcher.
    q = new BooleanQuery();
    pq = new PhraseQuery();
    q.add(new TermQuery(new Term("field", "a")), BooleanClause.Occur.SHOULD);
    q.add(pq, BooleanClause.Occur.MUST);
    assertEquals(0, s.search(q, 10).totalHits);

    DisjunctionMaxQuery dmq = new DisjunctionMaxQuery(1.0f);
    dmq.add(new TermQuery(new Term("field", "a")));
    dmq.add(pq);
    assertEquals(1, s.search(dmq, 10).totalHits);
    
    r.close();
    w.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583520980/fstmerge_var2_7919070324099756085

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestBooleanQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521035/fstmerge_var1_856603597850371124
public void assertFromTestData(int codePointTable[]) throws Exception {
    InputStream stream = getClass().getResourceAsStream("fuzzyTestData.txt");
    BufferedReader reader = new BufferedReader(new InputStreamReader(stream, "UTF-8"));
    
    int bits = Integer.parseInt(reader.readLine());
    int terms = (int) Math.pow(2, bits);
    
    RAMDirectory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));
    
    Document doc = new Document();
    Field field = new Field("field", "", Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field);
    
    for (int i = 0; i < terms; i++) {
      field.setValue(mapInt(codePointTable, i));
      writer.addDocument(doc);
    }   
    
    IndexReader r = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(r);
    writer.close();
    String line;
    while ((line = reader.readLine()) != null) {
      String params[] = line.split(",");
      String query = mapInt(codePointTable, Integer.parseInt(params[0]));
      int prefix = Integer.parseInt(params[1]);
      int pqSize = Integer.parseInt(params[2]);
      float minScore = Float.parseFloat(params[3]);
      FuzzyQuery q = new FuzzyQuery(new Term("field", query), minScore, prefix);
      q.setRewriteMethod(new MultiTermQuery.TopTermsBoostOnlyBooleanQueryRewrite(pqSize));
      int expectedResults = Integer.parseInt(reader.readLine());
      TopDocs docs = searcher.search(q, expectedResults);
      assertEquals(expectedResults, docs.totalHits);
      for (int i = 0; i < expectedResults; i++) {
        String scoreDoc[] = reader.readLine().split(",");
        assertEquals(Integer.parseInt(scoreDoc[0]), docs.scoreDocs[i].doc);
        assertEquals(Float.parseFloat(scoreDoc[1]), docs.scoreDocs[i].score, epsilon);
      }
    }
    searcher.close();
    r.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521035/fstmerge_base_4168533958973306630
public void assertFromTestData(int codePointTable[]) throws Exception {
    InputStream stream = getClass().getResourceAsStream("fuzzyTestData.txt");
    BufferedReader reader = new BufferedReader(new InputStreamReader(stream, "UTF-8"));
    
    int bits = Integer.parseInt(reader.readLine());
    int terms = (int) Math.pow(2, bits);
    
    RAMDirectory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false)));
    
    Document doc = new Document();
    Field field = new Field("field", "", Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field);
    
    for (int i = 0; i < terms; i++) {
      field.setValue(mapInt(codePointTable, i));
      writer.addDocument(doc);
    }   
    
    IndexReader r = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(r);
    writer.close();
    String line;
    while ((line = reader.readLine()) != null) {
      String params[] = line.split(",");
      String query = mapInt(codePointTable, Integer.parseInt(params[0]));
      int prefix = Integer.parseInt(params[1]);
      int pqSize = Integer.parseInt(params[2]);
      float minScore = Float.parseFloat(params[3]);
      FuzzyQuery q = new FuzzyQuery(new Term("field", query), minScore, prefix);
      q.setRewriteMethod(new MultiTermQuery.TopTermsBoostOnlyBooleanQueryRewrite(pqSize));
      int expectedResults = Integer.parseInt(reader.readLine());
      TopDocs docs = searcher.search(q, expectedResults);
      assertEquals(expectedResults, docs.totalHits);
      for (int i = 0; i < expectedResults; i++) {
        String scoreDoc[] = reader.readLine().split(",");
        assertEquals(Integer.parseInt(scoreDoc[0]), docs.scoreDocs[i].doc);
        assertEquals(Float.parseFloat(scoreDoc[1]), docs.scoreDocs[i].score, epsilon);
      }
    }
    searcher.close();
    r.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521035/fstmerge_var2_7327909283738711281

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestFuzzyQuery2.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521063/fstmerge_var1_8442402024582591594
public void testFarsi() throws Exception {
    
    /* build an index */
    RAMDirectory farsiIndex = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, farsiIndex);
    Document doc = new Document();
    doc.add(new Field("content", "\u0633\u0627\u0628", Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc
        .add(new Field("body", "body", Field.Store.YES,
            Field.Index.NOT_ANALYZED));
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    writer.close();
    
    IndexSearcher search = new IndexSearcher(reader);
    Query q = new TermQuery(new Term("body", "body"));
    
    // Neither Java 1.4.2 nor 1.5.0 has Farsi Locale collation available in
    // RuleBasedCollator. However, the Arabic Locale seems to order the Farsi
    // characters properly.
    Collator collator = Collator.getInstance(new Locale("ar"));
    
    // Unicode order would include U+0633 in [ U+062F - U+0698 ], but Farsi
    // orders the U+0698 character before the U+0633 character, so the single
    // index Term below should NOT be returned by a TermRangeFilter with a Farsi
    // Collator (or an Arabic one for the case when Farsi is not supported).
    int numHits = search.search(q, new TermRangeFilter("content", "\u062F",
        "\u0698", T, T, collator), 1000).totalHits;
    assertEquals("The index Term should not be included.", 0, numHits);
    
    numHits = search.search(q, new TermRangeFilter("content", "\u0633",
        "\u0638", T, T, collator), 1000).totalHits;
    assertEquals("The index Term should be included.", 1, numHits);
    search.close();
    reader.close();
    farsiIndex.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521063/fstmerge_base_6121100235001623737
public void testFarsi() throws Exception {
    
    /* build an index */
    RAMDirectory farsiIndex = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, farsiIndex, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    doc.add(new Field("content", "\u0633\u0627\u0628", Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc
        .add(new Field("body", "body", Field.Store.YES,
            Field.Index.NOT_ANALYZED));
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    writer.close();
    
    IndexSearcher search = new IndexSearcher(reader);
    Query q = new TermQuery(new Term("body", "body"));
    
    // Neither Java 1.4.2 nor 1.5.0 has Farsi Locale collation available in
    // RuleBasedCollator. However, the Arabic Locale seems to order the Farsi
    // characters properly.
    Collator collator = Collator.getInstance(new Locale("ar"));
    
    // Unicode order would include U+0633 in [ U+062F - U+0698 ], but Farsi
    // orders the U+0698 character before the U+0633 character, so the single
    // index Term below should NOT be returned by a TermRangeFilter with a Farsi
    // Collator (or an Arabic one for the case when Farsi is not supported).
    int numHits = search.search(q, new TermRangeFilter("content", "\u062F",
        "\u0698", T, T, collator), 1000).totalHits;
    assertEquals("The index Term should not be included.", 0, numHits);
    
    numHits = search.search(q, new TermRangeFilter("content", "\u0633",
        "\u0638", T, T, collator), 1000).totalHits;
    assertEquals("The index Term should be included.", 1, numHits);
    search.close();
    reader.close();
    farsiIndex.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521063/fstmerge_var2_3899266744950917138

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestTermRangeFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521068/fstmerge_var1_5382354740025703730
public void testDanish() throws Exception {
    
    /* build an index */
    RAMDirectory danishIndex = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, danishIndex);
    // Danish collation orders the words below in the given order
    // (example taken from TestSort.testInternationalSort() ).
    String[] words = {"H\u00D8T", "H\u00C5T", "MAND"};
    for (int docnum = 0; docnum < words.length; ++docnum) {
      Document doc = new Document();
      doc.add(new Field("content", words[docnum], Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      doc.add(new Field("body", "body", Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    IndexReader reader = writer.getReader();
    writer.close();
    
    IndexSearcher search = new IndexSearcher(reader);
    Query q = new TermQuery(new Term("body", "body"));
    
    Collator collator = Collator.getInstance(new Locale("da", "dk"));
    
    // Unicode order would not include "H\u00C5T" in [ "H\u00D8T", "MAND" ],
    // but Danish collation does.
    int numHits = search.search(q, new TermRangeFilter("content", "H\u00D8T",
        "MAND", F, F, collator), 1000).totalHits;
    assertEquals("The index Term should be included.", 1, numHits);
    
    numHits = search.search(q, new TermRangeFilter("content", "H\u00C5T",
        "MAND", F, F, collator), 1000).totalHits;
    assertEquals("The index Term should not be included.", 0, numHits);
    search.close();
    reader.close();
    danishIndex.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521068/fstmerge_base_5978966906848947777
public void testDanish() throws Exception {
    
    /* build an index */
    RAMDirectory danishIndex = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rand, danishIndex, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    // Danish collation orders the words below in the given order
    // (example taken from TestSort.testInternationalSort() ).
    String[] words = {"H\u00D8T", "H\u00C5T", "MAND"};
    for (int docnum = 0; docnum < words.length; ++docnum) {
      Document doc = new Document();
      doc.add(new Field("content", words[docnum], Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      doc.add(new Field("body", "body", Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    IndexReader reader = writer.getReader();
    writer.close();
    
    IndexSearcher search = new IndexSearcher(reader);
    Query q = new TermQuery(new Term("body", "body"));
    
    Collator collator = Collator.getInstance(new Locale("da", "dk"));
    
    // Unicode order would not include "H\u00C5T" in [ "H\u00D8T", "MAND" ],
    // but Danish collation does.
    int numHits = search.search(q, new TermRangeFilter("content", "H\u00D8T",
        "MAND", F, F, collator), 1000).totalHits;
    assertEquals("The index Term should be included.", 1, numHits);
    
    numHits = search.search(q, new TermRangeFilter("content", "H\u00C5T",
        "MAND", F, F, collator), 1000).totalHits;
    assertEquals("The index Term should not be included.", 0, numHits);
    search.close();
    reader.close();
    danishIndex.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521068/fstmerge_var2_3491200450305515146

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestTermRangeFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521072/fstmerge_var1_999100618321983647
@Override
  protected void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
    
    Document doc = new Document();
    Field field = new Field("field", "", Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field);
    
    NumberFormat df = new DecimalFormat("0000", new DecimalFormatSymbols(Locale.ENGLISH));
    for (int i = 0; i < 10000; i++) {
      field.setValue(df.format(i));
      writer.addDocument(doc);
    }
    
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521072/fstmerge_base_1712486592547290348
@Override
  protected void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    
    Document doc = new Document();
    Field field = new Field("field", "", Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field);
    
    NumberFormat df = new DecimalFormat("0000", new DecimalFormatSymbols(Locale.ENGLISH));
    for (int i = 0; i < 10000; i++) {
      field.setValue(df.format(i));
      writer.addDocument(doc);
    }
    
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521072/fstmerge_var2_2830224781045333609

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestRegexpRandom.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521105/fstmerge_var1_4623628351712537694
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(newRandom(), directory);
    for (int i = 0; i < docFields.length; i++) {
      Document doc = new Document();
      doc.add(new Field(KEY, ""+i, Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(new Field(FIELD, docFields[i], Field.Store.NO, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521105/fstmerge_base_3954118570419614373
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < docFields.length; i++) {
      Document doc = new Document();
      doc.add(new Field(KEY, ""+i, Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(new Field(FIELD, docFields[i], Field.Store.NO, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521105/fstmerge_var2_1331068112247962539

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestExplanations.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521277/fstmerge_var1_6746507041492455267
@Override
  protected void setUp() throws Exception {
    super.setUp();

    //
    dir = new RAMDirectory();

    Random random = newRandom();
    //
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);

    //
    Document d = new Document();
    d.add(new Field(
        FIELD_T,
        "Optimize not deleting all files",
        Field.Store.YES,
        Field.Index.ANALYZED));
    d.add(new Field(
        FIELD_C,
        "Deleted When I run an optimize in our production environment.",
        Field.Store.YES,
        Field.Index.ANALYZED));

    //
    writer.addDocument(d);

    reader = writer.getReader();
    //
    searcher = new IndexSearcher(reader);
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521277/fstmerge_base_2756114118503707766
@Override
  protected void setUp() throws Exception {
    super.setUp();

    //
    dir = new RAMDirectory();

    Random random = newRandom();
    //
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));

    //
    Document d = new Document();
    d.add(new Field(
        FIELD_T,
        "Optimize not deleting all files",
        Field.Store.YES,
        Field.Index.ANALYZED));
    d.add(new Field(
        FIELD_C,
        "Deleted When I run an optimize in our production environment.",
        Field.Store.YES,
        Field.Index.ANALYZED));

    //
    writer.addDocument(d);

    reader = writer.getReader();
    //
    searcher = new IndexSearcher(reader);
    writer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521277/fstmerge_var2_8901480210001888164

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestBooleanOr.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521287/fstmerge_var1_521150407454000364
@Override
  protected void setUp() throws Exception {
    super.setUp();
    rnd = newRandom();
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(rnd, directory);
    for (int i = 0; i < docFields.length; i++) {
      Document doc = new Document();
      doc.add(new Field(field, docFields[i], Field.Store.NO, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    writer.close();
    searcher = new IndexSearcher(directory, true);

    // Make big index
    dir2 = new MockRAMDirectory(directory);

    // First multiply small test index:
    mulFactor = 1;
    int docCount = 0;
    do {
      final Directory copy = new RAMDirectory(dir2);
      RandomIndexWriter w = new RandomIndexWriter(rnd, dir2);
      w.addIndexes(new Directory[] {copy});
      docCount = w.maxDoc();
      w.close();
      mulFactor *= 2;
    } while(docCount < 3000);

    RandomIndexWriter w = new RandomIndexWriter(rnd, dir2);
    Document doc = new Document();
    doc.add(new Field("field2", "xxx", Field.Store.NO, Field.Index.ANALYZED));
    for(int i=0;i<NUM_EXTRA_DOCS/2;i++) {
      w.addDocument(doc);
    }
    doc = new Document();
    doc.add(new Field("field2", "big bad bug", Field.Store.NO, Field.Index.ANALYZED));
    for(int i=0;i<NUM_EXTRA_DOCS/2;i++) {
      w.addDocument(doc);
    }
    reader = w.getReader();
    bigSearcher = new IndexSearcher(reader);
    w.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521287/fstmerge_base_8001919107612798701
@Override
  protected void setUp() throws Exception {
    super.setUp();
    rnd = newRandom();
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(rnd, directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < docFields.length; i++) {
      Document doc = new Document();
      doc.add(new Field(field, docFields[i], Field.Store.NO, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    writer.close();
    searcher = new IndexSearcher(directory, true);

    // Make big index
    dir2 = new MockRAMDirectory(directory);

    // First multiply small test index:
    mulFactor = 1;
    int docCount = 0;
    do {
      final Directory copy = new RAMDirectory(dir2);
      RandomIndexWriter w = new RandomIndexWriter(rnd, dir2, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
      w.addIndexes(new Directory[] {copy});
      docCount = w.maxDoc();
      w.close();
      mulFactor *= 2;
    } while(docCount < 3000);

    RandomIndexWriter w = new RandomIndexWriter(rnd, dir2, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    doc.add(new Field("field2", "xxx", Field.Store.NO, Field.Index.ANALYZED));
    for(int i=0;i<NUM_EXTRA_DOCS/2;i++) {
      w.addDocument(doc);
    }
    doc = new Document();
    doc.add(new Field("field2", "big bad bug", Field.Store.NO, Field.Index.ANALYZED));
    for(int i=0;i<NUM_EXTRA_DOCS/2;i++) {
      w.addDocument(doc);
    }
    reader = w.getReader();
    bigSearcher = new IndexSearcher(reader);
    w.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521287/fstmerge_var2_6932142091521074604

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestBoolean2.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521377/fstmerge_var1_4569843383866943934
public void testMethod() throws Exception {
    RAMDirectory directory = new RAMDirectory();

    String[] categories = new String[]{"food",
                                       "foodanddrink",
                                       "foodanddrinkandgoodtimes",
                                       "food and drink"};

    Query rw1 = null;
    Query rw2 = null;
    IndexReader reader = null;
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    for (int i = 0; i < categories.length; i++) {
      Document doc = new Document();
      doc.add(new Field("category", categories[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
      
    PrefixQuery query = new PrefixQuery(new Term("category", "foo"));
    rw1 = query.rewrite(reader);
      
    BooleanQuery bq = new BooleanQuery();
    bq.add(query, BooleanClause.Occur.MUST);
      
    rw2 = bq.rewrite(reader);

    assertEquals("Number of Clauses Mismatch", getCount(reader, rw1), getCount(reader, rw2));
    reader.close();
    directory.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521377/fstmerge_base_1654138412323824322
public void testMethod() throws Exception {
    RAMDirectory directory = new RAMDirectory();

    String[] categories = new String[]{"food",
                                       "foodanddrink",
                                       "foodanddrinkandgoodtimes",
                                       "food and drink"};

    Query rw1 = null;
    Query rw2 = null;
    IndexReader reader = null;
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, new IndexWriterConfig(
          TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < categories.length; i++) {
      Document doc = new Document();
      doc.add(new Field("category", categories[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
      
    PrefixQuery query = new PrefixQuery(new Term("category", "foo"));
    rw1 = query.rewrite(reader);
      
    BooleanQuery bq = new BooleanQuery();
    bq.add(query, BooleanClause.Occur.MUST);
      
    rw2 = bq.rewrite(reader);

    assertEquals("Number of Clauses Mismatch", getCount(reader, rw1), getCount(reader, rw2));
    reader.close();
    directory.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521377/fstmerge_var2_7183376739846899292

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestBooleanPrefixQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521391/fstmerge_var1_2414021424106580236
public void testDocBoost() throws Exception {
    RAMDirectory store = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), store);

    Fieldable f1 = new Field("field", "word", Field.Store.YES, Field.Index.ANALYZED);
    Fieldable f2 = new Field("field", "word", Field.Store.YES, Field.Index.ANALYZED);
    f2.setBoost(2.0f);

    Document d1 = new Document();
    Document d2 = new Document();
    Document d3 = new Document();
    Document d4 = new Document();
    d3.setBoost(3.0f);
    d4.setBoost(2.0f);

    d1.add(f1);                                 // boost = 1
    d2.add(f2);                                 // boost = 2
    d3.add(f1);                                 // boost = 3
    d4.add(f2);                                 // boost = 4

    writer.addDocument(d1);
    writer.addDocument(d2);
    writer.addDocument(d3);
    writer.addDocument(d4);

    IndexReader reader = writer.getReader();
    writer.close();

    final float[] scores = new float[4];

    new IndexSearcher(reader).search
      (new TermQuery(new Term("field", "word")),
       new Collector() {
         private int base = 0;
         private Scorer scorer;
         @Override
         public void setScorer(Scorer scorer) throws IOException {
          this.scorer = scorer;
         }
         @Override
         public final void collect(int doc) throws IOException {
           scores[doc + base] = scorer.score();
         }
         @Override
         public void setNextReader(IndexReader reader, int docBase) {
           base = docBase;
         }
         @Override
         public boolean acceptsDocsOutOfOrder() {
           return true;
         }
       });

    float lastScore = 0.0f;

    for (int i = 0; i < 4; i++) {
      assertTrue(scores[i] > lastScore);
      lastScore = scores[i];
    }
    
    reader.close();
    store.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521391/fstmerge_base_120323774455738584
public void testDocBoost() throws Exception {
    RAMDirectory store = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), store, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));

    Fieldable f1 = new Field("field", "word", Field.Store.YES, Field.Index.ANALYZED);
    Fieldable f2 = new Field("field", "word", Field.Store.YES, Field.Index.ANALYZED);
    f2.setBoost(2.0f);

    Document d1 = new Document();
    Document d2 = new Document();
    Document d3 = new Document();
    Document d4 = new Document();
    d3.setBoost(3.0f);
    d4.setBoost(2.0f);

    d1.add(f1);                                 // boost = 1
    d2.add(f2);                                 // boost = 2
    d3.add(f1);                                 // boost = 3
    d4.add(f2);                                 // boost = 4

    writer.addDocument(d1);
    writer.addDocument(d2);
    writer.addDocument(d3);
    writer.addDocument(d4);

    IndexReader reader = writer.getReader();
    writer.close();

    final float[] scores = new float[4];

    new IndexSearcher(reader).search
      (new TermQuery(new Term("field", "word")),
       new Collector() {
         private int base = 0;
         private Scorer scorer;
         @Override
         public void setScorer(Scorer scorer) throws IOException {
          this.scorer = scorer;
         }
         @Override
         public final void collect(int doc) throws IOException {
           scores[doc + base] = scorer.score();
         }
         @Override
         public void setNextReader(IndexReader reader, int docBase) {
           base = docBase;
         }
         @Override
         public boolean acceptsDocsOutOfOrder() {
           return true;
         }
       });

    float lastScore = 0.0f;

    for (int i = 0; i < 4; i++) {
      assertTrue(scores[i] > lastScore);
      lastScore = scores[i];
    }
    
    reader.close();
    store.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521391/fstmerge_var2_6952679737012204130

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestDocBoost.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521472/fstmerge_var1_6048512871543846336
private IndexReader build(Random random, TestIndex index) throws IOException {
    /* build an index */
    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
    .setOpenMode(OpenMode.CREATE));
    
    for (int d = minId; d <= maxId; d++) {
      Document doc = new Document();
      doc.add(new Field("id", pad(d), Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      int r = index.allowNegativeRandomInts ? rand.nextInt() : rand
          .nextInt(Integer.MAX_VALUE);
      if (index.maxR < r) {
        index.maxR = r;
      }
      if (r < index.minR) {
        index.minR = r;
      }
      doc.add(new Field("rand", pad(r), Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      doc.add(new Field("body", "body", Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    
    IndexReader ir = writer.getReader();
    writer.close();
    return ir;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521472/fstmerge_base_1228341920220377045
private IndexReader build(Random random, TestIndex index) throws IOException {
    /* build an index */
    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
    .setOpenMode(OpenMode.CREATE));
    
    for (int d = minId; d <= maxId; d++) {
      Document doc = new Document();
      doc.add(new Field("id", pad(d), Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      int r = index.allowNegativeRandomInts ? rand.nextInt() : rand
          .nextInt(Integer.MAX_VALUE);
      if (index.maxR < r) {
        index.maxR = r;
      }
      if (r < index.minR) {
        index.minR = r;
      }
      doc.add(new Field("rand", pad(r), Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      doc.add(new Field("body", "body", Field.Store.YES,
          Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    
    IndexReader ir = writer.getReader();
    writer.close();
    return ir;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521472/fstmerge_var2_3915187738816573922

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521481/fstmerge_var1_4889231082252803400
@Override
  protected void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
    
    Document doc = new Document();
    Field field = new Field("field", "", Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field);
    
    NumberFormat df = new DecimalFormat("0000", new DecimalFormatSymbols(Locale.ENGLISH));
    for (int i = 0; i < 10000; i++) {
      field.setValue(df.format(i));
      writer.addDocument(doc);
    }
    
    IndexReader reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521481/fstmerge_base_4163727026288575678
@Override
  protected void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    
    Document doc = new Document();
    Field field = new Field("field", "", Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field);
    
    NumberFormat df = new DecimalFormat("0000", new DecimalFormatSymbols(Locale.ENGLISH));
    for (int i = 0; i < 10000; i++) {
      field.setValue(df.format(i));
      writer.addDocument(doc);
    }
    
    IndexReader reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521481/fstmerge_var2_1514935090652428929

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestWildcardRandom.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521545/fstmerge_var1_42087129967443845
public void testPrefixQuery() throws Exception {
    RAMDirectory directory = new RAMDirectory();

    String[] categories = new String[] {"/Computers",
                                        "/Computers/Mac",
                                        "/Computers/Windows"};
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    for (int i = 0; i < categories.length; i++) {
      Document doc = new Document();
      doc.add(new Field("category", categories[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    IndexReader reader = writer.getReader();

    PrefixQuery query = new PrefixQuery(new Term("category", "/Computers"));
    IndexSearcher searcher = new IndexSearcher(reader);
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("All documents in /Computers category and below", 3, hits.length);

    query = new PrefixQuery(new Term("category", "/Computers/Mac"));
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("One in /Computers/Mac", 1, hits.length);

    query = new PrefixQuery(new Term("category", ""));
    assertFalse(query.getTermsEnum(searcher.getIndexReader()) instanceof PrefixTermsEnum);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("everything", 3, hits.length);
    writer.close();
    searcher.close();
    reader.close();
    directory.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521545/fstmerge_base_5059609194434470100
public void testPrefixQuery() throws Exception {
    RAMDirectory directory = new RAMDirectory();

    String[] categories = new String[] {"/Computers",
                                        "/Computers/Mac",
                                        "/Computers/Windows"};
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < categories.length; i++) {
      Document doc = new Document();
      doc.add(new Field("category", categories[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    IndexReader reader = writer.getReader();

    PrefixQuery query = new PrefixQuery(new Term("category", "/Computers"));
    IndexSearcher searcher = new IndexSearcher(reader);
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("All documents in /Computers category and below", 3, hits.length);

    query = new PrefixQuery(new Term("category", "/Computers/Mac"));
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("One in /Computers/Mac", 1, hits.length);

    query = new PrefixQuery(new Term("category", ""));
    assertFalse(query.getTermsEnum(searcher.getIndexReader()) instanceof PrefixTermsEnum);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("everything", 3, hits.length);
    writer.close();
    searcher.close();
    reader.close();
    directory.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521545/fstmerge_var2_7167075681773216337

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestPrefixQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521550/fstmerge_var1_8352041386875139072
public void testFuzziness() throws Exception {
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    addDoc("aaaaa", writer);
    addDoc("aaaab", writer);
    addDoc("aaabb", writer);
    addDoc("aabbb", writer);
    addDoc("abbbb", writer);
    addDoc("bbbbb", writer);
    addDoc("ddddd", writer);

    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    writer.close();

    FuzzyQuery query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 0);   
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    
    // same with prefix
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 3);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 4);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 5);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 6);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    
    // test scoring
    query = new FuzzyQuery(new Term("field", "bbbbb"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("3 documents should match", 3, hits.length);
    List<String> order = Arrays.asList("bbbbb","abbbb","aabbb");
    for (int i = 0; i < hits.length; i++) {
      final String term = searcher.doc(hits[i].doc).get("field");
      //System.out.println(hits[i].score);
      assertEquals(order.get(i), term);
    }

    // test pq size by supplying maxExpansions=2
    // This query would normally return 3 documents, because 3 terms match (see above):
    query = new FuzzyQuery(new Term("field", "bbbbb"), FuzzyQuery.defaultMinSimilarity, 0, 2); 
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("only 2 documents should match", 2, hits.length);
    order = Arrays.asList("bbbbb","abbbb");
    for (int i = 0; i < hits.length; i++) {
      final String term = searcher.doc(hits[i].doc).get("field");
      //System.out.println(hits[i].score);
      assertEquals(order.get(i), term);
    }

    // not similar enough:
    query = new FuzzyQuery(new Term("field", "xxxxx"), FuzzyQuery.defaultMinSimilarity, 0);  	
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    query = new FuzzyQuery(new Term("field", "aaccc"), FuzzyQuery.defaultMinSimilarity, 0);   // edit distance to "aaaaa" = 3
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // query identical to a word in the index:
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    // default allows for up to two edits:
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));

    // query similar to a word in the index:
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 3);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 4);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 5);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    

    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 3);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 4);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 5);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    

    // different field = no match:
    query = new FuzzyQuery(new Term("anotherfield", "ddddX"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    searcher.close();
    reader.close();
    directory.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521550/fstmerge_base_4143134522336743598
public void testFuzziness() throws Exception {
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    addDoc("aaaaa", writer);
    addDoc("aaaab", writer);
    addDoc("aaabb", writer);
    addDoc("aabbb", writer);
    addDoc("abbbb", writer);
    addDoc("bbbbb", writer);
    addDoc("ddddd", writer);

    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    writer.close();

    FuzzyQuery query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 0);   
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    
    // same with prefix
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 3);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 4);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 5);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 6);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    
    // test scoring
    query = new FuzzyQuery(new Term("field", "bbbbb"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("3 documents should match", 3, hits.length);
    List<String> order = Arrays.asList("bbbbb","abbbb","aabbb");
    for (int i = 0; i < hits.length; i++) {
      final String term = searcher.doc(hits[i].doc).get("field");
      //System.out.println(hits[i].score);
      assertEquals(order.get(i), term);
    }

    // test pq size by supplying maxExpansions=2
    // This query would normally return 3 documents, because 3 terms match (see above):
    query = new FuzzyQuery(new Term("field", "bbbbb"), FuzzyQuery.defaultMinSimilarity, 0, 2); 
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals("only 2 documents should match", 2, hits.length);
    order = Arrays.asList("bbbbb","abbbb");
    for (int i = 0; i < hits.length; i++) {
      final String term = searcher.doc(hits[i].doc).get("field");
      //System.out.println(hits[i].score);
      assertEquals(order.get(i), term);
    }

    // not similar enough:
    query = new FuzzyQuery(new Term("field", "xxxxx"), FuzzyQuery.defaultMinSimilarity, 0);  	
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    query = new FuzzyQuery(new Term("field", "aaccc"), FuzzyQuery.defaultMinSimilarity, 0);   // edit distance to "aaaaa" = 3
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // query identical to a word in the index:
    query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    // default allows for up to two edits:
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));

    // query similar to a word in the index:
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 3);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 4);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
    query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 5);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    

    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 3);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 4);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
    query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 5);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    

    // different field = no match:
    query = new FuzzyQuery(new Term("anotherfield", "ddddX"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    searcher.close();
    reader.close();
    directory.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521550/fstmerge_var2_2497993834845928392

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestFuzzyQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521560/fstmerge_var1_930386822749858152
public void testFuzzinessLong() throws Exception {
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    addDoc("aaaaaaa", writer);
    addDoc("segment", writer);

    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    writer.close();

    FuzzyQuery query;
    // not similar enough:
    query = new FuzzyQuery(new Term("field", "xxxxx"), FuzzyQuery.defaultMinSimilarity, 0);   
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    // edit distance to "aaaaaaa" = 3, this matches because the string is longer than
    // in testDefaultFuzziness so a bigger difference is allowed:
    query = new FuzzyQuery(new Term("field", "aaaaccc"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "aaaaccc"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
    query = new FuzzyQuery(new Term("field", "aaaaccc"), FuzzyQuery.defaultMinSimilarity, 4);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
    query = new FuzzyQuery(new Term("field", "aaaaccc"), FuzzyQuery.defaultMinSimilarity, 5);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // no match, more than half of the characters is wrong:
    query = new FuzzyQuery(new Term("field", "aaacccc"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "aaacccc"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // "student" and "stellent" are indeed similar to "segment" by default:
    query = new FuzzyQuery(new Term("field", "student"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    query = new FuzzyQuery(new Term("field", "stellent"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "student"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    query = new FuzzyQuery(new Term("field", "stellent"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    query = new FuzzyQuery(new Term("field", "student"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    query = new FuzzyQuery(new Term("field", "stellent"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    
    // "student" doesn't match anymore thanks to increased minimum similarity:
    query = new FuzzyQuery(new Term("field", "student"), 0.6f, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    try {
      query = new FuzzyQuery(new Term("field", "student"), 1.1f);
      fail("Expected IllegalArgumentException");
    } catch (IllegalArgumentException e) {
      // expecting exception
    }
    try {
      query = new FuzzyQuery(new Term("field", "student"), -0.1f);
      fail("Expected IllegalArgumentException");
    } catch (IllegalArgumentException e) {
      // expecting exception
    }

    searcher.close();
    reader.close();
    directory.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521560/fstmerge_base_7127184389062418614
public void testFuzzinessLong() throws Exception {
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    addDoc("aaaaaaa", writer);
    addDoc("segment", writer);

    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    writer.close();

    FuzzyQuery query;
    // not similar enough:
    query = new FuzzyQuery(new Term("field", "xxxxx"), FuzzyQuery.defaultMinSimilarity, 0);   
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    // edit distance to "aaaaaaa" = 3, this matches because the string is longer than
    // in testDefaultFuzziness so a bigger difference is allowed:
    query = new FuzzyQuery(new Term("field", "aaaaccc"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "aaaaccc"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
    query = new FuzzyQuery(new Term("field", "aaaaccc"), FuzzyQuery.defaultMinSimilarity, 4);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
    query = new FuzzyQuery(new Term("field", "aaaaccc"), FuzzyQuery.defaultMinSimilarity, 5);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // no match, more than half of the characters is wrong:
    query = new FuzzyQuery(new Term("field", "aaacccc"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "aaacccc"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // "student" and "stellent" are indeed similar to "segment" by default:
    query = new FuzzyQuery(new Term("field", "student"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    query = new FuzzyQuery(new Term("field", "stellent"), FuzzyQuery.defaultMinSimilarity, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    
    // now with prefix
    query = new FuzzyQuery(new Term("field", "student"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    query = new FuzzyQuery(new Term("field", "stellent"), FuzzyQuery.defaultMinSimilarity, 1);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    query = new FuzzyQuery(new Term("field", "student"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    query = new FuzzyQuery(new Term("field", "stellent"), FuzzyQuery.defaultMinSimilarity, 2);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    
    // "student" doesn't match anymore thanks to increased minimum similarity:
    query = new FuzzyQuery(new Term("field", "student"), 0.6f, 0);   
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    try {
      query = new FuzzyQuery(new Term("field", "student"), 1.1f);
      fail("Expected IllegalArgumentException");
    } catch (IllegalArgumentException e) {
      // expecting exception
    }
    try {
      query = new FuzzyQuery(new Term("field", "student"), -0.1f);
      fail("Expected IllegalArgumentException");
    } catch (IllegalArgumentException e) {
      // expecting exception
    }

    searcher.close();
    reader.close();
    directory.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521560/fstmerge_var2_8100746088700158905

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestFuzzyQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521567/fstmerge_var1_6078456815161348612
public void testTokenLengthOpt() throws IOException {
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    addDoc("12345678911", writer);
    addDoc("segment", writer);

    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    writer.close();

    Query query;
    // term not over 10 chars, so optimization shortcuts
    query = new FuzzyQuery(new Term("field", "1234569"), 0.9f);
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // 10 chars, so no optimization
    query = new FuzzyQuery(new Term("field", "1234567891"), 0.9f);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    
    // over 10 chars, so no optimization
    query = new FuzzyQuery(new Term("field", "12345678911"), 0.9f);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);

    // over 10 chars, no match
    query = new FuzzyQuery(new Term("field", "sdfsdfsdfsdf"), 0.9f);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    
    searcher.close();
    reader.close();
    directory.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521567/fstmerge_base_6626502746152981330
public void testTokenLengthOpt() throws IOException {
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    addDoc("12345678911", writer);
    addDoc("segment", writer);

    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    writer.close();

    Query query;
    // term not over 10 chars, so optimization shortcuts
    query = new FuzzyQuery(new Term("field", "1234569"), 0.9f);
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // 10 chars, so no optimization
    query = new FuzzyQuery(new Term("field", "1234567891"), 0.9f);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    
    // over 10 chars, so no optimization
    query = new FuzzyQuery(new Term("field", "12345678911"), 0.9f);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);

    // over 10 chars, no match
    query = new FuzzyQuery(new Term("field", "sdfsdfsdfsdf"), 0.9f);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    
    searcher.close();
    reader.close();
    directory.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521567/fstmerge_var2_3486938061077917841

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestFuzzyQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521572/fstmerge_var1_5976754900070014232
public void testBoostOnlyRewrite() throws Exception {
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    addDoc("Lucene", writer);
    addDoc("Lucene", writer);
    addDoc("Lucenne", writer);

    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    writer.close();
    
    FuzzyQuery query = new FuzzyQuery(new Term("field", "Lucene"));
    query.setRewriteMethod(new MultiTermQuery.TopTermsBoostOnlyBooleanQueryRewrite());
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    // normally, 'Lucenne' would be the first result as IDF will skew the score.
    assertEquals("Lucene", reader.document(hits[0].doc).get("field"));
    assertEquals("Lucene", reader.document(hits[1].doc).get("field"));
    assertEquals("Lucenne", reader.document(hits[2].doc).get("field"));
    searcher.close();
    reader.close();
    directory.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521572/fstmerge_base_8771163990727917784
public void testBoostOnlyRewrite() throws Exception {
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    addDoc("Lucene", writer);
    addDoc("Lucene", writer);
    addDoc("Lucenne", writer);

    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    writer.close();
    
    FuzzyQuery query = new FuzzyQuery(new Term("field", "Lucene"));
    query.setRewriteMethod(new MultiTermQuery.TopTermsBoostOnlyBooleanQueryRewrite());
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    // normally, 'Lucenne' would be the first result as IDF will skew the score.
    assertEquals("Lucene", reader.document(hits[0].doc).get("field"));
    assertEquals("Lucene", reader.document(hits[1].doc).get("field"));
    assertEquals("Lucenne", reader.document(hits[2].doc).get("field"));
    searcher.close();
    reader.close();
    directory.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521572/fstmerge_var2_3722042025933227440

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestFuzzyQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521576/fstmerge_var1_3289984664928692612
public void testGiga() throws Exception {

    MockAnalyzer analyzer = new MockAnalyzer();

    Directory index = new MockRAMDirectory();
    RandomIndexWriter w = new RandomIndexWriter(newRandom(), index);

    addDoc("Lucene in Action", w);
    addDoc("Lucene for Dummies", w);

    //addDoc("Giga", w);
    addDoc("Giga byte", w);

    addDoc("ManagingGigabytesManagingGigabyte", w);
    addDoc("ManagingGigabytesManagingGigabytes", w);

    addDoc("The Art of Computer Science", w);
    addDoc("J. K. Rowling", w);
    addDoc("JK Rowling", w);
    addDoc("Joanne K Roling", w);
    addDoc("Bruce Willis", w);
    addDoc("Willis bruce", w);
    addDoc("Brute willis", w);
    addDoc("B. willis", w);
    IndexReader r = w.getReader();
    w.close();

    Query q = new QueryParser(TEST_VERSION_CURRENT, "field", analyzer).parse( "giga~0.9" );

    // 3. search
    IndexSearcher searcher = new IndexSearcher(r);
    ScoreDoc[] hits = searcher.search(q, 10).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals("Giga byte", searcher.doc(hits[0].doc).get("field"));
    searcher.close();
    r.close();
    index.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521576/fstmerge_base_8939421077307060647
public void testGiga() throws Exception {

    MockAnalyzer analyzer = new MockAnalyzer();

    Directory index = new MockRAMDirectory();
    RandomIndexWriter w = new RandomIndexWriter(newRandom(), index, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer));

    addDoc("Lucene in Action", w);
    addDoc("Lucene for Dummies", w);

    //addDoc("Giga", w);
    addDoc("Giga byte", w);

    addDoc("ManagingGigabytesManagingGigabyte", w);
    addDoc("ManagingGigabytesManagingGigabytes", w);

    addDoc("The Art of Computer Science", w);
    addDoc("J. K. Rowling", w);
    addDoc("JK Rowling", w);
    addDoc("Joanne K Roling", w);
    addDoc("Bruce Willis", w);
    addDoc("Willis bruce", w);
    addDoc("Brute willis", w);
    addDoc("B. willis", w);
    IndexReader r = w.getReader();
    w.close();

    Query q = new QueryParser(TEST_VERSION_CURRENT, "field", analyzer).parse( "giga~0.9" );

    // 3. search
    IndexSearcher searcher = new IndexSearcher(r);
    ScoreDoc[] hits = searcher.search(q, 10).scoreDocs;
    assertEquals(1, hits.length);
    assertEquals("Giga byte", searcher.doc(hits[0].doc).get("field"));
    searcher.close();
    r.close();
    index.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521576/fstmerge_var2_3409908822005654117

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestFuzzyQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521584/fstmerge_var1_6569838656757588681
public void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    Document doc = new Document();
    doc.add(new Field(FN,
        "the quick brown fox jumps over the lazy ??? dog 493432 49344",
        Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521584/fstmerge_base_6379387003819345130
public void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    doc.add(new Field(FN,
        "the quick brown fox jumps over the lazy ??? dog 493432 49344",
        Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521584/fstmerge_var2_1626955615421831476

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestRegexpQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521668/fstmerge_var1_3977978850115913996
public void setUp() throws Exception {
    super.setUp();
    Random random = newRandom();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
    Document doc = new Document();
    Field titleField = new Field("title", "some title", Field.Store.NO,
        Field.Index.ANALYZED);
    Field field = new Field(FN, "this is document one 2345", Field.Store.NO,
        Field.Index.ANALYZED);
    Field footerField = new Field("footer", "a footer", Field.Store.NO,
        Field.Index.ANALYZED);
    doc.add(titleField);
    doc.add(field);
    doc.add(footerField);
    writer.addDocument(doc);
    field.setValue("some text from doc two a short piece 5678.91");
    writer.addDocument(doc);
    field.setValue("doc three has some different stuff"
        + " with numbers 1234 5678.9 and letter b");
    writer.addDocument(doc);
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521668/fstmerge_base_1503463646861080559
public void setUp() throws Exception {
    super.setUp();
    Random random = newRandom();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    Field titleField = new Field("title", "some title", Field.Store.NO,
        Field.Index.ANALYZED);
    Field field = new Field(FN, "this is document one 2345", Field.Store.NO,
        Field.Index.ANALYZED);
    Field footerField = new Field("footer", "a footer", Field.Store.NO,
        Field.Index.ANALYZED);
    doc.add(titleField);
    doc.add(field);
    doc.add(footerField);
    writer.addDocument(doc);
    field.setValue("some text from doc two a short piece 5678.91");
    writer.addDocument(doc);
    field.setValue("doc three has some different stuff"
        + " with numbers 1234 5678.9 and letter b");
    writer.addDocument(doc);
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521668/fstmerge_var2_5349339690552720432

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestAutomatonQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521712/fstmerge_var1_7884607190302847479
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter (newRandom(), directory);

    Document doc = new Document();
    doc.add (new Field("field", "one two three four five", Field.Store.YES, Field.Index.ANALYZED));
    doc.add (new Field("sorter", "b", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument (doc);

    doc = new Document();
    doc.add (new Field("field", "one two three four", Field.Store.YES, Field.Index.ANALYZED));
    doc.add (new Field("sorter", "d", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument (doc);

    doc = new Document();
    doc.add (new Field("field", "one two three y", Field.Store.YES, Field.Index.ANALYZED));
    doc.add (new Field("sorter", "a", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument (doc);

    doc = new Document();
    doc.add (new Field("field", "one two x", Field.Store.YES, Field.Index.ANALYZED));
    doc.add (new Field("sorter", "c", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument (doc);

    // tests here require single segment (eg try seed
    // 8239472272678419952L), because SingleDocTestFilter(x)
    // blindly accepts that docID in any sub-segment
    writer.optimize();

    reader = writer.getReader();
    writer.close ();

    searcher = new IndexSearcher (reader);
    query = new TermQuery (new Term ("field", "three"));
    filter = newStaticFilterB();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521712/fstmerge_base_713832777627833281
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter (newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));

    Document doc = new Document();
    doc.add (new Field("field", "one two three four five", Field.Store.YES, Field.Index.ANALYZED));
    doc.add (new Field("sorter", "b", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument (doc);

    doc = new Document();
    doc.add (new Field("field", "one two three four", Field.Store.YES, Field.Index.ANALYZED));
    doc.add (new Field("sorter", "d", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument (doc);

    doc = new Document();
    doc.add (new Field("field", "one two three y", Field.Store.YES, Field.Index.ANALYZED));
    doc.add (new Field("sorter", "a", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument (doc);

    doc = new Document();
    doc.add (new Field("field", "one two x", Field.Store.YES, Field.Index.ANALYZED));
    doc.add (new Field("sorter", "c", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument (doc);

    reader = writer.getReader();
    writer.close ();

    searcher = new IndexSearcher (reader);
    query = new TermQuery (new Term ("field", "three"));
    filter = newStaticFilterB();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521712/fstmerge_var2_2953383768972554421

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestFilteredQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521729/fstmerge_var1_2664500791445819007
public void testMissingTerms() throws Exception {
    String fieldName = "field1";
    MockRAMDirectory rd = new MockRAMDirectory();
    RandomIndexWriter w = new RandomIndexWriter(newRandom(), rd);
    for (int i = 0; i < 100; i++) {
      Document doc = new Document();
      int term = i * 10; //terms are units of 10;
      doc.add(new Field(fieldName, "" + term, Field.Store.YES, Field.Index.NOT_ANALYZED));
      w.addDocument(doc);
    }
    IndexReader reader = w.getReader();
    w.close();

    IndexSearcher searcher = new IndexSearcher(reader);
    int numDocs = reader.numDocs();
    ScoreDoc[] results;
    MatchAllDocsQuery q = new MatchAllDocsQuery();

    List<String> terms = new ArrayList<String>();
    terms.add("5");
    results = searcher.search(q, new FieldCacheTermsFilter(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
    assertEquals("Must match nothing", 0, results.length);

    terms = new ArrayList<String>();
    terms.add("10");
    results = searcher.search(q, new FieldCacheTermsFilter(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
    assertEquals("Must match 1", 1, results.length);

    terms = new ArrayList<String>();
    terms.add("10");
    terms.add("20");
    results = searcher.search(q, new FieldCacheTermsFilter(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
    assertEquals("Must match 2", 2, results.length);

    reader.close();
    rd.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521729/fstmerge_base_7112671700972893822
public void testMissingTerms() throws Exception {
    String fieldName = "field1";
    MockRAMDirectory rd = new MockRAMDirectory();
    RandomIndexWriter w = new RandomIndexWriter(newRandom(), rd, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < 100; i++) {
      Document doc = new Document();
      int term = i * 10; //terms are units of 10;
      doc.add(new Field(fieldName, "" + term, Field.Store.YES, Field.Index.NOT_ANALYZED));
      w.addDocument(doc);
    }
    IndexReader reader = w.getReader();
    w.close();

    IndexSearcher searcher = new IndexSearcher(reader);
    int numDocs = reader.numDocs();
    ScoreDoc[] results;
    MatchAllDocsQuery q = new MatchAllDocsQuery();

    List<String> terms = new ArrayList<String>();
    terms.add("5");
    results = searcher.search(q, new FieldCacheTermsFilter(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
    assertEquals("Must match nothing", 0, results.length);

    terms = new ArrayList<String>();
    terms.add("10");
    results = searcher.search(q, new FieldCacheTermsFilter(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
    assertEquals("Must match 1", 1, results.length);

    terms = new ArrayList<String>();
    terms.add("10");
    terms.add("20");
    results = searcher.search(q, new FieldCacheTermsFilter(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
    assertEquals("Must match 2", 2, results.length);

    reader.close();
    rd.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521729/fstmerge_var2_933991075583543314

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestFieldCacheTermsFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521751/fstmerge_var1_2373926333247275653
private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {
    query.setSlop(slop);

    RAMDirectory ramDir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, ramDir, new MockAnalyzer(MockTokenizer.WHITESPACE, false));
    writer.addDocument(doc);

    IndexReader reader = writer.getReader();

    IndexSearcher searcher = new IndexSearcher(reader);
    TopDocs td = searcher.search(query,null,10);
    //System.out.println("slop: "+slop+"  query: "+query+"  doc: "+doc+"  Expecting number of hits: "+expectedNumResults+" maxScore="+td.getMaxScore());
    assertEquals("slop: "+slop+"  query: "+query+"  doc: "+doc+"  Wrong number of hits", expectedNumResults, td.totalHits);

    //QueryUtils.check(query,searcher);
    writer.close();
    searcher.close();
    reader.close();
    ramDir.close();

    return td.getMaxScore();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521751/fstmerge_base_2758694907620334854
private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {
    query.setSlop(slop);

    RAMDirectory ramDir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, ramDir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
    writer.addDocument(doc);

    IndexReader reader = writer.getReader();

    IndexSearcher searcher = new IndexSearcher(reader);
    TopDocs td = searcher.search(query,null,10);
    //System.out.println("slop: "+slop+"  query: "+query+"  doc: "+doc+"  Expecting number of hits: "+expectedNumResults+" maxScore="+td.getMaxScore());
    assertEquals("slop: "+slop+"  query: "+query+"  doc: "+doc+"  Wrong number of hits", expectedNumResults, td.totalHits);

    //QueryUtils.check(query,searcher);
    writer.close();
    searcher.close();
    reader.close();
    ramDir.close();

    return td.getMaxScore();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521751/fstmerge_var2_1722436469219138208

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestSloppyPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521763/fstmerge_var1_726732309726216671
@Override
  public void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    directory = new RAMDirectory();
    Analyzer analyzer = new Analyzer() {
      @Override
      public TokenStream tokenStream(String fieldName, Reader reader) {
        return new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
      }

      @Override
      public int getPositionIncrementGap(String fieldName) {
        return 100;
      }
    };
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, analyzer);
    
    Document doc = new Document();
    doc.add(new Field("field", "one two three four five", Field.Store.YES, Field.Index.ANALYZED));
    doc.add(new Field("repeated", "this is a repeated field - first part", Field.Store.YES, Field.Index.ANALYZED));
    Fieldable repeatedField = new Field("repeated", "second part of a repeated field", Field.Store.YES, Field.Index.ANALYZED);
    doc.add(repeatedField);
    doc.add(new Field("palindrome", "one two three two one", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    doc = new Document();
    doc.add(new Field("nonexist", "phrase exist notexist exist found", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    doc = new Document();
    doc.add(new Field("nonexist", "phrase exist notexist exist found", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);

    reader = writer.getReader();
    writer.close();

    searcher = new IndexSearcher(reader);
    query = new PhraseQuery();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521763/fstmerge_base_5914136187603944310
@Override
  public void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    directory = new RAMDirectory();
    Analyzer analyzer = new Analyzer() {
      @Override
      public TokenStream tokenStream(String fieldName, Reader reader) {
        return new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
      }

      @Override
      public int getPositionIncrementGap(String fieldName) {
        return 100;
      }
    };
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
    
    Document doc = new Document();
    doc.add(new Field("field", "one two three four five", Field.Store.YES, Field.Index.ANALYZED));
    doc.add(new Field("repeated", "this is a repeated field - first part", Field.Store.YES, Field.Index.ANALYZED));
    Fieldable repeatedField = new Field("repeated", "second part of a repeated field", Field.Store.YES, Field.Index.ANALYZED);
    doc.add(repeatedField);
    doc.add(new Field("palindrome", "one two three two one", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    doc = new Document();
    doc.add(new Field("nonexist", "phrase exist notexist exist found", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    doc = new Document();
    doc.add(new Field("nonexist", "phrase exist notexist exist found", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);

    reader = writer.getReader();
    writer.close();

    searcher = new IndexSearcher(reader);
    query = new PhraseQuery();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521763/fstmerge_var2_4712540008085694139

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521795/fstmerge_var1_6514123368708911439
public void testPhraseQueryWithStopAnalyzer() throws Exception {
    RAMDirectory directory = new RAMDirectory();
    Analyzer stopAnalyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, false);
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(random, Version.LUCENE_24, stopAnalyzer));
    Document doc = new Document();
    doc.add(new Field("field", "the stop words are here", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    IndexReader reader = writer.getReader();
    writer.close();

    IndexSearcher searcher = new IndexSearcher(reader);

    // valid exact phrase query
    PhraseQuery query = new PhraseQuery();
    query.add(new Term("field","stop"));
    query.add(new Term("field","words"));
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    QueryUtils.check(query,searcher);


    // StopAnalyzer as of 2.4 does not leave "holes", so this matches.
    query = new PhraseQuery();
    query.add(new Term("field", "words"));
    query.add(new Term("field", "here"));
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    QueryUtils.check(query,searcher);


    searcher.close();
    reader.close();
    directory.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521795/fstmerge_base_7861314150840139107
public void testPhraseQueryWithStopAnalyzer() throws Exception {
    RAMDirectory directory = new RAMDirectory();
    Analyzer stopAnalyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, false);
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        new IndexWriterConfig(Version.LUCENE_24, stopAnalyzer));
    Document doc = new Document();
    doc.add(new Field("field", "the stop words are here", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    IndexReader reader = writer.getReader();
    writer.close();

    IndexSearcher searcher = new IndexSearcher(reader);

    // valid exact phrase query
    PhraseQuery query = new PhraseQuery();
    query.add(new Term("field","stop"));
    query.add(new Term("field","words"));
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    QueryUtils.check(query,searcher);


    // StopAnalyzer as of 2.4 does not leave "holes", so this matches.
    query = new PhraseQuery();
    query.add(new Term("field", "words"));
    query.add(new Term("field", "here"));
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    QueryUtils.check(query,searcher);


    searcher.close();
    reader.close();
    directory.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521795/fstmerge_var2_4796605484621771486

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521799/fstmerge_var1_7115642303709904579
public void testPhraseQueryInConjunctionScorer() throws Exception {
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
    
    Document doc = new Document();
    doc.add(new Field("source", "marketing info", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    doc = new Document();
    doc.add(new Field("contents", "foobar", Field.Store.YES, Field.Index.ANALYZED));
    doc.add(new Field("source", "marketing info", Field.Store.YES, Field.Index.ANALYZED)); 
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    writer.close();
    
    IndexSearcher searcher = new IndexSearcher(reader);
    
    PhraseQuery phraseQuery = new PhraseQuery();
    phraseQuery.add(new Term("source", "marketing"));
    phraseQuery.add(new Term("source", "info"));
    ScoreDoc[] hits = searcher.search(phraseQuery, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    QueryUtils.check(phraseQuery,searcher);

    
    TermQuery termQuery = new TermQuery(new Term("contents","foobar"));
    BooleanQuery booleanQuery = new BooleanQuery();
    booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
    booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    QueryUtils.check(termQuery,searcher);

    
    searcher.close();
    reader.close();
    
    writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
    doc = new Document();
    doc.add(new Field("contents", "map entry woo", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);

    doc = new Document();
    doc.add(new Field("contents", "woo map entry", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);

    doc = new Document();
    doc.add(new Field("contents", "map foobarword entry woo", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);

    reader = writer.getReader();
    writer.close();
    
    searcher = new IndexSearcher(reader);
    
    termQuery = new TermQuery(new Term("contents","woo"));
    phraseQuery = new PhraseQuery();
    phraseQuery.add(new Term("contents","map"));
    phraseQuery.add(new Term("contents","entry"));
    
    hits = searcher.search(termQuery, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    hits = searcher.search(phraseQuery, null, 1000).scoreDocs;
    assertEquals(2, hits.length);

    
    booleanQuery = new BooleanQuery();
    booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
    booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    
    booleanQuery = new BooleanQuery();
    booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
    booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    QueryUtils.check(booleanQuery,searcher);

    
    searcher.close();
    reader.close();
    directory.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521799/fstmerge_base_9156163066255242692
public void testPhraseQueryInConjunctionScorer() throws Exception {
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    
    Document doc = new Document();
    doc.add(new Field("source", "marketing info", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    doc = new Document();
    doc.add(new Field("contents", "foobar", Field.Store.YES, Field.Index.ANALYZED));
    doc.add(new Field("source", "marketing info", Field.Store.YES, Field.Index.ANALYZED)); 
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    writer.close();
    
    IndexSearcher searcher = new IndexSearcher(reader);
    
    PhraseQuery phraseQuery = new PhraseQuery();
    phraseQuery.add(new Term("source", "marketing"));
    phraseQuery.add(new Term("source", "info"));
    ScoreDoc[] hits = searcher.search(phraseQuery, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    QueryUtils.check(phraseQuery,searcher);

    
    TermQuery termQuery = new TermQuery(new Term("contents","foobar"));
    BooleanQuery booleanQuery = new BooleanQuery();
    booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
    booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    QueryUtils.check(termQuery,searcher);

    
    searcher.close();
    reader.close();
    
    writer = new RandomIndexWriter(random, directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
    doc = new Document();
    doc.add(new Field("contents", "map entry woo", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);

    doc = new Document();
    doc.add(new Field("contents", "woo map entry", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);

    doc = new Document();
    doc.add(new Field("contents", "map foobarword entry woo", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);

    reader = writer.getReader();
    writer.close();
    
    searcher = new IndexSearcher(reader);
    
    termQuery = new TermQuery(new Term("contents","woo"));
    phraseQuery = new PhraseQuery();
    phraseQuery.add(new Term("contents","map"));
    phraseQuery.add(new Term("contents","entry"));
    
    hits = searcher.search(termQuery, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    hits = searcher.search(phraseQuery, null, 1000).scoreDocs;
    assertEquals(2, hits.length);

    
    booleanQuery = new BooleanQuery();
    booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
    booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    
    booleanQuery = new BooleanQuery();
    booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
    booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
    assertEquals(2, hits.length);
    QueryUtils.check(booleanQuery,searcher);

    
    searcher.close();
    reader.close();
    directory.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521799/fstmerge_var2_9126093877830725127

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521804/fstmerge_var1_8273931366815490920
public void testSlopScoring() throws IOException {
    Directory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);

    Document doc = new Document();
    doc.add(new Field("field", "foo firstname lastname foo", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    Document doc2 = new Document();
    doc2.add(new Field("field", "foo firstname zzz lastname foo", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc2);
    
    Document doc3 = new Document();
    doc3.add(new Field("field", "foo firstname zzz yyy lastname foo", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc3);
    
    IndexReader reader = writer.getReader();
    writer.close();

    Searcher searcher = new IndexSearcher(reader);
    PhraseQuery query = new PhraseQuery();
    query.add(new Term("field", "firstname"));
    query.add(new Term("field", "lastname"));
    query.setSlop(Integer.MAX_VALUE);
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    // Make sure that those matches where the terms appear closer to
    // each other get a higher score:
    assertEquals(0.71, hits[0].score, 0.01);
    assertEquals(0, hits[0].doc);
    assertEquals(0.44, hits[1].score, 0.01);
    assertEquals(1, hits[1].doc);
    assertEquals(0.31, hits[2].score, 0.01);
    assertEquals(2, hits[2].doc);
    QueryUtils.check(query,searcher);
    searcher.close();
    reader.close();
    directory.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521804/fstmerge_base_7953041153213927400
public void testSlopScoring() throws IOException {
    Directory directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));

    Document doc = new Document();
    doc.add(new Field("field", "foo firstname lastname foo", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    Document doc2 = new Document();
    doc2.add(new Field("field", "foo firstname zzz lastname foo", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc2);
    
    Document doc3 = new Document();
    doc3.add(new Field("field", "foo firstname zzz yyy lastname foo", Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc3);
    
    IndexReader reader = writer.getReader();
    writer.close();

    Searcher searcher = new IndexSearcher(reader);
    PhraseQuery query = new PhraseQuery();
    query.add(new Term("field", "firstname"));
    query.add(new Term("field", "lastname"));
    query.setSlop(Integer.MAX_VALUE);
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    // Make sure that those matches where the terms appear closer to
    // each other get a higher score:
    assertEquals(0.71, hits[0].score, 0.01);
    assertEquals(0, hits[0].doc);
    assertEquals(0.44, hits[1].score, 0.01);
    assertEquals(1, hits[1].doc);
    assertEquals(0.31, hits[2].score, 0.01);
    assertEquals(2, hits[2].doc);
    QueryUtils.check(query,searcher);
    searcher.close();
    reader.close();
    directory.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521804/fstmerge_var2_3650888827392018179

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521838/fstmerge_var1_8758572626599669893
public void testRandomPhrases() throws Exception {
    Directory dir = new MockRAMDirectory();
    Analyzer analyzer = new MockAnalyzer();

    RandomIndexWriter w  = new RandomIndexWriter(random, dir, analyzer);
    List<List<String>> docs = new ArrayList<List<String>>();
    Document d = new Document();
    Field f = new Field("f", "", Field.Store.NO, Field.Index.ANALYZED);
    d.add(f);

    Random r = random;

    int NUM_DOCS = 10*_TestUtil.getRandomMultiplier();
    for(int i=0;i<NUM_DOCS;i++) {
      // must be > 4096 so it spans multiple chunks
      int termCount = _TestUtil.nextInt(r, 10000, 30000);

      List<String> doc = new ArrayList<String>();

      StringBuilder sb = new StringBuilder();
      while(doc.size() < termCount) {
        if (r.nextInt(5) == 1 || docs.size() == 0) {
          // make new non-empty-string term
          String term;
          while(true) {
            term = _TestUtil.randomUnicodeString(r);
            if (term.length() > 0) {
              break;
            }
          }
          TokenStream ts = analyzer.reusableTokenStream("ignore", new StringReader(term));
          CharTermAttribute termAttr = ts.addAttribute(CharTermAttribute.class);
          while(ts.incrementToken()) {
            String text = termAttr.toString();
            doc.add(text);
            sb.append(text).append(' ');
          }
        } else {
          // pick existing sub-phrase
          List<String> lastDoc = docs.get(r.nextInt(docs.size()));
          int len = _TestUtil.nextInt(r, 1, 10);
          int start = r.nextInt(lastDoc.size()-len);
          for(int k=start;k<start+len;k++) {
            String t = lastDoc.get(k);
            doc.add(t);
            sb.append(t).append(' ');
          }
        }
      }
      docs.add(doc);
      f.setValue(sb.toString());
      w.addDocument(d);
    }

    IndexReader reader = w.getReader();
    IndexSearcher s = new IndexSearcher(reader);
    w.close();

    // now search
    for(int i=0;i<100*_TestUtil.getRandomMultiplier();i++) {
      int docID = r.nextInt(docs.size());
      List<String> doc = docs.get(docID);
      
      final int numTerm = _TestUtil.nextInt(r, 2, 20);
      final int start = r.nextInt(doc.size()-numTerm);
      PhraseQuery pq = new PhraseQuery();
      StringBuilder sb = new StringBuilder();
      for(int t=start;t<start+numTerm;t++) {
        pq.add(new Term("f", doc.get(t)));
        sb.append(doc.get(t)).append(' ');
      }

      TopDocs hits = s.search(pq, NUM_DOCS);
      boolean found = false;
      for(int j=0;j<hits.scoreDocs.length;j++) {
        if (hits.scoreDocs[j].doc == docID) {
          found = true;
          break;
        }
      }

      assertTrue("phrase '" + sb + "' not found; start=" + start, found);
    }

    reader.close();
    s.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521838/fstmerge_base_624816196841860720
public void testRandomPhrases() throws Exception {
    Directory dir = new MockRAMDirectory();
    Analyzer analyzer = new MockAnalyzer();

    RandomIndexWriter w  = new RandomIndexWriter(random, dir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
    List<List<String>> docs = new ArrayList<List<String>>();
    Document d = new Document();
    Field f = new Field("f", "", Field.Store.NO, Field.Index.ANALYZED);
    d.add(f);

    Random r = random;

    int NUM_DOCS = 10*_TestUtil.getRandomMultiplier();
    for(int i=0;i<NUM_DOCS;i++) {
      // must be > 4096 so it spans multiple chunks
      int termCount = _TestUtil.nextInt(r, 10000, 30000);

      List<String> doc = new ArrayList<String>();

      StringBuilder sb = new StringBuilder();
      while(doc.size() < termCount) {
        if (r.nextInt(5) == 1 || docs.size() == 0) {
          // make new non-empty-string term
          String term;
          while(true) {
            term = _TestUtil.randomUnicodeString(r);
            if (term.length() > 0) {
              break;
            }
          }
          TokenStream ts = analyzer.reusableTokenStream("ignore", new StringReader(term));
          CharTermAttribute termAttr = ts.addAttribute(CharTermAttribute.class);
          while(ts.incrementToken()) {
            String text = termAttr.toString();
            doc.add(text);
            sb.append(text).append(' ');
          }
        } else {
          // pick existing sub-phrase
          List<String> lastDoc = docs.get(r.nextInt(docs.size()));
          int len = _TestUtil.nextInt(r, 1, 10);
          int start = r.nextInt(lastDoc.size()-len);
          for(int k=start;k<start+len;k++) {
            String t = lastDoc.get(k);
            doc.add(t);
            sb.append(t).append(' ');
          }
        }
      }
      docs.add(doc);
      f.setValue(sb.toString());
      w.addDocument(d);
    }

    IndexReader reader = w.getReader();
    IndexSearcher s = new IndexSearcher(reader);
    w.close();

    // now search
    for(int i=0;i<100*_TestUtil.getRandomMultiplier();i++) {
      int docID = r.nextInt(docs.size());
      List<String> doc = docs.get(docID);
      
      final int numTerm = _TestUtil.nextInt(r, 2, 20);
      final int start = r.nextInt(doc.size()-numTerm);
      PhraseQuery pq = new PhraseQuery();
      StringBuilder sb = new StringBuilder();
      for(int t=start;t<start+numTerm;t++) {
        pq.add(new Term("f", doc.get(t)));
        sb.append(doc.get(t)).append(' ');
      }

      TopDocs hits = s.search(pq, NUM_DOCS);
      boolean found = false;
      for(int j=0;j<hits.scoreDocs.length;j++) {
        if (hits.scoreDocs[j].doc == docID) {
          found = true;
          break;
        }
      }

      assertTrue("phrase '" + sb + "' not found; start=" + start, found);
    }

    reader.close();
    s.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521838/fstmerge_var2_4238433677721956801

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521854/fstmerge_var1_5022109941961955184
public void testBefore() throws IOException {
    // create an index
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);
    
    long now = System.currentTimeMillis();
    
    Document doc = new Document();
    // add time that is in the past
    doc.add(new Field("datefield", DateTools.timeToString(now - 1000,
        DateTools.Resolution.MILLISECOND), Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc.add(new Field("body", "Today is a very sunny day in New York City",
        Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    writer.close();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // filter that should preserve matches
    // DateFilter df1 = DateFilter.Before("datefield", now);
    TermRangeFilter df1 = new TermRangeFilter("datefield", DateTools
        .timeToString(now - 2000, DateTools.Resolution.MILLISECOND), DateTools
        .timeToString(now, DateTools.Resolution.MILLISECOND), false, true);
    // filter that should discard matches
    // DateFilter df2 = DateFilter.Before("datefield", now - 999999);
    TermRangeFilter df2 = new TermRangeFilter("datefield", DateTools
        .timeToString(0, DateTools.Resolution.MILLISECOND), DateTools
        .timeToString(now - 2000, DateTools.Resolution.MILLISECOND), true,
        false);
    
    // search something that doesn't exist with DateFilter
    Query query1 = new TermQuery(new Term("body", "NoMatchForThis"));
    
    // search for something that does exists
    Query query2 = new TermQuery(new Term("body", "sunny"));
    
    ScoreDoc[] result;
    
    // ensure that queries return expected results without DateFilter first
    result = searcher.search(query1, null, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query2, null, 1000).scoreDocs;
    assertEquals(1, result.length);
    
    // run queries with DateFilter
    result = searcher.search(query1, df1, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query1, df2, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query2, df1, 1000).scoreDocs;
    assertEquals(1, result.length);
    
    result = searcher.search(query2, df2, 1000).scoreDocs;
    assertEquals(0, result.length);
    reader.close();
    indexStore.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521854/fstmerge_base_4630540966936985643
public void testBefore() throws IOException {
    // create an index
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    
    long now = System.currentTimeMillis();
    
    Document doc = new Document();
    // add time that is in the past
    doc.add(new Field("datefield", DateTools.timeToString(now - 1000,
        DateTools.Resolution.MILLISECOND), Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc.add(new Field("body", "Today is a very sunny day in New York City",
        Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    writer.close();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // filter that should preserve matches
    // DateFilter df1 = DateFilter.Before("datefield", now);
    TermRangeFilter df1 = new TermRangeFilter("datefield", DateTools
        .timeToString(now - 2000, DateTools.Resolution.MILLISECOND), DateTools
        .timeToString(now, DateTools.Resolution.MILLISECOND), false, true);
    // filter that should discard matches
    // DateFilter df2 = DateFilter.Before("datefield", now - 999999);
    TermRangeFilter df2 = new TermRangeFilter("datefield", DateTools
        .timeToString(0, DateTools.Resolution.MILLISECOND), DateTools
        .timeToString(now - 2000, DateTools.Resolution.MILLISECOND), true,
        false);
    
    // search something that doesn't exist with DateFilter
    Query query1 = new TermQuery(new Term("body", "NoMatchForThis"));
    
    // search for something that does exists
    Query query2 = new TermQuery(new Term("body", "sunny"));
    
    ScoreDoc[] result;
    
    // ensure that queries return expected results without DateFilter first
    result = searcher.search(query1, null, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query2, null, 1000).scoreDocs;
    assertEquals(1, result.length);
    
    // run queries with DateFilter
    result = searcher.search(query1, df1, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query1, df2, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query2, df1, 1000).scoreDocs;
    assertEquals(1, result.length);
    
    result = searcher.search(query2, df2, 1000).scoreDocs;
    assertEquals(0, result.length);
    reader.close();
    indexStore.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521854/fstmerge_var2_5912788377203164257

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestDateFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521859/fstmerge_var1_2367625261092977310
public void testAfter() throws IOException {
    // create an index
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);
    
    long now = System.currentTimeMillis();
    
    Document doc = new Document();
    // add time that is in the future
    doc.add(new Field("datefield", DateTools.timeToString(now + 888888,
        DateTools.Resolution.MILLISECOND), Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc.add(new Field("body", "Today is a very sunny day in New York City",
        Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    writer.close();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // filter that should preserve matches
    // DateFilter df1 = DateFilter.After("datefield", now);
    TermRangeFilter df1 = new TermRangeFilter("datefield", DateTools
        .timeToString(now, DateTools.Resolution.MILLISECOND), DateTools
        .timeToString(now + 999999, DateTools.Resolution.MILLISECOND), true,
        false);
    // filter that should discard matches
    // DateFilter df2 = DateFilter.After("datefield", now + 999999);
    TermRangeFilter df2 = new TermRangeFilter("datefield", DateTools
        .timeToString(now + 999999, DateTools.Resolution.MILLISECOND),
        DateTools.timeToString(now + 999999999,
            DateTools.Resolution.MILLISECOND), false, true);
    
    // search something that doesn't exist with DateFilter
    Query query1 = new TermQuery(new Term("body", "NoMatchForThis"));
    
    // search for something that does exists
    Query query2 = new TermQuery(new Term("body", "sunny"));
    
    ScoreDoc[] result;
    
    // ensure that queries return expected results without DateFilter first
    result = searcher.search(query1, null, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query2, null, 1000).scoreDocs;
    assertEquals(1, result.length);
    
    // run queries with DateFilter
    result = searcher.search(query1, df1, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query1, df2, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query2, df1, 1000).scoreDocs;
    assertEquals(1, result.length);
    
    result = searcher.search(query2, df2, 1000).scoreDocs;
    assertEquals(0, result.length);
    reader.close();
    indexStore.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521859/fstmerge_base_2173513072052564486
public void testAfter() throws IOException {
    // create an index
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    
    long now = System.currentTimeMillis();
    
    Document doc = new Document();
    // add time that is in the future
    doc.add(new Field("datefield", DateTools.timeToString(now + 888888,
        DateTools.Resolution.MILLISECOND), Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    doc.add(new Field("body", "Today is a very sunny day in New York City",
        Field.Store.YES, Field.Index.ANALYZED));
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    writer.close();
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // filter that should preserve matches
    // DateFilter df1 = DateFilter.After("datefield", now);
    TermRangeFilter df1 = new TermRangeFilter("datefield", DateTools
        .timeToString(now, DateTools.Resolution.MILLISECOND), DateTools
        .timeToString(now + 999999, DateTools.Resolution.MILLISECOND), true,
        false);
    // filter that should discard matches
    // DateFilter df2 = DateFilter.After("datefield", now + 999999);
    TermRangeFilter df2 = new TermRangeFilter("datefield", DateTools
        .timeToString(now + 999999, DateTools.Resolution.MILLISECOND),
        DateTools.timeToString(now + 999999999,
            DateTools.Resolution.MILLISECOND), false, true);
    
    // search something that doesn't exist with DateFilter
    Query query1 = new TermQuery(new Term("body", "NoMatchForThis"));
    
    // search for something that does exists
    Query query2 = new TermQuery(new Term("body", "sunny"));
    
    ScoreDoc[] result;
    
    // ensure that queries return expected results without DateFilter first
    result = searcher.search(query1, null, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query2, null, 1000).scoreDocs;
    assertEquals(1, result.length);
    
    // run queries with DateFilter
    result = searcher.search(query1, df1, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query1, df2, 1000).scoreDocs;
    assertEquals(0, result.length);
    
    result = searcher.search(query2, df1, 1000).scoreDocs;
    assertEquals(1, result.length);
    
    result = searcher.search(query2, df2, 1000).scoreDocs;
    assertEquals(0, result.length);
    reader.close();
    indexStore.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521859/fstmerge_var2_2403050267199282928

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestDateFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521894/fstmerge_var1_5465103712509353236
private RAMDirectory getIndexStore(String field, String[] contents)
      throws IOException {
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
    for (int i = 0; i < contents.length; ++i) {
      Document doc = new Document();
      doc.add(new Field(field, contents[i], Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    writer.close();

    return indexStore;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521894/fstmerge_base_8293757821140163145
private RAMDirectory getIndexStore(String field, String[] contents)
      throws IOException {
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < contents.length; ++i) {
      Document doc = new Document();
      doc.add(new Field(field, contents[i], Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    writer.close();

    return indexStore;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521894/fstmerge_var2_9082394600771792852

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestWildcard.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521903/fstmerge_var1_8510577469005723517
public void testParsingAndSearching() throws Exception {
    String field = "content";
    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, field, new MockAnalyzer());
    qp.setAllowLeadingWildcard(true);
    String docs[] = {
        "\\ abcdefg1",
        "\\79 hijklmn1",
        "\\\\ opqrstu1",
    };
    // queries that should find all docs
    String matchAll[] = {
        "*", "*1", "**1", "*?", "*?1", "?*1", "**", "***", "\\\\*"
    };
    // queries that should find no docs
    String matchNone[] = {
        "a*h", "a?h", "*a*h", "?a", "a?",
    };
    // queries that should be parsed to prefix queries
    String matchOneDocPrefix[][] = {
        {"a*", "ab*", "abc*", }, // these should find only doc 0 
        {"h*", "hi*", "hij*", "\\\\7*"}, // these should find only doc 1
        {"o*", "op*", "opq*", "\\\\\\\\*"}, // these should find only doc 2
    };
    // queries that should be parsed to wildcard queries
    String matchOneDocWild[][] = {
        {"*a*", "*ab*", "*abc**", "ab*e*", "*g?", "*f?1", "abc**"}, // these should find only doc 0
        {"*h*", "*hi*", "*hij**", "hi*k*", "*n?", "*m?1", "hij**"}, // these should find only doc 1
        {"*o*", "*op*", "*opq**", "op*q*", "*u?", "*t?1", "opq**"}, // these should find only doc 2
    };

    // prepare the index
    RAMDirectory dir = new RAMDirectory();
    RandomIndexWriter iw = new RandomIndexWriter(random, dir);
    for (int i = 0; i < docs.length; i++) {
      Document doc = new Document();
      doc.add(new Field(field,docs[i],Store.NO,Index.ANALYZED));
      iw.addDocument(doc);
    }
    iw.close();
    
    IndexSearcher searcher = new IndexSearcher(dir, true);
    
    // test queries that must find all
    for (int i = 0; i < matchAll.length; i++) {
      String qtxt = matchAll[i];
      Query q = qp.parse(qtxt);
      if (VERBOSE) System.out.println("matchAll: qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
      ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
      assertEquals(docs.length,hits.length);
    }
    
    // test queries that must find none
    for (int i = 0; i < matchNone.length; i++) {
      String qtxt = matchNone[i];
      Query q = qp.parse(qtxt);
      if (VERBOSE) System.out.println("matchNone: qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
      ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
      assertEquals(0,hits.length);
    }

    // test queries that must be prefix queries and must find only one doc
    for (int i = 0; i < matchOneDocPrefix.length; i++) {
      for (int j = 0; j < matchOneDocPrefix[i].length; j++) {
        String qtxt = matchOneDocPrefix[i][j];
        Query q = qp.parse(qtxt);
        if (VERBOSE) System.out.println("match 1 prefix: doc="+docs[i]+" qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
        assertEquals(PrefixQuery.class, q.getClass());
        ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
        assertEquals(1,hits.length);
        assertEquals(i,hits[0].doc);
      }
    }

    // test queries that must be wildcard queries and must find only one doc
    for (int i = 0; i < matchOneDocPrefix.length; i++) {
      for (int j = 0; j < matchOneDocWild[i].length; j++) {
        String qtxt = matchOneDocWild[i][j];
        Query q = qp.parse(qtxt);
        if (VERBOSE) System.out.println("match 1 wild: doc="+docs[i]+" qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
        assertEquals(WildcardQuery.class, q.getClass());
        ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
        assertEquals(1,hits.length);
        assertEquals(i,hits[0].doc);
      }
    }

    searcher.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521903/fstmerge_base_7419027339072120479
public void testParsingAndSearching() throws Exception {
    String field = "content";
    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, field, new MockAnalyzer());
    qp.setAllowLeadingWildcard(true);
    String docs[] = {
        "\\ abcdefg1",
        "\\79 hijklmn1",
        "\\\\ opqrstu1",
    };
    // queries that should find all docs
    String matchAll[] = {
        "*", "*1", "**1", "*?", "*?1", "?*1", "**", "***", "\\\\*"
    };
    // queries that should find no docs
    String matchNone[] = {
        "a*h", "a?h", "*a*h", "?a", "a?",
    };
    // queries that should be parsed to prefix queries
    String matchOneDocPrefix[][] = {
        {"a*", "ab*", "abc*", }, // these should find only doc 0 
        {"h*", "hi*", "hij*", "\\\\7*"}, // these should find only doc 1
        {"o*", "op*", "opq*", "\\\\\\\\*"}, // these should find only doc 2
    };
    // queries that should be parsed to wildcard queries
    String matchOneDocWild[][] = {
        {"*a*", "*ab*", "*abc**", "ab*e*", "*g?", "*f?1", "abc**"}, // these should find only doc 0
        {"*h*", "*hi*", "*hij**", "hi*k*", "*n?", "*m?1", "hij**"}, // these should find only doc 1
        {"*o*", "*op*", "*opq**", "op*q*", "*u?", "*t?1", "opq**"}, // these should find only doc 2
    };

    // prepare the index
    RAMDirectory dir = new RAMDirectory();
    RandomIndexWriter iw = new RandomIndexWriter(random, dir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < docs.length; i++) {
      Document doc = new Document();
      doc.add(new Field(field,docs[i],Store.NO,Index.ANALYZED));
      iw.addDocument(doc);
    }
    iw.close();
    
    IndexSearcher searcher = new IndexSearcher(dir, true);
    
    // test queries that must find all
    for (int i = 0; i < matchAll.length; i++) {
      String qtxt = matchAll[i];
      Query q = qp.parse(qtxt);
      if (VERBOSE) System.out.println("matchAll: qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
      ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
      assertEquals(docs.length,hits.length);
    }
    
    // test queries that must find none
    for (int i = 0; i < matchNone.length; i++) {
      String qtxt = matchNone[i];
      Query q = qp.parse(qtxt);
      if (VERBOSE) System.out.println("matchNone: qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
      ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
      assertEquals(0,hits.length);
    }

    // test queries that must be prefix queries and must find only one doc
    for (int i = 0; i < matchOneDocPrefix.length; i++) {
      for (int j = 0; j < matchOneDocPrefix[i].length; j++) {
        String qtxt = matchOneDocPrefix[i][j];
        Query q = qp.parse(qtxt);
        if (VERBOSE) System.out.println("match 1 prefix: doc="+docs[i]+" qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
        assertEquals(PrefixQuery.class, q.getClass());
        ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
        assertEquals(1,hits.length);
        assertEquals(i,hits[0].doc);
      }
    }

    // test queries that must be wildcard queries and must find only one doc
    for (int i = 0; i < matchOneDocPrefix.length; i++) {
      for (int j = 0; j < matchOneDocWild[i].length; j++) {
        String qtxt = matchOneDocWild[i][j];
        Query q = qp.parse(qtxt);
        if (VERBOSE) System.out.println("match 1 wild: doc="+docs[i]+" qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
        assertEquals(WildcardQuery.class, q.getClass());
        ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
        assertEquals(1,hits.length);
        assertEquals(i,hits[0].doc);
      }
    }

    searcher.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521903/fstmerge_var2_5619301706193158322

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestWildcard.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521914/fstmerge_var1_3852242658677641024
public void testPhrasePrefix() throws IOException {
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);
    Document doc1 = new Document();
    Document doc2 = new Document();
    Document doc3 = new Document();
    Document doc4 = new Document();
    Document doc5 = new Document();
    doc1.add(new Field("body", "blueberry pie", Field.Store.YES,
        Field.Index.ANALYZED));
    doc2.add(new Field("body", "blueberry strudel", Field.Store.YES,
        Field.Index.ANALYZED));
    doc3.add(new Field("body", "blueberry pizza", Field.Store.YES,
        Field.Index.ANALYZED));
    doc4.add(new Field("body", "blueberry chewing gum", Field.Store.YES,
        Field.Index.ANALYZED));
    doc5.add(new Field("body", "piccadilly circus", Field.Store.YES,
        Field.Index.ANALYZED));
    writer.addDocument(doc1);
    writer.addDocument(doc2);
    writer.addDocument(doc3);
    writer.addDocument(doc4);
    writer.addDocument(doc5);
    IndexReader reader = writer.getReader();
    writer.close();
    
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();
    MultiPhraseQuery query1 = new MultiPhraseQuery();
    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();
    MultiPhraseQuery query2 = new MultiPhraseQuery();
    query1.add(new Term("body", "blueberry"));
    query2.add(new Term("body", "strawberry"));
    
    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();
    
    // this TermEnum gives "piccadilly", "pie" and "pizza".
    String prefix = "pi";
    TermsEnum te = MultiFields.getFields(reader).terms("body").iterator();
    te.seek(new BytesRef(prefix));
    do {
      String s = te.term().utf8ToString();
      if (s.startsWith(prefix)) {
        termsWithPrefix.add(new Term("body", s));
      } else {
        break;
      }
    } while (te.next() != null);
    
    query1.add(termsWithPrefix.toArray(new Term[0]));
    query2.add(termsWithPrefix.toArray(new Term[0]));
    
    ScoreDoc[] result;
    result = searcher.search(query1, null, 1000).scoreDocs;
    assertEquals(2, result.length);
    
    result = searcher.search(query2, null, 1000).scoreDocs;
    assertEquals(0, result.length);
    searcher.close();
    reader.close();
    indexStore.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521914/fstmerge_base_7370220462706757962
public void testPhrasePrefix() throws IOException {
    RAMDirectory indexStore = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc1 = new Document();
    Document doc2 = new Document();
    Document doc3 = new Document();
    Document doc4 = new Document();
    Document doc5 = new Document();
    doc1.add(new Field("body", "blueberry pie", Field.Store.YES,
        Field.Index.ANALYZED));
    doc2.add(new Field("body", "blueberry strudel", Field.Store.YES,
        Field.Index.ANALYZED));
    doc3.add(new Field("body", "blueberry pizza", Field.Store.YES,
        Field.Index.ANALYZED));
    doc4.add(new Field("body", "blueberry chewing gum", Field.Store.YES,
        Field.Index.ANALYZED));
    doc5.add(new Field("body", "piccadilly circus", Field.Store.YES,
        Field.Index.ANALYZED));
    writer.addDocument(doc1);
    writer.addDocument(doc2);
    writer.addDocument(doc3);
    writer.addDocument(doc4);
    writer.addDocument(doc5);
    IndexReader reader = writer.getReader();
    writer.close();
    
    IndexSearcher searcher = new IndexSearcher(reader);
    
    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();
    MultiPhraseQuery query1 = new MultiPhraseQuery();
    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();
    MultiPhraseQuery query2 = new MultiPhraseQuery();
    query1.add(new Term("body", "blueberry"));
    query2.add(new Term("body", "strawberry"));
    
    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();
    
    // this TermEnum gives "piccadilly", "pie" and "pizza".
    String prefix = "pi";
    TermsEnum te = MultiFields.getFields(reader).terms("body").iterator();
    te.seek(new BytesRef(prefix));
    do {
      String s = te.term().utf8ToString();
      if (s.startsWith(prefix)) {
        termsWithPrefix.add(new Term("body", s));
      } else {
        break;
      }
    } while (te.next() != null);
    
    query1.add(termsWithPrefix.toArray(new Term[0]));
    query2.add(termsWithPrefix.toArray(new Term[0]));
    
    ScoreDoc[] result;
    result = searcher.search(query1, null, 1000).scoreDocs;
    assertEquals(2, result.length);
    
    result = searcher.search(query2, null, 1000).scoreDocs;
    assertEquals(0, result.length);
    searcher.close();
    reader.close();
    indexStore.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583521914/fstmerge_var2_6690968956999312233

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522121/fstmerge_var1_4274237838974672909
public void testPrefixFilter() throws Exception {
    RAMDirectory directory = new RAMDirectory();

    String[] categories = new String[] {"/Computers/Linux",
                                        "/Computers/Mac/One",
                                        "/Computers/Mac/Two",
                                        "/Computers/Windows"};
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    for (int i = 0; i < categories.length; i++) {
      Document doc = new Document();
      doc.add(new Field("category", categories[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    IndexReader reader = writer.getReader();

    // PrefixFilter combined with ConstantScoreQuery
    PrefixFilter filter = new PrefixFilter(new Term("category", "/Computers"));
    Query query = new ConstantScoreQuery(filter);
    IndexSearcher searcher = new IndexSearcher(reader);
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(4, hits.length);

    // test middle of values
    filter = new PrefixFilter(new Term("category", "/Computers/Mac"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(2, hits.length);

    // test start of values
    filter = new PrefixFilter(new Term("category", "/Computers/Linux"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);

    // test end of values
    filter = new PrefixFilter(new Term("category", "/Computers/Windows"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);

    // test non-existant
    filter = new PrefixFilter(new Term("category", "/Computers/ObsoleteOS"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // test non-existant, before values
    filter = new PrefixFilter(new Term("category", "/Computers/AAA"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // test non-existant, after values
    filter = new PrefixFilter(new Term("category", "/Computers/ZZZ"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // test zero length prefix
    filter = new PrefixFilter(new Term("category", ""));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(4, hits.length);

    // test non existent field
    filter = new PrefixFilter(new Term("nonexistantfield", "/Computers"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    
    writer.close();
    searcher.close();
    reader.close();
    directory.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522121/fstmerge_base_8851752376735905948
public void testPrefixFilter() throws Exception {
    RAMDirectory directory = new RAMDirectory();

    String[] categories = new String[] {"/Computers/Linux",
                                        "/Computers/Mac/One",
                                        "/Computers/Mac/Two",
                                        "/Computers/Windows"};
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < categories.length; i++) {
      Document doc = new Document();
      doc.add(new Field("category", categories[i], Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    IndexReader reader = writer.getReader();

    // PrefixFilter combined with ConstantScoreQuery
    PrefixFilter filter = new PrefixFilter(new Term("category", "/Computers"));
    Query query = new ConstantScoreQuery(filter);
    IndexSearcher searcher = new IndexSearcher(reader);
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(4, hits.length);

    // test middle of values
    filter = new PrefixFilter(new Term("category", "/Computers/Mac"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(2, hits.length);

    // test start of values
    filter = new PrefixFilter(new Term("category", "/Computers/Linux"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);

    // test end of values
    filter = new PrefixFilter(new Term("category", "/Computers/Windows"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);

    // test non-existant
    filter = new PrefixFilter(new Term("category", "/Computers/ObsoleteOS"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // test non-existant, before values
    filter = new PrefixFilter(new Term("category", "/Computers/AAA"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // test non-existant, after values
    filter = new PrefixFilter(new Term("category", "/Computers/ZZZ"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);

    // test zero length prefix
    filter = new PrefixFilter(new Term("category", ""));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(4, hits.length);

    // test non existent field
    filter = new PrefixFilter(new Term("nonexistantfield", "/Computers"));
    query = new ConstantScoreQuery(filter);
    hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(0, hits.length);
    
    writer.close();
    searcher.close();
    reader.close();
    directory.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522121/fstmerge_var2_5247804696138130534

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestPrefixFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522135/fstmerge_var1_1020340761808297237
@Override
  protected void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    dir = new MockRAMDirectory();
    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));
    
    Document doc = new Document();
    Field field = new Field("field", "", Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field);

    for (int i = 0; i < 2000*_TestUtil.getRandomMultiplier(); i++) {
      field.setValue(_TestUtil.randomUnicodeString(random, 10));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522135/fstmerge_base_3847020356077311490
@Override
  protected void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    dir = new MockRAMDirectory();
    // TODO: fix mocktokenizer to not extend chartokenizer, so you can have an 'empty' keyword.
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.KEYWORD, false)));
    
    Document doc = new Document();
    Field field = new Field("field", "", Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field);

    for (int i = 0; i < 2000*_TestUtil.getRandomMultiplier(); i++) {
      field.setValue(_TestUtil.randomUnicodeString(random, 10));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522135/fstmerge_var2_8614977542709611537

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestPrefixRandom.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522208/fstmerge_var1_4995700178827843653
public void testSimilarity() throws Exception {
    RAMDirectory store = new RAMDirectory();
    Random random = newRandom();
    RandomIndexWriter writer = new RandomIndexWriter(random, store, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
        .setSimilarity(new SimpleSimilarity()));
    
    Document d1 = new Document();
    d1.add(new Field("field", "a c", Field.Store.YES, Field.Index.ANALYZED));

    Document d2 = new Document();
    d2.add(new Field("field", "a b c", Field.Store.YES, Field.Index.ANALYZED));
    
    writer.addDocument(d1);
    writer.addDocument(d2);
    IndexReader reader = writer.getReader();
    writer.close();

    Searcher searcher = new IndexSearcher(reader);
    searcher.setSimilarity(new SimpleSimilarity());

    Term a = new Term("field", "a");
    Term b = new Term("field", "b");
    Term c = new Term("field", "c");

    searcher.search(new TermQuery(b), new Collector() {
         private Scorer scorer;
         @Override
        public void setScorer(Scorer scorer) throws IOException {
           this.scorer = scorer; 
         }
         @Override
        public final void collect(int doc) throws IOException {
           assertEquals(1.0f, scorer.score());
         }
         @Override
        public void setNextReader(IndexReader reader, int docBase) {}
         @Override
        public boolean acceptsDocsOutOfOrder() {
           return true;
         }
       });

    BooleanQuery bq = new BooleanQuery();
    bq.add(new TermQuery(a), BooleanClause.Occur.SHOULD);
    bq.add(new TermQuery(b), BooleanClause.Occur.SHOULD);
    //System.out.println(bq.toString("field"));
    searcher.search(bq, new Collector() {
         private int base = 0;
         private Scorer scorer;
         @Override
        public void setScorer(Scorer scorer) throws IOException {
           this.scorer = scorer; 
         }
         @Override
        public final void collect(int doc) throws IOException {
           //System.out.println("Doc=" + doc + " score=" + score);
           assertEquals((float)doc+base+1, scorer.score());
         }
         @Override
        public void setNextReader(IndexReader reader, int docBase) {
           base = docBase;
         }
         @Override
        public boolean acceptsDocsOutOfOrder() {
           return true;
         }
       });

    PhraseQuery pq = new PhraseQuery();
    pq.add(a);
    pq.add(c);
    //System.out.println(pq.toString("field"));
    searcher.search(pq,
       new Collector() {
         private Scorer scorer;
         @Override
         public void setScorer(Scorer scorer) throws IOException {
          this.scorer = scorer; 
         }
         @Override
         public final void collect(int doc) throws IOException {
           //System.out.println("Doc=" + doc + " score=" + score);
           assertEquals(1.0f, scorer.score());
         }
         @Override
         public void setNextReader(IndexReader reader, int docBase) {}
         @Override
         public boolean acceptsDocsOutOfOrder() {
           return true;
         }
       });

    pq.setSlop(2);
    //System.out.println(pq.toString("field"));
    searcher.search(pq, new Collector() {
      private Scorer scorer;
      @Override
      public void setScorer(Scorer scorer) throws IOException {
        this.scorer = scorer; 
      }
      @Override
      public final void collect(int doc) throws IOException {
        //System.out.println("Doc=" + doc + " score=" + score);
        assertEquals(2.0f, scorer.score());
      }
      @Override
      public void setNextReader(IndexReader reader, int docBase) {}
      @Override
      public boolean acceptsDocsOutOfOrder() {
        return true;
      }
    });

    searcher.close();
    reader.close();
    store.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522208/fstmerge_base_772083783049861262
public void testSimilarity() throws Exception {
    RAMDirectory store = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), store, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
        .setSimilarity(new SimpleSimilarity()));
    
    Document d1 = new Document();
    d1.add(new Field("field", "a c", Field.Store.YES, Field.Index.ANALYZED));

    Document d2 = new Document();
    d2.add(new Field("field", "a b c", Field.Store.YES, Field.Index.ANALYZED));
    
    writer.addDocument(d1);
    writer.addDocument(d2);
    IndexReader reader = writer.getReader();
    writer.close();

    Searcher searcher = new IndexSearcher(reader);
    searcher.setSimilarity(new SimpleSimilarity());

    Term a = new Term("field", "a");
    Term b = new Term("field", "b");
    Term c = new Term("field", "c");

    searcher.search(new TermQuery(b), new Collector() {
         private Scorer scorer;
         @Override
        public void setScorer(Scorer scorer) throws IOException {
           this.scorer = scorer; 
         }
         @Override
        public final void collect(int doc) throws IOException {
           assertEquals(1.0f, scorer.score());
         }
         @Override
        public void setNextReader(IndexReader reader, int docBase) {}
         @Override
        public boolean acceptsDocsOutOfOrder() {
           return true;
         }
       });

    BooleanQuery bq = new BooleanQuery();
    bq.add(new TermQuery(a), BooleanClause.Occur.SHOULD);
    bq.add(new TermQuery(b), BooleanClause.Occur.SHOULD);
    //System.out.println(bq.toString("field"));
    searcher.search(bq, new Collector() {
         private int base = 0;
         private Scorer scorer;
         @Override
        public void setScorer(Scorer scorer) throws IOException {
           this.scorer = scorer; 
         }
         @Override
        public final void collect(int doc) throws IOException {
           //System.out.println("Doc=" + doc + " score=" + score);
           assertEquals((float)doc+base+1, scorer.score());
         }
         @Override
        public void setNextReader(IndexReader reader, int docBase) {
           base = docBase;
         }
         @Override
        public boolean acceptsDocsOutOfOrder() {
           return true;
         }
       });

    PhraseQuery pq = new PhraseQuery();
    pq.add(a);
    pq.add(c);
    //System.out.println(pq.toString("field"));
    searcher.search(pq,
       new Collector() {
         private Scorer scorer;
         @Override
         public void setScorer(Scorer scorer) throws IOException {
          this.scorer = scorer; 
         }
         @Override
         public final void collect(int doc) throws IOException {
           //System.out.println("Doc=" + doc + " score=" + score);
           assertEquals(1.0f, scorer.score());
         }
         @Override
         public void setNextReader(IndexReader reader, int docBase) {}
         @Override
         public boolean acceptsDocsOutOfOrder() {
           return true;
         }
       });

    pq.setSlop(2);
    //System.out.println(pq.toString("field"));
    searcher.search(pq, new Collector() {
      private Scorer scorer;
      @Override
      public void setScorer(Scorer scorer) throws IOException {
        this.scorer = scorer; 
      }
      @Override
      public final void collect(int doc) throws IOException {
        //System.out.println("Doc=" + doc + " score=" + score);
        assertEquals(2.0f, scorer.score());
      }
      @Override
      public void setNextReader(IndexReader reader, int docBase) {}
      @Override
      public boolean acceptsDocsOutOfOrder() {
        return true;
      }
    });

    searcher.close();
    reader.close();
    store.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522208/fstmerge_var2_3920497884166614860

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestSimilarity.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522270/fstmerge_var1_8231533892089776484
@Override
    protected void setUp() throws Exception {
        super.setUp();

        rnd = newRandom();
        
        String[] data = new String [] {
            "A 1 2 3 4 5 6",
            "Z       4 5 6",
            null,
            "B   2   4 5 6",
            "Y     3   5 6",
            null,
            "C     3     6",
            "X       4 5 6"
        };

        index = new RAMDirectory();
        RandomIndexWriter w = new RandomIndexWriter(rnd, index);

        for (int i = 0; i < data.length; i++) {
            Document doc = new Document();
            doc.add(new Field("id", String.valueOf(i), Field.Store.YES, Field.Index.NOT_ANALYZED));//Field.Keyword("id",String.valueOf(i)));
            doc.add(new Field("all", "all", Field.Store.YES, Field.Index.NOT_ANALYZED));//Field.Keyword("all","all"));
            if (null != data[i]) {
                doc.add(new Field("data", data[i], Field.Store.YES, Field.Index.ANALYZED));//Field.Text("data",data[i]));
            }
            w.addDocument(doc);
        }

        r = w.getReader();
        s = new IndexSearcher(r);
        w.close();
//System.out.println("Set up " + getName());
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522270/fstmerge_base_876625085011988844
@Override
    protected void setUp() throws Exception {
        super.setUp();

        rnd = newRandom();
        
        String[] data = new String [] {
            "A 1 2 3 4 5 6",
            "Z       4 5 6",
            null,
            "B   2   4 5 6",
            "Y     3   5 6",
            null,
            "C     3     6",
            "X       4 5 6"
        };

        index = new RAMDirectory();
        RandomIndexWriter w = new RandomIndexWriter(rnd, index, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer()));

        for (int i = 0; i < data.length; i++) {
            Document doc = new Document();
            doc.add(new Field("id", String.valueOf(i), Field.Store.YES, Field.Index.NOT_ANALYZED));//Field.Keyword("id",String.valueOf(i)));
            doc.add(new Field("all", "all", Field.Store.YES, Field.Index.NOT_ANALYZED));//Field.Keyword("all","all"));
            if (null != data[i]) {
                doc.add(new Field("data", data[i], Field.Store.YES, Field.Index.ANALYZED));//Field.Text("data",data[i]));
            }
            w.addDocument(doc);
        }

        r = w.getReader();
        s = new IndexSearcher(r);
        w.close();
//System.out.println("Set up " + getName());
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522270/fstmerge_var2_3163326938648083906

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522375/fstmerge_var1_3287050263299396413
@Override
  protected void setUp() throws Exception {
    super.setUp();
    
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);

    for (int i = 0; i < 5137; ++i) {
      Document doc = new Document();
      doc.add(new Field(FIELD, "meaninglessnames", Field.Store.YES,
                        Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    { 
      Document doc = new Document();
      doc.add(new Field(FIELD, "tangfulin", Field.Store.YES,
                        Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }

    for (int i = 5138; i < 11377; ++i) {
      Document doc = new Document();
      doc.add(new Field(FIELD, "meaninglessnames", Field.Store.YES,
                        Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    {
      Document doc = new Document();
      doc.add(new Field(FIELD, "tangfulin", Field.Store.YES,
                        Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522375/fstmerge_base_4989274364517238550
@Override
  protected void setUp() throws Exception {
    super.setUp();
    
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));

    for (int i = 0; i < 5137; ++i) {
      Document doc = new Document();
      doc.add(new Field(FIELD, "meaninglessnames", Field.Store.YES,
                        Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    { 
      Document doc = new Document();
      doc.add(new Field(FIELD, "tangfulin", Field.Store.YES,
                        Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }

    for (int i = 5138; i < 11377; ++i) {
      Document doc = new Document();
      doc.add(new Field(FIELD, "meaninglessnames", Field.Store.YES,
                        Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    {
      Document doc = new Document();
      doc.add(new Field(FIELD, "tangfulin", Field.Store.YES,
                        Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);
    }
    
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522375/fstmerge_var2_3958341761709084048

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestPrefixInBooleanQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522408/fstmerge_var1_8014896705792093888
public void testOutOfOrderCollection() throws Exception {

    Directory dir = new RAMDirectory();
    Random random = newRandom();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
    for (int i = 0; i < 10; i++) {
      writer.addDocument(new Document());
    }
    
    boolean[] inOrder = new boolean[] { false, true };
    String[] actualTSDCClass = new String[] {
        "OutOfOrderTopScoreDocCollector", 
        "InOrderTopScoreDocCollector" 
    };
    
    BooleanQuery bq = new BooleanQuery();
    // Add a Query with SHOULD, since bw.scorer() returns BooleanScorer2
    // which delegates to BS if there are no mandatory clauses.
    bq.add(new MatchAllDocsQuery(), Occur.SHOULD);
    // Set minNrShouldMatch to 1 so that BQ will not optimize rewrite to return
    // the clause instead of BQ.
    bq.setMinimumNumberShouldMatch(1);
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    for (int i = 0; i < inOrder.length; i++) {
      TopDocsCollector<ScoreDoc> tdc = TopScoreDocCollector.create(3, inOrder[i]);
      assertEquals("org.apache.lucene.search.TopScoreDocCollector$" + actualTSDCClass[i], tdc.getClass().getName());
      
      searcher.search(new MatchAllDocsQuery(), tdc);
      
      ScoreDoc[] sd = tdc.topDocs().scoreDocs;
      assertEquals(3, sd.length);
      for (int j = 0; j < sd.length; j++) {
        assertEquals("expected doc Id " + j + " found " + sd[j].doc, j, sd[j].doc);
      }
    }
    writer.close();
    searcher.close();
    reader.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522408/fstmerge_base_2747215088582889192
public void testOutOfOrderCollection() throws Exception {

    Directory dir = new RAMDirectory();
    Random random = newRandom();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < 10; i++) {
      writer.addDocument(new Document());
    }
    
    boolean[] inOrder = new boolean[] { false, true };
    String[] actualTSDCClass = new String[] {
        "OutOfOrderTopScoreDocCollector", 
        "InOrderTopScoreDocCollector" 
    };
    
    BooleanQuery bq = new BooleanQuery();
    // Add a Query with SHOULD, since bw.scorer() returns BooleanScorer2
    // which delegates to BS if there are no mandatory clauses.
    bq.add(new MatchAllDocsQuery(), Occur.SHOULD);
    // Set minNrShouldMatch to 1 so that BQ will not optimize rewrite to return
    // the clause instead of BQ.
    bq.setMinimumNumberShouldMatch(1);
    IndexReader reader = writer.getReader();
    IndexSearcher searcher = new IndexSearcher(reader);
    for (int i = 0; i < inOrder.length; i++) {
      TopDocsCollector<ScoreDoc> tdc = TopScoreDocCollector.create(3, inOrder[i]);
      assertEquals("org.apache.lucene.search.TopScoreDocCollector$" + actualTSDCClass[i], tdc.getClass().getName());
      
      searcher.search(new MatchAllDocsQuery(), tdc);
      
      ScoreDoc[] sd = tdc.topDocs().scoreDocs;
      assertEquals(3, sd.length);
      for (int j = 0; j < sd.length; j++) {
        assertEquals("expected doc Id " + j + " found " + sd[j].doc, j, sd[j].doc);
      }
    }
    writer.close();
    searcher.close();
    reader.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522408/fstmerge_var2_5493780369988173295

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestTopScoreDocCollector.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522417/fstmerge_var1_5026381480829942814
@Override
  protected void setUp() throws Exception {
    super.setUp();
    Random r = newRandom();
    NUM_DOCS = 1000 * _TestUtil.getRandomMultiplier();
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(r, directory);
    long theLong = Long.MAX_VALUE;
    double theDouble = Double.MAX_VALUE;
    byte theByte = Byte.MAX_VALUE;
    short theShort = Short.MAX_VALUE;
    int theInt = Integer.MAX_VALUE;
    float theFloat = Float.MAX_VALUE;
    unicodeStrings = new String[NUM_DOCS];
    for (int i = 0; i < NUM_DOCS; i++){
      Document doc = new Document();
      doc.add(new Field("theLong", String.valueOf(theLong--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(new Field("theDouble", String.valueOf(theDouble--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(new Field("theByte", String.valueOf(theByte--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(new Field("theShort", String.valueOf(theShort--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(new Field("theInt", String.valueOf(theInt--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(new Field("theFloat", String.valueOf(theFloat--), Field.Store.NO, Field.Index.NOT_ANALYZED));

      // sometimes skip the field:
      if (r.nextInt(40) != 17) {
        String s = null;
        if (i > 0 && r.nextInt(3) == 1) {
          // reuse past string -- try to find one that's not null
          for(int iter=0;iter<10 && s==null;iter++) {
            s = unicodeStrings[r.nextInt(i)];
          }
          if (s == null) {
            s = _TestUtil.randomUnicodeString(r, 250);
          }
        } else {
          s = _TestUtil.randomUnicodeString(r, 250);
        }
        unicodeStrings[i] = s;
        doc.add(new Field("theRandomUnicodeString", unicodeStrings[i], Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));
      }
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522417/fstmerge_base_1356980388568410391
@Override
  protected void setUp() throws Exception {
    super.setUp();
    Random r = newRandom();
    NUM_DOCS = 1000 * _TestUtil.getRandomMultiplier();
    RAMDirectory directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(r, directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    long theLong = Long.MAX_VALUE;
    double theDouble = Double.MAX_VALUE;
    byte theByte = Byte.MAX_VALUE;
    short theShort = Short.MAX_VALUE;
    int theInt = Integer.MAX_VALUE;
    float theFloat = Float.MAX_VALUE;
    unicodeStrings = new String[NUM_DOCS];
    for (int i = 0; i < NUM_DOCS; i++){
      Document doc = new Document();
      doc.add(new Field("theLong", String.valueOf(theLong--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(new Field("theDouble", String.valueOf(theDouble--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(new Field("theByte", String.valueOf(theByte--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(new Field("theShort", String.valueOf(theShort--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(new Field("theInt", String.valueOf(theInt--), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(new Field("theFloat", String.valueOf(theFloat--), Field.Store.NO, Field.Index.NOT_ANALYZED));

      // sometimes skip the field:
      if (r.nextInt(40) != 17) {
        String s = null;
        if (i > 0 && r.nextInt(3) == 1) {
          // reuse past string -- try to find one that's not null
          for(int iter=0;iter<10 && s==null;iter++) {
            s = unicodeStrings[r.nextInt(i)];
          }
          if (s == null) {
            s = _TestUtil.randomUnicodeString(r, 250);
          }
        } else {
          s = _TestUtil.randomUnicodeString(r, 250);
        }
        unicodeStrings[i] = s;
        doc.add(new Field("theRandomUnicodeString", unicodeStrings[i], Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));
      }
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522417/fstmerge_var2_7941671540794070749

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestFieldCache.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522497/fstmerge_var1_3301964444401158031
public void testFilterWorks() throws Exception {
    Directory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
    for (int i = 0; i < 500; i++) {
      Document document = new Document();
      document.add(new Field("field", English.intToEnglish(i) + " equals " + English.intToEnglish(i),
              Field.Store.NO, Field.Index.ANALYZED));
      writer.addDocument(document);
    }
    IndexReader reader = writer.getReader();
    writer.close();

    SpanTermQuery query = new SpanTermQuery(new Term("field", English.intToEnglish(10).trim()));
    SpanQueryFilter filter = new SpanQueryFilter(query);
    SpanFilterResult result = filter.bitSpans(reader);
    DocIdSet docIdSet = result.getDocIdSet();
    assertTrue("docIdSet is null and it shouldn't be", docIdSet != null);
    assertContainsDocId("docIdSet doesn't contain docId 10", docIdSet, 10);
    List<SpanFilterResult.PositionInfo> spans = result.getPositions();
    assertTrue("spans is null and it shouldn't be", spans != null);
    int size = getDocIdSetSize(docIdSet);
    assertTrue("spans Size: " + spans.size() + " is not: " + size, spans.size() == size);
    for (final SpanFilterResult.PositionInfo info: spans) {
      assertTrue("info is null and it shouldn't be", info != null);
      //The doc should indicate the bit is on
      assertContainsDocId("docIdSet doesn't contain docId " + info.getDoc(), docIdSet, info.getDoc());
      //There should be two positions in each
      assertTrue("info.getPositions() Size: " + info.getPositions().size() + " is not: " + 2, info.getPositions().size() == 2);
    }
    reader.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522497/fstmerge_base_3082020906386975307
public void testFilterWorks() throws Exception {
    Directory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < 500; i++) {
      Document document = new Document();
      document.add(new Field("field", English.intToEnglish(i) + " equals " + English.intToEnglish(i),
              Field.Store.NO, Field.Index.ANALYZED));
      writer.addDocument(document);
    }
    IndexReader reader = writer.getReader();
    writer.close();

    SpanTermQuery query = new SpanTermQuery(new Term("field", English.intToEnglish(10).trim()));
    SpanQueryFilter filter = new SpanQueryFilter(query);
    SpanFilterResult result = filter.bitSpans(reader);
    DocIdSet docIdSet = result.getDocIdSet();
    assertTrue("docIdSet is null and it shouldn't be", docIdSet != null);
    assertContainsDocId("docIdSet doesn't contain docId 10", docIdSet, 10);
    List<SpanFilterResult.PositionInfo> spans = result.getPositions();
    assertTrue("spans is null and it shouldn't be", spans != null);
    int size = getDocIdSetSize(docIdSet);
    assertTrue("spans Size: " + spans.size() + " is not: " + size, spans.size() == size);
    for (final SpanFilterResult.PositionInfo info: spans) {
      assertTrue("info is null and it shouldn't be", info != null);
      //The doc should indicate the bit is on
      assertContainsDocId("docIdSet doesn't contain docId " + info.getDoc(), docIdSet, info.getDoc());
      //There should be two positions in each
      assertTrue("info.getPositions() Size: " + info.getPositions().size() + " is not: " + 2, info.getPositions().size() == 2);
    }
    reader.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522497/fstmerge_var2_7901429376417836682

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestSpanQueryFilter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522511/fstmerge_var1_2613435359414197148
@BeforeClass
  public static void beforeClass() throws Exception {
    directory = new RAMDirectory();
    Random random = newStaticRandom(TestNumericRangeQuery64.class);
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
    
    NumericField
      field8 = new NumericField("field8", 8, Field.Store.YES, true),
      field6 = new NumericField("field6", 6, Field.Store.YES, true),
      field4 = new NumericField("field4", 4, Field.Store.YES, true),
      field2 = new NumericField("field2", 2, Field.Store.YES, true),
      fieldNoTrie = new NumericField("field"+Integer.MAX_VALUE, Integer.MAX_VALUE, Field.Store.YES, true),
      ascfield8 = new NumericField("ascfield8", 8, Field.Store.NO, true),
      ascfield6 = new NumericField("ascfield6", 6, Field.Store.NO, true),
      ascfield4 = new NumericField("ascfield4", 4, Field.Store.NO, true),
      ascfield2 = new NumericField("ascfield2", 2, Field.Store.NO, true);
    
    Document doc = new Document();
    // add fields, that have a distance to test general functionality
    doc.add(field8); doc.add(field6); doc.add(field4); doc.add(field2); doc.add(fieldNoTrie);
    // add ascending fields with a distance of 1, beginning at -noDocs/2 to test the correct splitting of range and inclusive/exclusive
    doc.add(ascfield8); doc.add(ascfield6); doc.add(ascfield4); doc.add(ascfield2);
    
    // Add a series of noDocs docs with increasing long values, by updating the fields
    for (int l=0; l<noDocs; l++) {
      long val=distance*l+startOffset;
      field8.setLongValue(val);
      field6.setLongValue(val);
      field4.setLongValue(val);
      field2.setLongValue(val);
      fieldNoTrie.setLongValue(val);

      val=l-(noDocs/2);
      ascfield8.setLongValue(val);
      ascfield6.setLongValue(val);
      ascfield4.setLongValue(val);
      ascfield2.setLongValue(val);
      writer.addDocument(doc);
    }
  
    reader = writer.getReader();
    searcher=new IndexSearcher(reader);
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522511/fstmerge_base_2180053861007223342
@BeforeClass
  public static void beforeClass() throws Exception {
    directory = new RAMDirectory();
    Random random = newStaticRandom(TestNumericRangeQuery64.class);
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    
    NumericField
      field8 = new NumericField("field8", 8, Field.Store.YES, true),
      field6 = new NumericField("field6", 6, Field.Store.YES, true),
      field4 = new NumericField("field4", 4, Field.Store.YES, true),
      field2 = new NumericField("field2", 2, Field.Store.YES, true),
      fieldNoTrie = new NumericField("field"+Integer.MAX_VALUE, Integer.MAX_VALUE, Field.Store.YES, true),
      ascfield8 = new NumericField("ascfield8", 8, Field.Store.NO, true),
      ascfield6 = new NumericField("ascfield6", 6, Field.Store.NO, true),
      ascfield4 = new NumericField("ascfield4", 4, Field.Store.NO, true),
      ascfield2 = new NumericField("ascfield2", 2, Field.Store.NO, true);
    
    Document doc = new Document();
    // add fields, that have a distance to test general functionality
    doc.add(field8); doc.add(field6); doc.add(field4); doc.add(field2); doc.add(fieldNoTrie);
    // add ascending fields with a distance of 1, beginning at -noDocs/2 to test the correct splitting of range and inclusive/exclusive
    doc.add(ascfield8); doc.add(ascfield6); doc.add(ascfield4); doc.add(ascfield2);
    
    // Add a series of noDocs docs with increasing long values, by updating the fields
    for (int l=0; l<noDocs; l++) {
      long val=distance*l+startOffset;
      field8.setLongValue(val);
      field6.setLongValue(val);
      field4.setLongValue(val);
      field2.setLongValue(val);
      fieldNoTrie.setLongValue(val);

      val=l-(noDocs/2);
      ascfield8.setLongValue(val);
      ascfield6.setLongValue(val);
      ascfield4.setLongValue(val);
      ascfield2.setLongValue(val);
      writer.addDocument(doc);
    }
  
    reader = writer.getReader();
    searcher=new IndexSearcher(reader);
    writer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522511/fstmerge_var2_1554608250485887741

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522725/fstmerge_var1_7602933357702160823
@Override
  protected void setUp() throws Exception {
    super.setUp();
    
    index = new RAMDirectory();
    Random random = newRandom();
    RandomIndexWriter writer = new RandomIndexWriter(random, index,
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
            .setSimilarity(sim));
    
    // hed is the most important field, dek is secondary
    
    // d1 is an "ok" match for: albino elephant
    {
      Document d1 = new Document();
      d1.add(new Field("id", "d1", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d1"));
      d1
          .add(new Field("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      d1
          .add(new Field("dek", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("dek", "elephant"));
      writer.addDocument(d1);
    }
    
    // d2 is a "good" match for: albino elephant
    {
      Document d2 = new Document();
      d2.add(new Field("id", "d2", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d2"));
      d2
          .add(new Field("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      d2.add(new Field("dek", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("dek",
                                                                                // "albino"));
      d2
          .add(new Field("dek", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("dek", "elephant"));
      writer.addDocument(d2);
    }
    
    // d3 is a "better" match for: albino elephant
    {
      Document d3 = new Document();
      d3.add(new Field("id", "d3", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d3"));
      d3.add(new Field("hed", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("hed",
                                                                                // "albino"));
      d3
          .add(new Field("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      writer.addDocument(d3);
    }
    
    // d4 is the "best" match for: albino elephant
    {
      Document d4 = new Document();
      d4.add(new Field("id", "d4", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d4"));
      d4.add(new Field("hed", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("hed",
                                                                                // "albino"));
      d4
          .add(new Field("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      d4.add(new Field("dek", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("dek",
                                                                                // "albino"));
      writer.addDocument(d4);
    }
    
    r = writer.getReader();
    writer.close();
    s = new IndexSearcher(r);
    s.setSimilarity(sim);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522725/fstmerge_base_4438417135131044679
@Override
  protected void setUp() throws Exception {
    super.setUp();
    
    index = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), index,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
            .setSimilarity(sim));
    
    // hed is the most important field, dek is secondary
    
    // d1 is an "ok" match for: albino elephant
    {
      Document d1 = new Document();
      d1.add(new Field("id", "d1", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d1"));
      d1
          .add(new Field("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      d1
          .add(new Field("dek", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("dek", "elephant"));
      writer.addDocument(d1);
    }
    
    // d2 is a "good" match for: albino elephant
    {
      Document d2 = new Document();
      d2.add(new Field("id", "d2", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d2"));
      d2
          .add(new Field("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      d2.add(new Field("dek", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("dek",
                                                                                // "albino"));
      d2
          .add(new Field("dek", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("dek", "elephant"));
      writer.addDocument(d2);
    }
    
    // d3 is a "better" match for: albino elephant
    {
      Document d3 = new Document();
      d3.add(new Field("id", "d3", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d3"));
      d3.add(new Field("hed", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("hed",
                                                                                // "albino"));
      d3
          .add(new Field("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      writer.addDocument(d3);
    }
    
    // d4 is the "best" match for: albino elephant
    {
      Document d4 = new Document();
      d4.add(new Field("id", "d4", Field.Store.YES, Field.Index.NOT_ANALYZED));// Field.Keyword("id",
                                                                               // "d4"));
      d4.add(new Field("hed", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("hed",
                                                                                // "albino"));
      d4
          .add(new Field("hed", "elephant", Field.Store.YES,
              Field.Index.ANALYZED));// Field.Text("hed", "elephant"));
      d4.add(new Field("dek", "albino", Field.Store.YES, Field.Index.ANALYZED));// Field.Text("dek",
                                                                                // "albino"));
      writer.addDocument(d4);
    }
    
    r = writer.getReader();
    writer.close();
    s = new IndexSearcher(r);
    s.setSimilarity(sim);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522725/fstmerge_var2_3088671670101012446

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522783/fstmerge_var1_6388571669437475857
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    Random random = newRandom();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new PayloadAnalyzer())
        .setSimilarity(similarity));
    //writer.infoStream = System.out;
    for (int i = 0; i < 1000; i++) {
      Document doc = new Document();
      doc.add(new Field("field", English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
      String txt = English.intToEnglish(i) +' '+English.intToEnglish(i+1);
      doc.add(new Field("field2",  txt, Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();

    searcher = new IndexSearcher(reader);
    searcher.setSimilarity(similarity);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522783/fstmerge_base_8641957332498706944
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new PayloadAnalyzer())
        .setSimilarity(similarity));
    //writer.infoStream = System.out;
    for (int i = 0; i < 1000; i++) {
      Document doc = new Document();
      doc.add(new Field("field", English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
      String txt = English.intToEnglish(i) +' '+English.intToEnglish(i+1);
      doc.add(new Field("field2",  txt, Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();

    searcher = new IndexSearcher(reader);
    searcher.setSimilarity(similarity);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522783/fstmerge_var2_8550721846978420958

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522858/fstmerge_var1_425971767875484518
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    Random random = newRandom();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new PayloadAnalyzer())
        .setSimilarity(similarity));
    //writer.infoStream = System.out;
    for (int i = 0; i < 1000; i++) {
      Document doc = new Document();
      Field noPayloadField = new Field(PayloadHelper.NO_PAYLOAD_FIELD, English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED);
      //noPayloadField.setBoost(0);
      doc.add(noPayloadField);
      doc.add(new Field("field", English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
      doc.add(new Field("multiField", English.intToEnglish(i) + "  " + English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();

    searcher = new IndexSearcher(reader);
    searcher.setSimilarity(similarity);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522858/fstmerge_base_817818840514076698
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new PayloadAnalyzer())
        .setSimilarity(similarity));
    //writer.infoStream = System.out;
    for (int i = 0; i < 1000; i++) {
      Document doc = new Document();
      Field noPayloadField = new Field(PayloadHelper.NO_PAYLOAD_FIELD, English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED);
      //noPayloadField.setBoost(0);
      doc.add(noPayloadField);
      doc.add(new Field("field", English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
      doc.add(new Field("multiField", English.intToEnglish(i) + "  " + English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();

    searcher = new IndexSearcher(reader);
    searcher.setSimilarity(similarity);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583522858/fstmerge_var2_3229010387539448912

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523254/fstmerge_var1_8182525837328480419
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(newRandom(), directory);
    for (int i = 0; i < docFields.length; i++) {
      Document doc = new Document();
      doc.add(new Field(FIELD, docFields[i], Field.Store.NO, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523254/fstmerge_base_844719757918416873
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < docFields.length; i++) {
      Document doc = new Document();
      doc.add(new Field(FIELD, docFields[i], Field.Store.NO, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523254/fstmerge_var2_2999309015569986435

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523432/fstmerge_var1_21179008555071763
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(newRandom(), directory);
    
    writer.addDocument(doc(new Field[] { field("id", "0")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "james"),
                                         field("last",   "jones")     }));
                                               
    writer.addDocument(doc(new Field[] { field("id", "1")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "james"),
                                         field("last",   "smith")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "sally"),
                                         field("last",   "jones")     }));
    
    writer.addDocument(doc(new Field[] { field("id", "2")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "greta"),
                                         field("last",   "jones")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "sally"),
                                         field("last",   "smith")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "james"),
                                         field("last",   "jones")     }));
     
    writer.addDocument(doc(new Field[] { field("id", "3")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "lisa"),
                                         field("last",   "jones")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "bob"),
                                         field("last",   "costas")     }));
    
    writer.addDocument(doc(new Field[] { field("id", "4")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "sally"),
                                         field("last",   "smith")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "linda"),
                                         field("last",   "dixit")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "bubba"),
                                         field("last",   "jones")     }));
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523432/fstmerge_base_8713836249699451454
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    
    writer.addDocument(doc(new Field[] { field("id", "0")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "james"),
                                         field("last",   "jones")     }));
                                               
    writer.addDocument(doc(new Field[] { field("id", "1")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "james"),
                                         field("last",   "smith")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "sally"),
                                         field("last",   "jones")     }));
    
    writer.addDocument(doc(new Field[] { field("id", "2")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "greta"),
                                         field("last",   "jones")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "sally"),
                                         field("last",   "smith")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "james"),
                                         field("last",   "jones")     }));
     
    writer.addDocument(doc(new Field[] { field("id", "3")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "lisa"),
                                         field("last",   "jones")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "bob"),
                                         field("last",   "costas")     }));
    
    writer.addDocument(doc(new Field[] { field("id", "4")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "sally"),
                                         field("last",   "smith")
                                         ,
                                         field("gender", "female"),
                                         field("first",  "linda"),
                                         field("last",   "dixit")
                                         ,
                                         field("gender", "male"),
                                         field("first",  "bubba"),
                                         field("last",   "jones")     }));
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523432/fstmerge_var2_4920143868716278867

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523502/fstmerge_var1_4326726103360366225
@Override
  protected void setUp() throws Exception {
    super.setUp();
    
    // create test index
    final RandomIndexWriter writer = new RandomIndexWriter(random, mDirectory,
        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(
            MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true))
            .setOpenMode(OpenMode.APPEND));
    addDocument(writer, "A", "Should we, could we, would we?");
    addDocument(writer, "B", "It should.  Should it?");
    addDocument(writer, "C", "It shouldn't.");
    addDocument(writer, "D", "Should we, should we, should we.");
    reader2 = writer.getReader();
    writer.close();
    
    // re-open the searcher since we added more docs
    searcher2 = new IndexSearcher(reader2);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523502/fstmerge_base_7996732897345146367
@Override
  protected void setUp() throws Exception {
    super.setUp();
    
    // create test index
    final RandomIndexWriter writer = new RandomIndexWriter(random, mDirectory,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(
            MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true))
            .setOpenMode(OpenMode.APPEND));
    addDocument(writer, "A", "Should we, could we, would we?");
    addDocument(writer, "B", "It should.  Should it?");
    addDocument(writer, "C", "It shouldn't.");
    addDocument(writer, "D", "Should we, should we, should we.");
    reader2 = writer.getReader();
    writer.close();
    
    // re-open the searcher since we added more docs
    searcher2 = new IndexSearcher(reader2);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523502/fstmerge_var2_8377387853087723191

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/spans/TestSpansAdvanced2.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523529/fstmerge_var1_8305654708023146879
@Override
  protected void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    // create test index
    mDirectory = new RAMDirectory();
    final RandomIndexWriter writer = new RandomIndexWriter(random,
        mDirectory, new MockAnalyzer(MockTokenizer.SIMPLE, true,
                MockTokenFilter.ENGLISH_STOPSET, true));
    addDocument(writer, "1", "I think it should work.");
    addDocument(writer, "2", "I think it should work.");
    addDocument(writer, "3", "I think it should work.");
    addDocument(writer, "4", "I think it should work.");
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523529/fstmerge_base_5982864536098515747
@Override
  protected void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    // create test index
    mDirectory = new RAMDirectory();
    final RandomIndexWriter writer = new RandomIndexWriter(random,
        mDirectory, new IndexWriterConfig(TEST_VERSION_CURRENT,
            new MockAnalyzer(MockTokenizer.SIMPLE, true,
                MockTokenFilter.ENGLISH_STOPSET, true)));
    addDocument(writer, "1", "I think it should work.");
    addDocument(writer, "2", "I think it should work.");
    addDocument(writer, "3", "I think it should work.");
    addDocument(writer, "4", "I think it should work.");
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523529/fstmerge_var2_8926408460492201107

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/spans/TestSpansAdvanced.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523678/fstmerge_var1_8428162574542843601
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new MockAnalyzer(MockTokenizer.SIMPLE, true));
    //writer.infoStream = System.out;
    for (int i = 0; i < 1000; i++) {
      Document doc = new Document();
      doc.add(new Field("field", English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523678/fstmerge_base_7877865436369119046
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));
    //writer.infoStream = System.out;
    for (int i = 0; i < 1000; i++) {
      Document doc = new Document();
      doc.add(new Field("field", English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    searcher = new IndexSearcher(reader);
    writer.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523678/fstmerge_var2_2172471834477583489

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/spans/TestBasics.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523896/fstmerge_var1_2834885855712273042
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(newRandom(), directory);
    for (int i = 0; i < docFields.length; i++) {
      Document doc = new Document();
      doc.add(new Field(field, docFields[i], Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523896/fstmerge_base_2011337410612455605
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer= new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < docFields.length; i++) {
      Document doc = new Document();
      doc.add(new Field(field, docFields[i], Field.Store.YES, Field.Index.ANALYZED));
      writer.addDocument(doc);
    }
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583523896/fstmerge_var2_6071100401737132606

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/search/spans/TestSpans.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583524928/fstmerge_var1_1337697643071923103
public void reportAdditionalFailureInfo() {
    Long staticSeed = staticSeeds.get(getClass());
    if (staticSeed != null) {
      System.out.println("NOTE: random static seed of testclass '" + getName() + "' was: " + staticSeed);
    }
    
    if (_TestUtil.getTestCodec().equals("random")) {
      System.out.println("NOTE: random codec of testcase '" + getName() + "' was: " + codec);
    }

    if (seed != null) {
      System.out.println("NOTE: random seed of testcase '" + getName() + "' was: " + seed);
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583524928/fstmerge_base_4557285691101157602
public void reportAdditionalFailureInfo() {
    Long staticSeed = staticSeeds.get(getClass());
    if (staticSeed != null) {
      System.out.println("NOTE: random static seed of testclass '" + getName() + "' was: " + staticSeed);
    }
    
    if (seed != null) {
      System.out.println("NOTE: random seed of testcase '" + getName() + "' was: " + seed);
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583524928/fstmerge_var2_6349465331667339372

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/util/LuceneTestCaseJ4.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525055/fstmerge_var1_1425737659097935187
@Override
  protected void setUp() throws Exception {
    super.setUp();
    assertFalse("ensure your tearDown() calls super.tearDown()!!!", setup);
    setup = true;
    savedUncaughtExceptionHandler = Thread.getDefaultUncaughtExceptionHandler();
    Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {
      public void uncaughtException(Thread t, Throwable e) {
        uncaughtExceptions.add(new UncaughtExceptionEntry(t, e));
        if (savedUncaughtExceptionHandler != null)
          savedUncaughtExceptionHandler.uncaughtException(t, e);
      }
    });
    
    ConcurrentMergeScheduler.setTestMode();
    savedBoolMaxClauseCount = BooleanQuery.getMaxClauseCount();
    savedDefaultCodec = CodecProvider.getDefaultCodec();

    codec = _TestUtil.getTestCodec();
    if (codec.equals("random"))
      codec = CodecProvider.CORE_CODECS[seedRnd.nextInt(CodecProvider.CORE_CODECS.length)];

    // If we're running w/ PreFlex codec we must swap in the
    // test-only PreFlexRW codec (since core PreFlex can
    // only read segments):
    if (codec.equals("PreFlex")) {
      preFlexSav = LuceneTestCaseJ4.installPreFlexRW();
    } 
    CodecProvider.setDefaultCodec(codec);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525055/fstmerge_base_7467791126548425600
@Override
  protected void setUp() throws Exception {
    super.setUp();
    assertFalse("ensure your tearDown() calls super.tearDown()!!!", setup);
    setup = true;
    savedUncaughtExceptionHandler = Thread.getDefaultUncaughtExceptionHandler();
    Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {
      public void uncaughtException(Thread t, Throwable e) {
        uncaughtExceptions.add(new UncaughtExceptionEntry(t, e));
        if (savedUncaughtExceptionHandler != null)
          savedUncaughtExceptionHandler.uncaughtException(t, e);
      }
    });
    
    ConcurrentMergeScheduler.setTestMode();
    savedBoolMaxClauseCount = BooleanQuery.getMaxClauseCount();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525055/fstmerge_var2_7658578959662318803

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/util/LuceneTestCase.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525069/fstmerge_var1_5451425745382763206
@Override
  protected void tearDown() throws Exception {
    assertTrue("ensure your setUp() calls super.setUp()!!!", setup);
    setup = false;
    BooleanQuery.setMaxClauseCount(savedBoolMaxClauseCount);
    // Restore read-only PreFlex codec:
    if (codec.equals("PreFlex")) {
      LuceneTestCaseJ4.restorePreFlex(preFlexSav);
    } 
    CodecProvider.setDefaultCodec(savedDefaultCodec);
    
    try {
      Thread.setDefaultUncaughtExceptionHandler(savedUncaughtExceptionHandler);
      if (!uncaughtExceptions.isEmpty()) {
        System.err.println("The following exceptions were thrown by threads:");
        for (UncaughtExceptionEntry entry : uncaughtExceptions) {
          System.err.println("*** Thread: " + entry.thread.getName() + " ***");
          entry.exception.printStackTrace(System.err);
        }
        fail("Some threads threw uncaught exceptions!");
      }

      // this isn't as useful as calling directly from the scope where the 
      // index readers are used, because they could be gc'ed just before
      // tearDown is called.
      // But it's better then nothing.
      assertSaneFieldCaches(getTestLabel());
      
      if (ConcurrentMergeScheduler.anyUnhandledExceptions()) {
        // Clear the failure so that we don't just keep
        // failing subsequent test cases
        ConcurrentMergeScheduler.clearUnhandledExceptions();
        fail("ConcurrentMergeScheduler hit unhandled exceptions");
      }
    } finally {
      purgeFieldCache(FieldCache.DEFAULT);
    }

    super.tearDown();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525069/fstmerge_base_6873234679747287567
@Override
  protected void tearDown() throws Exception {
    assertTrue("ensure your setUp() calls super.setUp()!!!", setup);
    setup = false;
    BooleanQuery.setMaxClauseCount(savedBoolMaxClauseCount);

    try {
      Thread.setDefaultUncaughtExceptionHandler(savedUncaughtExceptionHandler);
      if (!uncaughtExceptions.isEmpty()) {
        System.err.println("The following exceptions were thrown by threads:");
        for (UncaughtExceptionEntry entry : uncaughtExceptions) {
          System.err.println("*** Thread: " + entry.thread.getName() + " ***");
          entry.exception.printStackTrace(System.err);
        }
        fail("Some threads threw uncaught exceptions!");
      }

      // this isn't as useful as calling directly from the scope where the 
      // index readers are used, because they could be gc'ed just before
      // tearDown is called.
      // But it's better then nothing.
      assertSaneFieldCaches(getTestLabel());
      
      if (ConcurrentMergeScheduler.anyUnhandledExceptions()) {
        // Clear the failure so that we don't just keep
        // failing subsequent test cases
        ConcurrentMergeScheduler.clearUnhandledExceptions();
        fail("ConcurrentMergeScheduler hit unhandled exceptions");
      }
    } finally {
      purgeFieldCache(FieldCache.DEFAULT);
    }

    super.tearDown();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525069/fstmerge_var2_4295926845760669581

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/util/LuceneTestCase.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525107/fstmerge_var1_1713185896608455996
@Override
  public void runBare() throws Throwable {
    //long t0 = System.currentTimeMillis();
    try {
      seed = null;
      super.runBare();
    } catch (Throwable e) {
      if (_TestUtil.getTestCodec().equals("random")) {
        System.out.println("NOTE: random codec of testcase '" + getName() + "' was: " + codec);
      }
      if (seed != null) {
        System.out.println("NOTE: random seed of testcase '" + getName() + "' was: " + seed);
      }
      throw e;
    }
    //long t = System.currentTimeMillis() - t0;
    //System.out.println(t + " msec for " + getName());
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525107/fstmerge_base_893599692329287469
@Override
  public void runBare() throws Throwable {
    //long t0 = System.currentTimeMillis();
    try {
      seed = null;
      super.runBare();
    } catch (Throwable e) {
      if (seed != null) {
        System.out.println("NOTE: random seed of testcase '" + getName() + "' was: " + seed);
      }
      throw e;
    }
    //long t = System.currentTimeMillis() - t0;
    //System.out.println(t + " msec for " + getName());
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525107/fstmerge_var2_6945551947805023716

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/util/LuceneTestCase.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525434/fstmerge_var1_6375002961929725627
public static String randomUnicodeString(Random r, int maxLength) {
    final int end = r.nextInt(maxLength);
    if (end == 0) {
      // allow 0 length
      return "";
    }
    final char[] buffer = new char[end];
    for (int i = 0; i < end; i++) {

      int t = r.nextInt(5);

      //buffer[i] = (char) (97 + r.nextInt(26));

      /*
      if (0 == t && i < end - 1) {
        // hi
        buffer[i++] = (char) 0xd800;
        // lo
        buffer[i] = (char) 0xdc00;
      } else if (t <= 3) {
        buffer[i] = 'a';
      }  else if (4 == t) {
        buffer[i] = 0xe000;
      }
      */

      if (0 == t && i < end - 1) {
        // Make a surrogate pair
        // High surrogate
        buffer[i++] = (char) nextInt(r, 0xd800, 0xdbff);
        // Low surrogate
        buffer[i] = (char) nextInt(r, 0xdc00, 0xdfff);
      }
      else if (t <= 1) buffer[i] = (char) r.nextInt(0x80);
      else if (2 == t) buffer[i] = (char) nextInt(r, 0x80, 0x800);
      else if (3 == t) buffer[i] = (char) nextInt(r, 0x800, 0xd7ff);
      else if (4 == t) buffer[i] = (char) nextInt(r, 0xe000, 0xffff);
    }
    return new String(buffer, 0, end);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525434/fstmerge_base_6506329068609173411
public static String randomUnicodeString(Random r, int maxLength) {
    final int end = r.nextInt(maxLength);
    if (end == 0) {
      // allow 0 length
      return "";
    }
    final char[] buffer = new char[end];
    for (int i = 0; i < end; i++) {
      int t = r.nextInt(5);
      //buffer[i] = (char) (97 + r.nextInt(26));
      if (0 == t && i < end - 1) {
        // Make a surrogate pair
        // High surrogate
        buffer[i++] = (char) nextInt(r, 0xd800, 0xdbff);
        // Low surrogate
        buffer[i] = (char) nextInt(r, 0xdc00, 0xdfff);
      }
      else if (t <= 1) buffer[i] = (char) r.nextInt(0x80);
      else if (2 == t) buffer[i] = (char) nextInt(r, 0x80, 0x800);
      else if (3 == t) buffer[i] = (char) nextInt(r, 0x800, 0xd7ff);
      else if (4 == t) buffer[i] = (char) nextInt(r, 0xe000, 0xffff);
    }
    return new String(buffer, 0, end);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525434/fstmerge_var2_5001807449382471115

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/util/_TestUtil.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525734/fstmerge_var1_1074707277866009158
public void testBinaryFieldInIndex()
    throws Exception
  {
    Fieldable binaryFldStored = new Field("binaryStored", binaryValStored.getBytes());
    Fieldable stringFldStored = new Field("stringStored", binaryValStored, Field.Store.YES, Field.Index.NO, Field.TermVector.NO);

    try {
      // binary fields with store off are not allowed
      new Field("fail", binaryValStored.getBytes(), Field.Store.NO);
      fail();
    }
    catch (IllegalArgumentException iae) {
    }
    
    Document doc = new Document();
    
    doc.add(binaryFldStored);
    
    doc.add(stringFldStored);

    /** test for field count */
    assertEquals(2, doc.fields.size());
    
    /** add the doc to a ram index */
    MockRAMDirectory dir = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
    writer.addDocument(doc);
    
    /** open a reader and fetch the document */ 
    IndexReader reader = writer.getReader();
    Document docFromReader = reader.document(0);
    assertTrue(docFromReader != null);
    
    /** fetch the binary stored field and compare it's content with the original one */
    String binaryFldStoredTest = new String(docFromReader.getBinaryValue("binaryStored"));
    assertTrue(binaryFldStoredTest.equals(binaryValStored));
    
    /** fetch the string field and compare it's content with the original one */
    String stringFldStoredTest = docFromReader.get("stringStored");
    assertTrue(stringFldStoredTest.equals(binaryValStored));
    
    writer.close();    
    reader.close();
    
    reader = IndexReader.open(dir, false);
    /** delete the document from index */
    reader.deleteDocument(0);
    assertEquals(0, reader.numDocs());
    
    reader.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525734/fstmerge_base_3022195422916172120
public void testBinaryFieldInIndex()
    throws Exception
  {
    Fieldable binaryFldStored = new Field("binaryStored", binaryValStored.getBytes());
    Fieldable stringFldStored = new Field("stringStored", binaryValStored, Field.Store.YES, Field.Index.NO, Field.TermVector.NO);

    try {
      // binary fields with store off are not allowed
      new Field("fail", binaryValStored.getBytes(), Field.Store.NO);
      fail();
    }
    catch (IllegalArgumentException iae) {
    }
    
    Document doc = new Document();
    
    doc.add(binaryFldStored);
    
    doc.add(stringFldStored);

    /** test for field count */
    assertEquals(2, doc.fields.size());
    
    /** add the doc to a ram index */
    MockRAMDirectory dir = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    writer.addDocument(doc);
    
    /** open a reader and fetch the document */ 
    IndexReader reader = writer.getReader();
    Document docFromReader = reader.document(0);
    assertTrue(docFromReader != null);
    
    /** fetch the binary stored field and compare it's content with the original one */
    String binaryFldStoredTest = new String(docFromReader.getBinaryValue("binaryStored"));
    assertTrue(binaryFldStoredTest.equals(binaryValStored));
    
    /** fetch the string field and compare it's content with the original one */
    String stringFldStoredTest = docFromReader.get("stringStored");
    assertTrue(stringFldStoredTest.equals(binaryValStored));
    
    writer.close();    
    reader.close();
    
    reader = IndexReader.open(dir, false);
    /** delete the document from index */
    reader.deleteDocument(0);
    assertEquals(0, reader.numDocs());
    
    reader.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525734/fstmerge_var2_8319998691682232781

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/document/TestBinaryDocument.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525739/fstmerge_var1_57584893995810403
public void testCompressionTools() throws Exception {
    Fieldable binaryFldCompressed = new Field("binaryCompressed", CompressionTools.compress(binaryValCompressed.getBytes()));
    Fieldable stringFldCompressed = new Field("stringCompressed", CompressionTools.compressString(binaryValCompressed));
    
    Document doc = new Document();
    
    doc.add(binaryFldCompressed);
    doc.add(stringFldCompressed);
    
    /** add the doc to a ram index */
    MockRAMDirectory dir = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
    writer.addDocument(doc);
    
    /** open a reader and fetch the document */ 
    IndexReader reader = writer.getReader();
    Document docFromReader = reader.document(0);
    assertTrue(docFromReader != null);
    
    /** fetch the binary compressed field and compare it's content with the original one */
    String binaryFldCompressedTest = new String(CompressionTools.decompress(docFromReader.getBinaryValue("binaryCompressed")));
    assertTrue(binaryFldCompressedTest.equals(binaryValCompressed));
    assertTrue(CompressionTools.decompressString(docFromReader.getBinaryValue("stringCompressed")).equals(binaryValCompressed));

    writer.close();
    reader.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525739/fstmerge_base_366882763929688711
public void testCompressionTools() throws Exception {
    Fieldable binaryFldCompressed = new Field("binaryCompressed", CompressionTools.compress(binaryValCompressed.getBytes()));
    Fieldable stringFldCompressed = new Field("stringCompressed", CompressionTools.compressString(binaryValCompressed));
    
    Document doc = new Document();
    
    doc.add(binaryFldCompressed);
    doc.add(stringFldCompressed);
    
    /** add the doc to a ram index */
    MockRAMDirectory dir = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    writer.addDocument(doc);
    
    /** open a reader and fetch the document */ 
    IndexReader reader = writer.getReader();
    Document docFromReader = reader.document(0);
    assertTrue(docFromReader != null);
    
    /** fetch the binary compressed field and compare it's content with the original one */
    String binaryFldCompressedTest = new String(CompressionTools.decompress(docFromReader.getBinaryValue("binaryCompressed")));
    assertTrue(binaryFldCompressedTest.equals(binaryValCompressed));
    assertTrue(CompressionTools.decompressString(docFromReader.getBinaryValue("stringCompressed")).equals(binaryValCompressed));

    writer.close();
    reader.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525739/fstmerge_var2_2581426993807450953

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/document/TestBinaryDocument.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525770/fstmerge_var1_2022460159960313419
public void testGetValuesForIndexedDocument() throws Exception {
    RAMDirectory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
    writer.addDocument(makeDocumentWithFields());
    IndexReader reader = writer.getReader();
    
    Searcher searcher = new IndexSearcher(reader);
    
    // search for something that does exists
    Query query = new TermQuery(new Term("keyword", "test1"));
    
    // ensure that queries return expected results without DateFilter first
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    
    doAssert(searcher.doc(hits[0].doc), true);
    writer.close();
    searcher.close();
    reader.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525770/fstmerge_base_3125029876197776801
public void testGetValuesForIndexedDocument() throws Exception {
    RAMDirectory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    writer.addDocument(makeDocumentWithFields());
    IndexReader reader = writer.getReader();
    
    Searcher searcher = new IndexSearcher(reader);
    
    // search for something that does exists
    Query query = new TermQuery(new Term("keyword", "test1"));
    
    // ensure that queries return expected results without DateFilter first
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    
    doAssert(searcher.doc(hits[0].doc), true);
    writer.close();
    searcher.close();
    reader.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525770/fstmerge_var2_5941054180212502009

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/document/TestDocument.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525777/fstmerge_var1_1997439197969519071
public void testFieldSetValue() throws Exception {
    
    Field field = new Field("id", "id1", Field.Store.YES,
        Field.Index.NOT_ANALYZED);
    Document doc = new Document();
    doc.add(field);
    doc.add(new Field("keyword", "test", Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    
    RAMDirectory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir);
    writer.addDocument(doc);
    field.setValue("id2");
    writer.addDocument(doc);
    field.setValue("id3");
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    Searcher searcher = new IndexSearcher(reader);
    
    Query query = new TermQuery(new Term("keyword", "test"));
    
    // ensure that queries return expected results without DateFilter first
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    int result = 0;
    for (int i = 0; i < 3; i++) {
      Document doc2 = searcher.doc(hits[i].doc);
      Field f = doc2.getField("id");
      if (f.stringValue().equals("id1")) result |= 1;
      else if (f.stringValue().equals("id2")) result |= 2;
      else if (f.stringValue().equals("id3")) result |= 4;
      else fail("unexpected id field");
    }
    writer.close();
    searcher.close();
    reader.close();
    dir.close();
    assertEquals("did not see all IDs", 7, result);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525777/fstmerge_base_7257948370434941206
public void testFieldSetValue() throws Exception {
    
    Field field = new Field("id", "id1", Field.Store.YES,
        Field.Index.NOT_ANALYZED);
    Document doc = new Document();
    doc.add(field);
    doc.add(new Field("keyword", "test", Field.Store.YES,
        Field.Index.NOT_ANALYZED));
    
    RAMDirectory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), dir,
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    writer.addDocument(doc);
    field.setValue("id2");
    writer.addDocument(doc);
    field.setValue("id3");
    writer.addDocument(doc);
    
    IndexReader reader = writer.getReader();
    Searcher searcher = new IndexSearcher(reader);
    
    Query query = new TermQuery(new Term("keyword", "test"));
    
    // ensure that queries return expected results without DateFilter first
    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
    assertEquals(3, hits.length);
    int result = 0;
    for (int i = 0; i < 3; i++) {
      Document doc2 = searcher.doc(hits[i].doc);
      Field f = doc2.getField("id");
      if (f.stringValue().equals("id1")) result |= 1;
      else if (f.stringValue().equals("id2")) result |= 2;
      else if (f.stringValue().equals("id3")) result |= 4;
      else fail("unexpected id field");
    }
    writer.close();
    searcher.close();
    reader.close();
    dir.close();
    assertEquals("did not see all IDs", 7, result);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583525777/fstmerge_var2_5032419825712544546

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/document/TestDocument.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526319/fstmerge_var1_2450993257819804258
public void testDeletesOnDiskFull() throws IOException {
    doTestOperationsOnDiskFull(false);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526319/fstmerge_base_1196309379709394965
public void testDeletesOnDiskFull() throws IOException {
    testOperationsOnDiskFull(false);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526319/fstmerge_var2_5854172805081318739

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526323/fstmerge_var1_1897575137676425734
public void testUpdatesOnDiskFull() throws IOException {
    doTestOperationsOnDiskFull(true);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526323/fstmerge_base_2160379505079665133
public void testUpdatesOnDiskFull() throws IOException {
    testOperationsOnDiskFull(true);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526323/fstmerge_var2_4048229498367997448

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526328/fstmerge_var1_5994902198943683728
public void testErrorAfterApplyDeletes() throws IOException {
    
    MockRAMDirectory.Failure failure = new MockRAMDirectory.Failure() {
        boolean sawMaybe = false;
        boolean failed = false;
        @Override
        public MockRAMDirectory.Failure reset() {
          sawMaybe = false;
          failed = false;
          return this;
        }
        @Override
        public void eval(MockRAMDirectory dir)  throws IOException {
          if (sawMaybe && !failed) {
            boolean seen = false;
            StackTraceElement[] trace = new Exception().getStackTrace();
            for (int i = 0; i < trace.length; i++) {
              if ("applyDeletes".equals(trace[i].getMethodName())) {
                seen = true;
                break;
              }
            }
            if (!seen) {
              // Only fail once we are no longer in applyDeletes
              failed = true;
              throw new IOException("fail after applyDeletes");
            }
          }
          if (!failed) {
            StackTraceElement[] trace = new Exception().getStackTrace();
            for (int i = 0; i < trace.length; i++) {
              if ("applyDeletes".equals(trace[i].getMethodName())) {
                sawMaybe = true;
                break;
              }
            }
          }
        }
      };

    // create a couple of files

    String[] keywords = { "1", "2" };
    String[] unindexed = { "Netherlands", "Italy" };
    String[] unstored = { "Amsterdam has lots of bridges",
        "Venice has lots of canals" };
    String[] text = { "Amsterdam", "Venice" };

    MockRAMDirectory dir = new MockRAMDirectory();
    IndexWriter modifier = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setMaxBufferedDeleteTerms(2));
    LogMergePolicy lmp = (LogMergePolicy) modifier.getConfig().getMergePolicy();
    lmp.setUseCompoundFile(true);
    lmp.setUseCompoundDocStore(true);

    dir.failOn(failure.reset());

    for (int i = 0; i < keywords.length; i++) {
      Document doc = new Document();
      doc.add(new Field("id", keywords[i], Field.Store.YES,
                        Field.Index.NOT_ANALYZED));
      doc.add(new Field("country", unindexed[i], Field.Store.YES,
                        Field.Index.NO));
      doc.add(new Field("contents", unstored[i], Field.Store.NO,
                        Field.Index.ANALYZED));
      doc.add(new Field("city", text[i], Field.Store.YES,
                        Field.Index.ANALYZED));
      modifier.addDocument(doc);
    }
    // flush (and commit if ac)

    modifier.optimize();
    modifier.commit();

    // one of the two files hits

    Term term = new Term("city", "Amsterdam");
    int hitCount = getHitCount(dir, term);
    assertEquals(1, hitCount);

    // open the writer again (closed above)

    // delete the doc
    // max buf del terms is two, so this is buffered

    modifier.deleteDocuments(term);

    // add a doc (needed for the !ac case; see below)
    // doc remains buffered

    Document doc = new Document();
    modifier.addDocument(doc);

    // commit the changes, the buffered deletes, and the new doc

    // The failure object will fail on the first write after the del
    // file gets created when processing the buffered delete

    // in the ac case, this will be when writing the new segments
    // files so we really don't need the new doc, but it's harmless

    // in the !ac case, a new segments file won't be created but in
    // this case, creation of the cfs file happens next so we need
    // the doc (to test that it's okay that we don't lose deletes if
    // failing while creating the cfs file)

    boolean failed = false;
    try {
      modifier.commit();
    } catch (IOException ioe) {
      // expected
      failed = true;
    }

    assertTrue(failed);

    // The commit above failed, so we need to retry it (which will
    // succeed, because the failure is a one-shot)

    modifier.commit();

    hitCount = getHitCount(dir, term);

    // Make sure the delete was successfully flushed:
    assertEquals(0, hitCount);

    modifier.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526328/fstmerge_base_4945282192576422294
public void testErrorAfterApplyDeletes() throws IOException {
    
    MockRAMDirectory.Failure failure = new MockRAMDirectory.Failure() {
        boolean sawMaybe = false;
        boolean failed = false;
        @Override
        public MockRAMDirectory.Failure reset() {
          sawMaybe = false;
          failed = false;
          return this;
        }
        @Override
        public void eval(MockRAMDirectory dir)  throws IOException {
          if (sawMaybe && !failed) {
            boolean seen = false;
            StackTraceElement[] trace = new Exception().getStackTrace();
            for (int i = 0; i < trace.length; i++) {
              if ("applyDeletes".equals(trace[i].getMethodName())) {
                seen = true;
                break;
              }
            }
            if (!seen) {
              // Only fail once we are no longer in applyDeletes
              failed = true;
              throw new IOException("fail after applyDeletes");
            }
          }
          if (!failed) {
            StackTraceElement[] trace = new Exception().getStackTrace();
            for (int i = 0; i < trace.length; i++) {
              if ("applyDeletes".equals(trace[i].getMethodName())) {
                sawMaybe = true;
                break;
              }
            }
          }
        }
      };

    // create a couple of files

    String[] keywords = { "1", "2" };
    String[] unindexed = { "Netherlands", "Italy" };
    String[] unstored = { "Amsterdam has lots of bridges",
        "Venice has lots of canals" };
    String[] text = { "Amsterdam", "Venice" };

    MockRAMDirectory dir = new MockRAMDirectory();
    IndexWriter modifier = new IndexWriter(dir, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setMaxBufferedDeleteTerms(2));
    LogMergePolicy lmp = (LogMergePolicy) modifier.getConfig().getMergePolicy();
    lmp.setUseCompoundFile(true);
    lmp.setUseCompoundDocStore(true);

    dir.failOn(failure.reset());

    for (int i = 0; i < keywords.length; i++) {
      Document doc = new Document();
      doc.add(new Field("id", keywords[i], Field.Store.YES,
                        Field.Index.NOT_ANALYZED));
      doc.add(new Field("country", unindexed[i], Field.Store.YES,
                        Field.Index.NO));
      doc.add(new Field("contents", unstored[i], Field.Store.NO,
                        Field.Index.ANALYZED));
      doc.add(new Field("city", text[i], Field.Store.YES,
                        Field.Index.ANALYZED));
      modifier.addDocument(doc);
    }
    // flush (and commit if ac)

    modifier.optimize();
    modifier.commit();

    // one of the two files hits

    Term term = new Term("city", "Amsterdam");
    int hitCount = getHitCount(dir, term);
    assertEquals(1, hitCount);

    // open the writer again (closed above)

    // delete the doc
    // max buf del terms is two, so this is buffered

    modifier.deleteDocuments(term);

    // add a doc (needed for the !ac case; see below)
    // doc remains buffered

    Document doc = new Document();
    modifier.addDocument(doc);

    // commit the changes, the buffered deletes, and the new doc

    // The failure object will fail on the first write after the del
    // file gets created when processing the buffered delete

    // in the ac case, this will be when writing the new segments
    // files so we really don't need the new doc, but it's harmless

    // in the !ac case, a new segments file won't be created but in
    // this case, creation of the cfs file happens next so we need
    // the doc (to test that it's okay that we don't lose deletes if
    // failing while creating the cfs file)

    boolean failed = false;
    try {
      modifier.commit();
    } catch (IOException ioe) {
      failed = true;
    }

    assertTrue(failed);

    // The commit above failed, so we need to retry it (which will
    // succeed, because the failure is a one-shot)

    modifier.commit();

    hitCount = getHitCount(dir, term);

    // Make sure the delete was successfully flushed:
    assertEquals(0, hitCount);

    modifier.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526328/fstmerge_var2_8578580646485292898

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526581/fstmerge_var1_1705648432071251613
public void testUniqueTermCount() throws Exception {
    Directory dir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
    Document doc = new Document();
    doc.add(new Field("field", "a b c d e f g h i j k l m n o p q r s t u v w x y z", Field.Store.NO, Field.Index.ANALYZED));
    doc.add(new Field("number", "0 1 2 3 4 5 6 7 8 9", Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
    writer.addDocument(doc);
    writer.commit();

    IndexReader r = IndexReader.open(dir, false);
    IndexReader r1 = SegmentReader.getOnlySegmentReader(r);
    assertEquals(36, r1.getUniqueTermCount());
    writer.addDocument(doc);
    writer.commit();
    IndexReader r2 = r.reopen();
    r.close();
    try {
      r2.getUniqueTermCount();
      fail("expected exception");
    } catch (UnsupportedOperationException uoe) {
      // expected
    }
    IndexReader[] subs = r2.getSequentialSubReaders();
    for(int i=0;i<subs.length;i++) {
      assertEquals(36, subs[i].getUniqueTermCount());
    }
    r2.close();
    writer.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526581/fstmerge_base_6036298829893002089
public void testUniqueTermCount() throws Exception {
    Directory dir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    doc.add(new Field("field", "a b c d e f g h i j k l m n o p q r s t u v w x y z", Field.Store.NO, Field.Index.ANALYZED));
    doc.add(new Field("number", "0 1 2 3 4 5 6 7 8 9", Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
    writer.addDocument(doc);
    writer.commit();

    IndexReader r = IndexReader.open(dir, false);
    IndexReader r1 = SegmentReader.getOnlySegmentReader(r);
    assertEquals(36, r1.getUniqueTermCount());
    writer.addDocument(doc);
    writer.commit();
    IndexReader r2 = r.reopen();
    r.close();
    try {
      r2.getUniqueTermCount();
      fail("expected exception");
    } catch (UnsupportedOperationException uoe) {
      // expected
    }
    IndexReader[] subs = r2.getSequentialSubReaders();
    for(int i=0;i<subs.length;i++) {
      assertEquals(36, subs[i].getUniqueTermCount());
    }
    r2.close();
    writer.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526581/fstmerge_var2_206054955086997253

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526585/fstmerge_var1_8262082558124762576
public void testNoTermsIndex() throws Throwable {
    Directory dir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
    Document doc = new Document();
    doc.add(new Field("field", "a b c d e f g h i j k l m n o p q r s t u v w x y z", Field.Store.NO, Field.Index.ANALYZED));
    doc.add(new Field("number", "0 1 2 3 4 5 6 7 8 9", Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
    writer.addDocument(doc);
    writer.close();

    IndexReader r = IndexReader.open(dir, null, true, -1);
    try {
      r.docFreq(new Term("field", "f"));
      fail("did not hit expected exception");
    } catch (IllegalStateException ise) {
      // expected
    }

    assertEquals(-1, ((SegmentReader) r.getSequentialSubReaders()[0]).getTermInfosIndexDivisor());
    writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
    writer.addDocument(doc);
    writer.close();

    // LUCENE-1718: ensure re-open carries over no terms index:
    IndexReader r2 = r.reopen();
    r.close();
    IndexReader[] subReaders = r2.getSequentialSubReaders();
    assertEquals(2, subReaders.length);
    for(int i=0;i<2;i++) {
      try {
        subReaders[i].docFreq(new Term("field", "f"));
        fail("did not hit expected exception");
      } catch (IllegalStateException ise) {
        // expected
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526585/fstmerge_base_2834362801854908245
public void testNoTermsIndex() throws Throwable {
    Directory dir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    doc.add(new Field("field", "a b c d e f g h i j k l m n o p q r s t u v w x y z", Field.Store.NO, Field.Index.ANALYZED));
    doc.add(new Field("number", "0 1 2 3 4 5 6 7 8 9", Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
    writer.addDocument(doc);
    writer.close();

    IndexReader r = IndexReader.open(dir, null, true, -1);
    try {
      r.docFreq(new Term("field", "f"));
      fail("did not hit expected exception");
    } catch (IllegalStateException ise) {
      // expected
    }

    assertEquals(-1, ((SegmentReader) r.getSequentialSubReaders()[0]).getTermInfosIndexDivisor());
    writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    writer.addDocument(doc);
    writer.close();

    // LUCENE-1718: ensure re-open carries over no terms index:
    IndexReader r2 = r.reopen();
    r.close();
    IndexReader[] subReaders = r2.getSequentialSubReaders();
    assertEquals(2, subReaders.length);
    for(int i=0;i<2;i++) {
      try {
        subReaders[i].docFreq(new Term("field", "f"));
        fail("did not hit expected exception");
      } catch (IllegalStateException ise) {
        // expected
      }
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526585/fstmerge_var2_4247799892004353190

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526996/fstmerge_var1_6965834445086271185
public void testRandomIWReader() throws Throwable {
    r = newRandom();
    Directory dir = new MockRAMDirectory();
    
    // TODO: verify equals using IW.getReader
    DocsAndWriter dw = indexRandomIWReader(5, 3, 100, dir);
    IndexReader reader = dw.writer.getReader();
    dw.writer.commit();
    verifyEquals(r, reader, dir, "id");
    reader.close();
    dw.writer.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526996/fstmerge_base_4093765172410506394
public void testRandomIWReader() throws Throwable {
    r = newRandom();
    Directory dir = new MockRAMDirectory();
    
    // TODO: verify equals using IW.getReader
    DocsAndWriter dw = indexRandomIWReader(5, 3, 100, dir);
    IndexReader r = dw.writer.getReader();
    dw.writer.commit();
    verifyEquals(r, dir, "id");
    r.close();
    dw.writer.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583526996/fstmerge_var2_5253677940507632723

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/TestStressIndexing2.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583527215/fstmerge_var1_6953222086164876609
public void testRollbackIntegrityWithBufferFlush() throws Exception {
    Directory dir = new MockRAMDirectory();
    RandomIndexWriter rw = new RandomIndexWriter(newRandom(), dir);
    for (int i = 0; i < 5; i++) {
      Document doc = new Document();
      doc.add(new Field("pk", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));
      rw.addDocument(doc);
    }
    rw.close();

    // If buffer size is small enough to cause a flush, errors ensue...
    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));

    Term pkTerm = new Term("pk", "");
    for (int i = 0; i < 3; i++) {
      Document doc = new Document();
      String value = Integer.toString(i);
      doc.add(new Field("pk", value, Store.YES, Index.ANALYZED_NO_NORMS));
      doc.add(new Field("text", "foo", Store.YES, Index.ANALYZED_NO_NORMS));
      w.updateDocument(pkTerm.createTerm(value), doc);
    }
    w.rollback();

    IndexReader r = IndexReader.open(dir, true);
    assertEquals("index should contain same number of docs post rollback", 5, r.numDocs());
    r.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583527215/fstmerge_base_1475934162684715266
public void testRollbackIntegrityWithBufferFlush() throws Exception {
    Directory dir = new MockRAMDirectory();
    RandomIndexWriter rw = new RandomIndexWriter(newRandom(), dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    for (int i = 0; i < 5; i++) {
      Document doc = new Document();
      doc.add(new Field("pk", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));
      rw.addDocument(doc);
    }
    rw.close();

    // If buffer size is small enough to cause a flush, errors ensue...
    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));

    Term pkTerm = new Term("pk", "");
    for (int i = 0; i < 3; i++) {
      Document doc = new Document();
      String value = Integer.toString(i);
      doc.add(new Field("pk", value, Store.YES, Index.ANALYZED_NO_NORMS));
      doc.add(new Field("text", "foo", Store.YES, Index.ANALYZED_NO_NORMS));
      w.updateDocument(pkTerm.createTerm(value), doc);
    }
    w.rollback();

    IndexReader r = IndexReader.open(dir, true);
    assertEquals("index should contain same number of docs post rollback", 5, r.numDocs());
    r.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583527215/fstmerge_var2_974896535839351183

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/TestRollback.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583527319/fstmerge_var1_9198826353149293076
public void testRandom() throws Exception {

    Random r = newRandom();

    for(int iter=0;iter<2*_TestUtil.getRandomMultiplier();iter++) {
      Directory dir = new MockRAMDirectory();

      IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));

      Map<BytesRef,List<Integer>> docs = new HashMap<BytesRef,List<Integer>>();
      Set<Integer> deleted = new HashSet<Integer>();
      List<BytesRef> terms = new ArrayList<BytesRef>();

      int numDocs = _TestUtil.nextInt(r, 1, 100*_TestUtil.getRandomMultiplier());
      Document doc = new Document();
      Field f = new Field("field", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
      doc.add(f);
      Field id = new Field("id", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
      doc.add(id);

      boolean onlyUniqueTerms = r.nextBoolean();
      Set<BytesRef> uniqueTerms = new HashSet<BytesRef>();
      for(int i=0;i<numDocs;i++) {

        if (!onlyUniqueTerms && r.nextBoolean() && terms.size() > 0) {
          // re-use existing term
          BytesRef term = terms.get(r.nextInt(terms.size()));
          docs.get(term).add(i);
          f.setValue(term.utf8ToString());
        } else {
          String s = _TestUtil.randomUnicodeString(r, 10);
          BytesRef term = new BytesRef(s);
          if (!docs.containsKey(term)) {
            docs.put(term, new ArrayList<Integer>());
          }
          docs.get(term).add(i);
          terms.add(term);
          uniqueTerms.add(term);
          f.setValue(s);
        }
        id.setValue(""+i);
        w.addDocument(doc);
        if (r.nextInt(4) == 1) {
          w.commit();
        }
        if (i > 0 && r.nextInt(20) == 1) {
          int delID = r.nextInt(i);
          deleted.add(delID);
          w.deleteDocuments(new Term("id", ""+delID));
        }
      }

      if (VERBOSE) {
        List<BytesRef> termsList = new ArrayList<BytesRef>(uniqueTerms);
        Collections.sort(termsList, BytesRef.getUTF8SortedAsUTF16Comparator());
        System.out.println("UTF16 order:");
        for(BytesRef b : termsList) {
          System.out.println("  " + UnicodeUtil.toHexString(b.utf8ToString()));
        }
      }

      IndexReader reader = w.getReader();
      w.close();
      //System.out.println("TEST reader=" + reader);

      Bits delDocs = MultiFields.getDeletedDocs(reader);
      for(int delDoc : deleted) {
        assertTrue(delDocs.get(delDoc));
      }
      Terms terms2 = MultiFields.getTerms(reader, "field");

      for(int i=0;i<100;i++) {
        BytesRef term = terms.get(r.nextInt(terms.size()));
        
        DocsEnum docsEnum = terms2.docs(delDocs, term, null);
        assertNotNull(docsEnum);

        for(int docID : docs.get(term)) {
          if (!deleted.contains(docID)) {
            assertEquals(docID, docsEnum.nextDoc());
          }
        }
        assertEquals(docsEnum.NO_MORE_DOCS, docsEnum.nextDoc());
      }

      reader.close();
      dir.close();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583527319/fstmerge_base_4459797150598541143
public void testRandom() throws Exception {

    for(int iter=0;iter<2*_TestUtil.getRandomMultiplier();iter++) {
      Directory dir = new MockRAMDirectory();
      IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));

      Random r = new Random();

      Map<BytesRef,List<Integer>> docs = new HashMap<BytesRef,List<Integer>>();
      Set<Integer> deleted = new HashSet<Integer>();
      List<BytesRef> terms = new ArrayList<BytesRef>();

      int numDocs = _TestUtil.nextInt(r, 1, 100*_TestUtil.getRandomMultiplier());
      Document doc = new Document();
      Field f = new Field("field", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
      doc.add(f);
      Field id = new Field("id", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
      doc.add(id);

      boolean onlyUniqueTerms = r.nextBoolean();

      for(int i=0;i<numDocs;i++) {

        if (!onlyUniqueTerms && r.nextBoolean() && terms.size() > 0) {
          // re-use existing term
          BytesRef term = terms.get(r.nextInt(terms.size()));
          docs.get(term).add(i);
          f.setValue(term.utf8ToString());
        } else {
          String s = _TestUtil.randomUnicodeString(r, 10);
          BytesRef term = new BytesRef(s);
          if (!docs.containsKey(term)) {
            docs.put(term, new ArrayList<Integer>());
          }
          docs.get(term).add(i);
          terms.add(term);
          f.setValue(s);
        }
        id.setValue(""+i);
        w.addDocument(doc);
        if (r.nextInt(4) == 1) {
          w.commit();
        }
        if (i > 0 && r.nextInt(20) == 1) {
          int delID = r.nextInt(i);
          deleted.add(delID);
          w.deleteDocuments(new Term("id", ""+delID));
        }
      }

      IndexReader reader = w.getReader();
      w.close();

      Bits delDocs = MultiFields.getDeletedDocs(reader);
      for(int delDoc : deleted) {
        assertTrue(delDocs.get(delDoc));
      }
      Terms terms2 = MultiFields.getTerms(reader, "field");

      for(int i=0;i<100;i++) {
        BytesRef term = terms.get(r.nextInt(terms.size()));
        
        DocsEnum docsEnum = terms2.docs(delDocs, term, null);
        assertNotNull(docsEnum);

        for(int docID : docs.get(term)) {
          if (!deleted.contains(docID)) {
            assertEquals(docID, docsEnum.nextDoc());
          }
        }
        assertEquals(docsEnum.NO_MORE_DOCS, docsEnum.nextDoc());
      }

      reader.close();
      dir.close();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583527319/fstmerge_var2_8874141765231718263

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/TestMultiFields.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583527461/fstmerge_var1_3296159662613521226
public void testPrevTermAtEnd() throws IOException
  {
    Directory dir = new MockRAMDirectory();
    IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
    addDoc(writer, "aaa bbb");
    writer.close();
    SegmentReader reader = SegmentReader.getOnlySegmentReader(dir);
    TermsEnum terms = reader.fields().terms("content").iterator();
    assertNotNull(terms.next());
    assertEquals("aaa", terms.term().utf8ToString());
    assertNotNull(terms.next());
    long ordB = terms.ord();
    assertEquals("bbb", terms.term().utf8ToString());
    assertNull(terms.next());

    assertEquals(TermsEnum.SeekStatus.FOUND, terms.seek(ordB));
    assertEquals("bbb", terms.term().utf8ToString());
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583527461/fstmerge_base_8832536278134311269
public void testPrevTermAtEnd() throws IOException
  {
    Directory dir = new MockRAMDirectory();
    IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    addDoc(writer, "aaa bbb");
    writer.close();
    SegmentReader reader = SegmentReader.getOnlySegmentReader(dir);
    TermsEnum terms = reader.fields().terms("content").iterator();
    assertNotNull(terms.next());
    assertEquals("aaa", terms.term().utf8ToString());
    assertNotNull(terms.next());
    long ordB = terms.ord();
    assertEquals("bbb", terms.term().utf8ToString());
    assertNull(terms.next());

    assertEquals(TermsEnum.SeekStatus.FOUND, terms.seek(ordB));
    assertEquals("bbb", terms.term().utf8ToString());
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583527461/fstmerge_var2_1665721149029756502

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/TestSegmentTermEnum.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583527695/fstmerge_var1_2955901615899178944
public void _run() throws Throwable {

      for(int iter=0;iter<NUM_TEST_ITER;iter++) {
        final FieldData field = fields[TestCodecs.this.nextInt(fields.length)];
        final TermsEnum termsEnum = termsDict.terms(field.fieldInfo.name).iterator();

        // Test straight enum of the terms:
        int upto = 0;
        while(true) {
          final BytesRef term = termsEnum.next();
          if (term == null) {
            break;
          }
          assertTrue(new BytesRef(field.terms[upto++].text2).bytesEquals(term));
        }
        assertEquals(upto, field.terms.length);

        // Test random seek:
        TermData term = field.terms[TestCodecs.this.nextInt(field.terms.length)];
        TermsEnum.SeekStatus status = termsEnum.seek(new BytesRef(term.text2));
        assertEquals(status, TermsEnum.SeekStatus.FOUND);
        assertEquals(term.docs.length, termsEnum.docFreq());
        if (field.omitTF) {
          this.verifyDocs(term.docs, term.positions, termsEnum.docs(null, null), false);
        } else {
          this.verifyDocs(term.docs, term.positions, termsEnum.docsAndPositions(null, null), true);
        }

        // Test random seek by ord:
        final int idx = TestCodecs.this.nextInt(field.terms.length);
        term = field.terms[idx];
        try {
          status = termsEnum.seek(idx);
        } catch (UnsupportedOperationException uoe) {
          // ok -- skip it
          status = null;
        }
        if (status != null) {
          assertEquals(status, TermsEnum.SeekStatus.FOUND);
          assertTrue(termsEnum.term().bytesEquals(new BytesRef(term.text2)));
          assertEquals(term.docs.length, termsEnum.docFreq());
          if (field.omitTF) {
            this.verifyDocs(term.docs, term.positions, termsEnum.docs(null, null), false);
          } else {
            this.verifyDocs(term.docs, term.positions, termsEnum.docsAndPositions(null, null), true);
          }
        }

        // Test seek to non-existent terms:
        for(int i=0;i<100;i++) {
          final char[] text = TestCodecs.this.getRandomText();
          final String text2 = new String(text, 0, text.length-1) + ".";
          status = termsEnum.seek(new BytesRef(text2));
          assertTrue(status == TermsEnum.SeekStatus.NOT_FOUND ||
                     status == TermsEnum.SeekStatus.END);
        }

        // Seek to each term, backwards:
        for(int i=field.terms.length-1;i>=0;i--) {
          assertEquals(Thread.currentThread().getName() + ": field=" + field.fieldInfo.name + " term=" + field.terms[i].text2, TermsEnum.SeekStatus.FOUND, termsEnum.seek(new BytesRef(field.terms[i].text2)));
          assertEquals(field.terms[i].docs.length, termsEnum.docFreq());
        }

        // Seek to each term by ord, backwards
        for(int i=field.terms.length-1;i>=0;i--) {
          try {
            assertEquals(Thread.currentThread().getName() + ": field=" + field.fieldInfo.name + " term=" + field.terms[i].text2, TermsEnum.SeekStatus.FOUND, termsEnum.seek(i));
            assertEquals(field.terms[i].docs.length, termsEnum.docFreq());
            assertTrue(termsEnum.term().bytesEquals(new BytesRef(field.terms[i].text2)));
          } catch (UnsupportedOperationException uoe) {
          }
        }

        // Seek to non-existent empty-string term
        status = termsEnum.seek(new BytesRef(""));
        assertNotNull(status);
        assertEquals(status, TermsEnum.SeekStatus.NOT_FOUND);

        // Make sure we're now pointing to first term
        assertTrue(termsEnum.term().bytesEquals(new BytesRef(field.terms[0].text2)));

        // Test docs enum
        termsEnum.seek(new BytesRef(""));
        upto = 0;
        do {
          term = field.terms[upto];
          if (TestCodecs.this.nextInt(3) == 1) {
            final DocsEnum docs = termsEnum.docs(null, null);
            final DocsAndPositionsEnum postings = termsEnum.docsAndPositions(null, null);

            final DocsEnum docsEnum;
            if (postings != null) {
              docsEnum = postings;
            } else {
              docsEnum = docs;
            }
            int upto2 = -1;
            while(upto2 < term.docs.length-1) {
              // Maybe skip:
              final int left = term.docs.length-upto2;
              int doc;
              if (TestCodecs.this.nextInt(3) == 1 && left >= 1) {
                final int inc = 1+TestCodecs.this.nextInt(left-1);
                upto2 += inc;
                if (TestCodecs.this.nextInt(2) == 1) {
                  doc = docsEnum.advance(term.docs[upto2]);
                  assertEquals(term.docs[upto2], doc);
                } else {
                  doc = docsEnum.advance(1+term.docs[upto2]);
                  if (doc == DocIdSetIterator.NO_MORE_DOCS) {
                    // skipped past last doc
                    assert upto2 == term.docs.length-1;
                    break;
                  } else {
                    // skipped to next doc
                    assert upto2 < term.docs.length-1;
                    if (doc >= term.docs[1+upto2]) {
                      upto2++;
                    }
                  }
                }
              } else {
                doc = docsEnum.nextDoc();
                assertTrue(doc != -1);
                upto2++;
              }
              assertEquals(term.docs[upto2], doc);
              if (!field.omitTF) {
                assertEquals(term.positions[upto2].length, docsEnum.freq());
                if (TestCodecs.this.nextInt(2) == 1) {
                  this.verifyPositions(term.positions[upto2], postings);
                }
              }
            }

            assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());
          }
          upto++;

        } while (termsEnum.next() != null);

        assertEquals(upto, field.terms.length);
      }
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583527695/fstmerge_base_5331165092217321497
public void _run() throws Throwable {

      for(int iter=0;iter<NUM_TEST_ITER;iter++) {
        final FieldData field = fields[TestCodecs.this.nextInt(fields.length)];
        final TermsEnum termsEnum = termsDict.terms(field.fieldInfo.name).iterator();

        // Test straight enum of the terms:
        int upto = 0;
        while(true) {
          final BytesRef term = termsEnum.next();
          if (term == null) {
            break;
          }
          assertTrue(new BytesRef(field.terms[upto++].text2).bytesEquals(term));
        }
        assertEquals(upto, field.terms.length);

        // Test random seek:
        TermData term = field.terms[TestCodecs.this.nextInt(field.terms.length)];
        TermsEnum.SeekStatus status = termsEnum.seek(new BytesRef(term.text2));
        assertEquals(status, TermsEnum.SeekStatus.FOUND);
        assertEquals(term.docs.length, termsEnum.docFreq());
        if (field.omitTF) {
          this.verifyDocs(term.docs, term.positions, termsEnum.docs(null, null), false);
        } else {
          this.verifyDocs(term.docs, term.positions, termsEnum.docsAndPositions(null, null), true);
        }

        // Test random seek by ord:
        final int idx = TestCodecs.this.nextInt(field.terms.length);
        term = field.terms[idx];
        status = termsEnum.seek(idx);
        assertEquals(status, TermsEnum.SeekStatus.FOUND);
        assertTrue(termsEnum.term().bytesEquals(new BytesRef(term.text2)));
        assertEquals(term.docs.length, termsEnum.docFreq());
        if (field.omitTF) {
          this.verifyDocs(term.docs, term.positions, termsEnum.docs(null, null), false);
        } else {
          this.verifyDocs(term.docs, term.positions, termsEnum.docsAndPositions(null, null), true);
        }

        // Test seek to non-existent terms:
        for(int i=0;i<100;i++) {
          final char[] text = TestCodecs.this.getRandomText();
          final String text2 = new String(text, 0, text.length-1) + ".";
          status = termsEnum.seek(new BytesRef(text2));
          assertTrue(status == TermsEnum.SeekStatus.NOT_FOUND ||
                     status == TermsEnum.SeekStatus.END);
        }

        // Seek to each term, backwards:
        for(int i=field.terms.length-1;i>=0;i--) {
          assertEquals(Thread.currentThread().getName() + ": field=" + field.fieldInfo.name + " term=" + field.terms[i].text2, TermsEnum.SeekStatus.FOUND, termsEnum.seek(new BytesRef(field.terms[i].text2)));
          assertEquals(field.terms[i].docs.length, termsEnum.docFreq());
        }

        // Seek to each term by ord, backwards
        for(int i=field.terms.length-1;i>=0;i--) {
          assertEquals(Thread.currentThread().getName() + ": field=" + field.fieldInfo.name + " term=" + field.terms[i].text2, TermsEnum.SeekStatus.FOUND, termsEnum.seek(i));
          assertEquals(field.terms[i].docs.length, termsEnum.docFreq());
          assertTrue(termsEnum.term().bytesEquals(new BytesRef(field.terms[i].text2)));
        }

        // Seek to non-existent empty-string term
        status = termsEnum.seek(new BytesRef(""));
        assertNotNull(status);
        assertEquals(status, TermsEnum.SeekStatus.NOT_FOUND);

        // Make sure we're now pointing to first term
        assertTrue(termsEnum.term().bytesEquals(new BytesRef(field.terms[0].text2)));

        // Test docs enum
        termsEnum.seek(new BytesRef(""));
        upto = 0;
        do {
          term = field.terms[upto];
          if (TestCodecs.this.nextInt(3) == 1) {
            final DocsEnum docs = termsEnum.docs(null, null);
            final DocsAndPositionsEnum postings = termsEnum.docsAndPositions(null, null);

            final DocsEnum docsEnum;
            if (postings != null) {
              docsEnum = postings;
            } else {
              docsEnum = docs;
            }
            int upto2 = -1;
            while(upto2 < term.docs.length-1) {
              // Maybe skip:
              final int left = term.docs.length-upto2;
              int doc;
              if (TestCodecs.this.nextInt(3) == 1 && left >= 1) {
                final int inc = 1+TestCodecs.this.nextInt(left-1);
                upto2 += inc;
                if (TestCodecs.this.nextInt(2) == 1) {
                  doc = docsEnum.advance(term.docs[upto2]);
                  assertEquals(term.docs[upto2], doc);
                } else {
                  doc = docsEnum.advance(1+term.docs[upto2]);
                  if (doc == DocIdSetIterator.NO_MORE_DOCS) {
                    // skipped past last doc
                    assert upto2 == term.docs.length-1;
                    break;
                  } else {
                    // skipped to next doc
                    assert upto2 < term.docs.length-1;
                    if (doc >= term.docs[1+upto2]) {
                      upto2++;
                    }
                  }
                }
              } else {
                doc = docsEnum.nextDoc();
                assertTrue(doc != -1);
                upto2++;
              }
              assertEquals(term.docs[upto2], doc);
              if (!field.omitTF) {
                assertEquals(term.positions[upto2].length, docsEnum.freq());
                if (TestCodecs.this.nextInt(2) == 1) {
                  this.verifyPositions(term.positions[upto2], postings);
                }
              }
            }

            assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());
          }
          upto++;

        } while (termsEnum.next() != null);

        assertEquals(upto, field.terms.length);
      }
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583527695/fstmerge_var2_3740149968561046428

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/TestCodecs.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583528444/fstmerge_var1_4069187976089402146
public void testTermUTF16SortOrder() throws Throwable {
    Random rnd = newRandom();
    Directory dir = new MockRAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(rnd, dir);
    Document d = new Document();
    // Single segment
    Field f = new Field("f", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
    d.add(f);
    char[] chars = new char[2];
    final Set<String> allTerms = new HashSet<String>();

    for(int i=0;i<10*_TestUtil.getRandomMultiplier();i++) {

      final String s;
      if (rnd.nextBoolean()) {
        // Single char
        if (rnd.nextBoolean()) {
          // Above surrogates
          chars[0] = (char) getInt(rnd, 1+UnicodeUtil.UNI_SUR_LOW_END, 0xffff);
        } else {
          // Below surrogates
          chars[0] = (char) getInt(rnd, 0, UnicodeUtil.UNI_SUR_HIGH_START-1);
        }
        s = new String(chars, 0, 1);
      } else {
        // Surrogate pair
        chars[0] = (char) getInt(rnd, UnicodeUtil.UNI_SUR_HIGH_START, UnicodeUtil.UNI_SUR_HIGH_END);
        assertTrue(((int) chars[0]) >= UnicodeUtil.UNI_SUR_HIGH_START && ((int) chars[0]) <= UnicodeUtil.UNI_SUR_HIGH_END);
        chars[1] = (char) getInt(rnd, UnicodeUtil.UNI_SUR_LOW_START, UnicodeUtil.UNI_SUR_LOW_END);
        s = new String(chars, 0, 2);
      }
      allTerms.add(s);
      f.setValue(s);

      writer.addDocument(d);

      if ((1+i) % 42 == 0) {
        writer.commit();
      }
    }

    IndexReader r = writer.getReader();

    // Test each sub-segment
    final IndexReader[] subs = r.getSequentialSubReaders();
    for(int i=0;i<subs.length;i++) {
      checkTermsOrder(subs[i], allTerms, false);
    }
    checkTermsOrder(r, allTerms, true);

    // Test multi segment
    r.close();

    writer.optimize();

    // Test optimized single segment
    r = writer.getReader();
    checkTermsOrder(r, allTerms, true);
    r.close();

    writer.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583528444/fstmerge_base_3923395779824597677
public void testTermUTF16SortOrder() throws Throwable {
    Directory dir = new MockRAMDirectory();
    IndexWriter writer = new IndexWriter(dir, new MockAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);
    Document d = new Document();
    // Single segment
    Field f = new Field("f", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
    d.add(f);
    char[] chars = new char[2];
    Random rnd = newRandom();
    final Set<String> allTerms = new HashSet<String>();

    for(int i=0;i<200*_TestUtil.getRandomMultiplier();i++) {

      final String s;
      if (rnd.nextBoolean()) {
        // Single char
        if (rnd.nextBoolean()) {
          // Above surrogates
          chars[0] = (char) getInt(rnd, 1+UnicodeUtil.UNI_SUR_LOW_END, 0xffff);
        } else {
          // Below surrogates
          chars[0] = (char) getInt(rnd, 0, UnicodeUtil.UNI_SUR_HIGH_START-1);
        }
        s = new String(chars, 0, 1);
      } else {
        // Surrogate pair
        chars[0] = (char) getInt(rnd, UnicodeUtil.UNI_SUR_HIGH_START, UnicodeUtil.UNI_SUR_HIGH_END);
        assertTrue(((int) chars[0]) >= UnicodeUtil.UNI_SUR_HIGH_START && ((int) chars[0]) <= UnicodeUtil.UNI_SUR_HIGH_END);
        chars[1] = (char) getInt(rnd, UnicodeUtil.UNI_SUR_LOW_START, UnicodeUtil.UNI_SUR_LOW_END);
        s = new String(chars, 0, 2);
      }
      allTerms.add(s);
      f.setValue(s);

      //System.out.println("add " + termDesc(s));
      writer.addDocument(d);

      if ((1+i) % 42 == 0) {
        writer.commit();
      }
    }
    
    IndexReader r = writer.getReader();

    // Test each sub-segment
    final IndexReader[] subs = r.getSequentialSubReaders();
    for(int i=0;i<subs.length;i++) {
      checkTermsOrder(subs[i], allTerms, false);
    }
    checkTermsOrder(r, allTerms, true);

    // Test multi segment
    r.close();

    writer.optimize();

    // Test optimized single segment
    r = writer.getReader();
    checkTermsOrder(r, allTerms, true);
    r.close();

    writer.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583528444/fstmerge_var2_6225259559400976205

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583528884/fstmerge_var1_4180787133105646248
public void testTermOrd() throws Exception {
    Directory d = new MockRAMDirectory();
    IndexWriter w = new IndexWriter(d, new IndexWriterConfig(TEST_VERSION_CURRENT,
                                                             new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
    Document doc = new Document();
    doc.add(new Field("f", "a b c", Field.Store.NO, Field.Index.ANALYZED));
    w.addDocument(doc);
    IndexReader r = w.getReader();
    TermsEnum terms = r.getSequentialSubReaders()[0].fields().terms("f").iterator();
    assertTrue(terms.next() != null);
    assertEquals(0, terms.ord());
    r.close();
    w.close();
    d.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583528884/fstmerge_base_4927725819479732485
public void testTermOrd() throws Exception {
    Directory d = new MockRAMDirectory();
    IndexWriter w = new IndexWriter(d, new MockAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);
    Document doc = new Document();
    doc.add(new Field("f", "a b c", Field.Store.NO, Field.Index.ANALYZED));
    w.addDocument(doc);
    IndexReader r = w.getReader();
    TermsEnum terms = r.getSequentialSubReaders()[0].fields().terms("f").iterator();
    assertTrue(terms.next() != null);
    assertEquals(0, terms.ord());
    r.close();
    w.close();
    d.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583528884/fstmerge_var2_2575323652260952336

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/TestFlex.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583529452/fstmerge_var1_6046253626185212057
public RandomIndexWriter(Random r, Directory dir, IndexWriterConfig c) throws IOException {
    this.r = r;
    w = new MockIndexWriter(r, dir, c);
    flushAt = _TestUtil.nextInt(r, 10, 1000);
    if (LuceneTestCaseJ4.VERBOSE) {
      System.out.println("RIW config=" + w.getConfig());
      System.out.println("codec default=" + CodecProvider.getDefaultCodec());
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583529452/fstmerge_base_3286035920880497290
public RandomIndexWriter(Random r, Directory dir, IndexWriterConfig c) throws IOException {
    this.r = r;
    if (r.nextBoolean()) {
      c.setMergePolicy(new LogDocMergePolicy());
    }
    if (r.nextBoolean()) {
      c.setMergeScheduler(new SerialMergeScheduler());
    }
    if (r.nextBoolean()) {
      c.setMaxBufferedDocs(_TestUtil.nextInt(r, 2, 1000));
    }
    if (r.nextBoolean()) {
      c.setTermIndexInterval(_TestUtil.nextInt(r, 1, 1000));
    }
    
    if (c.getMergePolicy() instanceof LogMergePolicy) {
      LogMergePolicy logmp = (LogMergePolicy) c.getMergePolicy();
      logmp.setUseCompoundDocStore(r.nextBoolean());
      logmp.setUseCompoundFile(r.nextBoolean());
      logmp.setCalibrateSizeByDeletes(r.nextBoolean());
    }
    
    c.setReaderPooling(r.nextBoolean());
    c.setCodecProvider(new RandomCodecProvider(r));
    w = new IndexWriter(dir, c);
    flushAt = _TestUtil.nextInt(r, 10, 1000);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583529452/fstmerge_var2_6455682170461363781

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/RandomIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583529474/fstmerge_var1_1017385067787718808
public IndexReader getReader() throws IOException {
    // If we are writing with PreFlexRW, force a full
    // IndexReader.open so terms are sorted in codepoint
    // order during searching:
    if (!w.codecs.getWriter(null).name.equals("PreFlex") && r.nextBoolean()) {
      if (LuceneTestCaseJ4.VERBOSE) {
        System.out.println("RIW.getReader: use NRT reader");
      }
      return w.getReader();
    } else {
      if (LuceneTestCaseJ4.VERBOSE) {
        System.out.println("RIW.getReader: open new reader");
      }
      w.commit();
      return IndexReader.open(w.getDirectory(), new KeepOnlyLastCommitDeletionPolicy(), r.nextBoolean(), _TestUtil.nextInt(r, 1, 10));
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583529474/fstmerge_base_9039548293060302843
public IndexReader getReader() throws IOException {
    if (r.nextBoolean()) {
      return w.getReader();
    } else {
      w.commit();
      return IndexReader.open(w.getDirectory(), new KeepOnlyLastCommitDeletionPolicy(), r.nextBoolean(), _TestUtil.nextInt(r, 1, 10));
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583529474/fstmerge_var2_6321717856250753352

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/RandomIndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583529992/fstmerge_var1_4528868536000899684
public void testWithPendingDeletes() throws IOException {
    // main directory
    Directory dir = new MockRAMDirectory();
    // auxiliary directory
    Directory aux = new MockRAMDirectory();

    setUpDirs(dir, aux);
    IndexWriter writer = newWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
    writer.addIndexes(new Directory[] {aux});

    // Adds 10 docs, then replaces them with another 10
    // docs, so 10 pending deletes:
    for (int i = 0; i < 20; i++) {
      Document doc = new Document();
      doc.add(new Field("id", "" + (i % 10), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(new Field("content", "bbb " + i, Field.Store.NO,
                        Field.Index.ANALYZED));
      writer.updateDocument(new Term("id", "" + (i%10)), doc);
    }
    // Deletes one of the 10 added docs, leaving 9:
    PhraseQuery q = new PhraseQuery();
    q.add(new Term("content", "bbb"));
    q.add(new Term("content", "14"));
    writer.deleteDocuments(q);

    writer.optimize();
    writer.commit();

    verifyNumDocs(dir, 1039);
    verifyTermDocs(dir, new Term("content", "aaa"), 1030);
    verifyTermDocs(dir, new Term("content", "bbb"), 9);

    writer.close();
    dir.close();
    aux.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583529992/fstmerge_base_4375910480095068265
public void testWithPendingDeletes() throws IOException {
    // main directory
    Directory dir = new MockRAMDirectory();
    // auxiliary directory
    Directory aux = new MockRAMDirectory();

    setUpDirs(dir, aux);
    IndexWriter writer = newWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));

    writer.addIndexes(new Directory[] {aux});

    // Adds 10 docs, then replaces them with another 10
    // docs, so 10 pending deletes:
    for (int i = 0; i < 20; i++) {
      Document doc = new Document();
      doc.add(new Field("id", "" + (i % 10), Field.Store.NO, Field.Index.NOT_ANALYZED));
      doc.add(new Field("content", "bbb " + i, Field.Store.NO,
                        Field.Index.ANALYZED));
      writer.updateDocument(new Term("id", "" + (i%10)), doc);
    }
    // Deletes one of the 10 added docs, leaving 9:
    PhraseQuery q = new PhraseQuery();
    q.add(new Term("content", "bbb"));
    q.add(new Term("content", "14"));
    writer.deleteDocuments(q);

    writer.optimize();
    writer.commit();

    verifyNumDocs(dir, 1039);
    verifyTermDocs(dir, new Term("content", "aaa"), 1030);
    verifyTermDocs(dir, new Term("content", "bbb"), 9);

    writer.close();
    dir.close();
    aux.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583529992/fstmerge_var2_8200380571915554964

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583530135/fstmerge_var1_4478337356480153157
private static String makeDifficultRandomUnicodeString(Random r) {
    final int end = r.nextInt(20);
    if (end == 0) {
      // allow 0 length
      return "";
    }
    final char[] buffer = new char[end];
    for (int i = 0; i < end; i++) {
      int t = r.nextInt(5);

      if (0 == t && i < end - 1) {
        // hi
        buffer[i++] = (char) (0xd800 + r.nextInt(2));
        // lo
        buffer[i] = (char) (0xdc00 + r.nextInt(2));
      } else if (t <= 3) {
        buffer[i] = (char) ('a' + r.nextInt(2));
      }  else if (4 == t) {
        buffer[i] = (char) (0xe000 + r.nextInt(2));
      }
    }

    return new String(buffer, 0, end);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583530135/fstmerge_base_2285446858183324135
private static String makeDifficultRandomUnicodeString(Random r) {
    final int end = r.nextInt(20);
    if (end == 0) {
      // allow 0 length
      return "";
    }
    final char[] buffer = new char[end];
    for (int i = 0; i < end; i++) {
      int t = r.nextInt(5);

      if (0 == t && i < end - 1) {
        // hi
        buffer[i++] = (char) 0xd800;
        // lo
        buffer[i] = (char) 0xdc00;
      } else if (t <= 3) {
        buffer[i] = 'a';
      }  else if (4 == t) {
        buffer[i] = 0xe000;
      }
    }

    return new String(buffer, 0, end);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583530135/fstmerge_var2_1600981759202071667

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583530144/fstmerge_var1_5559532182615759662
@Test
  public void testSurrogatesOrder() throws Exception {
    Random r = newRandom();

    Directory dir = new MockRAMDirectory();
    RandomIndexWriter w = new RandomIndexWriter(r,
                                                dir,
                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,
                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));

    final int numField = _TestUtil.nextInt(r, 2, 5);

    int uniqueTermCount = 0;

    int tc = 0;

    List<Term> fieldTerms = new ArrayList<Term>();

    for(int f=0;f<numField;f++) {
      String field = "f" + f;
      final int numTerms = 10000*_TestUtil.getRandomMultiplier();

      final Set<String> uniqueTerms = new HashSet<String>();

      for(int i=0;i<numTerms;i++) {
        String term = getRandomString(r) + "_ " + (tc++);
        uniqueTerms.add(term);
        fieldTerms.add(new Term(field, term));
        Document doc = new Document();
        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));
        w.addDocument(doc);
      }
      uniqueTermCount += uniqueTerms.size();
    }

    IndexReader reader = w.getReader();

    if (VERBOSE) {
      Collections.sort(fieldTerms, termAsUTF16Comparator);

      System.out.println("\nTEST: UTF16 order");
      for(Term t: fieldTerms) {
        System.out.println("  " + toHexString(t));
      }
    }

    // sorts in code point order:
    Collections.sort(fieldTerms);

    if (VERBOSE) {
      System.out.println("\nTEST: codepoint order");
      for(Term t: fieldTerms) {
        System.out.println("  " + toHexString(t));
      }
    }

    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);

    //SegmentInfo si = makePreFlexSegment(r, "_0", dir, fieldInfos, codec, fieldTerms);

    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));
    //assertNotNull(fields);

    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);
    doTestSeekExists(r, fieldTerms, reader);
    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);

    reader.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583530144/fstmerge_base_3527488531570064006
@Test
  public void testSurrogatesOrder() throws Exception {
    Directory dir = new MockRAMDirectory();

    Codec codec = new PreFlexCodec();

    Random r = newRandom();
    FieldInfos fieldInfos = new FieldInfos();
    List<Term> fieldTerms = new ArrayList<Term>();
    SegmentInfo si = makePreFlexSegment(r, "_0", dir, fieldInfos, codec, fieldTerms);

    // hack alert!!
    int uniqueTermCount = si.docCount;

    FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));
    assertNotNull(fields);

    if (VERBOSE) {
      System.out.println("\nTEST: now enum");
    }
    FieldsEnum fieldsEnum = fields.iterator();
    String field;
    UnicodeUtil.UTF16Result utf16 = new UnicodeUtil.UTF16Result();

    int termCount = 0;
    while((field = fieldsEnum.next()) != null) {
      TermsEnum termsEnum = fieldsEnum.terms();
      BytesRef text;
      BytesRef lastText = null;
      while((text = termsEnum.next()) != null) {
        if (VERBOSE) {
          UnicodeUtil.UTF8toUTF16(text.bytes, text.offset, text.length, utf16);
          System.out.println("got term=" + field + ":" + UnicodeUtil.toHexString(new String(utf16.result, 0, utf16.length)));
          System.out.println();
        }
        if (lastText == null) {
          lastText = new BytesRef(text);
        } else {
          assertTrue(lastText.compareTo(text) < 0);
          lastText.copy(text);
        }
        assertEquals(fieldTerms.get(termCount).field(), field);
        assertEquals(fieldTerms.get(termCount).bytes(), text);
        termCount++;
      }
      if (VERBOSE) {
        System.out.println("  no more terms for field=" + field);
      }
    }
    assertEquals(uniqueTermCount, termCount);

    fields.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583530144/fstmerge_var2_8045606686820195222

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583534120/fstmerge_var1_4912088765762126432
public Sort(SortField field) {
    setSort(field);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583534120/fstmerge_base_3666546308398283682
public Sort(SortField... fields) {
    setSort(fields);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583534120/fstmerge_var2_727013751063059861

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/search/Sort.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583534129/fstmerge_var1_5601068425919791427
public void setSort(SortField field) {
    this.fields = new SortField[] { field };
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583534129/fstmerge_base_468684327341487994
public void setSort(SortField... fields) {
    this.fields = fields;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583534129/fstmerge_var2_939135996532270290

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/search/Sort.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583535376/fstmerge_var1_6328800411407281053
@Override
    protected Object createValue(IndexReader reader, Entry entryKey)
        throws IOException {

      String field = StringHelper.intern(entryKey.field);

      Terms terms = MultiFields.getTerms(reader, field);

      final boolean fasterButMoreRAM = ((Boolean) entryKey.custom).booleanValue();

      final PagedBytes bytes = new PagedBytes(15);

      int startBytesBPV;
      int startTermsBPV;
      int startNumUniqueTerms;

      int maxDoc = reader.maxDoc();
      final int termCountHardLimit;
      if (maxDoc == Integer.MAX_VALUE) {
        termCountHardLimit = Integer.MAX_VALUE;
      } else {
        termCountHardLimit = maxDoc+1;
      }

      if (terms != null) {
        // Try for coarse estimate for number of bits; this
        // should be an underestimate most of the time, which
        // is fine -- GrowableWriter will reallocate as needed
        long numUniqueTerms = 0;
        try {
          numUniqueTerms = terms.getUniqueTermCount();
        } catch (UnsupportedOperationException uoe) {
          numUniqueTerms = -1;
        }
        if (numUniqueTerms != -1) {

          if (numUniqueTerms > termCountHardLimit) {
            // app is misusing the API (there is more than
            // one term per doc); in this case we make best
            // effort to load what we can (see LUCENE-2142)
            numUniqueTerms = termCountHardLimit;
          }

          startBytesBPV = PackedInts.bitsRequired(numUniqueTerms*4);
          startTermsBPV = PackedInts.bitsRequired(numUniqueTerms);

          startNumUniqueTerms = (int) numUniqueTerms;
        } else {
          startBytesBPV = 1;
          startTermsBPV = 1;
          startNumUniqueTerms = 1;
        }
      } else {
        startBytesBPV = 1;
        startTermsBPV = 1;
        startNumUniqueTerms = 1;
      }

      GrowableWriter termOrdToBytesOffset = new GrowableWriter(startBytesBPV, 1+startNumUniqueTerms, fasterButMoreRAM);
      final GrowableWriter docToTermOrd = new GrowableWriter(startTermsBPV, reader.maxDoc(), fasterButMoreRAM);

      // 0 is reserved for "unset"
      bytes.copyUsingLengthPrefix(new BytesRef());
      int termOrd = 1;

      if (terms != null) {
        final TermsEnum termsEnum = terms.iterator();
        final Bits delDocs = MultiFields.getDeletedDocs(reader);
        DocsEnum docs = null;

        while(true) {
          final BytesRef term = termsEnum.next();
          if (term == null) {
            break;
          }
          if (termOrd >= termCountHardLimit) {
            break;
          }

          if (termOrd == termOrdToBytesOffset.size()) {
            // NOTE: this code only runs if the incoming
            // reader impl doesn't implement
            // getUniqueTermCount (which should be uncommon)
            termOrdToBytesOffset = termOrdToBytesOffset.resize(ArrayUtil.oversize(1+termOrd, 1));
          }
          termOrdToBytesOffset.set(termOrd, bytes.copyUsingLengthPrefix(term));
          docs = termsEnum.docs(delDocs, docs);
          while (true) {
            final int docID = docs.nextDoc();
            if (docID == DocsEnum.NO_MORE_DOCS) {
              break;
            }
            docToTermOrd.set(docID, termOrd);
          }
          termOrd++;
        }

        if (termOrdToBytesOffset.size() > termOrd) {
          termOrdToBytesOffset = termOrdToBytesOffset.resize(termOrd);
        }
      }

      // maybe an int-only impl?
      return new DocTermsIndexImpl(bytes.freeze(true), termOrdToBytesOffset.getMutable(), docToTermOrd.getMutable(), termOrd);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583535376/fstmerge_base_4111439977279973242
@Override
    protected Object createValue(IndexReader reader, Entry entryKey)
        throws IOException {

      String field = StringHelper.intern(entryKey.field);
      Terms terms = MultiFields.getTerms(reader, field);

      final boolean fasterButMoreRAM = ((Boolean) entryKey.custom).booleanValue();

      final PagedBytes bytes = new PagedBytes(15);

      int startBytesBPV;
      int startTermsBPV;
      int startNumUniqueTerms;

      int maxDoc = reader.maxDoc();
      final int termCountHardLimit;
      if (maxDoc == Integer.MAX_VALUE) {
        termCountHardLimit = Integer.MAX_VALUE;
      } else {
        termCountHardLimit = maxDoc+1;
      }

      if (terms != null) {
        // Try for coarse estimate for number of bits; this
        // should be an underestimate most of the time, which
        // is fine -- GrowableWriter will reallocate as needed
        long numUniqueTerms = 0;
        try {
          numUniqueTerms = terms.getUniqueTermCount();
        } catch (UnsupportedOperationException uoe) {
          numUniqueTerms = -1;
        }
        if (numUniqueTerms != -1) {

          if (numUniqueTerms > termCountHardLimit) {
            // app is misusing the API (there is more than
            // one term per doc); in this case we make best
            // effort to load what we can (see LUCENE-2142)
            numUniqueTerms = termCountHardLimit;
          }

          startBytesBPV = PackedInts.bitsRequired(numUniqueTerms*4);
          startTermsBPV = PackedInts.bitsRequired(numUniqueTerms);

          startNumUniqueTerms = (int) numUniqueTerms;
        } else {
          startBytesBPV = 1;
          startTermsBPV = 1;
          startNumUniqueTerms = 1;
        }
      } else {
        startBytesBPV = 1;
        startTermsBPV = 1;
        startNumUniqueTerms = 1;
      }

      GrowableWriter termOrdToBytesOffset = new GrowableWriter(startBytesBPV, 1+startNumUniqueTerms, fasterButMoreRAM);
      final GrowableWriter docToTermOrd = new GrowableWriter(startTermsBPV, reader.maxDoc(), fasterButMoreRAM);

      // 0 is reserved for "unset"
      bytes.copyUsingLengthPrefix(new BytesRef());
      int termOrd = 1;

      if (terms != null) {
        final TermsEnum termsEnum = terms.iterator();
        final Bits delDocs = MultiFields.getDeletedDocs(reader);
        DocsEnum docs = null;

        while(true) {
          final BytesRef term = termsEnum.next();
          if (term == null) {
            break;
          }
          if (termOrd >= termCountHardLimit) {
            break;
          }

          if (termOrd == termOrdToBytesOffset.size()) {
            // NOTE: this code only runs if the incoming
            // reader impl doesn't implement
            // getUniqueTermCount (which should be uncommon)
            termOrdToBytesOffset = termOrdToBytesOffset.resize(ArrayUtil.oversize(1+termOrd, 1));
          }
          termOrdToBytesOffset.set(termOrd, bytes.copyUsingLengthPrefix(term));
          docs = termsEnum.docs(delDocs, docs);
          while (true) {
            final int docID = docs.nextDoc();
            if (docID == DocsEnum.NO_MORE_DOCS) {
              break;
            }
            docToTermOrd.set(docID, termOrd);
          }
          termOrd++;
        }

        if (termOrdToBytesOffset.size() > termOrd) {
          termOrdToBytesOffset = termOrdToBytesOffset.resize(termOrd);
        }
      }

      // maybe an int-only impl?
      return new DocTermsIndexImpl(bytes.freeze(true), termOrdToBytesOffset.getMutable(), docToTermOrd.getMutable(), termOrd);
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583535376/fstmerge_var2_349324670217348030

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/search/FieldCacheImpl.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583535967/fstmerge_var1_8961580170464013615
public CustomScoreQuery(Query subQuery, ValueSourceQuery valSrcQuery) {
	  this(subQuery, valSrcQuery!=null ? // don't want an array that contains a single null.. 
        new ValueSourceQuery[] {valSrcQuery} : new ValueSourceQuery[0]);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583535967/fstmerge_base_8564718360596470552
public CustomScoreQuery(Query subQuery, ValueSourceQuery... valSrcQueries) {
    this.subQuery = subQuery;
    this.valSrcQueries = valSrcQueries!=null?
        valSrcQueries : new ValueSourceQuery[0];
    if (subQuery == null) throw new IllegalArgumentException("<subquery> must not be null!");
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583535967/fstmerge_var2_5246746903423739759

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/search/function/CustomScoreQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583536184/fstmerge_var1_3043285397036796040
public float customScore(int doc, float subQueryScore, float valSrcScores[]) throws IOException {
    if (valSrcScores.length == 1) {
      return customScore(doc, subQueryScore, valSrcScores[0]);
    }
    if (valSrcScores.length == 0) {
      return customScore(doc, subQueryScore, 1);
    }
    float score = subQueryScore;
    for(int i = 0; i < valSrcScores.length; i++) {
      score *= valSrcScores[i];
    }
    return score;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583536184/fstmerge_base_6711373316331041747
public float customScore(int doc, float subQueryScore, float valSrcScore) throws IOException {
    return subQueryScore * valSrcScore;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583536184/fstmerge_var2_6211288531408914163

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/search/function/CustomScoreProvider.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583536193/fstmerge_var1_6966199774760824222
public Explanation customExplain(int doc, Explanation subQueryExpl, Explanation valSrcExpls[]) throws IOException {
    if (valSrcExpls.length == 1) {
      return customExplain(doc, subQueryExpl, valSrcExpls[0]);
    }
    if (valSrcExpls.length == 0) {
      return subQueryExpl;
    }
    float valSrcScore = 1;
    for (int i = 0; i < valSrcExpls.length; i++) {
      valSrcScore *= valSrcExpls[i].getValue();
    }
    Explanation exp = new Explanation( valSrcScore * subQueryExpl.getValue(), "custom score: product of:");
    exp.addDetail(subQueryExpl);
    for (int i = 0; i < valSrcExpls.length; i++) {
      exp.addDetail(valSrcExpls[i]);
    }
    return exp;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583536193/fstmerge_base_1242138791186763117
public Explanation customExplain(int doc, Explanation subQueryExpl, Explanation valSrcExpl) throws IOException {
    float valSrcScore = 1;
    if (valSrcExpl != null) {
      valSrcScore *= valSrcExpl.getValue();
    }
    Explanation exp = new Explanation( valSrcScore * subQueryExpl.getValue(), "custom score: product of:");
    exp.addDetail(subQueryExpl);
    exp.addDetail(valSrcExpl);
    return exp;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583536193/fstmerge_var2_5940486765082285382

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/search/function/CustomScoreProvider.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583538278/fstmerge_var1_815990876761619187
public int compare(BytesRef a, BytesRef b) {

      final byte[] aBytes = a.bytes;
      int aUpto = a.offset;
      final byte[] bBytes = b.bytes;
      int bUpto = b.offset;
      
      final int aStop;
      if (a.length < b.length) {
        aStop = aUpto + a.length;
      } else {
        aStop = aUpto + b.length;
      }

      while(aUpto < aStop) {
        int aByte = aBytes[aUpto++] & 0xff;
        int bByte = bBytes[bUpto++] & 0xff;

        if (aByte != bByte) {

          // See http://icu-project.org/docs/papers/utf16_code_point_order.html#utf-8-in-utf-16-order

          // We know the terms are not equal, but, we may
          // have to carefully fixup the bytes at the
          // difference to match UTF16's sort order:
          
          // NOTE: instead of moving supplementary code points (0xee and 0xef) to the unused 0xfe and 0xff, 
          // we move them to the unused 0xfc and 0xfd [reserved for future 6-byte character sequences]
          // this reserves 0xff for preflex's term reordering (surrogate dance), and if unicode grows such
          // that 6-byte sequences are needed we have much bigger problems anyway.
          if (aByte >= 0xee && bByte >= 0xee) {
            if ((aByte & 0xfe) == 0xee) {
              aByte += 0xe;
            }
            if ((bByte&0xfe) == 0xee) {
              bByte += 0xe;
            }
          }
          return aByte - bByte;
        }
      }

      // One is a prefix of the other, or, they are equal:
      return a.length - b.length;
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583538278/fstmerge_base_4708562078301503290
public int compare(BytesRef a, BytesRef b) {

      final byte[] aBytes = a.bytes;
      int aUpto = a.offset;
      final byte[] bBytes = b.bytes;
      int bUpto = b.offset;
      
      final int aStop;
      if (a.length < b.length) {
        aStop = aUpto + a.length;
      } else {
        aStop = aUpto + b.length;
      }

      while(aUpto < aStop) {
        int aByte = aBytes[aUpto++] & 0xff;
        int bByte = bBytes[bUpto++] & 0xff;

        if (aByte != bByte) {

          // See http://icu-project.org/docs/papers/utf16_code_point_order.html#utf-8-in-utf-16-order

          // We know the terms are not equal, but, we may
          // have to carefully fixup the bytes at the
          // difference to match UTF16's sort order:
          if (aByte >= 0xee && bByte >= 0xee) {
            if ((aByte & 0xfe) == 0xee) {
              aByte += 0x10;
            }
            if ((bByte&0xfe) == 0xee) {
              bByte += 0x10;
            }
          }
          return aByte - bByte;
        }
      }

      // One is a prefix of the other, or, they are equal:
      return a.length - b.length;
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583538278/fstmerge_var2_6634291941997978249

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/util/BytesRef.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583544588/fstmerge_var1_3350510252237499668
public TermsEnum reset(TermsEnumIndex[] termsEnumsIndex) throws IOException {
    assert termsEnumsIndex.length <= top.length;
    numSubs = 0;
    numTop = 0;
    termComp = null;
    queue.clear();
    for(int i=0;i<termsEnumsIndex.length;i++) {

      final TermsEnumIndex termsEnumIndex = termsEnumsIndex[i];
      assert termsEnumIndex != null;

      // init our term comp
      if (termComp == null) {
        queue.termComp = termComp = termsEnumIndex.termsEnum.getComparator();
      } else {
        // We cannot merge sub-readers that have
        // different TermComps
        final Comparator<BytesRef> subTermComp = termsEnumIndex.termsEnum.getComparator();
        if (subTermComp != null && !subTermComp.equals(termComp)) {
          throw new IllegalStateException("sub-readers have different BytesRef.Comparators: " + subTermComp + " vs " + termComp + "; cannot merge");
        }
      }

      final BytesRef term = termsEnumIndex.termsEnum.next();
      if (term != null) {
        final TermsEnumWithSlice entry = subs[termsEnumIndex.subIndex];
        entry.reset(termsEnumIndex.termsEnum, term);
        queue.add(entry);
        currentSubs[numSubs++] = entry;
      } else {
        // field has no terms
      }
    }

    if (queue.size() == 0) {
      return TermsEnum.EMPTY;
    } else {
      return this;
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583544588/fstmerge_base_6771921099277322015
public TermsEnum reset(TermsEnumIndex[] termsEnumsIndex) throws IOException {
    assert termsEnumsIndex.length <= top.length;
    numSubs = 0;
    numTop = 0;
    termComp = null;
    queue.clear();
    for(int i=0;i<termsEnumsIndex.length;i++) {

      final TermsEnumIndex termsEnumIndex = termsEnumsIndex[i];
      assert termsEnumIndex != null;

      // init our term comp
      if (termComp == null) {
        queue.termComp = termComp = termsEnumIndex.termsEnum.getComparator();
      } else {
        // We cannot merge sub-readers that have
        // different TermComps
        final Comparator<BytesRef> subTermComp = termsEnumIndex.termsEnum.getComparator();
        if (subTermComp != null && !subTermComp.equals(termComp)) {
          throw new IllegalStateException("sub-readers have different BytesRef.Comparators; cannot merge");
        }
      }

      final BytesRef term = termsEnumIndex.termsEnum.next();
      if (term != null) {
        final TermsEnumWithSlice entry = subs[termsEnumIndex.subIndex];
        entry.reset(termsEnumIndex.termsEnum, term);
        queue.add(entry);
        currentSubs[numSubs++] = entry;
      } else {
        // field has no terms
      }
    }

    if (queue.size() == 0) {
      return TermsEnum.EMPTY;
    } else {
      return this;
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583544588/fstmerge_var2_5564498254907486204

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/MultiTermsEnum.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583545693/fstmerge_var1_8196167697686281176
private final synchronized boolean applyDeletes(IndexReader reader, int docIDStart)
    throws CorruptIndexException, IOException {

    final int docEnd = docIDStart + reader.maxDoc();
    boolean any = false;

    assert checkDeleteTerm(null);

    // Delete by term
    if (deletesFlushed.terms.size() > 0) {
      Fields fields = reader.fields();
      if (fields == null) {
        // This reader has no postings
        return false;
      }

      TermsEnum termsEnum = null;
        
      String currentField = null;
      DocsEnum docs = null;
        
      for (Entry<Term, BufferedDeletes.Num> entry: deletesFlushed.terms.entrySet()) {
        Term term = entry.getKey();
        // Since we visit terms sorted, we gain performance
        // by re-using the same TermsEnum and seeking only
        // forwards
        if (term.field() != currentField) {
          assert currentField == null || currentField.compareTo(term.field()) < 0;
          currentField = term.field();
          Terms terms = fields.terms(currentField);
          if (terms != null) {
            termsEnum = terms.iterator();
          } else {
            termsEnum = null;
          }
        }
          
        if (termsEnum == null) {
          continue;
        }
        assert checkDeleteTerm(term);

        if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {
          DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);
            
          if (docsEnum != null) {
            docs = docsEnum;
            int limit = entry.getValue().getNum();
            while (true) {
              final int docID = docs.nextDoc();
              if (docID == DocsEnum.NO_MORE_DOCS || docIDStart+docID >= limit) {
                break;
              }
              reader.deleteDocument(docID);
              any = true;
            }
          }
        }
      }
    }

    // Delete by docID
    for (Integer docIdInt : deletesFlushed.docIDs) {
      int docID = docIdInt.intValue();
      if (docID >= docIDStart && docID < docEnd) {
        reader.deleteDocument(docID-docIDStart);
        any = true;
      }
    }

    // Delete by query
    if (deletesFlushed.queries.size() > 0) {
      IndexSearcher searcher = new IndexSearcher(reader);
      try {
        for (Entry<Query, Integer> entry : deletesFlushed.queries.entrySet()) {
          Query query = entry.getKey();
          int limit = entry.getValue().intValue();
          Weight weight = query.weight(searcher);
          Scorer scorer = weight.scorer(reader, true, false);
          if (scorer != null) {
            while(true)  {
              int doc = scorer.nextDoc();
              if (((long) docIDStart) + doc >= limit)
                break;
              reader.deleteDocument(doc);
              any = true;
            }
          }
        }
      } finally {
        searcher.close();
      }
    }
    return any;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583545693/fstmerge_base_4778295271055380602
private final synchronized boolean applyDeletes(IndexReader reader, int docIDStart)
    throws CorruptIndexException, IOException {

    final int docEnd = docIDStart + reader.maxDoc();
    boolean any = false;

    assert checkDeleteTerm(null);

    // Delete by term
    if (deletesFlushed.terms.size() > 0) {
      Fields fields = reader.fields();
      if (fields == null) {
        // This reader has no postings
        return false;
      }

      TermsEnum termsEnum = null;
        
      String currentField = null;
      DocsEnum docs = null;
        
      for (Entry<Term, BufferedDeletes.Num> entry: deletesFlushed.terms.entrySet()) {
        Term term = entry.getKey();
        // Since we visit terms sorted, we gain performance
        // by re-using the same TermsEnum and seeking only
        // forwards
        if (term.field() != currentField) {
          assert currentField == null || currentField.compareTo(term.field()) < 0;
          currentField = term.field();
          Terms terms = fields.terms(currentField);
          if (terms != null) {
            termsEnum = terms.iterator();
          } else {
            termsEnum = null;
          }
        }
          
        if (termsEnum == null) {
          continue;
        }
        assert checkDeleteTerm(term);
          
        if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {
          DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);
            
          if (docsEnum != null) {
            docs = docsEnum;
            int limit = entry.getValue().getNum();
            while (true) {
              final int docID = docs.nextDoc();
              if (docID == DocsEnum.NO_MORE_DOCS || docIDStart+docID >= limit) {
                break;
              }
              reader.deleteDocument(docID);
              any = true;
            }
          }
        }
      }
    }

    // Delete by docID
    for (Integer docIdInt : deletesFlushed.docIDs) {
      int docID = docIdInt.intValue();
      if (docID >= docIDStart && docID < docEnd) {
        reader.deleteDocument(docID-docIDStart);
        any = true;
      }
    }

    // Delete by query
    if (deletesFlushed.queries.size() > 0) {
      IndexSearcher searcher = new IndexSearcher(reader);
      try {
        for (Entry<Query, Integer> entry : deletesFlushed.queries.entrySet()) {
          Query query = entry.getKey();
          int limit = entry.getValue().intValue();
          Weight weight = query.weight(searcher);
          Scorer scorer = weight.scorer(reader, true, false);
          if (scorer != null) {
            while(true)  {
              int doc = scorer.nextDoc();
              if (((long) docIDStart) + doc >= limit)
                break;
              reader.deleteDocument(doc);
              any = true;
            }
          }
        }
      } finally {
        searcher.close();
      }
    }
    return any;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583545693/fstmerge_var2_6638971203336413727

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583549186/fstmerge_var1_2852096865819054245
public void deleteDocuments(Term term) throws CorruptIndexException, IOException {
    ensureOpen();
    try {
      boolean doFlush = docWriter.bufferDeleteTerm(term);
      if (doFlush)
        flush(true, false, false);
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Term)");
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583549186/fstmerge_base_6472583980839421374
public void deleteDocuments(Term... terms) throws CorruptIndexException, IOException {
    ensureOpen();
    try {
      boolean doFlush = docWriter.bufferDeleteTerms(terms);
      if (doFlush)
        flush(true, false, false);
    } catch (OutOfMemoryError oom) {
      handleOOM(oom, "deleteDocuments(Term..)");
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583549186/fstmerge_var2_7842775834932967900

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583549195/fstmerge_var1_8341762843255856958
public void deleteDocuments(Query query) throws CorruptIndexException, IOException {
    ensureOpen();
    boolean doFlush = docWriter.bufferDeleteQuery(query);
    if (doFlush)
      flush(true, false, false);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583549195/fstmerge_base_8317051372719223787
public void deleteDocuments(Query... queries) throws CorruptIndexException, IOException {
    ensureOpen();
    boolean doFlush = docWriter.bufferDeleteQueries(queries);
    if (doFlush)
      flush(true, false, false);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583549195/fstmerge_var2_4399010169545494007

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/IndexWriter.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ public final static String[] CORE_CODECS = new String[] {"Standard", "Sep", "Pulsing", "IntBlock", "PreFlex"}; ##FSTMerge## public final static String[] CORE_CODECS = new String[] {"Standard", "Sep", "Pulsing", "IntBlock"}; ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/CodecProvider.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583550360/fstmerge_var1_3208104015606163406
public void register(Codec codec) {
    if (codec.name == null) {
      throw new IllegalArgumentException("code.name is null");
    }
    if (!codecs.containsKey(codec.name)) {
      codecs.put(codec.name, codec);
      codec.getExtensions(knownExtensions);
    } else if (codecs.get(codec.name) != codec) {
      throw new IllegalArgumentException("codec '" + codec.name + "' is already registered as a different codec instance");
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583550360/fstmerge_base_5914883756376207020
public void register(Codec codec) {
    if (codec.name == null) {
      throw new IllegalArgumentException("code.name is null");
    }

    if (!codecs.containsKey(codec.name)) {
      codecs.put(codec.name, codec);
      codec.getExtensions(knownExtensions);
    } else if (codecs.get(codec.name) != codec) {
      throw new IllegalArgumentException("codec '" + codec.name + "' is already registered as a different codec instance");
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583550360/fstmerge_var2_1404795868988211481

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/CodecProvider.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583550399/fstmerge_var1_6282776061168788302
@Override
  public Codec getWriter(SegmentWriteState state) {
    return lookup(CodecProvider.getDefaultCodec());
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583550399/fstmerge_base_4999474469059354862
@Override
  public Codec getWriter(SegmentWriteState state) {
    return lookup(CodecProvider.getDefaultCodec());
    //return lookup("Pulsing");
    //return lookup("Sep");
    //return lookup("IntBlock");
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583550399/fstmerge_var2_3392921762962658015

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/CodecProvider.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551934/fstmerge_var1_7746372908389741594
TermInfosReader(Directory dir, String seg, FieldInfos fis, int readBufferSize, int indexDivisor)
       throws CorruptIndexException, IOException {
    boolean success = false;

    if (indexDivisor < 1 && indexDivisor != -1) {
      throw new IllegalArgumentException("indexDivisor must be -1 (don't load terms index) or greater than 0: got " + indexDivisor);
    }

    try {
      directory = dir;
      segment = seg;
      fieldInfos = fis;

      origEnum = new SegmentTermEnum(directory.openInput(IndexFileNames.segmentFileName(segment, "", PreFlexCodec.TERMS_EXTENSION),
                                                         readBufferSize), fieldInfos, false);
      size = origEnum.size;


      if (indexDivisor != -1) {
        // Load terms index
        totalIndexInterval = origEnum.indexInterval * indexDivisor;
        final SegmentTermEnum indexEnum = new SegmentTermEnum(directory.openInput(IndexFileNames.segmentFileName(segment, "", PreFlexCodec.TERMS_INDEX_EXTENSION),
                                                                                  readBufferSize), fieldInfos, true);

        try {
          int indexSize = 1+((int)indexEnum.size-1)/indexDivisor;  // otherwise read index

          indexTerms = new Term[indexSize];
          indexInfos = new TermInfo[indexSize];
          indexPointers = new long[indexSize];

          for (int i=0;indexEnum.next(); i++) {
            indexTerms[i] = indexEnum.term();
            assert indexTerms[i] != null;
            assert indexTerms[i].text() != null;
            assert indexTerms[i].field() != null;
            indexInfos[i] = indexEnum.termInfo();
            indexPointers[i] = indexEnum.indexPointer;
        
            for (int j = 1; j < indexDivisor; j++)
              if (!indexEnum.next())
                break;
          }
        } finally {
          indexEnum.close();
        }
      } else {
        // Do not load terms index:
        totalIndexInterval = -1;
        indexTerms = null;
        indexInfos = null;
        indexPointers = null;
      }
      success = true;
    } finally {
      // With lock-less commits, it's entirely possible (and
      // fine) to hit a FileNotFound exception above. In
      // this case, we want to explicitly close any subset
      // of things that were opened so that we don't have to
      // wait for a GC to do so.
      if (!success) {
        close();
      }
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551934/fstmerge_base_1760269722312235847
TermInfosReader(Directory dir, String seg, FieldInfos fis, int readBufferSize, int indexDivisor)
       throws CorruptIndexException, IOException {
    boolean success = false;

    if (indexDivisor < 1 && indexDivisor != -1) {
      throw new IllegalArgumentException("indexDivisor must be -1 (don't load terms index) or greater than 0: got " + indexDivisor);
    }

    try {
      directory = dir;
      segment = seg;
      fieldInfos = fis;

      origEnum = new SegmentTermEnum(directory.openInput(IndexFileNames.segmentFileName(segment, "", PreFlexCodec.TERMS_EXTENSION),
                                                         readBufferSize), fieldInfos, false);
      size = origEnum.size;


      if (indexDivisor != -1) {
        // Load terms index
        totalIndexInterval = origEnum.indexInterval * indexDivisor;
        final SegmentTermEnum indexEnum = new SegmentTermEnum(directory.openInput(IndexFileNames.segmentFileName(segment, "", PreFlexCodec.TERMS_INDEX_EXTENSION),
                                                                                  readBufferSize), fieldInfos, true);

        try {
          int indexSize = 1+((int)indexEnum.size-1)/indexDivisor;  // otherwise read index

          indexTerms = new Term[indexSize];
          indexInfos = new TermInfo[indexSize];
          indexPointers = new long[indexSize];
        
          for (int i = 0; indexEnum.next(); i++) {
            indexTerms[i] = indexEnum.term();
            indexInfos[i] = indexEnum.termInfo();
            indexPointers[i] = indexEnum.indexPointer;
        
            for (int j = 1; j < indexDivisor; j++)
              if (!indexEnum.next())
                break;
          }
        } finally {
          indexEnum.close();
        }
      } else {
        // Do not load terms index:
        totalIndexInterval = -1;
        indexTerms = null;
        indexInfos = null;
        indexPointers = null;
      }
      success = true;
    } finally {
      // With lock-less commits, it's entirely possible (and
      // fine) to hit a FileNotFound exception above. In
      // this case, we want to explicitly close any subset
      // of things that were opened so that we don't have to
      // wait for a GC to do so.
      if (!success) {
        close();
      }
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551934/fstmerge_var2_7944701382006198005

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfosReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551949/fstmerge_var1_3815564098650097461
void close() throws IOException {
    if (origEnum != null)
      origEnum.close();
    threadResources.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551949/fstmerge_base_2255831447656947439
final void close() throws IOException {
    if (origEnum != null)
      origEnum.close();
    threadResources.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551949/fstmerge_var2_8453222116830606861

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfosReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551953/fstmerge_var1_8574336969831622239
long size() {
    return size;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551953/fstmerge_base_5122588728036583514
final long size() {
    return size;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551953/fstmerge_var2_7959291110660470163

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfosReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551962/fstmerge_var1_5716461349847927423
private int getIndexOffset(Term term) {
    int lo = 0;					  // binary search indexTerms[]
    int hi = indexTerms.length - 1;

    while (hi >= lo) {
      int mid = (lo + hi) >>> 1;
      assert indexTerms[mid] != null : "indexTerms = " + indexTerms.length + " mid=" + mid;
      int delta = term.compareToUTF16(indexTerms[mid]);
      if (delta < 0)
	hi = mid - 1;
      else if (delta > 0)
	lo = mid + 1;
      else
	return mid;
    }
    return hi;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551962/fstmerge_base_6076445769013868852
private final int getIndexOffset(Term term) {
    int lo = 0;					  // binary search indexTerms[]
    int hi = indexTerms.length - 1;

    while (hi >= lo) {
      int mid = (lo + hi) >>> 1;
      int delta = term.compareToUTF16(indexTerms[mid]);
      if (delta < 0)
	hi = mid - 1;
      else if (delta > 0)
	lo = mid + 1;
      else
	return mid;
    }
    return hi;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551962/fstmerge_var2_8430967478973359653

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfosReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551967/fstmerge_var1_7934149417387978638
private void seekEnum(SegmentTermEnum enumerator, int indexOffset) throws IOException {
    enumerator.seek(indexPointers[indexOffset],
                    ((long) indexOffset * totalIndexInterval) - 1,
                    indexTerms[indexOffset], indexInfos[indexOffset]);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551967/fstmerge_base_5662486488156641802
private final void seekEnum(SegmentTermEnum enumerator, int indexOffset) throws IOException {
    enumerator.seek(indexPointers[indexOffset],
                    ((long) indexOffset * totalIndexInterval) - 1,
                    indexTerms[indexOffset], indexInfos[indexOffset]);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551967/fstmerge_var2_4761958076681807881

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfosReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551984/fstmerge_var1_6044205787359655897
TermInfo seekEnum(SegmentTermEnum enumerator, Term term, TermInfoAndOrd tiOrd) throws IOException {
    if (size == 0) {
      return null;
    }

    // optimize sequential access: first try scanning cached enum w/o seeking
    if (enumerator.term() != null                 // term is at or past current
	&& ((enumerator.prev() != null && term.compareToUTF16(enumerator.prev())> 0)
	    || term.compareToUTF16(enumerator.term()) >= 0)) {
      int enumOffset = (int)(enumerator.position/totalIndexInterval)+1;
      if (indexTerms.length == enumOffset	  // but before end of block
    || term.compareToUTF16(indexTerms[enumOffset]) < 0) {
       // no need to seek

        final TermInfo ti;
        int numScans = enumerator.scanTo(term);
        if (enumerator.term() != null && term.compareToUTF16(enumerator.term()) == 0) {
          ti = enumerator.termInfo();
          if (numScans > 1) {
            // we only  want to put this TermInfo into the cache if
            // scanEnum skipped more than one dictionary entry.
            // This prevents RangeQueries or WildcardQueries to 
            // wipe out the cache when they iterate over a large numbers
            // of terms in order
            if (tiOrd == null) {
              termsCache.put(new CloneableTerm(term), new TermInfoAndOrd(ti, (int) enumerator.position));
            } else {
              assert sameTermInfo(ti, tiOrd, enumerator);
              assert (int) enumerator.position == tiOrd.termOrd;
            }
          }
        } else {
          ti = null;
        }

        return ti;
      }  
    }

    // random-access: must seek
    final int indexPos;
    if (tiOrd != null) {
      indexPos = tiOrd.termOrd / totalIndexInterval;
    } else {
      // Must do binary search:
      indexPos = getIndexOffset(term);
    }

    seekEnum(enumerator, indexPos);
    enumerator.scanTo(term);
    final TermInfo ti;

    if (enumerator.term() != null && term.compareToUTF16(enumerator.term()) == 0) {
      ti = enumerator.termInfo();
      if (tiOrd == null) {
        termsCache.put(new CloneableTerm(term), new TermInfoAndOrd(ti, (int) enumerator.position));
      } else {
        assert sameTermInfo(ti, tiOrd, enumerator);
        assert (int) enumerator.position == tiOrd.termOrd;
      }
    } else {
      ti = null;
    }
    return ti;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551984/fstmerge_base_900151314282679016
TermInfo seekEnum(SegmentTermEnum enumerator, Term term, TermInfoAndOrd tiOrd) throws IOException {

    // optimize sequential access: first try scanning cached enum w/o seeking
    if (enumerator.term() != null                 // term is at or past current
	&& ((enumerator.prev() != null && term.compareToUTF16(enumerator.prev())> 0)
	    || term.compareToUTF16(enumerator.term()) >= 0)) {
      int enumOffset = (int)(enumerator.position/totalIndexInterval)+1;
      if (indexTerms.length == enumOffset	  // but before end of block
    || term.compareToUTF16(indexTerms[enumOffset]) < 0) {
       // no need to seek

        final TermInfo ti;

        int numScans = enumerator.scanTo(term);
        if (enumerator.term() != null && term.compareToUTF16(enumerator.term()) == 0) {
          ti = enumerator.termInfo();
          if (numScans > 1) {
            // we only  want to put this TermInfo into the cache if
            // scanEnum skipped more than one dictionary entry.
            // This prevents RangeQueries or WildcardQueries to 
            // wipe out the cache when they iterate over a large numbers
            // of terms in order
            if (tiOrd == null) {
              termsCache.put(new CloneableTerm(term), new TermInfoAndOrd(ti, (int) enumerator.position));
            } else {
              assert sameTermInfo(ti, tiOrd, enumerator);
              assert (int) enumerator.position == tiOrd.termOrd;
            }
          }
        } else {
          ti = null;
        }

        return ti;
      }  
    }

    // random-access: must seek
    final int indexPos;
    if (tiOrd != null) {
      indexPos = tiOrd.termOrd / totalIndexInterval;
    } else {
      // Must do binary search:
      indexPos = getIndexOffset(term);
    }

    seekEnum(enumerator, indexPos);
    enumerator.scanTo(term);
    final TermInfo ti;
    if (enumerator.term() != null && term.compareToUTF16(enumerator.term()) == 0) {
      ti = enumerator.termInfo();
      if (tiOrd == null) {
        termsCache.put(new CloneableTerm(term), new TermInfoAndOrd(ti, (int) enumerator.position));
      } else {
        assert sameTermInfo(ti, tiOrd, enumerator);
        assert (int) enumerator.position == tiOrd.termOrd;
      }
    } else {
      ti = null;
    }
    return ti;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551984/fstmerge_var2_7802936974553334486

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfosReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551988/fstmerge_var1_6856151685390989500
private boolean sameTermInfo(TermInfo ti1, TermInfo ti2, SegmentTermEnum enumerator) {
    if (ti1.docFreq != ti2.docFreq) {
      return false;
    }
    if (ti1.freqPointer != ti2.freqPointer) {
      return false;
    }
    if (ti1.proxPointer != ti2.proxPointer) {
      return false;
    }
    // skipOffset is only valid when docFreq >= skipInterval:
    if (ti1.docFreq >= enumerator.skipInterval &&
        ti1.skipOffset != ti2.skipOffset) {
      return false;
    }
    return true;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551988/fstmerge_base_3347448882456173139
private final boolean sameTermInfo(TermInfo ti1, TermInfo ti2, SegmentTermEnum enumerator) {
    if (ti1.docFreq != ti2.docFreq) {
      return false;
    }
    if (ti1.freqPointer != ti2.freqPointer) {
      return false;
    }
    if (ti1.proxPointer != ti2.proxPointer) {
      return false;
    }
    // skipOffset is only valid when docFreq >= skipInterval:
    if (ti1.docFreq >= enumerator.skipInterval &&
        ti1.skipOffset != ti2.skipOffset) {
      return false;
    }
    return true;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551988/fstmerge_var2_3096356571759352880

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfosReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551997/fstmerge_var1_4412749107440174911
long getPosition(Term term) throws IOException {
    if (size == 0) return -1;

    ensureIndexIsRead();
    int indexOffset = getIndexOffset(term);
    
    SegmentTermEnum enumerator = getThreadResources().termEnum;
    seekEnum(enumerator, indexOffset);

    while(term.compareToUTF16(enumerator.term()) > 0 && enumerator.next()) {}

    if (term.compareToUTF16(enumerator.term()) == 0)
      return enumerator.position;
    else
      return -1;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551997/fstmerge_base_8009399750752719273
final long getPosition(Term term) throws IOException {
    if (size == 0) return -1;

    ensureIndexIsRead();
    int indexOffset = getIndexOffset(term);
    
    SegmentTermEnum enumerator = getThreadResources().termEnum;
    seekEnum(enumerator, indexOffset);

    while(term.compareToUTF16(enumerator.term()) > 0 && enumerator.next()) {}

    if (term.compareToUTF16(enumerator.term()) == 0)
      return enumerator.position;
    else
      return -1;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583551997/fstmerge_var2_4294100196115453928

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfosReader.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552075/fstmerge_var1_3509168201501922271
public int compareTo(TermBuffer other) {
    if (field == other.field) 	  // fields are interned
      return utf8AsUTF16Comparator.compare(bytes, other.bytes);
    else
      return field.compareTo(other.field);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552075/fstmerge_base_940572401487154024
public final int compareTo(TermBuffer other) {
    if (field == other.field) 	  // fields are interned
      return compareChars(text.result, text.length, other.text.result, other.text.length);
    else
      return field.compareTo(other.field);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552075/fstmerge_var2_2200897322052628093

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermBuffer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552080/fstmerge_var1_8634255618283066413
public void read(IndexInput input, FieldInfos fieldInfos)
    throws IOException {
    this.term = null;                           // invalidate cache
    newSuffixStart = input.readVInt();
    int length = input.readVInt();
    int totalLength = newSuffixStart + length;
    if (bytes.bytes.length < totalLength) {
      bytes.grow(totalLength);
    }
    bytes.length = totalLength;
    input.readBytes(bytes.bytes, newSuffixStart, length);
    this.field = fieldInfos.fieldName(input.readVInt());
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552080/fstmerge_base_4670532462276248085
public final void read(IndexInput input, FieldInfos fieldInfos)
    throws IOException {
    this.term = null;                           // invalidate cache
    int start = input.readVInt();
    int length = input.readVInt();
    int totalLength = start + length;
    if (bytes.bytes.length < totalLength) {
      bytes.grow(totalLength);
    }
    if (dirty) {
      // Fully convert all bytes since bytes is dirty
      UnicodeUtil.UTF16toUTF8(text.result, 0, text.length, bytes);
      bytes.length = totalLength;
      input.readBytes(bytes.bytes, start, length);
      UnicodeUtil.UTF8toUTF16(bytes.bytes, 0, totalLength, text);
      dirty = false;
    } else {
      // Incrementally convert only the UTF8 bytes that are new:
      bytes.length = totalLength;
      input.readBytes(bytes.bytes, start, length);
      UnicodeUtil.UTF8toUTF16(bytes.bytes, start, length, text);
    }

    while(true) {
      newSuffixStart = text.offsets[start];
      if (newSuffixStart != -1) {
        break;
      }
      if (--start == 0) {
        newSuffixStart = 0;
        break;
      }
    }
    this.field = fieldInfos.fieldName(input.readVInt());
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552080/fstmerge_var2_2181301429152854560

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermBuffer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552085/fstmerge_var1_2009995517690073568
public void set(Term term) {
    if (term == null) {
      reset();
      return;
    }
    bytes.copy(term.bytes());
    field = term.field();
    this.term = term;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552085/fstmerge_base_1017109357317752069
public final void set(Term term) {
    if (term == null) {
      reset();
      return;
    }
    
    final BytesRef termBytes = term.bytes();
    UnicodeUtil.UTF8toUTF16(termBytes.bytes, termBytes.offset, termBytes.length, text);
    dirty = true;
    field = term.field();
    this.term = term;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552085/fstmerge_var2_7131250579335872899

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermBuffer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552091/fstmerge_var1_5428331456828374903
public void set(TermBuffer other) {
    field = other.field;
    // dangerous to copy Term over, since the underlying
    // BytesRef could subsequently be modified:
    term = null;
    bytes.copy(other.bytes);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552091/fstmerge_base_3336582814332400351
public final void set(TermBuffer other) {
    text.copyText(other.text);
    dirty = true;
    field = other.field;
    term = other.term;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552091/fstmerge_var2_3633284872959763944

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermBuffer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552096/fstmerge_var1_5496659782525687714
public void reset() {
    field = null;
    term = null;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552096/fstmerge_base_1424473687673340805
public void reset() {
    field = null;
    text.setLength(0);
    term = null;
    dirty = true;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552096/fstmerge_var2_5048452256410668782

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermBuffer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552101/fstmerge_var1_2810318024306057051
public Term toTerm() {
    if (field == null)                            // unset
      return null;

    if (term == null) {
      term = new Term(field, new BytesRef(bytes), false);
      //term = new Term(field, bytes, false);
    }

    return term;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552101/fstmerge_base_595244427154122579
public Term toTerm() {
    if (field == null)                            // unset
      return null;

    if (term == null)
      term = new Term(field, new BytesRef(text.result, 0, text.length), false);

    return term;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552101/fstmerge_var2_2402440014606021647

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermBuffer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552104/fstmerge_var1_2688353273851854615
@Override
  protected Object clone() {
    TermBuffer clone = null;
    try {
      clone = (TermBuffer)super.clone();
    } catch (CloneNotSupportedException e) {}
    clone.bytes = new BytesRef(bytes);
    return clone;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552104/fstmerge_base_8730587820196782218
@Override
  protected Object clone() {
    TermBuffer clone = null;
    try {
      clone = (TermBuffer)super.clone();
    } catch (CloneNotSupportedException e) {}
    clone.dirty = true;
    clone.bytes = new BytesRef(10);
    clone.text = new UnicodeUtil.UTF16Result();
    clone.text.offsets = new int[text.offsets.length];
    System.arraycopy(text.offsets, 0, clone.text.offsets, 0, text.offsets.length);
    clone.text.copyText(text);
    return clone;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552104/fstmerge_var2_2636301039162480506

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermBuffer.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552105/fstmerge_var1_1111907305440934354
SegmentTermEnum(IndexInput i, FieldInfos fis, boolean isi)
          throws CorruptIndexException, IOException {
    input = i;
    fieldInfos = fis;
    isIndex = isi;
    maxSkipLevels = 1; // use single-level skip lists for formats > -3 
    
    int firstInt = input.readInt();
    if (firstInt >= 0) {
      // original-format file, without explicit format version number
      format = 0;
      size = firstInt;

      // back-compatible settings
      indexInterval = 128;
      skipInterval = Integer.MAX_VALUE; // switch off skipTo optimization
    } else {
      // we have a format version number
      format = firstInt;

      // check that it is a format we can understand
      if (format > FORMAT_MINIMUM)
        throw new IndexFormatTooOldException(null, format, FORMAT_MINIMUM, FORMAT_CURRENT);
      if (format < FORMAT_CURRENT)
        throw new IndexFormatTooNewException(null, format, FORMAT_MINIMUM, FORMAT_CURRENT);

      size = input.readLong();                    // read the size
      
      indexInterval = input.readInt();
      skipInterval = input.readInt();
      maxSkipLevels = input.readInt();
      assert indexInterval > 0: "indexInterval=" + indexInterval + " is negative; must be > 0";
      assert skipInterval > 0: "skipInterval=" + skipInterval + " is negative; must be > 0";
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552105/fstmerge_base_394090839888593520
SegmentTermEnum(IndexInput i, FieldInfos fis, boolean isi)
          throws CorruptIndexException, IOException {
    input = i;
    fieldInfos = fis;
    isIndex = isi;
    maxSkipLevels = 1; // use single-level skip lists for formats > -3 
    
    int firstInt = input.readInt();
    if (firstInt >= 0) {
      // original-format file, without explicit format version number
      format = 0;
      size = firstInt;

      // back-compatible settings
      indexInterval = 128;
      skipInterval = Integer.MAX_VALUE; // switch off skipTo optimization
    } else {
      // we have a format version number
      format = firstInt;

      // check that it is a format we can understand
    if (format > FORMAT_MINIMUM)
      throw new IndexFormatTooOldException(null, format, FORMAT_MINIMUM, FORMAT_CURRENT);
    if (format < FORMAT_CURRENT)
      throw new IndexFormatTooNewException(null, format, FORMAT_MINIMUM, FORMAT_CURRENT);

      size = input.readLong();                    // read the size
      
      if(format == -1){
        if (!isIndex) {
          indexInterval = input.readInt();
          formatM1SkipInterval = input.readInt();
        }
        // switch off skipTo optimization for file format prior to 1.4rc2 in order to avoid a bug in 
        // skipTo implementation of these versions
        skipInterval = Integer.MAX_VALUE;
      } else {
        indexInterval = input.readInt();
        skipInterval = input.readInt();
        maxSkipLevels = input.readInt();
      }
      assert indexInterval > 0: "indexInterval=" + indexInterval + " is negative; must be > 0";
      assert skipInterval > 0: "skipInterval=" + skipInterval + " is negative; must be > 0";
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552105/fstmerge_var2_2114015069484307267

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermEnum.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552108/fstmerge_var1_5224120222665491621
final void seek(long pointer, long p, Term t, TermInfo ti)
          throws IOException {
    input.seek(pointer);
    position = p;
    termBuffer.set(t);
    prevBuffer.reset();
    //System.out.println("  ste doSeek prev=" + prevBuffer.toTerm() + " this=" + this);
    termInfo.set(ti);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552108/fstmerge_base_7889348642204939253
final void seek(long pointer, long p, Term t, TermInfo ti)
          throws IOException {
    input.seek(pointer);
    position = p;
    termBuffer.set(t);
    prevBuffer.reset();
    termInfo.set(ti);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552108/fstmerge_var2_1702826929618193490

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermEnum.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552110/fstmerge_var1_8014952578938999442
public final boolean next() throws IOException {
    prevBuffer.set(termBuffer);
    //System.out.println("  ste setPrev=" + prev() + " this=" + this);

    if (position++ >= size - 1) {
      termBuffer.reset();
      //System.out.println("    EOF");
      return false;
    }

    termBuffer.read(input, fieldInfos);
    newSuffixStart = termBuffer.newSuffixStart;

    termInfo.docFreq = input.readVInt();	  // read doc freq
    termInfo.freqPointer += input.readVLong();	  // read freq pointer
    termInfo.proxPointer += input.readVLong();	  // read prox pointer
    
    if(format == -1){
    //  just read skipOffset in order to increment  file pointer; 
    // value is never used since skipTo is switched off
      if (!isIndex) {
        if (termInfo.docFreq > formatM1SkipInterval) {
          termInfo.skipOffset = input.readVInt(); 
        }
      }
    }
    else{
      if (termInfo.docFreq >= skipInterval) 
        termInfo.skipOffset = input.readVInt();
    }
    
    if (isIndex)
      indexPointer += input.readVLong();	  // read index pointer

    //System.out.println("  ste ret term=" + term());
    return true;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552110/fstmerge_base_4784409252388770398
public final boolean next() throws IOException {
    if (position++ >= size - 1) {
      prevBuffer.set(termBuffer);
      termBuffer.reset();
      return false;
    }

    prevBuffer.set(termBuffer);
    termBuffer.read(input, fieldInfos);
    newSuffixStart = termBuffer.newSuffixStart;

    termInfo.docFreq = input.readVInt();	  // read doc freq
    termInfo.freqPointer += input.readVLong();	  // read freq pointer
    termInfo.proxPointer += input.readVLong();	  // read prox pointer
    
    if(format == -1){
    //  just read skipOffset in order to increment  file pointer; 
    // value is never used since skipTo is switched off
      if (!isIndex) {
        if (termInfo.docFreq > formatM1SkipInterval) {
          termInfo.skipOffset = input.readVInt(); 
        }
      }
    }
    else{
      if (termInfo.docFreq >= skipInterval) 
        termInfo.skipOffset = input.readVInt();
    }
    
    if (isIndex)
      indexPointer += input.readVLong();	  // read index pointer

    return true;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552110/fstmerge_var2_3521905721516805941

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermEnum.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ public static final String TERMS_EXTENSION = "tis"; ##FSTMerge## static final String TERMS_EXTENSION = "tis"; ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ public static final String TERMS_INDEX_EXTENSION = "tii"; ##FSTMerge## static final String TERMS_INDEX_EXTENSION = "tii"; ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ public static final String FREQ_EXTENSION = "frq"; ##FSTMerge## static final String FREQ_EXTENSION = "frq"; ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ public static final String PROX_EXTENSION = "prx"; ##FSTMerge## static final String PROX_EXTENSION = "prx"; ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexCodec.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552162/fstmerge_var1_182887819635971094
public PreFlexFields(Directory dir, FieldInfos fieldInfos, SegmentInfo info, int readBufferSize, int indexDivisor)
    throws IOException {

    si = info;

    // NOTE: we must always load terms index, even for
    // "sequential" scan during merging, because what is
    // sequential to merger may not be to TermInfosReader
    // since we do the surrogates dance:
    if (indexDivisor < 0) {
      indexDivisor = -indexDivisor;
    }

    TermInfosReader r = new TermInfosReader(dir, info.name, fieldInfos, readBufferSize, indexDivisor);    
    if (indexDivisor == -1) {
      tisNoIndex = r;
    } else {
      tisNoIndex = null;
      tis = r;
    }
    this.readBufferSize = readBufferSize;
    this.fieldInfos = fieldInfos;

    // make sure that all index files have been read or are kept open
    // so that if an index update removes them we'll still have them
    freqStream = dir.openInput(info.name + ".frq", readBufferSize);
    boolean anyProx = false;
    final int numFields = fieldInfos.size();
    for(int i=0;i<numFields;i++) {
      final FieldInfo fieldInfo = fieldInfos.fieldInfo(i);
      if (fieldInfo.isIndexed) {
        fields.put(fieldInfo.name, fieldInfo);
        if (!fieldInfo.omitTermFreqAndPositions) {
          anyProx = true;
        }
      }
    }

    if (anyProx) {
      proxStream = dir.openInput(info.name + ".prx", readBufferSize);
    } else {
      proxStream = null;
    }

    this.dir = dir;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552162/fstmerge_base_8118321080281621259
PreFlexFields(Directory dir, FieldInfos fieldInfos, SegmentInfo info, int readBufferSize, int indexDivisor)
    throws IOException {

    si = info;

    // NOTE: we must always load terms index, even for
    // "sequential" scan during merging, because what is
    // sequential to merger may not be to TermInfosReader
    // since we do the surrogates dance:
    if (indexDivisor < 0) {
      indexDivisor = -indexDivisor;
    }

    TermInfosReader r = new TermInfosReader(dir, info.name, fieldInfos, readBufferSize, indexDivisor);    
    if (indexDivisor == -1) {
      tisNoIndex = r;
    } else {
      tisNoIndex = null;
      tis = r;
    }
    this.readBufferSize = readBufferSize;
    this.fieldInfos = fieldInfos;

    // make sure that all index files have been read or are kept open
    // so that if an index update removes them we'll still have them
    freqStream = dir.openInput(info.name + ".frq", readBufferSize);
    boolean anyProx = false;
    final int numFields = fieldInfos.size();
    for(int i=0;i<numFields;i++) {
      final FieldInfo fieldInfo = fieldInfos.fieldInfo(i);
      if (fieldInfo.isIndexed) {
        fields.put(fieldInfo.name, fieldInfo);
        if (!fieldInfo.omitTermFreqAndPositions) {
          anyProx = true;
        }
      }
    }

    if (anyProx) {
      proxStream = dir.openInput(info.name + ".prx", readBufferSize);
    } else {
      proxStream = null;
    }

    this.dir = dir;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552162/fstmerge_var2_3382036396051598698

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552207/fstmerge_var1_7878923922412437309
@Override
  public void close() throws IOException {
    if (tis != null) {
      tis.close();
    }
    if (tisNoIndex != null) {
      tisNoIndex.close();
    }
    if (cfsReader != null) {
      cfsReader.close();
    }
    if (freqStream != null) {
      freqStream.close();
    }
    if (proxStream != null) {
      proxStream.close();
    }
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552207/fstmerge_base_2698092150865092171
@Override
  public void close() throws IOException {
    if (tis != null) {
      tis.close();
    }
    if (tisNoIndex != null) {
      tisNoIndex.close();
    }
    if (cfsReader != null) {
      cfsReader.close();
    }
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552207/fstmerge_var2_8846246913883249355

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552235/fstmerge_var1_4065510413989633509
@Override
    public Comparator<BytesRef> getComparator() {
      // Pre-flex indexes always sorted in UTF16 order, but
      // we remap on-the-fly to unicode order
      if (sortTermsByUnicode()) {
        return BytesRef.getUTF8SortedAsUnicodeComparator();
      } else {
        return BytesRef.getUTF8SortedAsUTF16Comparator();
      }
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552235/fstmerge_base_3332352164698477856
@Override
    public Comparator<BytesRef> getComparator() {
      // Pre-flex indexes always sorted in UTF16 order, but
      // we remap on-the-fly to unicode order
      return BytesRef.getUTF8SortedAsUnicodeComparator();
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552235/fstmerge_var2_8871436622204198786

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552240/fstmerge_var1_3800862584732672937
void reset(FieldInfo fieldInfo) throws IOException {
      //System.out.println("pff.reset te=" + termEnum);
      this.fieldInfo = fieldInfo;
      protoTerm = new Term(fieldInfo.name);
      if (termEnum == null) {
        termEnum = getTermsDict().terms(protoTerm);
        seekTermEnum = getTermsDict().terms(protoTerm);
        //System.out.println("  term=" + termEnum.term());
      } else {
        getTermsDict().seekEnum(termEnum, protoTerm);
      }
      skipNext = true;

      unicodeSortOrder = sortTermsByUnicode();

      final Term t = termEnum.term();
      if (t != null && t.field() == fieldInfo.name) {
        newSuffixStart = 0;
        prevTerm.length = 0;
        surrogateDance();
      }
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552240/fstmerge_base_798351267223676542
void reset(FieldInfo fieldInfo) throws IOException {
      this.fieldInfo = fieldInfo;
      protoTerm = new Term(fieldInfo.name);
      if (termEnum == null) {
        termEnum = getTermsDict().terms(protoTerm);
        seekTermEnum = getTermsDict().terms(protoTerm);
      } else {
        getTermsDict().seekEnum(termEnum, protoTerm);
      }
      skipNext = true;
      
      surrogateSeekUpto = 0;
      newSuffixStart = 0;

      surrogatesDance();
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552240/fstmerge_var2_5408887335946375279

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552244/fstmerge_var1_8962085036939202055
@Override
    public Comparator<BytesRef> getComparator() {
      // Pre-flex indexes always sorted in UTF16 order, but
      // we remap on-the-fly to unicode order
      if (unicodeSortOrder) {
        return BytesRef.getUTF8SortedAsUnicodeComparator();
      } else {
        return BytesRef.getUTF8SortedAsUTF16Comparator();
      }
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552244/fstmerge_base_560831634303411680
@Override
    public Comparator<BytesRef> getComparator() {
      // Pre-flex indexes always sorted in UTF16 order, but
      // we remap on-the-fly to unicode order
      return BytesRef.getUTF8SortedAsUnicodeComparator();
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552244/fstmerge_var2_2350882935230415848

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552257/fstmerge_var1_2268568351166648688
@Override
    public SeekStatus seek(BytesRef term, boolean useCache) throws IOException {
      if (DEBUG_SURROGATES) {
        System.out.println("TE.seek target=" + UnicodeUtil.toHexString(term.utf8ToString()));
      }
      skipNext = false;
      final TermInfosReader tis = getTermsDict();
      final Term t0 = protoTerm.createTerm(term);

      assert termEnum != null;

      tis.seekEnum(termEnum, t0);

      final Term t = termEnum.term();

      if (t != null && t.field() == fieldInfo.name && term.bytesEquals(t.bytes())) {
        // If we found an exact match, no need to do the
        // surrogate dance
        if (DEBUG_SURROGATES) {
          System.out.println("  seek exact match");
        }
        current = t.bytes();
        return SeekStatus.FOUND;
      } else if (t == null || t.field() != fieldInfo.name) {

        // TODO: maybe we can handle this like the next()
        // into null?  set term as prevTerm then dance?

        if (DEBUG_SURROGATES) {
          System.out.println("  seek hit EOF");
        }

        // We hit EOF; try end-case surrogate dance: if we
        // find an E, try swapping in S, backwards:
        scratchTerm.copy(term);

        assert scratchTerm.offset == 0;

        for(int i=scratchTerm.length-1;i>=0;i--) {
          if (isHighBMPChar(scratchTerm.bytes, i)) {
            if (DEBUG_SURROGATES) {
              System.out.println("    found E pos=" + i + "; try seek");
            }

            if (seekToNonBMP(seekTermEnum, scratchTerm, i)) {

              scratchTerm.copy(seekTermEnum.term().bytes());
              getTermsDict().seekEnum(termEnum, seekTermEnum.term());

              newSuffixStart = 1+i;

              doPushes();

              // Found a match
              // TODO: faster seek?
              current = termEnum.term().bytes();
              return SeekStatus.NOT_FOUND;
            }
          }
        }
        
        if (DEBUG_SURROGATES) {
          System.out.println("  seek END");
        }

        current = null;
        return SeekStatus.END;
      } else {

        // We found a non-exact but non-null term; this one
        // is fun -- just treat it like next, by pretending
        // requested term was prev:
        prevTerm.copy(term);

        if (DEBUG_SURROGATES) {
          System.out.println("  seek hit non-exact term=" + UnicodeUtil.toHexString(t.text()));
        }

        final BytesRef br = t.bytes();
        assert br.offset == 0;

        setNewSuffixStart(term, br);

        surrogateDance();

        final Term t2 = termEnum.term();
        if (t2 == null || t2.field() != fieldInfo.name) {
          assert t2 == null || !t2.field().equals(fieldInfo.name); // make sure fields are in fact interned
          current = null;
          return SeekStatus.END;
        } else {
          current = t2.bytes();
          assert !unicodeSortOrder || term.compareTo(current) < 0 : "term=" + UnicodeUtil.toHexString(term.utf8ToString()) + " vs current=" + UnicodeUtil.toHexString(current.utf8ToString());
          return SeekStatus.NOT_FOUND;
        }
      }
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552257/fstmerge_base_6963561471347765022
@Override
    public SeekStatus seek(BytesRef term, boolean useCache) throws IOException {
      if (DEBUG_SURROGATES) {
        System.out.println("TE.seek() term=" + term.utf8ToString());
      }
      skipNext = false;
      final TermInfosReader tis = getTermsDict();
      final Term t0 = protoTerm.createTerm(term);

      assert termEnum != null;

      if (termEnum == null) {
        termEnum = tis.terms(t0);
      } else {
        tis.seekEnum(termEnum, t0);
      }

      surrogateSeekUpto = 0;
      surrogatesDance();

      final Term t = termEnum.term();

      final BytesRef tr = t == null ? null : t.bytes();

      if (t != null && t.field() == fieldInfo.name && term.bytesEquals(tr)) {
        current = tr;
        return SeekStatus.FOUND;
      } else if (t == null || t.field() != fieldInfo.name) {
        current = null;
        return SeekStatus.END;
      } else {
        current = tr;
        return SeekStatus.NOT_FOUND;
      }
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552257/fstmerge_var2_2903693967712579677

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552262/fstmerge_var1_3241737781010369883
@Override
    public BytesRef next() throws IOException {
      if (DEBUG_SURROGATES) {
        System.out.println("TE.next()");
      }
      if (skipNext) {
        if (DEBUG_SURROGATES) {
          System.out.println("  skipNext=true");
        }
        skipNext = false;
        if (termEnum.term() == null) {
          return null;
        } else if (termEnum.term().field() != fieldInfo.name) {
          return null;
        } else {
          return current = termEnum.term().bytes();
        }
      }

      // TODO: can we use STE's prevBuffer here?
      prevTerm.copy(termEnum.term().bytes());

      if (termEnum.next() && termEnum.term().field() == fieldInfo.name) {
        newSuffixStart = termEnum.newSuffixStart;
        if (DEBUG_SURROGATES) {
          System.out.println("  newSuffixStart=" + newSuffixStart);
        }
        surrogateDance();
        final Term t = termEnum.term();
        if (t == null || t.field() != fieldInfo.name) {
          assert t == null || !t.field().equals(fieldInfo.name); // make sure fields are in fact interned
          current = null;
        } else {
          current = t.bytes();
        }
        return current;
      } else {
        // This field is exhausted, but we have to give
        // surrogateDance a chance to seek back:
        if (DEBUG_SURROGATES) {
          System.out.println("  force cont");
        }
        //newSuffixStart = prevTerm.length;
        newSuffixStart = 0;
        surrogateDance();
        
        final Term t = termEnum.term();
        if (t == null || t.field() != fieldInfo.name) {
          assert t == null || !t.field().equals(fieldInfo.name); // make sure fields are in fact interned
          return null;
        } else {
          current = t.bytes();
          return current;
        }
      }
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552262/fstmerge_base_2082510630805125323
@Override
    public BytesRef next() throws IOException {
      if (DEBUG_SURROGATES) {
        System.out.println("TE.next() skipNext=" + skipNext);
      }
      if (skipNext) {
        skipNext = false;
        if (termEnum.term() == null) {
          return null;
        } else {
          return current = termEnum.term().bytes();
        }
      }
      if (termEnum.next() && termEnum.term().field() == fieldInfo.name) {
        newSuffixStart = termEnum.newSuffixStart;
        if (DEBUG_SURROGATES) {
          System.out.println("  set newSuffixStart=" + newSuffixStart);
        }
        surrogatesDance();
        final Term t = termEnum.term();
        if (t == null || t.field() != fieldInfo.name) {
          assert t == null || !t.field().equals(fieldInfo.name); // make sure fields are in fact interned
          current = null;
        } else {
          current = t.bytes();
        }
        return current;
      } else {
        if (DEBUG_SURROGATES) {
          System.out.println("  force pop");
        }
        // force pop
        newSuffixStart = -1;
        surrogatesDance();
        final Term t = termEnum.term();
        if (t == null || t.field() != fieldInfo.name) {
          assert t == null || !t.field().equals(fieldInfo.name); // make sure fields are in fact interned
          return null;
        } else {
          current = t.bytes();
          return current;
        }
      }
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552262/fstmerge_var2_1927231532716461370

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552275/fstmerge_var1_7576173029403094256
@Override
    public DocsEnum docs(Bits skipDocs, DocsEnum reuse) throws IOException {
      PreDocsEnum docsEnum;
      if (reuse == null || !(reuse instanceof PreDocsEnum)) {
        docsEnum = new PreDocsEnum();
      } else {
        docsEnum = (PreDocsEnum) reuse;
        if (docsEnum.getFreqStream() != freqStream) {
          docsEnum = new PreDocsEnum();
        }
      }
      return docsEnum.reset(termEnum, skipDocs);
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552275/fstmerge_base_8762463723208673076
@Override
    public DocsEnum docs(Bits skipDocs, DocsEnum reuse) throws IOException {
      if (reuse != null) {
        return ((PreDocsEnum) reuse).reset(termEnum, skipDocs);        
      } else {
        return (new PreDocsEnum()).reset(termEnum, skipDocs);
      }
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552275/fstmerge_var2_220332020242958524

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552279/fstmerge_var1_3967773333420689633
@Override
    public DocsAndPositionsEnum docsAndPositions(Bits skipDocs, DocsAndPositionsEnum reuse) throws IOException {
      PreDocsAndPositionsEnum docsPosEnum;
      if (fieldInfo.omitTermFreqAndPositions) {
        return null;
      } else if (reuse == null || !(reuse instanceof PreDocsAndPositionsEnum)) {
        docsPosEnum = new PreDocsAndPositionsEnum();
      } else {
        docsPosEnum = (PreDocsAndPositionsEnum) reuse;
        if (docsPosEnum.getFreqStream() != freqStream) {
          docsPosEnum = new PreDocsAndPositionsEnum();
        }
      }
      return docsPosEnum.reset(termEnum, skipDocs);        
    }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552279/fstmerge_base_2543864752512378863
@Override
    public DocsAndPositionsEnum docsAndPositions(Bits skipDocs, DocsAndPositionsEnum reuse) throws IOException {
      if (reuse != null) {
        return ((PreDocsAndPositionsEnum) reuse).reset(termEnum, skipDocs);        
      } else {
        return (new PreDocsAndPositionsEnum()).reset(termEnum, skipDocs);
      }
    }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552279/fstmerge_var2_7858864268096541772

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
Conflict type: ModifierList
Conflict body: 
~~FSTMerge~~ @Deprecated
public ##FSTMerge## @Deprecated ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ public int docFreq = 0; ##FSTMerge## int docFreq = 0; ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ public long freqPointer = 0; ##FSTMerge## long freqPointer = 0; ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ public long proxPointer = 0; ##FSTMerge## long proxPointer = 0; ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
~~FSTMerge~~ public int skipOffset; ##FSTMerge## int skipOffset; ##FSTMerge##
File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552348/fstmerge_var1_659872096737634403
public TermInfo() {}
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552348/fstmerge_base_8708775627035094625
TermInfo() {}
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552348/fstmerge_var2_3662897061661240316

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552353/fstmerge_var1_4177090036280914760
public TermInfo(int df, long fp, long pp) {
    docFreq = df;
    freqPointer = fp;
    proxPointer = pp;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552353/fstmerge_base_1840088699322394886
TermInfo(int df, long fp, long pp) {
    docFreq = df;
    freqPointer = fp;
    proxPointer = pp;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552353/fstmerge_var2_3253235069449393099

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552357/fstmerge_var1_6908011658449630241
public TermInfo(TermInfo ti) {
    docFreq = ti.docFreq;
    freqPointer = ti.freqPointer;
    proxPointer = ti.proxPointer;
    skipOffset = ti.skipOffset;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552357/fstmerge_base_2472940575124442976
TermInfo(TermInfo ti) {
    docFreq = ti.docFreq;
    freqPointer = ti.freqPointer;
    proxPointer = ti.proxPointer;
    skipOffset = ti.skipOffset;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552357/fstmerge_var2_666424161228030676

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552361/fstmerge_var1_1335522367365906790
public final void set(int docFreq,
                 long freqPointer, long proxPointer, int skipOffset) {
    this.docFreq = docFreq;
    this.freqPointer = freqPointer;
    this.proxPointer = proxPointer;
    this.skipOffset = skipOffset;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552361/fstmerge_base_2276453634266743343
final void set(int docFreq,
                 long freqPointer, long proxPointer, int skipOffset) {
    this.docFreq = docFreq;
    this.freqPointer = freqPointer;
    this.proxPointer = proxPointer;
    this.skipOffset = skipOffset;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552361/fstmerge_var2_2730619521862336049

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552366/fstmerge_var1_970592569848617332
public final void set(TermInfo ti) {
    docFreq = ti.docFreq;
    freqPointer = ti.freqPointer;
    proxPointer = ti.proxPointer;
    skipOffset = ti.skipOffset;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552366/fstmerge_base_3032390861986859164
final void set(TermInfo ti) {
    docFreq = ti.docFreq;
    freqPointer = ti.freqPointer;
    proxPointer = ti.proxPointer;
    skipOffset = ti.skipOffset;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583552366/fstmerge_var2_1238492914715305457

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfo.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583563973/fstmerge_var1_4602090903292600889
public void assertAgainstRAMDirectory() throws Exception {
    StringBuilder fooField = new StringBuilder();
    StringBuilder termField = new StringBuilder();
 
    // add up to 250 terms to field "foo"
    final int numFooTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());
    for (int i = 0; i < numFooTerms; i++) {
      fooField.append(" ");
      fooField.append(randomTerm());
    }

    // add up to 250 terms to field "term"
    final int numTermTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());
    for (int i = 0; i < numTermTerms; i++) {
      termField.append(" ");
      termField.append(randomTerm());
    }
    
    RAMDirectory ramdir = new RAMDirectory();
    Analyzer analyzer = randomAnalyzer();
    IndexWriter writer = new IndexWriter(ramdir,
                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
    Document doc = new Document();
    Field field1 = new Field("foo", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);
    Field field2 = new Field("term", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field1);
    doc.add(field2);
    writer.addDocument(doc);
    writer.close();
    
    MemoryIndex memory = new MemoryIndex();
    memory.addField("foo", fooField.toString(), analyzer);
    memory.addField("term", termField.toString(), analyzer);
    assertAllQueries(memory, ramdir, analyzer);  
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583563973/fstmerge_base_9192198224209613050
public void assertAgainstRAMDirectory() throws Exception {
    StringBuilder fooField = new StringBuilder();
    StringBuilder termField = new StringBuilder();
 
    // add up to 250 terms to field "foo"
    final int numFooTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());
    for (int i = 0; i < numFooTerms; i++) {
      fooField.append(" ");
      fooField.append(randomTerm());
    }

    // add up to 250 terms to field "term"
    final int numTermTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());
    for (int i = 0; i < numTermTerms; i++) {
      termField.append(" ");
      termField.append(randomTerm());
    }
    
    RAMDirectory ramdir = new RAMDirectory();
    Analyzer analyzer = randomAnalyzer();
    IndexWriter writer = new IndexWriter(ramdir, analyzer,
        IndexWriter.MaxFieldLength.UNLIMITED);
    Document doc = new Document();
    Field field1 = new Field("foo", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);
    Field field2 = new Field("term", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);
    doc.add(field1);
    doc.add(field2);
    writer.addDocument(doc);
    writer.close();
    
    MemoryIndex memory = new MemoryIndex();
    memory.addField("foo", fooField.toString(), analyzer);
    memory.addField("term", termField.toString(), analyzer);
    assertAllQueries(memory, ramdir, analyzer);  
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583563973/fstmerge_var2_2014707774657588298

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583570031/fstmerge_var1_2186561486000175749
public SimpleQQParser(String qqNames[], String indexField) {
    this.qqNames = qqNames;
    this.indexField = indexField;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583570031/fstmerge_base_2320156731141497187
public SimpleQQParser(String qqName, String indexField) {
    this(new String[] { qqName }, indexField);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583570031/fstmerge_var2_8569263285345232110

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/utils/SimpleQQParser.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572350/fstmerge_var1_6352761616234204434
@Override
	protected void setUp() throws Exception {
    super.setUp();
		directory = new RAMDirectory();
		RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
		
		//Add series of docs with filterable fields : url, text and dates  flags
		addDoc(writer, "http://lucene.apache.org", "lucene 1.4.3 available", "20040101");
		addDoc(writer, "http://lucene.apache.org", "New release pending", "20040102");
		addDoc(writer, "http://lucene.apache.org", "Lucene 1.9 out now", "20050101");		
		addDoc(writer, "http://www.bar.com", "Local man bites dog", "20040101");
		addDoc(writer, "http://www.bar.com", "Dog bites local man", "20040102");
		addDoc(writer, "http://www.bar.com", "Dog uses Lucene", "20050101");
		addDoc(writer, "http://lucene.apache.org", "Lucene 2.0 out", "20050101");
		addDoc(writer, "http://lucene.apache.org", "Oops. Lucene 2.1 out", "20050102");

                // Until we fix LUCENE-2348, the index must
                // have only 1 segment:
                writer.optimize();

		reader = writer.getReader();
		writer.close();			
		searcher =new IndexSearcher(reader);
		
	}
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572350/fstmerge_base_8949487483123035163
@Override
	protected void setUp() throws Exception {
    super.setUp();
		directory = new RAMDirectory();
		RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
		    new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
		
		//Add series of docs with filterable fields : url, text and dates  flags
		addDoc(writer, "http://lucene.apache.org", "lucene 1.4.3 available", "20040101");
		addDoc(writer, "http://lucene.apache.org", "New release pending", "20040102");
		addDoc(writer, "http://lucene.apache.org", "Lucene 1.9 out now", "20050101");		
		addDoc(writer, "http://www.bar.com", "Local man bites dog", "20040101");
		addDoc(writer, "http://www.bar.com", "Dog bites local man", "20040102");
		addDoc(writer, "http://www.bar.com", "Dog uses Lucene", "20050101");
		addDoc(writer, "http://lucene.apache.org", "Lucene 2.0 out", "20050101");
		addDoc(writer, "http://lucene.apache.org", "Oops. Lucene 2.1 out", "20050102");

                // Until we fix LUCENE-2348, the index must
                // have only 1 segment:
                writer.optimize();

		reader = writer.getReader();
		writer.close();			
		searcher =new IndexSearcher(reader);
		
	}
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572350/fstmerge_var2_150714950438948474

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/contrib/queries/src/test/org/apache/lucene/search/DuplicateFilterTest.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572384/fstmerge_var1_298634172509816995
@Override
	protected void setUp() throws Exception	{
	  super.setUp();
		directory = new RAMDirectory();
		RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
		
		//Add series of docs with misspelt names
		addDoc(writer, "jonathon smythe","1");
		addDoc(writer, "jonathan smith","2");
		addDoc(writer, "johnathon smyth","3");
		addDoc(writer, "johnny smith","4" );
		addDoc(writer, "jonny smith","5" );
		addDoc(writer, "johnathon smythe","6");
		reader = writer.getReader();
		writer.close();
		searcher=new IndexSearcher(reader);			
	}
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572384/fstmerge_base_1632247935434857254
@Override
	protected void setUp() throws Exception	{
	  super.setUp();
		directory = new RAMDirectory();
		RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
		    new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
		
		//Add series of docs with misspelt names
		addDoc(writer, "jonathon smythe","1");
		addDoc(writer, "jonathan smith","2");
		addDoc(writer, "johnathon smyth","3");
		addDoc(writer, "johnny smith","4" );
		addDoc(writer, "jonny smith","5" );
		addDoc(writer, "johnathon smythe","6");
		reader = writer.getReader();
		writer.close();
		searcher=new IndexSearcher(reader);			
	}
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572384/fstmerge_var2_7073050563483733364

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/contrib/queries/src/test/org/apache/lucene/search/FuzzyLikeThisQueryTest.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572416/fstmerge_var1_8694525512257813534
public void testMissingTerms() throws Exception {
		String fieldName="field1";
		RAMDirectory rd=new RAMDirectory();
		RandomIndexWriter w = new RandomIndexWriter(newRandom(), rd);
		for (int i = 0; i < 100; i++) {
			Document doc=new Document();
			int term=i*10; //terms are units of 10;
			doc.add(new Field(fieldName,""+term,Field.Store.YES,Field.Index.NOT_ANALYZED));
			w.addDocument(doc);			
		}
		IndexReader reader = w.getReader();
		w.close();
		
		TermsFilter tf=new TermsFilter();
		tf.addTerm(new Term(fieldName,"19"));
		OpenBitSet bits = (OpenBitSet)tf.getDocIdSet(reader);
		assertEquals("Must match nothing", 0, bits.cardinality());

		tf.addTerm(new Term(fieldName,"20"));
		bits = (OpenBitSet)tf.getDocIdSet(reader);
		assertEquals("Must match 1", 1, bits.cardinality());
		
		tf.addTerm(new Term(fieldName,"10"));
		bits = (OpenBitSet)tf.getDocIdSet(reader);
		assertEquals("Must match 2", 2, bits.cardinality());
		
		tf.addTerm(new Term(fieldName,"00"));
		bits = (OpenBitSet)tf.getDocIdSet(reader);
		assertEquals("Must match 2", 2, bits.cardinality());
		
		reader.close();
		rd.close();
	}
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572416/fstmerge_base_8953960138296915011
public void testMissingTerms() throws Exception {
		String fieldName="field1";
		RAMDirectory rd=new RAMDirectory();
		RandomIndexWriter w = new RandomIndexWriter(newRandom(), rd, 
		    new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
		for (int i = 0; i < 100; i++) {
			Document doc=new Document();
			int term=i*10; //terms are units of 10;
			doc.add(new Field(fieldName,""+term,Field.Store.YES,Field.Index.NOT_ANALYZED));
			w.addDocument(doc);			
		}
		IndexReader reader = w.getReader();
		w.close();
		
		TermsFilter tf=new TermsFilter();
		tf.addTerm(new Term(fieldName,"19"));
		OpenBitSet bits = (OpenBitSet)tf.getDocIdSet(reader);
		assertEquals("Must match nothing", 0, bits.cardinality());

		tf.addTerm(new Term(fieldName,"20"));
		bits = (OpenBitSet)tf.getDocIdSet(reader);
		assertEquals("Must match 1", 1, bits.cardinality());
		
		tf.addTerm(new Term(fieldName,"10"));
		bits = (OpenBitSet)tf.getDocIdSet(reader);
		assertEquals("Must match 2", 2, bits.cardinality());
		
		tf.addTerm(new Term(fieldName,"00"));
		bits = (OpenBitSet)tf.getDocIdSet(reader);
		assertEquals("Must match 2", 2, bits.cardinality());
		
		reader.close();
		rd.close();
	}
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572416/fstmerge_var2_2386745986418068098

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572421/fstmerge_var1_332899494815647070
@Override
	protected void setUp() throws Exception {
	  super.setUp();
		directory = new RAMDirectory();
		RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, new MockAnalyzer(MockTokenizer.WHITESPACE, false));
		
		//Add series of docs with filterable fields : acces rights, prices, dates and "in-stock" flags
		addDoc(writer, "admin guest", "010", "20040101","Y");
		addDoc(writer, "guest", "020", "20040101","Y");
		addDoc(writer, "guest", "020", "20050101","Y");
		addDoc(writer, "admin", "020", "20050101","Maybe");
		addDoc(writer, "admin guest", "030", "20050101","N");
		reader = writer.getReader();
		writer.close();	
	}
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572421/fstmerge_base_3438907157280481315
@Override
	protected void setUp() throws Exception {
	  super.setUp();
		directory = new RAMDirectory();
		RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, new IndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
		
		//Add series of docs with filterable fields : acces rights, prices, dates and "in-stock" flags
		addDoc(writer, "admin guest", "010", "20040101","Y");
		addDoc(writer, "guest", "020", "20040101","Y");
		addDoc(writer, "guest", "020", "20050101","Y");
		addDoc(writer, "admin", "020", "20050101","Maybe");
		addDoc(writer, "admin guest", "030", "20050101","N");
		reader = writer.getReader();
		writer.close();	
	}
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572421/fstmerge_var2_1455989193186672927

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/contrib/queries/src/test/org/apache/lucene/search/BooleanFilterTest.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572492/fstmerge_var1_5134647518633277180
@Override
  protected void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
    Calendar cal = new GregorianCalendar();
    cal.clear();
    cal.setTimeInMillis(1041397200000L); // 2003 January 01

    for (int i = 0; i < MAX; i++) {
      Document doc = new Document();
      doc.add(new Field("key", "" + (i + 1), Field.Store.YES, Field.Index.NOT_ANALYZED));
      doc.add(new Field("owner", (i < MAX / 2) ? "bob" : "sue", Field.Store.YES, Field.Index.NOT_ANALYZED));
      doc.add(new Field("date", cal.getTime().toString(), Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);

      cal.add(Calendar.DATE, 1);
    }
    reader = writer.getReader();
    writer.close();

    searcher = new IndexSearcher(reader);

    // query for everything to make life easier
    BooleanQuery bq = new BooleanQuery();
    bq.add(new TermQuery(new Term("owner", "bob")), BooleanClause.Occur.SHOULD);
    bq.add(new TermQuery(new Term("owner", "sue")), BooleanClause.Occur.SHOULD);
    query = bq;

    // date filter matches everything too
    //Date pastTheEnd = parseDate("2099 Jan 1");
    // dateFilter = DateFilter.Before("date", pastTheEnd);
    // just treat dates as strings and select the whole range for now...
    dateFilter = new TermRangeFilter("date","","ZZZZ",true,true);

    bobFilter = new QueryWrapperFilter(
        new TermQuery(new Term("owner", "bob")));
    sueFilter = new QueryWrapperFilter(
        new TermQuery(new Term("owner", "sue")));
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572492/fstmerge_base_3040715968212129932
@Override
  protected void setUp() throws Exception {
    super.setUp();
    random = newRandom();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));

    Calendar cal = new GregorianCalendar();
    cal.clear();
    cal.setTimeInMillis(1041397200000L); // 2003 January 01

    for (int i = 0; i < MAX; i++) {
      Document doc = new Document();
      doc.add(new Field("key", "" + (i + 1), Field.Store.YES, Field.Index.NOT_ANALYZED));
      doc.add(new Field("owner", (i < MAX / 2) ? "bob" : "sue", Field.Store.YES, Field.Index.NOT_ANALYZED));
      doc.add(new Field("date", cal.getTime().toString(), Field.Store.YES, Field.Index.NOT_ANALYZED));
      writer.addDocument(doc);

      cal.add(Calendar.DATE, 1);
    }
    reader = writer.getReader();
    writer.close();

    searcher = new IndexSearcher(reader);

    // query for everything to make life easier
    BooleanQuery bq = new BooleanQuery();
    bq.add(new TermQuery(new Term("owner", "bob")), BooleanClause.Occur.SHOULD);
    bq.add(new TermQuery(new Term("owner", "sue")), BooleanClause.Occur.SHOULD);
    query = bq;

    // date filter matches everything too
    //Date pastTheEnd = parseDate("2099 Jan 1");
    // dateFilter = DateFilter.Before("date", pastTheEnd);
    // just treat dates as strings and select the whole range for now...
    dateFilter = new TermRangeFilter("date","","ZZZZ",true,true);

    bobFilter = new QueryWrapperFilter(
        new TermQuery(new Term("owner", "bob")));
    sueFilter = new QueryWrapperFilter(
        new TermQuery(new Term("owner", "sue")));
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572492/fstmerge_var2_7544579911795633885

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/contrib/queries/src/test/org/apache/lucene/search/ChainedFilterTest.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572535/fstmerge_var1_3853080564954465776
public void testWithCachingFilter() throws Exception {
    Directory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
    IndexReader reader = writer.getReader();
    writer.close();
  
    Searcher searcher = new IndexSearcher(reader);
  
    Query query = new TermQuery(new Term("none", "none"));
  
    QueryWrapperFilter queryFilter = new QueryWrapperFilter(query);
    CachingWrapperFilter cachingFilter = new CachingWrapperFilter(queryFilter);
  
    searcher.search(query, cachingFilter, 1);
  
    CachingWrapperFilter cachingFilter2 = new CachingWrapperFilter(queryFilter);
    Filter[] chain = new Filter[2];
    chain[0] = cachingFilter;
    chain[1] = cachingFilter2;
    ChainedFilter cf = new ChainedFilter(chain);
  
    // throws java.lang.ClassCastException: org.apache.lucene.util.OpenBitSet cannot be cast to java.util.BitSet
    searcher.search(new MatchAllDocsQuery(), cf, 1);
    searcher.close();
    reader.close();
    dir.close();
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572535/fstmerge_base_3341141457864850147
public void testWithCachingFilter() throws Exception {
    Directory dir = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(random, dir, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    IndexReader reader = writer.getReader();
    writer.close();
  
    Searcher searcher = new IndexSearcher(reader);
  
    Query query = new TermQuery(new Term("none", "none"));
  
    QueryWrapperFilter queryFilter = new QueryWrapperFilter(query);
    CachingWrapperFilter cachingFilter = new CachingWrapperFilter(queryFilter);
  
    searcher.search(query, cachingFilter, 1);
  
    CachingWrapperFilter cachingFilter2 = new CachingWrapperFilter(queryFilter);
    Filter[] chain = new Filter[2];
    chain[0] = cachingFilter;
    chain[1] = cachingFilter2;
    ChainedFilter cf = new ChainedFilter(chain);
  
    // throws java.lang.ClassCastException: org.apache.lucene.util.OpenBitSet cannot be cast to java.util.BitSet
    searcher.search(new MatchAllDocsQuery(), cf, 1);
    searcher.close();
    reader.close();
    dir.close();
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572535/fstmerge_var2_2520119871413273959

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/contrib/queries/src/test/org/apache/lucene/search/ChainedFilterTest.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572556/fstmerge_var1_7064140500975028269
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    Document doc = new Document();
    doc.add(new Field(FN, "the quick brown fox jumps over the lazy dog", Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572556/fstmerge_base_2158864401553312939
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    Document doc = new Document();
    doc.add(new Field(FN, "the quick brown fox jumps over the lazy dog", Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572556/fstmerge_var2_541435150252955885

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestRegexQuery.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572642/fstmerge_var1_7376895012035803670
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory);
    
    // Add series of docs with specific information for MoreLikeThis
    addDoc(writer, "lucene");
    addDoc(writer, "lucene release");

    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572642/fstmerge_base_4558579093899031259
@Override
  protected void setUp() throws Exception {
    super.setUp();
    directory = new RAMDirectory();
    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), directory, 
        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
    
    // Add series of docs with specific information for MoreLikeThis
    addDoc(writer, "lucene");
    addDoc(writer, "lucene release");

    reader = writer.getReader();
    writer.close();
    searcher = new IndexSearcher(reader);
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583572642/fstmerge_var2_6640079527111641036

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/lucene/contrib/queries/src/test/org/apache/lucene/search/similar/TestMoreLikeThis.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583603800/fstmerge_var1_5263218190834479610
public void write(byte b[]) throws IOException {
    write(b,0,b.length);
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583603800/fstmerge_base_3254335244880482255
public void write(byte b) throws IOException {
    if (pos >= buf.length) {
      out.write(buf);
      written += pos;
      pos=0;
    }
    buf[pos++] = b;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583603800/fstmerge_var2_1820080859365485949

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/solr/src/common/org/apache/solr/common/util/FastOutputStream.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583617017/fstmerge_var1_8257367799005889932
public long hash1(char c) {
    final long p = 1099511628211L;
    long hash = 0xcbf29ce484222325L;
    hash = (hash ^ (c & 0x00FF)) * p;
    hash = (hash ^ (c >> 8)) * p;
    hash += hash << 13;
    hash ^= hash >> 7;
    hash += hash << 3;
    hash ^= hash >> 17;
    hash += hash << 5;
    return hash;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583617017/fstmerge_base_7957033695953001467
public long hash1(char carray[]) {
    final long p = 1099511628211L;
    long hash = 0xcbf29ce484222325L;
    for (int i = 0; i < carray.length; i++) {
      char d = carray[i];
      hash = (hash ^ (d & 0x00FF)) * p;
      hash = (hash ^ (d >> 8)) * p;
    }

    // hash += hash << 13;
    // hash ^= hash >> 7;
    // hash += hash << 3;
    // hash ^= hash >> 17;
    // hash += hash << 5;
    return hash;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583617017/fstmerge_var2_8570015147886267708

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/modules/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/AbstractDictionary.java
Conflict type: LineBasedMCFd
Conflict body: 
<<<<<<< /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583617024/fstmerge_var1_5518669737889700451
public int hash2(char c) {
    int hash = 5381;

    /* hash 33 + c */
    hash = ((hash << 5) + hash) + c & 0x00FF;
    hash = ((hash << 5) + hash) + c >> 8;

    return hash;
  }
||||||| /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583617024/fstmerge_base_1671124785680576996
public int hash2(char carray[]) {
    int hash = 5381;

    /* hash 33 + c */
    for (int i = 0; i < carray.length; i++) {
      char d = carray[i];
      hash = ((hash << 5) + hash) + d & 0x00FF;
      hash = ((hash << 5) + hash) + d >> 8;
    }

    return hash;
  }
=======
>>>>>>> /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/conflictsAnalyzer/fstmerge_tmp1420583617024/fstmerge_var2_7958951478432918109

File path: /media/ines/b9d638e1-93ee-435a-af41-80d544917e00/gitClones/conflictsStudy/downloads/lucene-solr/revisions/rev_a5bc3_586e4/rev_a5bc3-586e4/modules/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/AbstractDictionary.java

=========================================================